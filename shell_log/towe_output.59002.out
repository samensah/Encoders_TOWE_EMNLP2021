	Python3 anaconda is now loaded in your environment.

	CUDA-10.2 loaded

	GCC 9.1.0 environment now loaded

	CUDA-10.2 loaded

	Python3 Pytorch for CUDA-10.2 is now loaded in your environment.

loading vocab and embedding matrix from ../data/14lap
size of vocab: 3463
shape of loaded embedding matrix: (3463, 300)
Generating mappings
Loading data from ../data/14lap with batch size 16...
102 batches created for ../data/14lap/train.json
31 batches created for ../data/14lap/test.json
Building model...
1416933
[1] train_loss: 20.3794
[1] train_loss: 14.1195
[1] train_loss: 11.3632
[1] train_loss: 9.8607
[1] train_loss: 8.8626
[1] train_loss: 8.2008
[1] train_loss: 7.8081
[1] train_loss: 7.5530
[1] train_loss: 7.3366
[1] train_loss: 7.1702
3.4768593311309814

Evaluating...Epoch: 1
Prec: 1.0000, Recall: 0.0106, F1: 0.0209
model saved to random1_layers0_14lap/best_model.pt
New best model saved!

[2] train_loss: 4.5744
[2] train_loss: 4.5901
[2] train_loss: 4.3728
[2] train_loss: 4.2525
[2] train_loss: 4.1324
[2] train_loss: 4.0770
[2] train_loss: 4.1346
[2] train_loss: 4.1956
[2] train_loss: 4.2593
[2] train_loss: 4.3076
1.4546287059783936

Evaluating...Epoch: 2
Prec: 0.7173, Recall: 0.4162, F1: 0.5268
model saved to random1_layers0_14lap/best_model.pt
New best model saved!

[3] train_loss: 3.8688
[3] train_loss: 3.8532
[3] train_loss: 3.6450
[3] train_loss: 3.5678
[3] train_loss: 3.5003
[3] train_loss: 3.4753
[3] train_loss: 3.5495
[3] train_loss: 3.6204
[3] train_loss: 3.7015
[3] train_loss: 3.7326
1.4705703258514404

Evaluating...Epoch: 3
Prec: 0.6335, Recall: 0.6067, F1: 0.6198
model saved to random1_layers0_14lap/best_model.pt
New best model saved!

[4] train_loss: 3.3885
[4] train_loss: 3.3642
[4] train_loss: 3.2256
[4] train_loss: 3.1506
[4] train_loss: 3.1064
[4] train_loss: 3.0494
[4] train_loss: 3.1125
[4] train_loss: 3.1596
[4] train_loss: 3.2325
[4] train_loss: 3.2667
1.4599583148956299

Evaluating...Epoch: 4
Prec: 0.6142, Recall: 0.6543, F1: 0.6336
model saved to random1_layers0_14lap/best_model.pt
New best model saved!

[5] train_loss: 2.9017
[5] train_loss: 3.0001
[5] train_loss: 2.8925
[5] train_loss: 2.8276
[5] train_loss: 2.7645
[5] train_loss: 2.7386
[5] train_loss: 2.8077
[5] train_loss: 2.8589
[5] train_loss: 2.9432
[5] train_loss: 3.0071
1.4599270820617676

Evaluating...Epoch: 5
Prec: 0.6347, Recall: 0.6649, F1: 0.6494
model saved to random1_layers0_14lap/best_model.pt
New best model saved!

[6] train_loss: 2.7618
[6] train_loss: 2.7866
[6] train_loss: 2.6945
[6] train_loss: 2.6550
[6] train_loss: 2.6082
[6] train_loss: 2.5688
[6] train_loss: 2.6279
[6] train_loss: 2.6799
[6] train_loss: 2.7339
[6] train_loss: 2.7825
1.518301248550415

Evaluating...Epoch: 6
Prec: 0.6537, Recall: 0.6790, F1: 0.6661
model saved to random1_layers0_14lap/best_model.pt
New best model saved!

[7] train_loss: 2.5813
[7] train_loss: 2.5397
[7] train_loss: 2.4442
[7] train_loss: 2.3644
[7] train_loss: 2.3268
[7] train_loss: 2.2977
[7] train_loss: 2.3698
[7] train_loss: 2.4160
[7] train_loss: 2.4709
[7] train_loss: 2.5041
1.459937334060669

Evaluating...Epoch: 7
Prec: 0.6590, Recall: 0.7055, F1: 0.6814
model saved to random1_layers0_14lap/best_model.pt
New best model saved!

[8] train_loss: 2.4189
[8] train_loss: 2.3529
[8] train_loss: 2.2097
[8] train_loss: 2.1784
[8] train_loss: 2.1566
[8] train_loss: 2.1257
[8] train_loss: 2.2083
[8] train_loss: 2.2631
[8] train_loss: 2.3235
[8] train_loss: 2.3606
1.4527294635772705

Evaluating...Epoch: 8
Prec: 0.6683, Recall: 0.7284, F1: 0.6970
model saved to random1_layers0_14lap/best_model.pt
New best model saved!

[9] train_loss: 2.1490
[9] train_loss: 2.1673
[9] train_loss: 2.0890
[9] train_loss: 2.0239
[9] train_loss: 2.0062
[9] train_loss: 1.9838
[9] train_loss: 2.0381
[9] train_loss: 2.0774
[9] train_loss: 2.1399
[9] train_loss: 2.1738
1.4530179500579834

Evaluating...Epoch: 9
Prec: 0.6365, Recall: 0.7566, F1: 0.6914

[10] train_loss: 1.9040
[10] train_loss: 2.0009
[10] train_loss: 1.9675
[10] train_loss: 1.8880
[10] train_loss: 1.8953
[10] train_loss: 1.8689
[10] train_loss: 1.9111
[10] train_loss: 1.9503
[10] train_loss: 2.0142
[10] train_loss: 2.0441
1.464442253112793

Evaluating...Epoch: 10
Prec: 0.6840, Recall: 0.7178, F1: 0.7005
model saved to random1_layers0_14lap/best_model.pt
New best model saved!

[11] train_loss: 2.0525
[11] train_loss: 2.0094
[11] train_loss: 1.8698
[11] train_loss: 1.8244
[11] train_loss: 1.8228
[11] train_loss: 1.7977
[11] train_loss: 1.8755
[11] train_loss: 1.9067
[11] train_loss: 1.9649
[11] train_loss: 2.0110
1.5137834548950195

Evaluating...Epoch: 11
Prec: 0.6777, Recall: 0.7231, F1: 0.6997

[12] train_loss: 1.8165
[12] train_loss: 1.7736
[12] train_loss: 1.7361
[12] train_loss: 1.6719
[12] train_loss: 1.7001
[12] train_loss: 1.6781
[12] train_loss: 1.7419
[12] train_loss: 1.7874
[12] train_loss: 1.8387
[12] train_loss: 1.8883
1.456878423690796

Evaluating...Epoch: 12
Prec: 0.6406, Recall: 0.7354, F1: 0.6847

[13] train_loss: 1.7014
[13] train_loss: 1.7452
[13] train_loss: 1.6527
[13] train_loss: 1.6242
[13] train_loss: 1.6122
[13] train_loss: 1.5815
[13] train_loss: 1.6373
[13] train_loss: 1.6844
[13] train_loss: 1.7279
[13] train_loss: 1.7662
1.4631221294403076

Evaluating...Epoch: 13
Prec: 0.6877, Recall: 0.7302, F1: 0.7083
model saved to random1_layers0_14lap/best_model.pt
New best model saved!

[14] train_loss: 1.5088
[14] train_loss: 1.5874
[14] train_loss: 1.5772
[14] train_loss: 1.5149
[14] train_loss: 1.5235
[14] train_loss: 1.5111
[14] train_loss: 1.5652
[14] train_loss: 1.6035
[14] train_loss: 1.6761
[14] train_loss: 1.7043
1.4677295684814453

Evaluating...Epoch: 14
Prec: 0.6609, Recall: 0.7425, F1: 0.6993

[15] train_loss: 1.7421
[15] train_loss: 1.7491
[15] train_loss: 1.6334
[15] train_loss: 1.5336
[15] train_loss: 1.5296
[15] train_loss: 1.5288
[15] train_loss: 1.5812
[15] train_loss: 1.6112
[15] train_loss: 1.6490
[15] train_loss: 1.6639
1.4620332717895508

Evaluating...Epoch: 15
Prec: 0.6993, Recall: 0.7055, F1: 0.7024

[16] train_loss: 1.5055
[16] train_loss: 1.5687
[16] train_loss: 1.5525
[16] train_loss: 1.4710
[16] train_loss: 1.4719
[16] train_loss: 1.4294
[16] train_loss: 1.4819
[16] train_loss: 1.5161
[16] train_loss: 1.5589
[16] train_loss: 1.6012
1.4623236656188965

Evaluating...Epoch: 16
Prec: 0.6940, Recall: 0.6878, F1: 0.6909

[17] train_loss: 1.4711
[17] train_loss: 1.4853
[17] train_loss: 1.4284
[17] train_loss: 1.3531
[17] train_loss: 1.3605
[17] train_loss: 1.3577
[17] train_loss: 1.3726
[17] train_loss: 1.4137
[17] train_loss: 1.4682
[17] train_loss: 1.4952
1.517638921737671

Evaluating...Epoch: 17
Prec: 0.7303, Recall: 0.6878, F1: 0.7084
model saved to random1_layers0_14lap/best_model.pt
New best model saved!

[18] train_loss: 1.4291
[18] train_loss: 1.4068
[18] train_loss: 1.3085
[18] train_loss: 1.2314
[18] train_loss: 1.2604
[18] train_loss: 1.2513
[18] train_loss: 1.3097
[18] train_loss: 1.3225
[18] train_loss: 1.3707
[18] train_loss: 1.3931
1.4639723300933838

Evaluating...Epoch: 18
Prec: 0.6948, Recall: 0.6825, F1: 0.6886

[19] train_loss: 1.1957
[19] train_loss: 1.2206
[19] train_loss: 1.2504
[19] train_loss: 1.1922
[19] train_loss: 1.1846
[19] train_loss: 1.1665
[19] train_loss: 1.1899
[19] train_loss: 1.2263
[19] train_loss: 1.2849
[19] train_loss: 1.3115
1.4580962657928467

Evaluating...Epoch: 19
Prec: 0.7211, Recall: 0.6931, F1: 0.7068

[20] train_loss: 1.2874
[20] train_loss: 1.2223
[20] train_loss: 1.1889
[20] train_loss: 1.1115
[20] train_loss: 1.1269
[20] train_loss: 1.1150
[20] train_loss: 1.1768
[20] train_loss: 1.2007
[20] train_loss: 1.2686
[20] train_loss: 1.3045
1.4633734226226807

Evaluating...Epoch: 20
Prec: 0.6968, Recall: 0.6931, F1: 0.6950

[21] train_loss: 1.0240
[21] train_loss: 1.0802
[21] train_loss: 1.0776
[21] train_loss: 1.0481
[21] train_loss: 1.0515
[21] train_loss: 1.0379
[21] train_loss: 1.0660
[21] train_loss: 1.1056
[21] train_loss: 1.1544
[21] train_loss: 1.1884
1.4622960090637207

Evaluating...Epoch: 21
Prec: 0.7089, Recall: 0.6914, F1: 0.7000

[22] train_loss: 1.1089
[22] train_loss: 1.2385
[22] train_loss: 1.1971
[22] train_loss: 1.0944
[22] train_loss: 1.1224
[22] train_loss: 1.1056
[22] train_loss: 1.1265
[22] train_loss: 1.1682
[22] train_loss: 1.2266
[22] train_loss: 1.2320
1.539595603942871

Evaluating...Epoch: 22
Prec: 0.7026, Recall: 0.6790, F1: 0.6906

[23] train_loss: 1.2178
[23] train_loss: 1.0956
[23] train_loss: 1.0568
[23] train_loss: 1.0145
[23] train_loss: 1.0046
[23] train_loss: 1.0026
[23] train_loss: 1.0212
[23] train_loss: 1.0528
[23] train_loss: 1.0879
[23] train_loss: 1.1121
1.460559368133545

Evaluating...Epoch: 23
Prec: 0.7343, Recall: 0.7019, F1: 0.7178
model saved to random1_layers0_14lap/best_model.pt
New best model saved!

[24] train_loss: 0.9424
[24] train_loss: 0.9158
[24] train_loss: 0.9538
[24] train_loss: 0.8968
[24] train_loss: 0.9238
[24] train_loss: 0.9335
[24] train_loss: 0.9702
[24] train_loss: 0.9913
[24] train_loss: 1.0287
[24] train_loss: 1.0515
1.4755616188049316

Evaluating...Epoch: 24
Prec: 0.7259, Recall: 0.6914, F1: 0.7082

[25] train_loss: 0.9961
[25] train_loss: 0.8848
[25] train_loss: 0.8273
[25] train_loss: 0.8026
[25] train_loss: 0.8215
[25] train_loss: 0.8569
[25] train_loss: 0.8975
[25] train_loss: 0.9517
[25] train_loss: 0.9688
[25] train_loss: 0.9992
1.4590299129486084

Evaluating...Epoch: 25
Prec: 0.7183, Recall: 0.7196, F1: 0.7189
model saved to random1_layers0_14lap/best_model.pt
New best model saved!

[26] train_loss: 1.2416
[26] train_loss: 1.1230
[26] train_loss: 1.0629
[26] train_loss: 0.9588
[26] train_loss: 0.9575
[26] train_loss: 0.9616
[26] train_loss: 0.9892
[26] train_loss: 1.0226
[26] train_loss: 1.0637
[26] train_loss: 1.0837
1.4598407745361328

Evaluating...Epoch: 26
Prec: 0.7286, Recall: 0.6914, F1: 0.7095

[27] train_loss: 1.0282
[27] train_loss: 0.9775
[27] train_loss: 0.9295
[27] train_loss: 0.8981
[27] train_loss: 0.8839
[27] train_loss: 0.8766
[27] train_loss: 0.9071
[27] train_loss: 0.9345
[27] train_loss: 0.9504
[27] train_loss: 0.9708
1.5257763862609863

Evaluating...Epoch: 27
Prec: 0.7592, Recall: 0.6949, F1: 0.7256
model saved to random1_layers0_14lap/best_model.pt
New best model saved!

[28] train_loss: 0.8784
[28] train_loss: 0.9245
[28] train_loss: 0.8817
[28] train_loss: 0.8255
[28] train_loss: 0.7918
[28] train_loss: 0.7990
[28] train_loss: 0.8195
[28] train_loss: 0.8502
[28] train_loss: 0.8674
[28] train_loss: 0.8941
1.4511253833770752

Evaluating...Epoch: 28
Prec: 0.7288, Recall: 0.6966, F1: 0.7124

[29] train_loss: 0.8540
[29] train_loss: 0.8291
[29] train_loss: 0.8330
[29] train_loss: 0.7725
[29] train_loss: 0.7808
[29] train_loss: 0.7680
[29] train_loss: 0.8001
[29] train_loss: 0.8017
[29] train_loss: 0.8361
[29] train_loss: 0.8740
1.4495394229888916

Evaluating...Epoch: 29
Prec: 0.7457, Recall: 0.6931, F1: 0.7185

[30] train_loss: 0.9399
[30] train_loss: 0.8746
[30] train_loss: 0.8583
[30] train_loss: 0.8077
[30] train_loss: 0.7821
[30] train_loss: 0.7737
[30] train_loss: 0.8082
[30] train_loss: 0.8264
[30] train_loss: 0.8560
[30] train_loss: 0.8735
1.4539949893951416

Evaluating...Epoch: 30
Prec: 0.7326, Recall: 0.6861, F1: 0.7086

[31] train_loss: 0.8888
[31] train_loss: 0.8168
[31] train_loss: 0.7595
[31] train_loss: 0.7144
[31] train_loss: 0.7473
[31] train_loss: 0.7447
[31] train_loss: 0.7676
[31] train_loss: 0.7985
[31] train_loss: 0.8258
[31] train_loss: 0.8577
1.4641883373260498

Evaluating...Epoch: 31
Prec: 0.7414, Recall: 0.6878, F1: 0.7136

[32] train_loss: 0.8571
[32] train_loss: 0.7762
[32] train_loss: 0.7691
[32] train_loss: 0.7095
[32] train_loss: 0.7066
[32] train_loss: 0.7335
[32] train_loss: 0.7506
[32] train_loss: 0.7717
[32] train_loss: 0.8007
[32] train_loss: 0.8309
1.5296673774719238

Evaluating...Epoch: 32
Prec: 0.7382, Recall: 0.6914, F1: 0.7140

[33] train_loss: 0.8166
[33] train_loss: 0.7795
[33] train_loss: 0.7586
[33] train_loss: 0.6894
[33] train_loss: 0.7097
[33] train_loss: 0.6909
[33] train_loss: 0.7124
[33] train_loss: 0.7250
[33] train_loss: 0.7489
[33] train_loss: 0.7748
1.4649152755737305

Evaluating...Epoch: 33
Prec: 0.7515, Recall: 0.6825, F1: 0.7153

[34] train_loss: 0.7197
[34] train_loss: 0.7182
[34] train_loss: 0.7323
[34] train_loss: 0.6787
[34] train_loss: 0.6866
[34] train_loss: 0.6605
[34] train_loss: 0.6728
[34] train_loss: 0.6801
[34] train_loss: 0.7097
[34] train_loss: 0.7249
1.456371545791626

Evaluating...Epoch: 34
Prec: 0.7308, Recall: 0.6896, F1: 0.7096

[35] train_loss: 0.6637
[35] train_loss: 0.7400
[35] train_loss: 0.7027
[35] train_loss: 0.6677
[35] train_loss: 0.6687
[35] train_loss: 0.6621
[35] train_loss: 0.6652
[35] train_loss: 0.6897
[35] train_loss: 0.7273
[35] train_loss: 0.7452
1.4414992332458496

Evaluating...Epoch: 35
Prec: 0.7296, Recall: 0.6949, F1: 0.7118

[36] train_loss: 0.7871
[36] train_loss: 0.6408
[36] train_loss: 0.6425
[36] train_loss: 0.6039
[36] train_loss: 0.5965
[36] train_loss: 0.5905
[36] train_loss: 0.6140
[36] train_loss: 0.6282
[36] train_loss: 0.6646
[36] train_loss: 0.6772
1.4539077281951904

Evaluating...Epoch: 36
Prec: 0.7448, Recall: 0.7002, F1: 0.7218

[37] train_loss: 0.6277
[37] train_loss: 0.6756
[37] train_loss: 0.6781
[37] train_loss: 0.6263
[37] train_loss: 0.6042
[37] train_loss: 0.5882
[37] train_loss: 0.6112
[37] train_loss: 0.6464
[37] train_loss: 0.6790
[37] train_loss: 0.6958
1.5238609313964844

Evaluating...Epoch: 37
Prec: 0.7638, Recall: 0.7072, F1: 0.7344
model saved to random1_layers0_14lap/best_model.pt
New best model saved!

[38] train_loss: 0.5845
[38] train_loss: 0.6317
[38] train_loss: 0.5885
[38] train_loss: 0.5516
[38] train_loss: 0.5296
[38] train_loss: 0.5437
[38] train_loss: 0.5693
[38] train_loss: 0.5726
[38] train_loss: 0.5999
[38] train_loss: 0.6286
1.4401183128356934

Evaluating...Epoch: 38
Prec: 0.7392, Recall: 0.6949, F1: 0.7164

[39] train_loss: 0.7120
[39] train_loss: 0.6572
[39] train_loss: 0.6115
[39] train_loss: 0.5924
[39] train_loss: 0.5880
[39] train_loss: 0.5888
[39] train_loss: 0.6005
[39] train_loss: 0.6154
[39] train_loss: 0.6330
[39] train_loss: 0.6448
1.4521198272705078

Evaluating...Epoch: 39
Prec: 0.7725, Recall: 0.6825, F1: 0.7247

[40] train_loss: 0.5858
[40] train_loss: 0.5712
[40] train_loss: 0.5437
[40] train_loss: 0.5241
[40] train_loss: 0.5245
[40] train_loss: 0.5113
[40] train_loss: 0.5209
[40] train_loss: 0.5448
[40] train_loss: 0.5778
[40] train_loss: 0.5999
1.4516911506652832

Evaluating...Epoch: 40
Prec: 0.7538, Recall: 0.6966, F1: 0.7241

[41] train_loss: 0.6323
[41] train_loss: 0.6395
[41] train_loss: 0.5993
[41] train_loss: 0.5578
[41] train_loss: 0.5486
[41] train_loss: 0.5509
[41] train_loss: 0.5840
[41] train_loss: 0.5973
[41] train_loss: 0.6222
[41] train_loss: 0.6406
1.4618957042694092

Evaluating...Epoch: 41
Prec: 0.7547, Recall: 0.7108, F1: 0.7321

[42] train_loss: 0.5510
[42] train_loss: 0.5315
[42] train_loss: 0.5331
[42] train_loss: 0.5077
[42] train_loss: 0.5248
[42] train_loss: 0.5318
[42] train_loss: 0.5423
[42] train_loss: 0.5543
[42] train_loss: 0.5800
[42] train_loss: 0.6078
1.5226373672485352

Evaluating...Epoch: 42
Prec: 0.7616, Recall: 0.6931, F1: 0.7258

[43] train_loss: 0.5355
[43] train_loss: 0.5826
[43] train_loss: 0.5202
[43] train_loss: 0.5052
[43] train_loss: 0.4817
[43] train_loss: 0.4887
[43] train_loss: 0.5058
[43] train_loss: 0.5182
[43] train_loss: 0.5361
[43] train_loss: 0.5695
1.456111192703247

Evaluating...Epoch: 43
Prec: 0.7349, Recall: 0.7090, F1: 0.7217

[44] train_loss: 0.7396
[44] train_loss: 0.7004
[44] train_loss: 0.6377
[44] train_loss: 0.5636
[44] train_loss: 0.5952
[44] train_loss: 0.5696
[44] train_loss: 0.5868
[44] train_loss: 0.5963
[44] train_loss: 0.6045
[44] train_loss: 0.6280
1.454451560974121

Evaluating...Epoch: 44
Prec: 0.7555, Recall: 0.7302, F1: 0.7426
model saved to random1_layers0_14lap/best_model.pt
New best model saved!

[45] train_loss: 0.5080
[45] train_loss: 0.4962
[45] train_loss: 0.4935
[45] train_loss: 0.4444
[45] train_loss: 0.4483
[45] train_loss: 0.4359
[45] train_loss: 0.4653
[45] train_loss: 0.4896
[45] train_loss: 0.5280
[45] train_loss: 0.5537
1.453561782836914

Evaluating...Epoch: 45
Prec: 0.7773, Recall: 0.7019, F1: 0.7377

[46] train_loss: 0.4594
[46] train_loss: 0.4778
[46] train_loss: 0.4913
[46] train_loss: 0.4727
[46] train_loss: 0.4650
[46] train_loss: 0.4614
[46] train_loss: 0.4744
[46] train_loss: 0.5150
[46] train_loss: 0.5333
[46] train_loss: 0.5414
1.4609222412109375

Evaluating...Epoch: 46
Prec: 0.7348, Recall: 0.7231, F1: 0.7289

[47] train_loss: 0.5932
[47] train_loss: 0.6186
[47] train_loss: 0.5825
[47] train_loss: 0.5290
[47] train_loss: 0.4948
[47] train_loss: 0.5001
[47] train_loss: 0.5078
[47] train_loss: 0.5104
[47] train_loss: 0.5136
[47] train_loss: 0.5235
1.5410351753234863

Evaluating...Epoch: 47
Prec: 0.7729, Recall: 0.7143, F1: 0.7424

[48] train_loss: 0.5811
[48] train_loss: 0.4923
[48] train_loss: 0.4419
[48] train_loss: 0.4074
[48] train_loss: 0.3994
[48] train_loss: 0.4020
[48] train_loss: 0.4363
[48] train_loss: 0.4568
[48] train_loss: 0.4761
[48] train_loss: 0.4845
1.4538474082946777

Evaluating...Epoch: 48
Prec: 0.7592, Recall: 0.6949, F1: 0.7256

[49] train_loss: 0.4942
[49] train_loss: 0.4757
[49] train_loss: 0.4512
[49] train_loss: 0.4083
[49] train_loss: 0.4107
[49] train_loss: 0.4210
[49] train_loss: 0.4308
[49] train_loss: 0.4569
[49] train_loss: 0.4732
[49] train_loss: 0.4879
1.4356286525726318

Evaluating...Epoch: 49
Prec: 0.7623, Recall: 0.7125, F1: 0.7366

[50] train_loss: 0.4448
[50] train_loss: 0.4238
[50] train_loss: 0.4152
[50] train_loss: 0.4067
[50] train_loss: 0.3934
[50] train_loss: 0.4436
[50] train_loss: 0.4541
[50] train_loss: 0.4841
[50] train_loss: 0.4851
[50] train_loss: 0.5072
1.446432113647461

Evaluating...Epoch: 50
Prec: 0.7426, Recall: 0.7072, F1: 0.7245

[51] train_loss: 0.5366
[51] train_loss: 0.5153
[51] train_loss: 0.5050
[51] train_loss: 0.4377
[51] train_loss: 0.4224
[51] train_loss: 0.4368
[51] train_loss: 0.4568
[51] train_loss: 0.4684
[51] train_loss: 0.4730
[51] train_loss: 0.5015
1.4591171741485596

Evaluating...Epoch: 51
Prec: 0.7553, Recall: 0.6914, F1: 0.7219

[52] train_loss: 0.5311
[52] train_loss: 0.4961
[52] train_loss: 0.4316
[52] train_loss: 0.4126
[52] train_loss: 0.4067
[52] train_loss: 0.4011
[52] train_loss: 0.4197
[52] train_loss: 0.4166
[52] train_loss: 0.4206
[52] train_loss: 0.4491
1.5130841732025146

Evaluating...Epoch: 52
Prec: 0.7445, Recall: 0.7143, F1: 0.7291

[53] train_loss: 0.4002
[53] train_loss: 0.3992
[53] train_loss: 0.3906
[53] train_loss: 0.3904
[53] train_loss: 0.3873
[53] train_loss: 0.3928
[53] train_loss: 0.3987
[53] train_loss: 0.4026
[53] train_loss: 0.4214
[53] train_loss: 0.4358
1.4529316425323486

Evaluating...Epoch: 53
Prec: 0.7365, Recall: 0.7002, F1: 0.7179

[54] train_loss: 0.4163
[54] train_loss: 0.4716
[54] train_loss: 0.4316
[54] train_loss: 0.3957
[54] train_loss: 0.3830
[54] train_loss: 0.3688
[54] train_loss: 0.4078
[54] train_loss: 0.4079
[54] train_loss: 0.4263
[54] train_loss: 0.4321
1.4517910480499268

Evaluating...Epoch: 54
Prec: 0.7477, Recall: 0.7055, F1: 0.7260

[55] train_loss: 0.4213
[55] train_loss: 0.3807
[55] train_loss: 0.3908
[55] train_loss: 0.3570
[55] train_loss: 0.3636
[55] train_loss: 0.3562
[55] train_loss: 0.3599
[55] train_loss: 0.3690
[55] train_loss: 0.3974
[55] train_loss: 0.4081
1.4606389999389648

Evaluating...Epoch: 55
Prec: 0.7352, Recall: 0.7002, F1: 0.7173

[56] train_loss: 0.4881
[56] train_loss: 0.5226
[56] train_loss: 0.5006
[56] train_loss: 0.4349
[56] train_loss: 0.4101
[56] train_loss: 0.4064
[56] train_loss: 0.3970
[56] train_loss: 0.4018
[56] train_loss: 0.4196
[56] train_loss: 0.4226
1.4655418395996094

Evaluating...Epoch: 56
Prec: 0.7495, Recall: 0.6966, F1: 0.7221

[57] train_loss: 0.4889
[57] train_loss: 0.4721
[57] train_loss: 0.4538
[57] train_loss: 0.4014
[57] train_loss: 0.3817
[57] train_loss: 0.3663
[57] train_loss: 0.3594
[57] train_loss: 0.3798
[57] train_loss: 0.3869
[57] train_loss: 0.4046
1.45039963722229

Evaluating...Epoch: 57
Prec: 0.7402, Recall: 0.6984, F1: 0.7187

[58] train_loss: 0.4822
[58] train_loss: 0.4378
[58] train_loss: 0.4038
[58] train_loss: 0.3790
[58] train_loss: 0.3720
[58] train_loss: 0.3680
[58] train_loss: 0.3646
[58] train_loss: 0.3683
[58] train_loss: 0.3799
[58] train_loss: 0.3986
1.4452908039093018

Evaluating...Epoch: 58
Prec: 0.7486, Recall: 0.7143, F1: 0.7310

[59] train_loss: 0.4680
[59] train_loss: 0.4563
[59] train_loss: 0.3812
[59] train_loss: 0.3443
[59] train_loss: 0.3378
[59] train_loss: 0.3304
[59] train_loss: 0.3345
[59] train_loss: 0.3522
[59] train_loss: 0.3712
[59] train_loss: 0.3958
1.4594230651855469

Evaluating...Epoch: 59
Prec: 0.7566, Recall: 0.7072, F1: 0.7311

[60] train_loss: 0.4086
[60] train_loss: 0.3695
[60] train_loss: 0.3922
[60] train_loss: 0.3700
[60] train_loss: 0.3717
[60] train_loss: 0.3654
[60] train_loss: 0.3700
[60] train_loss: 0.3790
[60] train_loss: 0.3980
[60] train_loss: 0.4065
1.4628040790557861

Evaluating...Epoch: 60
Prec: 0.7552, Recall: 0.7072, F1: 0.7304

[61] train_loss: 0.4232
[61] train_loss: 0.4257
[61] train_loss: 0.4091
[61] train_loss: 0.3607
[61] train_loss: 0.3646
[61] train_loss: 0.3579
[61] train_loss: 0.3572
[61] train_loss: 0.3623
[61] train_loss: 0.3795
[61] train_loss: 0.3967
1.471269130706787

Evaluating...Epoch: 61
Prec: 0.7553, Recall: 0.6966, F1: 0.7248

[62] train_loss: 0.3745
[62] train_loss: 0.3393
[62] train_loss: 0.3462
[62] train_loss: 0.3137
[62] train_loss: 0.3065
[62] train_loss: 0.3049
[62] train_loss: 0.3198
[62] train_loss: 0.3320
[62] train_loss: 0.3621
[62] train_loss: 0.3766
1.4693260192871094

Evaluating...Epoch: 62
Prec: 0.7557, Recall: 0.6984, F1: 0.7259

[63] train_loss: 0.3661
[63] train_loss: 0.3360
[63] train_loss: 0.3145
[63] train_loss: 0.3111
[63] train_loss: 0.3025
[63] train_loss: 0.2986
[63] train_loss: 0.3053
[63] train_loss: 0.3117
[63] train_loss: 0.3306
[63] train_loss: 0.3488
1.4588696956634521

Evaluating...Epoch: 63
Prec: 0.7572, Recall: 0.6931, F1: 0.7238

[64] train_loss: 0.4786
[64] train_loss: 0.4544
[64] train_loss: 0.3860
[64] train_loss: 0.3575
[64] train_loss: 0.3408
[64] train_loss: 0.3234
[64] train_loss: 0.3185
[64] train_loss: 0.3168
[64] train_loss: 0.3182
[64] train_loss: 0.3342
1.4514532089233398

Evaluating...Epoch: 64
Prec: 0.7394, Recall: 0.7108, F1: 0.7248

Training ended with 65 epochs.
Final result:
Prec: 0.7555, Recall: 0.7302, F1: 0.7426
loading vocab and embedding matrix from ../data/14lap
size of vocab: 3463
shape of loaded embedding matrix: (3463, 300)
Generating mappings
Loading data from ../data/14lap with batch size 16...
102 batches created for ../data/14lap/train.json
31 batches created for ../data/14lap/test.json
Building model...
1457133
[1] train_loss: 17.2078
[1] train_loss: 12.1580
[1] train_loss: 10.0563
[1] train_loss: 8.8996
[1] train_loss: 8.1278
[1] train_loss: 7.5957
[1] train_loss: 7.3005
[1] train_loss: 7.1119
[1] train_loss: 6.9433
[1] train_loss: 6.8194
1.7798244953155518

Evaluating...Epoch: 1
Prec: 0.8140, Recall: 0.0617, F1: 0.1148
model saved to random1_layers1_14lap/best_model.pt
New best model saved!

[2] train_loss: 4.4713
[2] train_loss: 4.5521
[2] train_loss: 4.3747
[2] train_loss: 4.2743
[2] train_loss: 4.1709
[2] train_loss: 4.1058
[2] train_loss: 4.1369
[2] train_loss: 4.2002
[2] train_loss: 4.2528
[2] train_loss: 4.2943
1.4878692626953125

Evaluating...Epoch: 2
Prec: 0.6796, Recall: 0.4938, F1: 0.5720
model saved to random1_layers1_14lap/best_model.pt
New best model saved!

[3] train_loss: 3.7198
[3] train_loss: 3.7866
[3] train_loss: 3.6286
[3] train_loss: 3.5407
[3] train_loss: 3.4762
[3] train_loss: 3.4253
[3] train_loss: 3.4538
[3] train_loss: 3.5220
[3] train_loss: 3.6034
[3] train_loss: 3.6464
1.4935827255249023

Evaluating...Epoch: 3
Prec: 0.6405, Recall: 0.6190, F1: 0.6296
model saved to random1_layers1_14lap/best_model.pt
New best model saved!

[4] train_loss: 3.1544
[4] train_loss: 3.2750
[4] train_loss: 3.1774
[4] train_loss: 3.1321
[4] train_loss: 3.0746
[4] train_loss: 3.0251
[4] train_loss: 3.0786
[4] train_loss: 3.1367
[4] train_loss: 3.2085
[4] train_loss: 3.2478
1.4860107898712158

Evaluating...Epoch: 4
Prec: 0.6100, Recall: 0.6702, F1: 0.6387
model saved to random1_layers1_14lap/best_model.pt
New best model saved!

[5] train_loss: 2.9252
[5] train_loss: 2.9669
[5] train_loss: 2.8364
[5] train_loss: 2.7895
[5] train_loss: 2.7577
[5] train_loss: 2.7182
[5] train_loss: 2.7908
[5] train_loss: 2.8538
[5] train_loss: 2.9152
[5] train_loss: 2.9652
1.479217767715454

Evaluating...Epoch: 5
Prec: 0.6352, Recall: 0.6755, F1: 0.6547
model saved to random1_layers1_14lap/best_model.pt
New best model saved!

[6] train_loss: 2.5533
[6] train_loss: 2.6478
[6] train_loss: 2.5620
[6] train_loss: 2.5232
[6] train_loss: 2.5007
[6] train_loss: 2.4785
[6] train_loss: 2.5287
[6] train_loss: 2.5979
[6] train_loss: 2.6631
[6] train_loss: 2.7037
1.5488526821136475

Evaluating...Epoch: 6
Prec: 0.6849, Recall: 0.6173, F1: 0.6494

[7] train_loss: 2.3691
[7] train_loss: 2.4330
[7] train_loss: 2.3585
[7] train_loss: 2.2896
[7] train_loss: 2.2592
[7] train_loss: 2.2481
[7] train_loss: 2.3244
[7] train_loss: 2.3734
[7] train_loss: 2.4516
[7] train_loss: 2.5165
1.492048978805542

Evaluating...Epoch: 7
Prec: 0.6661, Recall: 0.6720, F1: 0.6690
model saved to random1_layers1_14lap/best_model.pt
New best model saved!

[8] train_loss: 2.2835
[8] train_loss: 2.2367
[8] train_loss: 2.2380
[8] train_loss: 2.2006
[8] train_loss: 2.1766
[8] train_loss: 2.1579
[8] train_loss: 2.2280
[8] train_loss: 2.2789
[8] train_loss: 2.3428
[8] train_loss: 2.3877
1.47969388961792

Evaluating...Epoch: 8
Prec: 0.6757, Recall: 0.6614, F1: 0.6684

[9] train_loss: 1.9861
[9] train_loss: 2.0756
[9] train_loss: 2.0214
[9] train_loss: 1.9752
[9] train_loss: 1.9707
[9] train_loss: 1.9758
[9] train_loss: 2.0444
[9] train_loss: 2.1128
[9] train_loss: 2.1710
[9] train_loss: 2.2152
1.486893892288208

Evaluating...Epoch: 9
Prec: 0.6848, Recall: 0.6896, F1: 0.6872
model saved to random1_layers1_14lap/best_model.pt
New best model saved!

[10] train_loss: 1.9764
[10] train_loss: 2.0237
[10] train_loss: 1.9650
[10] train_loss: 1.9213
[10] train_loss: 1.9068
[10] train_loss: 1.8951
[10] train_loss: 1.9382
[10] train_loss: 1.9788
[10] train_loss: 2.0381
[10] train_loss: 2.0772
1.4949731826782227

Evaluating...Epoch: 10
Prec: 0.7236, Recall: 0.6649, F1: 0.6930
model saved to random1_layers1_14lap/best_model.pt
New best model saved!

[11] train_loss: 1.6629
[11] train_loss: 1.7784
[11] train_loss: 1.7834
[11] train_loss: 1.7383
[11] train_loss: 1.7457
[11] train_loss: 1.7182
[11] train_loss: 1.7565
[11] train_loss: 1.8022
[11] train_loss: 1.8723
[11] train_loss: 1.9134
1.5562458038330078

Evaluating...Epoch: 11
Prec: 0.7067, Recall: 0.6843, F1: 0.6953
model saved to random1_layers1_14lap/best_model.pt
New best model saved!

[12] train_loss: 1.6438
[12] train_loss: 1.7846
[12] train_loss: 1.7762
[12] train_loss: 1.6873
[12] train_loss: 1.6870
[12] train_loss: 1.6597
[12] train_loss: 1.7232
[12] train_loss: 1.7636
[12] train_loss: 1.7980
[12] train_loss: 1.8281
1.4840991497039795

Evaluating...Epoch: 12
Prec: 0.6841, Recall: 0.6914, F1: 0.6877

[13] train_loss: 1.6569
[13] train_loss: 1.7506
[13] train_loss: 1.7358
[13] train_loss: 1.6611
[13] train_loss: 1.6509
[13] train_loss: 1.6439
[13] train_loss: 1.6861
[13] train_loss: 1.7312
[13] train_loss: 1.7692
[13] train_loss: 1.8180
1.4951236248016357

Evaluating...Epoch: 13
Prec: 0.7114, Recall: 0.6914, F1: 0.7013
model saved to random1_layers1_14lap/best_model.pt
New best model saved!

[14] train_loss: 1.5605
[14] train_loss: 1.6012
[14] train_loss: 1.5412
[14] train_loss: 1.4635
[14] train_loss: 1.4656
[14] train_loss: 1.4443
[14] train_loss: 1.4951
[14] train_loss: 1.5654
[14] train_loss: 1.6138
[14] train_loss: 1.6471
1.4875543117523193

Evaluating...Epoch: 14
Prec: 0.6937, Recall: 0.7390, F1: 0.7156
model saved to random1_layers1_14lap/best_model.pt
New best model saved!

[15] train_loss: 1.4553
[15] train_loss: 1.5174
[15] train_loss: 1.4536
[15] train_loss: 1.4022
[15] train_loss: 1.3900
[15] train_loss: 1.3756
[15] train_loss: 1.4361
[15] train_loss: 1.4907
[15] train_loss: 1.5523
[15] train_loss: 1.5782
1.5111968517303467

Evaluating...Epoch: 15
Prec: 0.7302, Recall: 0.6825, F1: 0.7056

[16] train_loss: 1.4684
[16] train_loss: 1.4708
[16] train_loss: 1.4385
[16] train_loss: 1.3742
[16] train_loss: 1.3485
[16] train_loss: 1.3249
[16] train_loss: 1.3831
[16] train_loss: 1.4284
[16] train_loss: 1.4771
[16] train_loss: 1.5177
1.4877698421478271

Evaluating...Epoch: 16
Prec: 0.7032, Recall: 0.7019, F1: 0.7026

[17] train_loss: 1.2445
[17] train_loss: 1.2982
[17] train_loss: 1.2712
[17] train_loss: 1.2169
[17] train_loss: 1.2197
[17] train_loss: 1.2187
[17] train_loss: 1.2893
[17] train_loss: 1.3174
[17] train_loss: 1.3698
[17] train_loss: 1.3960
1.53230881690979

Evaluating...Epoch: 17
Prec: 0.6843, Recall: 0.6843, F1: 0.6843

[18] train_loss: 1.3221
[18] train_loss: 1.3467
[18] train_loss: 1.3040
[18] train_loss: 1.2076
[18] train_loss: 1.1836
[18] train_loss: 1.1776
[18] train_loss: 1.2289
[18] train_loss: 1.2697
[18] train_loss: 1.3285
[18] train_loss: 1.3643
1.478442907333374

Evaluating...Epoch: 18
Prec: 0.6793, Recall: 0.6949, F1: 0.6870

[19] train_loss: 1.2306
[19] train_loss: 1.1776
[19] train_loss: 1.1712
[19] train_loss: 1.0982
[19] train_loss: 1.0929
[19] train_loss: 1.0817
[19] train_loss: 1.1264
[19] train_loss: 1.1770
[19] train_loss: 1.2212
[19] train_loss: 1.2647
1.4714577198028564

Evaluating...Epoch: 19
Prec: 0.6811, Recall: 0.7196, F1: 0.6998

[20] train_loss: 1.1935
[20] train_loss: 1.2166
[20] train_loss: 1.1764
[20] train_loss: 1.1152
[20] train_loss: 1.1254
[20] train_loss: 1.1446
[20] train_loss: 1.1649
[20] train_loss: 1.1960
[20] train_loss: 1.2295
[20] train_loss: 1.2657
1.4744412899017334

Evaluating...Epoch: 20
Prec: 0.6722, Recall: 0.7125, F1: 0.6918

[21] train_loss: 1.4100
[21] train_loss: 1.2546
[21] train_loss: 1.1338
[21] train_loss: 1.0977
[21] train_loss: 1.0835
[21] train_loss: 1.0887
[21] train_loss: 1.1505
[21] train_loss: 1.2083
[21] train_loss: 1.2420
[21] train_loss: 1.2726
1.487212896347046

Evaluating...Epoch: 21
Prec: 0.6869, Recall: 0.7196, F1: 0.7028

[22] train_loss: 1.1588
[22] train_loss: 1.1249
[22] train_loss: 1.0865
[22] train_loss: 1.0263
[22] train_loss: 0.9903
[22] train_loss: 1.0073
[22] train_loss: 1.0474
[22] train_loss: 1.1179
[22] train_loss: 1.1563
[22] train_loss: 1.1803
1.4631156921386719

Evaluating...Epoch: 22
Prec: 0.6789, Recall: 0.6825, F1: 0.6807

[23] train_loss: 1.2326
[23] train_loss: 1.1653
[23] train_loss: 1.1172
[23] train_loss: 1.0165
[23] train_loss: 1.0210
[23] train_loss: 1.0049
[23] train_loss: 1.0449
[23] train_loss: 1.0555
[23] train_loss: 1.0818
[23] train_loss: 1.1117
1.4764513969421387

Evaluating...Epoch: 23
Prec: 0.7078, Recall: 0.7178, F1: 0.7128

[24] train_loss: 1.0167
[24] train_loss: 0.9500
[24] train_loss: 0.9353
[24] train_loss: 0.8866
[24] train_loss: 0.8788
[24] train_loss: 0.8934
[24] train_loss: 0.9125
[24] train_loss: 0.9467
[24] train_loss: 0.9771
[24] train_loss: 0.9996
1.4781382083892822

Evaluating...Epoch: 24
Prec: 0.6763, Recall: 0.7037, F1: 0.6897

[25] train_loss: 1.0594
[25] train_loss: 1.0082
[25] train_loss: 0.9828
[25] train_loss: 0.9358
[25] train_loss: 0.9320
[25] train_loss: 0.9062
[25] train_loss: 0.9516
[25] train_loss: 0.9721
[25] train_loss: 0.9981
[25] train_loss: 1.0264
1.4892723560333252

Evaluating...Epoch: 25
Prec: 0.7234, Recall: 0.6966, F1: 0.7098

[26] train_loss: 0.9923
[26] train_loss: 0.9385
[26] train_loss: 0.9171
[26] train_loss: 0.8729
[26] train_loss: 0.8598
[26] train_loss: 0.8599
[26] train_loss: 0.8983
[26] train_loss: 0.9211
[26] train_loss: 0.9576
[26] train_loss: 0.9792
1.4884114265441895

Evaluating...Epoch: 26
Prec: 0.6981, Recall: 0.7178, F1: 0.7078

[27] train_loss: 1.0017
[27] train_loss: 0.9249
[27] train_loss: 0.8641
[27] train_loss: 0.8260
[27] train_loss: 0.8451
[27] train_loss: 0.8297
[27] train_loss: 0.8747
[27] train_loss: 0.8972
[27] train_loss: 0.9250
[27] train_loss: 0.9545
1.484520673751831

Evaluating...Epoch: 27
Prec: 0.7289, Recall: 0.7160, F1: 0.7224
model saved to random1_layers1_14lap/best_model.pt
New best model saved!

[28] train_loss: 0.8728
[28] train_loss: 0.8459
[28] train_loss: 0.7986
[28] train_loss: 0.7629
[28] train_loss: 0.7506
[28] train_loss: 0.7796
[28] train_loss: 0.8105
[28] train_loss: 0.8262
[28] train_loss: 0.8666
[28] train_loss: 0.9026
1.4830901622772217

Evaluating...Epoch: 28
Prec: 0.7224, Recall: 0.6931, F1: 0.7075

[29] train_loss: 0.7852
[29] train_loss: 0.7987
[29] train_loss: 0.8138
[29] train_loss: 0.7545
[29] train_loss: 0.7251
[29] train_loss: 0.7106
[29] train_loss: 0.7395
[29] train_loss: 0.7604
[29] train_loss: 0.7963
[29] train_loss: 0.8372
1.483872413635254

Evaluating...Epoch: 29
Prec: 0.7375, Recall: 0.6790, F1: 0.7071

[30] train_loss: 0.8151
[30] train_loss: 0.7611
[30] train_loss: 0.7808
[30] train_loss: 0.7304
[30] train_loss: 0.7144
[30] train_loss: 0.7125
[30] train_loss: 0.7246
[30] train_loss: 0.7633
[30] train_loss: 0.8136
[30] train_loss: 0.8476
1.4900951385498047

Evaluating...Epoch: 30
Prec: 0.7432, Recall: 0.6790, F1: 0.7097

[31] train_loss: 0.7919
[31] train_loss: 0.7777
[31] train_loss: 0.7356
[31] train_loss: 0.6761
[31] train_loss: 0.7081
[31] train_loss: 0.6991
[31] train_loss: 0.7302
[31] train_loss: 0.7677
[31] train_loss: 0.8020
[31] train_loss: 0.8340
1.4795267581939697

Evaluating...Epoch: 31
Prec: 0.7215, Recall: 0.7266, F1: 0.7241
model saved to random1_layers1_14lap/best_model.pt
New best model saved!

[32] train_loss: 0.7161
[32] train_loss: 0.6795
[32] train_loss: 0.6634
[32] train_loss: 0.6537
[32] train_loss: 0.6608
[32] train_loss: 0.6515
[32] train_loss: 0.6852
[32] train_loss: 0.7187
[32] train_loss: 0.7542
[32] train_loss: 0.7966
1.5400173664093018

Evaluating...Epoch: 32
Prec: 0.7424, Recall: 0.6914, F1: 0.7160

[33] train_loss: 0.6419
[33] train_loss: 0.6846
[33] train_loss: 0.6558
[33] train_loss: 0.6390
[33] train_loss: 0.6231
[33] train_loss: 0.6213
[33] train_loss: 0.6492
[33] train_loss: 0.6785
[33] train_loss: 0.7019
[33] train_loss: 0.7284
1.4895081520080566

Evaluating...Epoch: 33
Prec: 0.7472, Recall: 0.7037, F1: 0.7248
model saved to random1_layers1_14lap/best_model.pt
New best model saved!

[34] train_loss: 0.8484
[34] train_loss: 0.7303
[34] train_loss: 0.7246
[34] train_loss: 0.6589
[34] train_loss: 0.6659
[34] train_loss: 0.6439
[34] train_loss: 0.6554
[34] train_loss: 0.6750
[34] train_loss: 0.7024
[34] train_loss: 0.7332
1.5061590671539307

Evaluating...Epoch: 34
Prec: 0.7298, Recall: 0.7002, F1: 0.7147

[35] train_loss: 0.8019
[35] train_loss: 0.7361
[35] train_loss: 0.7515
[35] train_loss: 0.6774
[35] train_loss: 0.6383
[35] train_loss: 0.6517
[35] train_loss: 0.6764
[35] train_loss: 0.6919
[35] train_loss: 0.7139
[35] train_loss: 0.7161
1.487823724746704

Evaluating...Epoch: 35
Prec: 0.7607, Recall: 0.6896, F1: 0.7234

[36] train_loss: 0.6610
[36] train_loss: 0.6593
[36] train_loss: 0.6017
[36] train_loss: 0.5496
[36] train_loss: 0.5572
[36] train_loss: 0.5621
[36] train_loss: 0.6149
[36] train_loss: 0.6482
[36] train_loss: 0.6871
[36] train_loss: 0.7060
1.4871206283569336

Evaluating...Epoch: 36
Prec: 0.7467, Recall: 0.7019, F1: 0.7236

[37] train_loss: 0.6205
[37] train_loss: 0.5445
[37] train_loss: 0.5371
[37] train_loss: 0.5209
[37] train_loss: 0.5441
[37] train_loss: 0.5559
[37] train_loss: 0.5887
[37] train_loss: 0.5912
[37] train_loss: 0.6181
[37] train_loss: 0.6347
1.5523605346679688

Evaluating...Epoch: 37
Prec: 0.7379, Recall: 0.7002, F1: 0.7186

[38] train_loss: 0.8298
[38] train_loss: 0.7104
[38] train_loss: 0.6709
[38] train_loss: 0.6157
[38] train_loss: 0.5754
[38] train_loss: 0.5912
[38] train_loss: 0.5942
[38] train_loss: 0.6154
[38] train_loss: 0.6360
[38] train_loss: 0.6525
1.4831514358520508

Evaluating...Epoch: 38
Prec: 0.7560, Recall: 0.7266, F1: 0.7410
model saved to random1_layers1_14lap/best_model.pt
New best model saved!

[39] train_loss: 0.6665
[39] train_loss: 0.5995
[39] train_loss: 0.5491
[39] train_loss: 0.5254
[39] train_loss: 0.5065
[39] train_loss: 0.5097
[39] train_loss: 0.5222
[39] train_loss: 0.5494
[39] train_loss: 0.5448
[39] train_loss: 0.5697
1.4626500606536865

Evaluating...Epoch: 39
Prec: 0.7463, Recall: 0.7160, F1: 0.7309

[40] train_loss: 0.7242
[40] train_loss: 0.6300
[40] train_loss: 0.6184
[40] train_loss: 0.5899
[40] train_loss: 0.5774
[40] train_loss: 0.5742
[40] train_loss: 0.5787
[40] train_loss: 0.6023
[40] train_loss: 0.6085
[40] train_loss: 0.6122
1.4855918884277344

Evaluating...Epoch: 40
Prec: 0.7528, Recall: 0.7037, F1: 0.7274

[41] train_loss: 0.6383
[41] train_loss: 0.6127
[41] train_loss: 0.6120
[41] train_loss: 0.5384
[41] train_loss: 0.5309
[41] train_loss: 0.5227
[41] train_loss: 0.5434
[41] train_loss: 0.5390
[41] train_loss: 0.5791
[41] train_loss: 0.5892
1.4836409091949463

Evaluating...Epoch: 41
Prec: 0.7244, Recall: 0.6861, F1: 0.7047

[42] train_loss: 0.6835
[42] train_loss: 0.6046
[42] train_loss: 0.5595
[42] train_loss: 0.5214
[42] train_loss: 0.5135
[42] train_loss: 0.4786
[42] train_loss: 0.4732
[42] train_loss: 0.5052
[42] train_loss: 0.5010
[42] train_loss: 0.5195
1.5659527778625488

Evaluating...Epoch: 42
Prec: 0.7313, Recall: 0.7055, F1: 0.7181

[43] train_loss: 0.4551
[43] train_loss: 0.5252
[43] train_loss: 0.5394
[43] train_loss: 0.5195
[43] train_loss: 0.4978
[43] train_loss: 0.4938
[43] train_loss: 0.5104
[43] train_loss: 0.5250
[43] train_loss: 0.5431
[43] train_loss: 0.5491
1.481644630432129

Evaluating...Epoch: 43
Prec: 0.7426, Recall: 0.7125, F1: 0.7273

[44] train_loss: 0.5271
[44] train_loss: 0.4895
[44] train_loss: 0.4701
[44] train_loss: 0.4404
[44] train_loss: 0.4349
[44] train_loss: 0.4330
[44] train_loss: 0.4439
[44] train_loss: 0.4699
[44] train_loss: 0.4855
[44] train_loss: 0.5057
1.469977855682373

Evaluating...Epoch: 44
Prec: 0.7271, Recall: 0.6861, F1: 0.7060

[45] train_loss: 0.5546
[45] train_loss: 0.5174
[45] train_loss: 0.5098
[45] train_loss: 0.4670
[45] train_loss: 0.4352
[45] train_loss: 0.4431
[45] train_loss: 0.4472
[45] train_loss: 0.4785
[45] train_loss: 0.5024
[45] train_loss: 0.5406
1.4723825454711914

Evaluating...Epoch: 45
Prec: 0.7391, Recall: 0.7143, F1: 0.7265

[46] train_loss: 0.5395
[46] train_loss: 0.4424
[46] train_loss: 0.4327
[46] train_loss: 0.3957
[46] train_loss: 0.3889
[46] train_loss: 0.3880
[46] train_loss: 0.4135
[46] train_loss: 0.4338
[46] train_loss: 0.4697
[46] train_loss: 0.4808
1.4849135875701904

Evaluating...Epoch: 46
Prec: 0.7500, Recall: 0.6878, F1: 0.7176

[47] train_loss: 0.4818
[47] train_loss: 0.4593
[47] train_loss: 0.4542
[47] train_loss: 0.4213
[47] train_loss: 0.4233
[47] train_loss: 0.4147
[47] train_loss: 0.4277
[47] train_loss: 0.4861
[47] train_loss: 0.5053
[47] train_loss: 0.5052
1.5346827507019043

Evaluating...Epoch: 47
Prec: 0.7271, Recall: 0.7143, F1: 0.7206

[48] train_loss: 0.3292
[48] train_loss: 0.3773
[48] train_loss: 0.3955
[48] train_loss: 0.3808
[48] train_loss: 0.3803
[48] train_loss: 0.3941
[48] train_loss: 0.4127
[48] train_loss: 0.4203
[48] train_loss: 0.4381
[48] train_loss: 0.4578
1.4797227382659912

Evaluating...Epoch: 48
Prec: 0.7197, Recall: 0.7337, F1: 0.7266

[49] train_loss: 0.5376
[49] train_loss: 0.5224
[49] train_loss: 0.4322
[49] train_loss: 0.3826
[49] train_loss: 0.3722
[49] train_loss: 0.3798
[49] train_loss: 0.3867
[49] train_loss: 0.4001
[49] train_loss: 0.4211
[49] train_loss: 0.4284
1.4857254028320312

Evaluating...Epoch: 49
Prec: 0.7514, Recall: 0.7090, F1: 0.7296

[50] train_loss: 0.4049
[50] train_loss: 0.4593
[50] train_loss: 0.4199
[50] train_loss: 0.4145
[50] train_loss: 0.3961
[50] train_loss: 0.4061
[50] train_loss: 0.4045
[50] train_loss: 0.4219
[50] train_loss: 0.4341
[50] train_loss: 0.4429
1.486680269241333

Evaluating...Epoch: 50
Prec: 0.7463, Recall: 0.7108, F1: 0.7281

[51] train_loss: 0.5028
[51] train_loss: 0.4298
[51] train_loss: 0.4099
[51] train_loss: 0.3796
[51] train_loss: 0.3856
[51] train_loss: 0.3753
[51] train_loss: 0.4072
[51] train_loss: 0.4185
[51] train_loss: 0.4264
[51] train_loss: 0.4398
1.4956209659576416

Evaluating...Epoch: 51
Prec: 0.7312, Recall: 0.7390, F1: 0.7351

[52] train_loss: 0.5485
[52] train_loss: 0.6152
[52] train_loss: 0.5395
[52] train_loss: 0.4653
[52] train_loss: 0.4245
[52] train_loss: 0.4179
[52] train_loss: 0.4188
[52] train_loss: 0.4157
[52] train_loss: 0.4181
[52] train_loss: 0.4276
1.4784460067749023

Evaluating...Epoch: 52
Prec: 0.7403, Recall: 0.7090, F1: 0.7243

[53] train_loss: 0.3846
[53] train_loss: 0.4270
[53] train_loss: 0.4215
[53] train_loss: 0.3882
[53] train_loss: 0.3576
[53] train_loss: 0.3550
[53] train_loss: 0.3654
[53] train_loss: 0.3844
[53] train_loss: 0.4337
[53] train_loss: 0.4568
1.5387980937957764

Evaluating...Epoch: 53
Prec: 0.7416, Recall: 0.6984, F1: 0.7193

[54] train_loss: 0.4353
[54] train_loss: 0.4118
[54] train_loss: 0.3759
[54] train_loss: 0.3349
[54] train_loss: 0.3239
[54] train_loss: 0.3393
[54] train_loss: 0.3548
[54] train_loss: 0.3743
[54] train_loss: 0.3836
[54] train_loss: 0.3975
1.4879186153411865

Evaluating...Epoch: 54
Prec: 0.7350, Recall: 0.7337, F1: 0.7343

[55] train_loss: 0.4329
[55] train_loss: 0.4133
[55] train_loss: 0.3854
[55] train_loss: 0.3603
[55] train_loss: 0.3634
[55] train_loss: 0.3479
[55] train_loss: 0.3566
[55] train_loss: 0.3654
[55] train_loss: 0.3918
[55] train_loss: 0.4027
1.4833853244781494

Evaluating...Epoch: 55
Prec: 0.6932, Recall: 0.7055, F1: 0.6993

[56] train_loss: 0.4857
[56] train_loss: 0.4459
[56] train_loss: 0.4199
[56] train_loss: 0.3950
[56] train_loss: 0.3672
[56] train_loss: 0.3512
[56] train_loss: 0.3564
[56] train_loss: 0.3541
[56] train_loss: 0.3830
[56] train_loss: 0.4028
1.483705997467041

Evaluating...Epoch: 56
Prec: 0.7518, Recall: 0.7319, F1: 0.7417
model saved to random1_layers1_14lap/best_model.pt
New best model saved!

[57] train_loss: 0.3552
[57] train_loss: 0.3398
[57] train_loss: 0.3619
[57] train_loss: 0.3227
[57] train_loss: 0.3264
[57] train_loss: 0.3215
[57] train_loss: 0.3164
[57] train_loss: 0.3383
[57] train_loss: 0.3527
[57] train_loss: 0.3767
1.4902467727661133

Evaluating...Epoch: 57
Prec: 0.7252, Recall: 0.7213, F1: 0.7233

[58] train_loss: 0.4574
[58] train_loss: 0.3808
[58] train_loss: 0.3626
[58] train_loss: 0.3297
[58] train_loss: 0.3165
[58] train_loss: 0.3381
[58] train_loss: 0.3359
[58] train_loss: 0.3559
[58] train_loss: 0.3623
[58] train_loss: 0.3710
1.4860773086547852

Evaluating...Epoch: 58
Prec: 0.7655, Recall: 0.7196, F1: 0.7418
model saved to random1_layers1_14lap/best_model.pt
New best model saved!

[59] train_loss: 0.3796
[59] train_loss: 0.3437
[59] train_loss: 0.3328
[59] train_loss: 0.3049
[59] train_loss: 0.3122
[59] train_loss: 0.3134
[59] train_loss: 0.3118
[59] train_loss: 0.3217
[59] train_loss: 0.3412
[59] train_loss: 0.3519
1.4709546566009521

Evaluating...Epoch: 59
Prec: 0.7366, Recall: 0.7496, F1: 0.7430
model saved to random1_layers1_14lap/best_model.pt
New best model saved!

[60] train_loss: 0.4502
[60] train_loss: 0.4214
[60] train_loss: 0.3789
[60] train_loss: 0.3420
[60] train_loss: 0.3188
[60] train_loss: 0.3185
[60] train_loss: 0.3205
[60] train_loss: 0.3124
[60] train_loss: 0.3174
[60] train_loss: 0.3193
1.4749908447265625

Evaluating...Epoch: 60
Prec: 0.7138, Recall: 0.7478, F1: 0.7304

[61] train_loss: 0.5020
[61] train_loss: 0.4283
[61] train_loss: 0.3943
[61] train_loss: 0.3713
[61] train_loss: 0.3522
[61] train_loss: 0.3661
[61] train_loss: 0.3734
[61] train_loss: 0.3764
[61] train_loss: 0.3986
[61] train_loss: 0.4130
1.4870333671569824

Evaluating...Epoch: 61
Prec: 0.7349, Recall: 0.7284, F1: 0.7316

[62] train_loss: 0.3468
[62] train_loss: 0.3415
[62] train_loss: 0.3041
[62] train_loss: 0.2948
[62] train_loss: 0.2755
[62] train_loss: 0.2819
[62] train_loss: 0.2908
[62] train_loss: 0.2910
[62] train_loss: 0.2991
[62] train_loss: 0.3217
1.4909179210662842

Evaluating...Epoch: 62
Prec: 0.7179, Recall: 0.7584, F1: 0.7376

[63] train_loss: 0.4866
[63] train_loss: 0.4255
[63] train_loss: 0.3858
[63] train_loss: 0.3346
[63] train_loss: 0.3245
[63] train_loss: 0.3099
[63] train_loss: 0.3069
[63] train_loss: 0.3165
[63] train_loss: 0.3273
[63] train_loss: 0.3255
1.545781135559082

Evaluating...Epoch: 63
Prec: 0.7334, Recall: 0.7425, F1: 0.7379

[64] train_loss: 0.3262
[64] train_loss: 0.3128
[64] train_loss: 0.3184
[64] train_loss: 0.3012
[64] train_loss: 0.2704
[64] train_loss: 0.2673
[64] train_loss: 0.2761
[64] train_loss: 0.2977
[64] train_loss: 0.3007
[64] train_loss: 0.3153
1.4835925102233887

Evaluating...Epoch: 64
Prec: 0.7437, Recall: 0.7266, F1: 0.7351

[65] train_loss: 0.3834
[65] train_loss: 0.2925
[65] train_loss: 0.2723
[65] train_loss: 0.2503
[65] train_loss: 0.2436
[65] train_loss: 0.2650
[65] train_loss: 0.2791
[65] train_loss: 0.2896
[65] train_loss: 0.2981
[65] train_loss: 0.3061
1.4952833652496338

Evaluating...Epoch: 65
Prec: 0.7300, Recall: 0.7249, F1: 0.7274

[66] train_loss: 0.3478
[66] train_loss: 0.3552
[66] train_loss: 0.3476
[66] train_loss: 0.3110
[66] train_loss: 0.3126
[66] train_loss: 0.3252
[66] train_loss: 0.3258
[66] train_loss: 0.3414
[66] train_loss: 0.3425
[66] train_loss: 0.3409
1.4921550750732422

Evaluating...Epoch: 66
Prec: 0.7409, Recall: 0.7213, F1: 0.7310

[67] train_loss: 0.3658
[67] train_loss: 0.2987
[67] train_loss: 0.2881
[67] train_loss: 0.2797
[67] train_loss: 0.2691
[67] train_loss: 0.2564
[67] train_loss: 0.2493
[67] train_loss: 0.2552
[67] train_loss: 0.2933
[67] train_loss: 0.3056
1.4882948398590088

Evaluating...Epoch: 67
Prec: 0.7317, Recall: 0.7407, F1: 0.7362

[68] train_loss: 0.2722
[68] train_loss: 0.3008
[68] train_loss: 0.2908
[68] train_loss: 0.2600
[68] train_loss: 0.2900
[68] train_loss: 0.2946
[68] train_loss: 0.2983
[68] train_loss: 0.2939
[68] train_loss: 0.3336
[68] train_loss: 0.3409
1.544243574142456

Evaluating...Epoch: 68
Prec: 0.7523, Recall: 0.7337, F1: 0.7429

[69] train_loss: 0.3555
[69] train_loss: 0.3475
[69] train_loss: 0.3056
[69] train_loss: 0.2665
[69] train_loss: 0.2467
[69] train_loss: 0.2477
[69] train_loss: 0.2515
[69] train_loss: 0.2683
[69] train_loss: 0.2671
[69] train_loss: 0.2905
1.5028510093688965

Evaluating...Epoch: 69
Prec: 0.7400, Recall: 0.7478, F1: 0.7439
model saved to random1_layers1_14lap/best_model.pt
New best model saved!

[70] train_loss: 0.4543
[70] train_loss: 0.4113
[70] train_loss: 0.3806
[70] train_loss: 0.3444
[70] train_loss: 0.3212
[70] train_loss: 0.3051
[70] train_loss: 0.3167
[70] train_loss: 0.3110
[70] train_loss: 0.3122
[70] train_loss: 0.3193
1.495373010635376

Evaluating...Epoch: 70
Prec: 0.7238, Recall: 0.7443, F1: 0.7339

[71] train_loss: 0.3542
[71] train_loss: 0.3337
[71] train_loss: 0.3010
[71] train_loss: 0.2780
[71] train_loss: 0.2564
[71] train_loss: 0.2528
[71] train_loss: 0.2541
[71] train_loss: 0.2595
[71] train_loss: 0.2566
[71] train_loss: 0.2646
1.5011892318725586

Evaluating...Epoch: 71
Prec: 0.7513, Recall: 0.7407, F1: 0.7460
model saved to random1_layers1_14lap/best_model.pt
New best model saved!

[72] train_loss: 0.2403
[72] train_loss: 0.2573
[72] train_loss: 0.2495
[72] train_loss: 0.2288
[72] train_loss: 0.2255
[72] train_loss: 0.2431
[72] train_loss: 0.2388
[72] train_loss: 0.2401
[72] train_loss: 0.2706
[72] train_loss: 0.2792
1.4944355487823486

Evaluating...Epoch: 72
Prec: 0.7569, Recall: 0.7302, F1: 0.7433

[73] train_loss: 0.3331
[73] train_loss: 0.3177
[73] train_loss: 0.2737
[73] train_loss: 0.2486
[73] train_loss: 0.2450
[73] train_loss: 0.2451
[73] train_loss: 0.2506
[73] train_loss: 0.2565
[73] train_loss: 0.2551
[73] train_loss: 0.2621
1.55519700050354

Evaluating...Epoch: 73
Prec: 0.7555, Recall: 0.7302, F1: 0.7426

[74] train_loss: 0.3980
[74] train_loss: 0.3376
[74] train_loss: 0.3023
[74] train_loss: 0.2636
[74] train_loss: 0.2713
[74] train_loss: 0.2552
[74] train_loss: 0.2577
[74] train_loss: 0.2774
[74] train_loss: 0.2703
[74] train_loss: 0.2867
1.4919369220733643

Evaluating...Epoch: 74
Prec: 0.7394, Recall: 0.7407, F1: 0.7401

[75] train_loss: 0.2975
[75] train_loss: 0.2649
[75] train_loss: 0.2437
[75] train_loss: 0.2295
[75] train_loss: 0.2559
[75] train_loss: 0.2676
[75] train_loss: 0.2608
[75] train_loss: 0.2701
[75] train_loss: 0.2875
[75] train_loss: 0.2901
1.485886573791504

Evaluating...Epoch: 75
Prec: 0.7505, Recall: 0.7160, F1: 0.7329

[76] train_loss: 0.2492
[76] train_loss: 0.2521
[76] train_loss: 0.2203
[76] train_loss: 0.2102
[76] train_loss: 0.2370
[76] train_loss: 0.2254
[76] train_loss: 0.2403
[76] train_loss: 0.2461
[76] train_loss: 0.2534
[76] train_loss: 0.2669
1.4897005558013916

Evaluating...Epoch: 76
Prec: 0.7345, Recall: 0.7319, F1: 0.7332

[77] train_loss: 0.2506
[77] train_loss: 0.3073
[77] train_loss: 0.3054
[77] train_loss: 0.2633
[77] train_loss: 0.2552
[77] train_loss: 0.2658
[77] train_loss: 0.2692
[77] train_loss: 0.2796
[77] train_loss: 0.2823
[77] train_loss: 0.2830
1.4905900955200195

Evaluating...Epoch: 77
Prec: 0.7677, Recall: 0.7284, F1: 0.7475
model saved to random1_layers1_14lap/best_model.pt
New best model saved!

[78] train_loss: 0.3442
[78] train_loss: 0.2441
[78] train_loss: 0.2572
[78] train_loss: 0.2345
[78] train_loss: 0.2339
[78] train_loss: 0.2291
[78] train_loss: 0.2255
[78] train_loss: 0.2359
[78] train_loss: 0.2387
[78] train_loss: 0.2539
1.5375313758850098

Evaluating...Epoch: 78
Prec: 0.7354, Recall: 0.7354, F1: 0.7354

[79] train_loss: 0.2930
[79] train_loss: 0.2779
[79] train_loss: 0.2139
[79] train_loss: 0.1915
[79] train_loss: 0.1906
[79] train_loss: 0.2054
[79] train_loss: 0.2111
[79] train_loss: 0.2279
[79] train_loss: 0.2468
[79] train_loss: 0.2644
1.477583408355713

Evaluating...Epoch: 79
Prec: 0.7331, Recall: 0.7266, F1: 0.7298

[80] train_loss: 0.2727
[80] train_loss: 0.2934
[80] train_loss: 0.2441
[80] train_loss: 0.2120
[80] train_loss: 0.2252
[80] train_loss: 0.2292
[80] train_loss: 0.2289
[80] train_loss: 0.2400
[80] train_loss: 0.2494
[80] train_loss: 0.2637
1.4756765365600586

Evaluating...Epoch: 80
Prec: 0.7337, Recall: 0.7337, F1: 0.7337

[81] train_loss: 0.3520
[81] train_loss: 0.3148
[81] train_loss: 0.2942
[81] train_loss: 0.2589
[81] train_loss: 0.2662
[81] train_loss: 0.2447
[81] train_loss: 0.2465
[81] train_loss: 0.2573
[81] train_loss: 0.2588
[81] train_loss: 0.2613
1.494215726852417

Evaluating...Epoch: 81
Prec: 0.7708, Recall: 0.7178, F1: 0.7434

[82] train_loss: 0.2468
[82] train_loss: 0.1982
[82] train_loss: 0.1829
[82] train_loss: 0.1740
[82] train_loss: 0.1879
[82] train_loss: 0.1973
[82] train_loss: 0.2012
[82] train_loss: 0.2147
[82] train_loss: 0.2284
[82] train_loss: 0.2323
1.49013090133667

Evaluating...Epoch: 82
Prec: 0.7310, Recall: 0.7478, F1: 0.7393

[83] train_loss: 0.2389
[83] train_loss: 0.3411
[83] train_loss: 0.2851
[83] train_loss: 0.2460
[83] train_loss: 0.2228
[83] train_loss: 0.2139
[83] train_loss: 0.2164
[83] train_loss: 0.2321
[83] train_loss: 0.2549
[83] train_loss: 0.2650
1.5381460189819336

Evaluating...Epoch: 83
Prec: 0.7330, Recall: 0.7213, F1: 0.7271

[84] train_loss: 0.1990
[84] train_loss: 0.2018
[84] train_loss: 0.2086
[84] train_loss: 0.1809
[84] train_loss: 0.1728
[84] train_loss: 0.1698
[84] train_loss: 0.1911
[84] train_loss: 0.2025
[84] train_loss: 0.2051
[84] train_loss: 0.2168
1.4809939861297607

Evaluating...Epoch: 84
Prec: 0.7673, Recall: 0.7443, F1: 0.7556
model saved to random1_layers1_14lap/best_model.pt
New best model saved!

[85] train_loss: 0.2519
[85] train_loss: 0.2237
[85] train_loss: 0.2153
[85] train_loss: 0.1929
[85] train_loss: 0.1965
[85] train_loss: 0.2026
[85] train_loss: 0.2059
[85] train_loss: 0.2070
[85] train_loss: 0.2303
[85] train_loss: 0.2323
1.4788768291473389

Evaluating...Epoch: 85
Prec: 0.7454, Recall: 0.7178, F1: 0.7314

[86] train_loss: 0.2182
[86] train_loss: 0.2119
[86] train_loss: 0.1895
[86] train_loss: 0.1882
[86] train_loss: 0.1781
[86] train_loss: 0.1798
[86] train_loss: 0.1972
[86] train_loss: 0.2063
[86] train_loss: 0.2058
[86] train_loss: 0.2151
1.4759016036987305

Evaluating...Epoch: 86
Prec: 0.7606, Recall: 0.7284, F1: 0.7441

[87] train_loss: 0.2904
[87] train_loss: 0.1994
[87] train_loss: 0.1868
[87] train_loss: 0.1698
[87] train_loss: 0.1808
[87] train_loss: 0.1690
[87] train_loss: 0.1786
[87] train_loss: 0.1829
[87] train_loss: 0.1878
[87] train_loss: 0.1867
1.4887864589691162

Evaluating...Epoch: 87
Prec: 0.7296, Recall: 0.7090, F1: 0.7191

[88] train_loss: 0.1996
[88] train_loss: 0.2046
[88] train_loss: 0.1982
[88] train_loss: 0.1900
[88] train_loss: 0.1795
[88] train_loss: 0.1864
[88] train_loss: 0.1819
[88] train_loss: 0.1972
[88] train_loss: 0.2119
[88] train_loss: 0.2194
1.4909489154815674

Evaluating...Epoch: 88
Prec: 0.7523, Recall: 0.7231, F1: 0.7374

[89] train_loss: 0.2565
[89] train_loss: 0.2213
[89] train_loss: 0.1851
[89] train_loss: 0.1754
[89] train_loss: 0.1777
[89] train_loss: 0.1726
[89] train_loss: 0.1783
[89] train_loss: 0.1942
[89] train_loss: 0.2068
[89] train_loss: 0.2247
1.5398876667022705

Evaluating...Epoch: 89
Prec: 0.7603, Recall: 0.7496, F1: 0.7549

[90] train_loss: 0.2932
[90] train_loss: 0.2230
[90] train_loss: 0.2108
[90] train_loss: 0.1972
[90] train_loss: 0.1832
[90] train_loss: 0.1765
[90] train_loss: 0.1723
[90] train_loss: 0.1735
[90] train_loss: 0.1819
[90] train_loss: 0.1992
1.4803047180175781

Evaluating...Epoch: 90
Prec: 0.7761, Recall: 0.7213, F1: 0.7477

[91] train_loss: 0.2046
[91] train_loss: 0.1558
[91] train_loss: 0.1435
[91] train_loss: 0.1328
[91] train_loss: 0.1278
[91] train_loss: 0.1295
[91] train_loss: 0.1481
[91] train_loss: 0.1727
[91] train_loss: 0.1875
[91] train_loss: 0.2009
1.4855594635009766

Evaluating...Epoch: 91
Prec: 0.7522, Recall: 0.7549, F1: 0.7535

[92] train_loss: 0.1763
[92] train_loss: 0.1888
[92] train_loss: 0.1686
[92] train_loss: 0.1523
[92] train_loss: 0.1452
[92] train_loss: 0.1472
[92] train_loss: 0.1518
[92] train_loss: 0.1669
[92] train_loss: 0.1795
[92] train_loss: 0.1787
1.5028107166290283

Evaluating...Epoch: 92
Prec: 0.7487, Recall: 0.7354, F1: 0.7420

[93] train_loss: 0.3421
[93] train_loss: 0.3079
[93] train_loss: 0.2442
[93] train_loss: 0.2199
[93] train_loss: 0.2041
[93] train_loss: 0.2038
[93] train_loss: 0.2018
[93] train_loss: 0.2133
[93] train_loss: 0.2143
[93] train_loss: 0.2136
1.5073328018188477

Evaluating...Epoch: 93
Prec: 0.7678, Recall: 0.7231, F1: 0.7448

[94] train_loss: 0.3986
[94] train_loss: 0.3436
[94] train_loss: 0.3156
[94] train_loss: 0.2759
[94] train_loss: 0.2660
[94] train_loss: 0.2694
[94] train_loss: 0.2683
[94] train_loss: 0.2739
[94] train_loss: 0.2714
[94] train_loss: 0.2669
1.508617639541626

Evaluating...Epoch: 94
Prec: 0.7441, Recall: 0.7284, F1: 0.7362

[95] train_loss: 0.1977
[95] train_loss: 0.2018
[95] train_loss: 0.1849
[95] train_loss: 0.1619
[95] train_loss: 0.1584
[95] train_loss: 0.1550
[95] train_loss: 0.1550
[95] train_loss: 0.1694
[95] train_loss: 0.1871
[95] train_loss: 0.1884
1.503880262374878

Evaluating...Epoch: 95
Prec: 0.7486, Recall: 0.7143, F1: 0.7310

[96] train_loss: 0.1789
[96] train_loss: 0.1470
[96] train_loss: 0.1322
[96] train_loss: 0.1263
[96] train_loss: 0.1286
[96] train_loss: 0.1329
[96] train_loss: 0.1363
[96] train_loss: 0.1528
[96] train_loss: 0.1649
[96] train_loss: 0.1609
1.4990146160125732

Evaluating...Epoch: 96
Prec: 0.7446, Recall: 0.7302, F1: 0.7373

[97] train_loss: 0.2123
[97] train_loss: 0.1817
[97] train_loss: 0.1594
[97] train_loss: 0.1550
[97] train_loss: 0.1560
[97] train_loss: 0.1558
[97] train_loss: 0.1590
[97] train_loss: 0.1663
[97] train_loss: 0.1866
[97] train_loss: 0.1815
1.5004115104675293

Evaluating...Epoch: 97
Prec: 0.7362, Recall: 0.7284, F1: 0.7323

[98] train_loss: 0.2135
[98] train_loss: 0.2298
[98] train_loss: 0.2396
[98] train_loss: 0.2007
[98] train_loss: 0.1979
[98] train_loss: 0.1884
[98] train_loss: 0.1765
[98] train_loss: 0.1780
[98] train_loss: 0.1880
[98] train_loss: 0.1972
1.5101394653320312

Evaluating...Epoch: 98
Prec: 0.7398, Recall: 0.7319, F1: 0.7358

[99] train_loss: 0.1600
[99] train_loss: 0.1721
[99] train_loss: 0.1439
[99] train_loss: 0.1312
[99] train_loss: 0.1253
[99] train_loss: 0.1381
[99] train_loss: 0.1429
[99] train_loss: 0.1517
[99] train_loss: 0.1538
[99] train_loss: 0.1685
1.4967150688171387

Evaluating...Epoch: 99
Prec: 0.7342, Recall: 0.7354, F1: 0.7348

[100] train_loss: 0.1420
[100] train_loss: 0.1307
[100] train_loss: 0.1456
[100] train_loss: 0.1305
[100] train_loss: 0.1280
[100] train_loss: 0.1190
[100] train_loss: 0.1357
[100] train_loss: 0.1461
[100] train_loss: 0.1549
[100] train_loss: 0.1609
1.4972081184387207

Evaluating...Epoch: 100
Prec: 0.7295, Recall: 0.7372, F1: 0.7333

Training ended with 100 epochs.
Final result:
Prec: 0.7673, Recall: 0.7443, F1: 0.7556
loading vocab and embedding matrix from ../data/14lap
size of vocab: 3463
shape of loaded embedding matrix: (3463, 300)
Generating mappings
Loading data from ../data/14lap with batch size 16...
102 batches created for ../data/14lap/train.json
31 batches created for ../data/14lap/test.json
Building model...
1497333
[1] train_loss: 16.3849
[1] train_loss: 11.9241
[1] train_loss: 9.8559
[1] train_loss: 8.7792
[1] train_loss: 8.0811
[1] train_loss: 7.5649
[1] train_loss: 7.2659
[1] train_loss: 7.0812
[1] train_loss: 6.9350
[1] train_loss: 6.8228
1.6655313968658447

Evaluating...Epoch: 1
Prec: 0.8235, Recall: 0.0988, F1: 0.1764
model saved to random1_layers2_14lap/best_model.pt
New best model saved!

[2] train_loss: 4.5955
[2] train_loss: 4.5697
[2] train_loss: 4.3288
[2] train_loss: 4.1961
[2] train_loss: 4.1001
[2] train_loss: 4.0411
[2] train_loss: 4.0548
[2] train_loss: 4.1271
[2] train_loss: 4.1938
[2] train_loss: 4.2422
1.5704448223114014

Evaluating...Epoch: 2
Prec: 0.6274, Recall: 0.5256, F1: 0.5720
model saved to random1_layers2_14lap/best_model.pt
New best model saved!

[3] train_loss: 3.6716
[3] train_loss: 3.6581
[3] train_loss: 3.5277
[3] train_loss: 3.4692
[3] train_loss: 3.4076
[3] train_loss: 3.3933
[3] train_loss: 3.4258
[3] train_loss: 3.4695
[3] train_loss: 3.5536
[3] train_loss: 3.5900
1.5700273513793945

Evaluating...Epoch: 3
Prec: 0.6337, Recall: 0.6102, F1: 0.6217
model saved to random1_layers2_14lap/best_model.pt
New best model saved!

[4] train_loss: 3.2195
[4] train_loss: 3.3287
[4] train_loss: 3.1704
[4] train_loss: 3.1037
[4] train_loss: 3.0697
[4] train_loss: 3.0264
[4] train_loss: 3.0765
[4] train_loss: 3.1382
[4] train_loss: 3.2122
[4] train_loss: 3.2655
1.5754694938659668

Evaluating...Epoch: 4
Prec: 0.6496, Recall: 0.6508, F1: 0.6502
model saved to random1_layers2_14lap/best_model.pt
New best model saved!

[5] train_loss: 2.7675
[5] train_loss: 2.8790
[5] train_loss: 2.7765
[5] train_loss: 2.7257
[5] train_loss: 2.6935
[5] train_loss: 2.6811
[5] train_loss: 2.7541
[5] train_loss: 2.8141
[5] train_loss: 2.8814
[5] train_loss: 2.9336
1.5729694366455078

Evaluating...Epoch: 5
Prec: 0.6538, Recall: 0.6861, F1: 0.6695
model saved to random1_layers2_14lap/best_model.pt
New best model saved!

[6] train_loss: 2.4727
[6] train_loss: 2.6243
[6] train_loss: 2.5144
[6] train_loss: 2.5024
[6] train_loss: 2.4863
[6] train_loss: 2.4633
[6] train_loss: 2.5292
[6] train_loss: 2.5912
[6] train_loss: 2.6500
[6] train_loss: 2.6933
1.635831356048584

Evaluating...Epoch: 6
Prec: 0.6615, Recall: 0.6825, F1: 0.6719
model saved to random1_layers2_14lap/best_model.pt
New best model saved!

[7] train_loss: 2.5217
[7] train_loss: 2.5014
[7] train_loss: 2.4045
[7] train_loss: 2.3525
[7] train_loss: 2.2940
[7] train_loss: 2.2889
[7] train_loss: 2.3448
[7] train_loss: 2.3969
[7] train_loss: 2.4612
[7] train_loss: 2.5368
1.5609352588653564

Evaluating...Epoch: 7
Prec: 0.7130, Recall: 0.6878, F1: 0.7002
model saved to random1_layers2_14lap/best_model.pt
New best model saved!

[8] train_loss: 2.1967
[8] train_loss: 2.2297
[8] train_loss: 2.2196
[8] train_loss: 2.1614
[8] train_loss: 2.1541
[8] train_loss: 2.1404
[8] train_loss: 2.2035
[8] train_loss: 2.2576
[8] train_loss: 2.3151
[8] train_loss: 2.3601
1.5658528804779053

Evaluating...Epoch: 8
Prec: 0.6793, Recall: 0.6949, F1: 0.6870

[9] train_loss: 2.1117
[9] train_loss: 2.0994
[9] train_loss: 2.0711
[9] train_loss: 2.0203
[9] train_loss: 2.0020
[9] train_loss: 1.9883
[9] train_loss: 2.0428
[9] train_loss: 2.0935
[9] train_loss: 2.1563
[9] train_loss: 2.2014
1.5779047012329102

Evaluating...Epoch: 9
Prec: 0.6960, Recall: 0.6984, F1: 0.6972

[10] train_loss: 1.8705
[10] train_loss: 1.9258
[10] train_loss: 1.8547
[10] train_loss: 1.8118
[10] train_loss: 1.8334
[10] train_loss: 1.8147
[10] train_loss: 1.8571
[10] train_loss: 1.9068
[10] train_loss: 1.9745
[10] train_loss: 2.0275
1.5798048973083496

Evaluating...Epoch: 10
Prec: 0.6815, Recall: 0.6755, F1: 0.6785

[11] train_loss: 1.8573
[11] train_loss: 1.8411
[11] train_loss: 1.7911
[11] train_loss: 1.7368
[11] train_loss: 1.7292
[11] train_loss: 1.7558
[11] train_loss: 1.8104
[11] train_loss: 1.8280
[11] train_loss: 1.9076
[11] train_loss: 1.9782
1.6499578952789307

Evaluating...Epoch: 11
Prec: 0.7043, Recall: 0.6596, F1: 0.6812

[12] train_loss: 1.8047
[12] train_loss: 1.7789
[12] train_loss: 1.7523
[12] train_loss: 1.6943
[12] train_loss: 1.6993
[12] train_loss: 1.6623
[12] train_loss: 1.7228
[12] train_loss: 1.7814
[12] train_loss: 1.8227
[12] train_loss: 1.8724
1.5732519626617432

Evaluating...Epoch: 12
Prec: 0.6789, Recall: 0.7160, F1: 0.6970

[13] train_loss: 1.5512
[13] train_loss: 1.5965
[13] train_loss: 1.5774
[13] train_loss: 1.5348
[13] train_loss: 1.5252
[13] train_loss: 1.5049
[13] train_loss: 1.5496
[13] train_loss: 1.6047
[13] train_loss: 1.6608
[13] train_loss: 1.6933
1.5697309970855713

Evaluating...Epoch: 13
Prec: 0.6838, Recall: 0.7019, F1: 0.6928

[14] train_loss: 1.6787
[14] train_loss: 1.6689
[14] train_loss: 1.5895
[14] train_loss: 1.4985
[14] train_loss: 1.5143
[14] train_loss: 1.5094
[14] train_loss: 1.5351
[14] train_loss: 1.5660
[14] train_loss: 1.6095
[14] train_loss: 1.6498
1.5510034561157227

Evaluating...Epoch: 14
Prec: 0.7096, Recall: 0.6896, F1: 0.6995

[15] train_loss: 1.4369
[15] train_loss: 1.5053
[15] train_loss: 1.4867
[15] train_loss: 1.4193
[15] train_loss: 1.4180
[15] train_loss: 1.4112
[15] train_loss: 1.4403
[15] train_loss: 1.4669
[15] train_loss: 1.5160
[15] train_loss: 1.5505
1.5738458633422852

Evaluating...Epoch: 15
Prec: 0.6843, Recall: 0.7072, F1: 0.6956

[16] train_loss: 1.4490
[16] train_loss: 1.3639
[16] train_loss: 1.3762
[16] train_loss: 1.2759
[16] train_loss: 1.2661
[16] train_loss: 1.2940
[16] train_loss: 1.3490
[16] train_loss: 1.3926
[16] train_loss: 1.4176
[16] train_loss: 1.4537
1.5752558708190918

Evaluating...Epoch: 16
Prec: 0.7007, Recall: 0.7390, F1: 0.7193
model saved to random1_layers2_14lap/best_model.pt
New best model saved!

[17] train_loss: 1.3301
[17] train_loss: 1.3593
[17] train_loss: 1.3439
[17] train_loss: 1.2583
[17] train_loss: 1.2739
[17] train_loss: 1.2767
[17] train_loss: 1.3105
[17] train_loss: 1.3575
[17] train_loss: 1.3958
[17] train_loss: 1.4444
1.6351993083953857

Evaluating...Epoch: 17
Prec: 0.6737, Recall: 0.7319, F1: 0.7016

[18] train_loss: 1.3322
[18] train_loss: 1.4015
[18] train_loss: 1.3130
[18] train_loss: 1.2336
[18] train_loss: 1.2229
[18] train_loss: 1.2372
[18] train_loss: 1.2879
[18] train_loss: 1.3265
[18] train_loss: 1.3786
[18] train_loss: 1.4068
1.5724620819091797

Evaluating...Epoch: 18
Prec: 0.6915, Recall: 0.7354, F1: 0.7128

[19] train_loss: 1.3855
[19] train_loss: 1.2784
[19] train_loss: 1.2355
[19] train_loss: 1.1670
[19] train_loss: 1.1618
[19] train_loss: 1.1603
[19] train_loss: 1.1927
[19] train_loss: 1.2095
[19] train_loss: 1.2313
[19] train_loss: 1.2729
1.5526509284973145

Evaluating...Epoch: 19
Prec: 0.6970, Recall: 0.7425, F1: 0.7190

[20] train_loss: 1.3170
[20] train_loss: 1.2533
[20] train_loss: 1.2582
[20] train_loss: 1.1699
[20] train_loss: 1.1402
[20] train_loss: 1.1084
[20] train_loss: 1.1355
[20] train_loss: 1.1864
[20] train_loss: 1.2103
[20] train_loss: 1.2380
1.5647022724151611

Evaluating...Epoch: 20
Prec: 0.7243, Recall: 0.7090, F1: 0.7166

[21] train_loss: 1.2312
[21] train_loss: 1.2594
[21] train_loss: 1.1679
[21] train_loss: 1.1206
[21] train_loss: 1.1094
[21] train_loss: 1.1054
[21] train_loss: 1.1149
[21] train_loss: 1.1507
[21] train_loss: 1.1775
[21] train_loss: 1.2122
1.5790538787841797

Evaluating...Epoch: 21
Prec: 0.7413, Recall: 0.7178, F1: 0.7294
model saved to random1_layers2_14lap/best_model.pt
New best model saved!

[22] train_loss: 1.0755
[22] train_loss: 0.9962
[22] train_loss: 0.9808
[22] train_loss: 0.9541
[22] train_loss: 0.9458
[22] train_loss: 0.9399
[22] train_loss: 0.9814
[22] train_loss: 1.0239
[22] train_loss: 1.0719
[22] train_loss: 1.1249
1.6356711387634277

Evaluating...Epoch: 22
Prec: 0.7299, Recall: 0.7055, F1: 0.7175

[23] train_loss: 1.0228
[23] train_loss: 0.9865
[23] train_loss: 0.9531
[23] train_loss: 0.9309
[23] train_loss: 0.9533
[23] train_loss: 0.9841
[23] train_loss: 0.9917
[23] train_loss: 1.0224
[23] train_loss: 1.0717
[23] train_loss: 1.1005
1.5695586204528809

Evaluating...Epoch: 23
Prec: 0.7098, Recall: 0.7249, F1: 0.7173

[24] train_loss: 1.1152
[24] train_loss: 1.0707
[24] train_loss: 1.0009
[24] train_loss: 0.9440
[24] train_loss: 0.9173
[24] train_loss: 0.9473
[24] train_loss: 0.9803
[24] train_loss: 1.0063
[24] train_loss: 1.0112
[24] train_loss: 1.0493
1.5711479187011719

Evaluating...Epoch: 24
Prec: 0.7278, Recall: 0.7213, F1: 0.7245

[25] train_loss: 1.0415
[25] train_loss: 0.9405
[25] train_loss: 0.9171
[25] train_loss: 0.8769
[25] train_loss: 0.8870
[25] train_loss: 0.8803
[25] train_loss: 0.9114
[25] train_loss: 0.9437
[25] train_loss: 0.9707
[25] train_loss: 0.9890
1.5685875415802002

Evaluating...Epoch: 25
Prec: 0.7086, Recall: 0.7160, F1: 0.7123

[26] train_loss: 1.0586
[26] train_loss: 1.0679
[26] train_loss: 0.9626
[26] train_loss: 0.8518
[26] train_loss: 0.8385
[26] train_loss: 0.8341
[26] train_loss: 0.8673
[26] train_loss: 0.8908
[26] train_loss: 0.9171
[26] train_loss: 0.9620
1.5722622871398926

Evaluating...Epoch: 26
Prec: 0.7258, Recall: 0.7002, F1: 0.7127

[27] train_loss: 0.9570
[27] train_loss: 0.9223
[27] train_loss: 0.9140
[27] train_loss: 0.8578
[27] train_loss: 0.8355
[27] train_loss: 0.8137
[27] train_loss: 0.8035
[27] train_loss: 0.8250
[27] train_loss: 0.8552
[27] train_loss: 0.8881
1.6305336952209473

Evaluating...Epoch: 27
Prec: 0.7140, Recall: 0.7002, F1: 0.7070

[28] train_loss: 0.9054
[28] train_loss: 0.8670
[28] train_loss: 0.8001
[28] train_loss: 0.7611
[28] train_loss: 0.7703
[28] train_loss: 0.7595
[28] train_loss: 0.7795
[28] train_loss: 0.8094
[28] train_loss: 0.8353
[28] train_loss: 0.8718
1.5660293102264404

Evaluating...Epoch: 28
Prec: 0.7246, Recall: 0.7055, F1: 0.7149

[29] train_loss: 0.8168
[29] train_loss: 0.8427
[29] train_loss: 0.8308
[29] train_loss: 0.7742
[29] train_loss: 0.7918
[29] train_loss: 0.8015
[29] train_loss: 0.8185
[29] train_loss: 0.8395
[29] train_loss: 0.8952
[29] train_loss: 0.9197
1.5608646869659424

Evaluating...Epoch: 29
Prec: 0.7213, Recall: 0.6755, F1: 0.6976

[30] train_loss: 0.8284
[30] train_loss: 0.7690
[30] train_loss: 0.7298
[30] train_loss: 0.7111
[30] train_loss: 0.7188
[30] train_loss: 0.7199
[30] train_loss: 0.7425
[30] train_loss: 0.7836
[30] train_loss: 0.8325
[30] train_loss: 0.8662
1.5615549087524414

Evaluating...Epoch: 30
Prec: 0.7408, Recall: 0.7108, F1: 0.7255

[31] train_loss: 0.8290
[31] train_loss: 0.8335
[31] train_loss: 0.7780
[31] train_loss: 0.7012
[31] train_loss: 0.6716
[31] train_loss: 0.6596
[31] train_loss: 0.6783
[31] train_loss: 0.7122
[31] train_loss: 0.7510
[31] train_loss: 0.7798
1.5682449340820312

Evaluating...Epoch: 31
Prec: 0.7397, Recall: 0.6966, F1: 0.7175

[32] train_loss: 0.7407
[32] train_loss: 0.7561
[32] train_loss: 0.7520
[32] train_loss: 0.6758
[32] train_loss: 0.6872
[32] train_loss: 0.6759
[32] train_loss: 0.7095
[32] train_loss: 0.7328
[32] train_loss: 0.7560
[32] train_loss: 0.7845
1.642660140991211

Evaluating...Epoch: 32
Prec: 0.7225, Recall: 0.6843, F1: 0.7029

[33] train_loss: 0.8347
[33] train_loss: 0.7849
[33] train_loss: 0.7383
[33] train_loss: 0.6737
[33] train_loss: 0.6739
[33] train_loss: 0.6752
[33] train_loss: 0.6897
[33] train_loss: 0.7067
[33] train_loss: 0.7062
[33] train_loss: 0.7387
1.5566918849945068

Evaluating...Epoch: 33
Prec: 0.7324, Recall: 0.7143, F1: 0.7232

[34] train_loss: 0.9326
[34] train_loss: 0.8042
[34] train_loss: 0.7606
[34] train_loss: 0.7060
[34] train_loss: 0.6796
[34] train_loss: 0.6788
[34] train_loss: 0.7028
[34] train_loss: 0.7042
[34] train_loss: 0.7353
[34] train_loss: 0.7562
1.55415678024292

Evaluating...Epoch: 34
Prec: 0.7203, Recall: 0.6949, F1: 0.7074

[35] train_loss: 0.7750
[35] train_loss: 0.6342
[35] train_loss: 0.5874
[35] train_loss: 0.5302
[35] train_loss: 0.5490
[35] train_loss: 0.5710
[35] train_loss: 0.5975
[35] train_loss: 0.6096
[35] train_loss: 0.6222
[35] train_loss: 0.6361
1.5795536041259766

Evaluating...Epoch: 35
Prec: 0.7326, Recall: 0.7249, F1: 0.7287

[36] train_loss: 0.5935
[36] train_loss: 0.5989
[36] train_loss: 0.6319
[36] train_loss: 0.5825
[36] train_loss: 0.5647
[36] train_loss: 0.5482
[36] train_loss: 0.5634
[36] train_loss: 0.5842
[36] train_loss: 0.6157
[36] train_loss: 0.6346
1.5647430419921875

Evaluating...Epoch: 36
Prec: 0.7399, Recall: 0.7072, F1: 0.7232

[37] train_loss: 0.7016
[37] train_loss: 0.6305
[37] train_loss: 0.6251
[37] train_loss: 0.5607
[37] train_loss: 0.5439
[37] train_loss: 0.5434
[37] train_loss: 0.5695
[37] train_loss: 0.5890
[37] train_loss: 0.6039
[37] train_loss: 0.6222
1.629723310470581

Evaluating...Epoch: 37
Prec: 0.7071, Recall: 0.6896, F1: 0.6982

[38] train_loss: 0.7797
[38] train_loss: 0.6571
[38] train_loss: 0.5848
[38] train_loss: 0.5259
[38] train_loss: 0.5211
[38] train_loss: 0.4991
[38] train_loss: 0.5062
[38] train_loss: 0.5391
[38] train_loss: 0.5605
[38] train_loss: 0.5917
1.557471752166748

Evaluating...Epoch: 38
Prec: 0.7243, Recall: 0.6949, F1: 0.7093

[39] train_loss: 0.5881
[39] train_loss: 0.5633
[39] train_loss: 0.5342
[39] train_loss: 0.4967
[39] train_loss: 0.4951
[39] train_loss: 0.5038
[39] train_loss: 0.5027
[39] train_loss: 0.5362
[39] train_loss: 0.5532
[39] train_loss: 0.5692
1.5598461627960205

Evaluating...Epoch: 39
Prec: 0.7175, Recall: 0.6720, F1: 0.6940

[40] train_loss: 0.6378
[40] train_loss: 0.5357
[40] train_loss: 0.5391
[40] train_loss: 0.4995
[40] train_loss: 0.5145
[40] train_loss: 0.5215
[40] train_loss: 0.5312
[40] train_loss: 0.5419
[40] train_loss: 0.5698
[40] train_loss: 0.5768
1.5629644393920898

Evaluating...Epoch: 40
Prec: 0.7408, Recall: 0.6755, F1: 0.7066

[41] train_loss: 0.5122
[41] train_loss: 0.5135
[41] train_loss: 0.4984
[41] train_loss: 0.4630
[41] train_loss: 0.4469
[41] train_loss: 0.4490
[41] train_loss: 0.4653
[41] train_loss: 0.4784
[41] train_loss: 0.4985
[41] train_loss: 0.5126
1.5675849914550781

Evaluating...Epoch: 41
Prec: 0.7611, Recall: 0.7249, F1: 0.7425
model saved to random1_layers2_14lap/best_model.pt
New best model saved!

[42] train_loss: 0.5244
[42] train_loss: 0.4603
[42] train_loss: 0.4681
[42] train_loss: 0.4252
[42] train_loss: 0.4355
[42] train_loss: 0.4273
[42] train_loss: 0.4509
[42] train_loss: 0.4993
[42] train_loss: 0.5118
[42] train_loss: 0.5301
1.6292071342468262

Evaluating...Epoch: 42
Prec: 0.7694, Recall: 0.7178, F1: 0.7427
model saved to random1_layers2_14lap/best_model.pt
New best model saved!

[43] train_loss: 0.5516
[43] train_loss: 0.5647
[43] train_loss: 0.5471
[43] train_loss: 0.5080
[43] train_loss: 0.4984
[43] train_loss: 0.4942
[43] train_loss: 0.4939
[43] train_loss: 0.4939
[43] train_loss: 0.5268
[43] train_loss: 0.5587
1.5652515888214111

Evaluating...Epoch: 43
Prec: 0.7403, Recall: 0.7037, F1: 0.7215

[44] train_loss: 0.5006
[44] train_loss: 0.4850
[44] train_loss: 0.4555
[44] train_loss: 0.4122
[44] train_loss: 0.4109
[44] train_loss: 0.4084
[44] train_loss: 0.4315
[44] train_loss: 0.4639
[44] train_loss: 0.4769
[44] train_loss: 0.4758
1.5673654079437256

Evaluating...Epoch: 44
Prec: 0.7612, Recall: 0.6914, F1: 0.7246

[45] train_loss: 0.5732
[45] train_loss: 0.5447
[45] train_loss: 0.5557
[45] train_loss: 0.4840
[45] train_loss: 0.4820
[45] train_loss: 0.4728
[45] train_loss: 0.4879
[45] train_loss: 0.4944
[45] train_loss: 0.5022
[45] train_loss: 0.5157
1.566525936126709

Evaluating...Epoch: 45
Prec: 0.7520, Recall: 0.6737, F1: 0.7107

[46] train_loss: 0.4744
[46] train_loss: 0.5339
[46] train_loss: 0.4999
[46] train_loss: 0.4662
[46] train_loss: 0.4578
[46] train_loss: 0.4393
[46] train_loss: 0.4548
[46] train_loss: 0.4620
[46] train_loss: 0.4771
[46] train_loss: 0.4987
1.567931890487671

Evaluating...Epoch: 46
Prec: 0.7709, Recall: 0.6825, F1: 0.7240

[47] train_loss: 0.5488
[47] train_loss: 0.4942
[47] train_loss: 0.4511
[47] train_loss: 0.4031
[47] train_loss: 0.4211
[47] train_loss: 0.4127
[47] train_loss: 0.3942
[47] train_loss: 0.4096
[47] train_loss: 0.4287
[47] train_loss: 0.4426
1.632641315460205

Evaluating...Epoch: 47
Prec: 0.7816, Recall: 0.6755, F1: 0.7247

[48] train_loss: 0.5212
[48] train_loss: 0.4818
[48] train_loss: 0.4764
[48] train_loss: 0.4358
[48] train_loss: 0.4401
[48] train_loss: 0.4396
[48] train_loss: 0.4463
[48] train_loss: 0.4340
[48] train_loss: 0.4480
[48] train_loss: 0.4452
1.5585951805114746

Evaluating...Epoch: 48
Prec: 0.7466, Recall: 0.6861, F1: 0.7151

[49] train_loss: 0.8045
[49] train_loss: 0.5919
[49] train_loss: 0.5143
[49] train_loss: 0.4714
[49] train_loss: 0.4511
[49] train_loss: 0.4385
[49] train_loss: 0.4196
[49] train_loss: 0.4219
[49] train_loss: 0.4377
[49] train_loss: 0.4582
1.5600757598876953

Evaluating...Epoch: 49
Prec: 0.7385, Recall: 0.6825, F1: 0.7094

[50] train_loss: 0.4916
[50] train_loss: 0.4274
[50] train_loss: 0.4488
[50] train_loss: 0.3874
[50] train_loss: 0.3819
[50] train_loss: 0.3770
[50] train_loss: 0.3626
[50] train_loss: 0.3929
[50] train_loss: 0.4144
[50] train_loss: 0.4250
1.5631439685821533

Evaluating...Epoch: 50
Prec: 0.7249, Recall: 0.6878, F1: 0.7059

[51] train_loss: 0.5885
[51] train_loss: 0.4690
[51] train_loss: 0.4214
[51] train_loss: 0.3883
[51] train_loss: 0.3790
[51] train_loss: 0.3953
[51] train_loss: 0.3806
[51] train_loss: 0.4118
[51] train_loss: 0.4357
[51] train_loss: 0.4493
1.5695874691009521

Evaluating...Epoch: 51
Prec: 0.7569, Recall: 0.6755, F1: 0.7139

[52] train_loss: 0.3888
[52] train_loss: 0.4042
[52] train_loss: 0.3750
[52] train_loss: 0.3533
[52] train_loss: 0.3426
[52] train_loss: 0.3342
[52] train_loss: 0.3442
[52] train_loss: 0.3909
[52] train_loss: 0.3969
[52] train_loss: 0.4154
1.5624902248382568

Evaluating...Epoch: 52
Prec: 0.7750, Recall: 0.6984, F1: 0.7347

[53] train_loss: 0.4504
[53] train_loss: 0.4241
[53] train_loss: 0.4358
[53] train_loss: 0.3808
[53] train_loss: 0.3859
[53] train_loss: 0.3661
[53] train_loss: 0.3668
[53] train_loss: 0.3717
[53] train_loss: 0.3958
[53] train_loss: 0.4241
1.6108198165893555

Evaluating...Epoch: 53
Prec: 0.7793, Recall: 0.6914, F1: 0.7327

[54] train_loss: 0.3423
[54] train_loss: 0.3550
[54] train_loss: 0.3621
[54] train_loss: 0.3531
[54] train_loss: 0.3330
[54] train_loss: 0.3319
[54] train_loss: 0.3409
[54] train_loss: 0.3441
[54] train_loss: 0.3594
[54] train_loss: 0.3945
1.5663375854492188

Evaluating...Epoch: 54
Prec: 0.7417, Recall: 0.7443, F1: 0.7430
model saved to random1_layers2_14lap/best_model.pt
New best model saved!

[55] train_loss: 0.5262
[55] train_loss: 0.4756
[55] train_loss: 0.4079
[55] train_loss: 0.3722
[55] train_loss: 0.3512
[55] train_loss: 0.3374
[55] train_loss: 0.3501
[55] train_loss: 0.3410
[55] train_loss: 0.3838
[55] train_loss: 0.4020
1.5654137134552002

Evaluating...Epoch: 55
Prec: 0.7405, Recall: 0.7196, F1: 0.7299

[56] train_loss: 0.4001
[56] train_loss: 0.4042
[56] train_loss: 0.3630
[56] train_loss: 0.3375
[56] train_loss: 0.3392
[56] train_loss: 0.3349
[56] train_loss: 0.3292
[56] train_loss: 0.3296
[56] train_loss: 0.3409
[56] train_loss: 0.3529
1.5711421966552734

Evaluating...Epoch: 56
Prec: 0.7537, Recall: 0.7231, F1: 0.7381

[57] train_loss: 0.4695
[57] train_loss: 0.3702
[57] train_loss: 0.3312
[57] train_loss: 0.2883
[57] train_loss: 0.2928
[57] train_loss: 0.2919
[57] train_loss: 0.2923
[57] train_loss: 0.3211
[57] train_loss: 0.3353
[57] train_loss: 0.3529
1.568044900894165

Evaluating...Epoch: 57
Prec: 0.7566, Recall: 0.7125, F1: 0.7339

[58] train_loss: 0.3545
[58] train_loss: 0.3698
[58] train_loss: 0.3605
[58] train_loss: 0.3318
[58] train_loss: 0.3267
[58] train_loss: 0.3152
[58] train_loss: 0.3211
[58] train_loss: 0.3452
[58] train_loss: 0.3483
[58] train_loss: 0.3803
1.601653814315796

Evaluating...Epoch: 58
Prec: 0.7381, Recall: 0.7407, F1: 0.7394

[59] train_loss: 0.3359
[59] train_loss: 0.3462
[59] train_loss: 0.3156
[59] train_loss: 0.2874
[59] train_loss: 0.2767
[59] train_loss: 0.2784
[59] train_loss: 0.3000
[59] train_loss: 0.2929
[59] train_loss: 0.3053
[59] train_loss: 0.3224
1.557650089263916

Evaluating...Epoch: 59
Prec: 0.7715, Recall: 0.6966, F1: 0.7322

[60] train_loss: 0.3417
[60] train_loss: 0.3558
[60] train_loss: 0.3352
[60] train_loss: 0.2873
[60] train_loss: 0.2638
[60] train_loss: 0.2690
[60] train_loss: 0.2706
[60] train_loss: 0.2875
[60] train_loss: 0.3012
[60] train_loss: 0.3117
1.5767874717712402

Evaluating...Epoch: 60
Prec: 0.7633, Recall: 0.7108, F1: 0.7361

[61] train_loss: 0.2587
[61] train_loss: 0.2345
[61] train_loss: 0.2636
[61] train_loss: 0.2500
[61] train_loss: 0.2576
[61] train_loss: 0.2548
[61] train_loss: 0.2739
[61] train_loss: 0.2885
[61] train_loss: 0.3179
[61] train_loss: 0.3391
1.5792322158813477

Evaluating...Epoch: 61
Prec: 0.7437, Recall: 0.7266, F1: 0.7351

[62] train_loss: 0.4291
[62] train_loss: 0.3479
[62] train_loss: 0.3014
[62] train_loss: 0.2755
[62] train_loss: 0.3021
[62] train_loss: 0.3053
[62] train_loss: 0.2996
[62] train_loss: 0.3043
[62] train_loss: 0.3355
[62] train_loss: 0.3336
1.584012746810913

Evaluating...Epoch: 62
Prec: 0.7561, Recall: 0.7055, F1: 0.7299

[63] train_loss: 0.3583
[63] train_loss: 0.3013
[63] train_loss: 0.2649
[63] train_loss: 0.2683
[63] train_loss: 0.2657
[63] train_loss: 0.2879
[63] train_loss: 0.3006
[63] train_loss: 0.3305
[63] train_loss: 0.3187
[63] train_loss: 0.3351
1.6496291160583496

Evaluating...Epoch: 63
Prec: 0.7472, Recall: 0.7037, F1: 0.7248

[64] train_loss: 0.4847
[64] train_loss: 0.4531
[64] train_loss: 0.3822
[64] train_loss: 0.3366
[64] train_loss: 0.3247
[64] train_loss: 0.3031
[64] train_loss: 0.2962
[64] train_loss: 0.3028
[64] train_loss: 0.3116
[64] train_loss: 0.3276
1.582482099533081

Evaluating...Epoch: 64
Prec: 0.7341, Recall: 0.7108, F1: 0.7222

[65] train_loss: 0.3265
[65] train_loss: 0.2685
[65] train_loss: 0.2319
[65] train_loss: 0.2354
[65] train_loss: 0.2296
[65] train_loss: 0.2208
[65] train_loss: 0.2415
[65] train_loss: 0.2537
[65] train_loss: 0.2724
[65] train_loss: 0.2784
1.585026741027832

Evaluating...Epoch: 65
Prec: 0.7444, Recall: 0.7090, F1: 0.7263

[66] train_loss: 0.3630
[66] train_loss: 0.3297
[66] train_loss: 0.3012
[66] train_loss: 0.2776
[66] train_loss: 0.2696
[66] train_loss: 0.2813
[66] train_loss: 0.2852
[66] train_loss: 0.2805
[66] train_loss: 0.2947
[66] train_loss: 0.3198
1.5928685665130615

Evaluating...Epoch: 66
Prec: 0.7454, Recall: 0.7125, F1: 0.7286

[67] train_loss: 0.2592
[67] train_loss: 0.2455
[67] train_loss: 0.2388
[67] train_loss: 0.2194
[67] train_loss: 0.2191
[67] train_loss: 0.2210
[67] train_loss: 0.2326
[67] train_loss: 0.2342
[67] train_loss: 0.2497
[67] train_loss: 0.2643
1.5879993438720703

Evaluating...Epoch: 67
Prec: 0.7597, Recall: 0.6914, F1: 0.7239

[68] train_loss: 0.2742
[68] train_loss: 0.3077
[68] train_loss: 0.3380
[68] train_loss: 0.2978
[68] train_loss: 0.2819
[68] train_loss: 0.2943
[68] train_loss: 0.2938
[68] train_loss: 0.2884
[68] train_loss: 0.2993
[68] train_loss: 0.3001
1.6448209285736084

Evaluating...Epoch: 68
Prec: 0.7495, Recall: 0.7178, F1: 0.7333

[69] train_loss: 0.3312
[69] train_loss: 0.3240
[69] train_loss: 0.2828
[69] train_loss: 0.2584
[69] train_loss: 0.2526
[69] train_loss: 0.2582
[69] train_loss: 0.2525
[69] train_loss: 0.2651
[69] train_loss: 0.2683
[69] train_loss: 0.2757
1.5828640460968018

Evaluating...Epoch: 69
Prec: 0.7542, Recall: 0.7090, F1: 0.7309

[70] train_loss: 0.3061
[70] train_loss: 0.3435
[70] train_loss: 0.2669
[70] train_loss: 0.2559
[70] train_loss: 0.2424
[70] train_loss: 0.2621
[70] train_loss: 0.2527
[70] train_loss: 0.2536
[70] train_loss: 0.2536
[70] train_loss: 0.2710
1.580817461013794

Evaluating...Epoch: 70
Prec: 0.7577, Recall: 0.7337, F1: 0.7455
model saved to random1_layers2_14lap/best_model.pt
New best model saved!

[71] train_loss: 0.2963
[71] train_loss: 0.2662
[71] train_loss: 0.2653
[71] train_loss: 0.2265
[71] train_loss: 0.2218
[71] train_loss: 0.2244
[71] train_loss: 0.2242
[71] train_loss: 0.2393
[71] train_loss: 0.2497
[71] train_loss: 0.2605
1.5813751220703125

Evaluating...Epoch: 71
Prec: 0.7500, Recall: 0.7090, F1: 0.7289

[72] train_loss: 0.4227
[72] train_loss: 0.2879
[72] train_loss: 0.2538
[72] train_loss: 0.2270
[72] train_loss: 0.2470
[72] train_loss: 0.2492
[72] train_loss: 0.2564
[72] train_loss: 0.2610
[72] train_loss: 0.2674
[72] train_loss: 0.2750
1.5640456676483154

Evaluating...Epoch: 72
Prec: 0.7648, Recall: 0.7284, F1: 0.7462
model saved to random1_layers2_14lap/best_model.pt
New best model saved!

[73] train_loss: 0.2595
[73] train_loss: 0.2181
[73] train_loss: 0.1962
[73] train_loss: 0.1813
[73] train_loss: 0.1844
[73] train_loss: 0.1959
[73] train_loss: 0.1984
[73] train_loss: 0.2168
[73] train_loss: 0.2372
[73] train_loss: 0.2455
1.646024465560913

Evaluating...Epoch: 73
Prec: 0.7405, Recall: 0.7196, F1: 0.7299

[74] train_loss: 0.3041
[74] train_loss: 0.2812
[74] train_loss: 0.2319
[74] train_loss: 0.2098
[74] train_loss: 0.2143
[74] train_loss: 0.2197
[74] train_loss: 0.2233
[74] train_loss: 0.2356
[74] train_loss: 0.2609
[74] train_loss: 0.2665
1.5744647979736328

Evaluating...Epoch: 74
Prec: 0.7558, Recall: 0.6931, F1: 0.7231

[75] train_loss: 0.1834
[75] train_loss: 0.2077
[75] train_loss: 0.2104
[75] train_loss: 0.1958
[75] train_loss: 0.2161
[75] train_loss: 0.2203
[75] train_loss: 0.2334
[75] train_loss: 0.2472
[75] train_loss: 0.2569
[75] train_loss: 0.2603
1.5869357585906982

Evaluating...Epoch: 75
Prec: 0.7857, Recall: 0.6790, F1: 0.7285

[76] train_loss: 0.3252
[76] train_loss: 0.3216
[76] train_loss: 0.3001
[76] train_loss: 0.2559
[76] train_loss: 0.2447
[76] train_loss: 0.2421
[76] train_loss: 0.2335
[76] train_loss: 0.2424
[76] train_loss: 0.2453
[76] train_loss: 0.2535
1.582972526550293

Evaluating...Epoch: 76
Prec: 0.7664, Recall: 0.7002, F1: 0.7318

[77] train_loss: 0.2551
[77] train_loss: 0.2627
[77] train_loss: 0.2322
[77] train_loss: 0.2111
[77] train_loss: 0.2145
[77] train_loss: 0.2086
[77] train_loss: 0.2021
[77] train_loss: 0.2104
[77] train_loss: 0.2256
[77] train_loss: 0.2294
1.5819246768951416

Evaluating...Epoch: 77
Prec: 0.7532, Recall: 0.7160, F1: 0.7342

[78] train_loss: 0.2243
[78] train_loss: 0.2183
[78] train_loss: 0.1853
[78] train_loss: 0.1764
[78] train_loss: 0.2006
[78] train_loss: 0.2138
[78] train_loss: 0.2134
[78] train_loss: 0.2336
[78] train_loss: 0.2438
[78] train_loss: 0.2595
1.5909595489501953

Evaluating...Epoch: 78
Prec: 0.7601, Recall: 0.6984, F1: 0.7279

[79] train_loss: 0.1614
[79] train_loss: 0.1683
[79] train_loss: 0.1637
[79] train_loss: 0.1658
[79] train_loss: 0.1723
[79] train_loss: 0.1790
[79] train_loss: 0.1741
[79] train_loss: 0.1982
[79] train_loss: 0.2086
[79] train_loss: 0.2200
1.5838623046875

Evaluating...Epoch: 79
Prec: 0.7543, Recall: 0.6931, F1: 0.7224

[80] train_loss: 0.1874
[80] train_loss: 0.2205
[80] train_loss: 0.2084
[80] train_loss: 0.1905
[80] train_loss: 0.1859
[80] train_loss: 0.1910
[80] train_loss: 0.1854
[80] train_loss: 0.1918
[80] train_loss: 0.1961
[80] train_loss: 0.2154
1.5830399990081787

Evaluating...Epoch: 80
Prec: 0.7616, Recall: 0.7213, F1: 0.7409

[81] train_loss: 0.2340
[81] train_loss: 0.2103
[81] train_loss: 0.1956
[81] train_loss: 0.1760
[81] train_loss: 0.1981
[81] train_loss: 0.1970
[81] train_loss: 0.1975
[81] train_loss: 0.2037
[81] train_loss: 0.2095
[81] train_loss: 0.2227
1.5838842391967773

Evaluating...Epoch: 81
Prec: 0.7765, Recall: 0.7231, F1: 0.7489
model saved to random1_layers2_14lap/best_model.pt
New best model saved!

[82] train_loss: 0.2151
[82] train_loss: 0.2014
[82] train_loss: 0.1846
[82] train_loss: 0.1738
[82] train_loss: 0.1755
[82] train_loss: 0.1733
[82] train_loss: 0.1808
[82] train_loss: 0.1793
[82] train_loss: 0.1896
[82] train_loss: 0.2027
1.5805683135986328

Evaluating...Epoch: 82
Prec: 0.7694, Recall: 0.7354, F1: 0.7520
model saved to random1_layers2_14lap/best_model.pt
New best model saved!

[83] train_loss: 0.2684
[83] train_loss: 0.2540
[83] train_loss: 0.2554
[83] train_loss: 0.2274
[83] train_loss: 0.2022
[83] train_loss: 0.2093
[83] train_loss: 0.2235
[83] train_loss: 0.2159
[83] train_loss: 0.2096
[83] train_loss: 0.2159
1.636106252670288

Evaluating...Epoch: 83
Prec: 0.7686, Recall: 0.7090, F1: 0.7376

[84] train_loss: 0.2178
[84] train_loss: 0.2013
[84] train_loss: 0.2129
[84] train_loss: 0.2076
[84] train_loss: 0.2018
[84] train_loss: 0.1910
[84] train_loss: 0.2291
[84] train_loss: 0.2348
[84] train_loss: 0.2401
[84] train_loss: 0.2651
1.571485996246338

Evaluating...Epoch: 84
Prec: 0.7784, Recall: 0.6878, F1: 0.7303

[85] train_loss: 0.2355
[85] train_loss: 0.2388
[85] train_loss: 0.2024
[85] train_loss: 0.1780
[85] train_loss: 0.1743
[85] train_loss: 0.1719
[85] train_loss: 0.1713
[85] train_loss: 0.1749
[85] train_loss: 0.1783
[85] train_loss: 0.1805
1.5772113800048828

Evaluating...Epoch: 85
Prec: 0.7598, Recall: 0.7143, F1: 0.7364

[86] train_loss: 0.2366
[86] train_loss: 0.1925
[86] train_loss: 0.1765
[86] train_loss: 0.1711
[86] train_loss: 0.1576
[86] train_loss: 0.1649
[86] train_loss: 0.1643
[86] train_loss: 0.1920
[86] train_loss: 0.1907
[86] train_loss: 0.1933
1.5849289894104004

Evaluating...Epoch: 86
Prec: 0.7612, Recall: 0.7196, F1: 0.7398

[87] train_loss: 0.3250
[87] train_loss: 0.2407
[87] train_loss: 0.2135
[87] train_loss: 0.1981
[87] train_loss: 0.2041
[87] train_loss: 0.1985
[87] train_loss: 0.2000
[87] train_loss: 0.1998
[87] train_loss: 0.2135
[87] train_loss: 0.2171
1.5853385925292969

Evaluating...Epoch: 87
Prec: 0.7459, Recall: 0.7249, F1: 0.7352

[88] train_loss: 0.3659
[88] train_loss: 0.3004
[88] train_loss: 0.2471
[88] train_loss: 0.2158
[88] train_loss: 0.2018
[88] train_loss: 0.1949
[88] train_loss: 0.1957
[88] train_loss: 0.2027
[88] train_loss: 0.2129
[88] train_loss: 0.2072
1.6414787769317627

Evaluating...Epoch: 88
Prec: 0.7697, Recall: 0.7249, F1: 0.7466

[89] train_loss: 0.3552
[89] train_loss: 0.3231
[89] train_loss: 0.2654
[89] train_loss: 0.2326
[89] train_loss: 0.2186
[89] train_loss: 0.2137
[89] train_loss: 0.2200
[89] train_loss: 0.2247
[89] train_loss: 0.2353
[89] train_loss: 0.2592
1.5635437965393066

Evaluating...Epoch: 89
Prec: 0.7670, Recall: 0.7143, F1: 0.7397

[90] train_loss: 0.2120
[90] train_loss: 0.2419
[90] train_loss: 0.2123
[90] train_loss: 0.2029
[90] train_loss: 0.1860
[90] train_loss: 0.1753
[90] train_loss: 0.1874
[90] train_loss: 0.2011
[90] train_loss: 0.2184
[90] train_loss: 0.2268
1.5624535083770752

Evaluating...Epoch: 90
Prec: 0.7571, Recall: 0.7037, F1: 0.7294

[91] train_loss: 0.1670
[91] train_loss: 0.2025
[91] train_loss: 0.1777
[91] train_loss: 0.1557
[91] train_loss: 0.1557
[91] train_loss: 0.1416
[91] train_loss: 0.1446
[91] train_loss: 0.1430
[91] train_loss: 0.1704
[91] train_loss: 0.1962
1.5843791961669922

Evaluating...Epoch: 91
Prec: 0.7509, Recall: 0.7178, F1: 0.7340

[92] train_loss: 0.2712
[92] train_loss: 0.2578
[92] train_loss: 0.2289
[92] train_loss: 0.2119
[92] train_loss: 0.1956
[92] train_loss: 0.1891
[92] train_loss: 0.1840
[92] train_loss: 0.1852
[92] train_loss: 0.1925
[92] train_loss: 0.2001
1.5887980461120605

Evaluating...Epoch: 92
Prec: 0.7670, Recall: 0.6966, F1: 0.7301

[93] train_loss: 0.2032
[93] train_loss: 0.1868
[93] train_loss: 0.2142
[93] train_loss: 0.1908
[93] train_loss: 0.2030
[93] train_loss: 0.1913
[93] train_loss: 0.1785
[93] train_loss: 0.1924
[93] train_loss: 0.2062
[93] train_loss: 0.2060
1.5820550918579102

Evaluating...Epoch: 93
Prec: 0.7607, Recall: 0.7231, F1: 0.7414

[94] train_loss: 0.1561
[94] train_loss: 0.1224
[94] train_loss: 0.1329
[94] train_loss: 0.1297
[94] train_loss: 0.1374
[94] train_loss: 0.1380
[94] train_loss: 0.1390
[94] train_loss: 0.1659
[94] train_loss: 0.1694
[94] train_loss: 0.1809
1.578071117401123

Evaluating...Epoch: 94
Prec: 0.7570, Recall: 0.7196, F1: 0.7378

[95] train_loss: 0.3501
[95] train_loss: 0.2398
[95] train_loss: 0.2528
[95] train_loss: 0.2058
[95] train_loss: 0.1865
[95] train_loss: 0.1946
[95] train_loss: 0.1881
[95] train_loss: 0.1946
[95] train_loss: 0.2051
[95] train_loss: 0.2055
1.5591423511505127

Evaluating...Epoch: 95
Prec: 0.7495, Recall: 0.7337, F1: 0.7415

[96] train_loss: 0.1894
[96] train_loss: 0.1462
[96] train_loss: 0.1438
[96] train_loss: 0.1538
[96] train_loss: 0.1431
[96] train_loss: 0.1478
[96] train_loss: 0.1512
[96] train_loss: 0.1564
[96] train_loss: 0.1725
[96] train_loss: 0.1893
1.5688087940216064

Evaluating...Epoch: 96
Prec: 0.7374, Recall: 0.7231, F1: 0.7302

[97] train_loss: 0.2127
[97] train_loss: 0.1845
[97] train_loss: 0.1780
[97] train_loss: 0.1602
[97] train_loss: 0.1499
[97] train_loss: 0.1662
[97] train_loss: 0.1709
[97] train_loss: 0.1945
[97] train_loss: 0.2069
[97] train_loss: 0.2116
1.5941853523254395

Evaluating...Epoch: 97
Prec: 0.7555, Recall: 0.7249, F1: 0.7399

[98] train_loss: 0.1796
[98] train_loss: 0.1714
[98] train_loss: 0.1472
[98] train_loss: 0.1268
[98] train_loss: 0.1214
[98] train_loss: 0.1222
[98] train_loss: 0.1289
[98] train_loss: 0.1377
[98] train_loss: 0.1450
[98] train_loss: 0.1618
1.668534278869629

Evaluating...Epoch: 98
Prec: 0.7714, Recall: 0.7143, F1: 0.7418

[99] train_loss: 0.1493
[99] train_loss: 0.1200
[99] train_loss: 0.1203
[99] train_loss: 0.1071
[99] train_loss: 0.1160
[99] train_loss: 0.1207
[99] train_loss: 0.1316
[99] train_loss: 0.1356
[99] train_loss: 0.1357
[99] train_loss: 0.1505
1.5822739601135254

Evaluating...Epoch: 99
Prec: 0.7803, Recall: 0.7266, F1: 0.7525
model saved to random1_layers2_14lap/best_model.pt
New best model saved!

[100] train_loss: 0.1727
[100] train_loss: 0.1510
[100] train_loss: 0.1379
[100] train_loss: 0.1426
[100] train_loss: 0.1316
[100] train_loss: 0.1332
[100] train_loss: 0.1378
[100] train_loss: 0.1452
[100] train_loss: 0.1477
[100] train_loss: 0.1497
1.5848073959350586

Evaluating...Epoch: 100
Prec: 0.7831, Recall: 0.7196, F1: 0.7500

Training ended with 100 epochs.
Final result:
Prec: 0.7803, Recall: 0.7266, F1: 0.7525
loading vocab and embedding matrix from ../data/14lap
size of vocab: 3463
shape of loaded embedding matrix: (3463, 300)
Generating mappings
Loading data from ../data/14lap with batch size 16...
102 batches created for ../data/14lap/train.json
31 batches created for ../data/14lap/test.json
Building model...
1537533
[1] train_loss: 14.0686
[1] train_loss: 10.9328
[1] train_loss: 9.2158
[1] train_loss: 8.2685
[1] train_loss: 7.6342
[1] train_loss: 7.2208
[1] train_loss: 6.9976
[1] train_loss: 6.8608
[1] train_loss: 6.7488
[1] train_loss: 6.6603
1.753859519958496

Evaluating...Epoch: 1
Prec: 0.8276, Recall: 0.0423, F1: 0.0805
model saved to random1_layers3_14lap/best_model.pt
New best model saved!

[2] train_loss: 4.7091
[2] train_loss: 4.6760
[2] train_loss: 4.4830
[2] train_loss: 4.3419
[2] train_loss: 4.2548
[2] train_loss: 4.1840
[2] train_loss: 4.1807
[2] train_loss: 4.2143
[2] train_loss: 4.2601
[2] train_loss: 4.2916
1.6753296852111816

Evaluating...Epoch: 2
Prec: 0.5883, Recall: 0.5697, F1: 0.5789
model saved to random1_layers3_14lap/best_model.pt
New best model saved!

[3] train_loss: 3.6100
[3] train_loss: 3.8063
[3] train_loss: 3.6936
[3] train_loss: 3.5639
[3] train_loss: 3.4851
[3] train_loss: 3.4426
[3] train_loss: 3.4790
[3] train_loss: 3.5459
[3] train_loss: 3.5969
[3] train_loss: 3.6467
1.6720459461212158

Evaluating...Epoch: 3
Prec: 0.5650, Recall: 0.6667, F1: 0.6117
model saved to random1_layers3_14lap/best_model.pt
New best model saved!

[4] train_loss: 3.2966
[4] train_loss: 3.3383
[4] train_loss: 3.2655
[4] train_loss: 3.1576
[4] train_loss: 3.0889
[4] train_loss: 3.0445
[4] train_loss: 3.0830
[4] train_loss: 3.1385
[4] train_loss: 3.2155
[4] train_loss: 3.2577
1.6823501586914062

Evaluating...Epoch: 4
Prec: 0.5523, Recall: 0.6984, F1: 0.6168
model saved to random1_layers3_14lap/best_model.pt
New best model saved!

[5] train_loss: 2.8206
[5] train_loss: 2.9598
[5] train_loss: 2.8730
[5] train_loss: 2.8282
[5] train_loss: 2.7505
[5] train_loss: 2.7054
[5] train_loss: 2.7479
[5] train_loss: 2.8230
[5] train_loss: 2.8963
[5] train_loss: 2.9482
1.6648306846618652

Evaluating...Epoch: 5
Prec: 0.5720, Recall: 0.7496, F1: 0.6489
model saved to random1_layers3_14lap/best_model.pt
New best model saved!

[6] train_loss: 2.7159
[6] train_loss: 2.6869
[6] train_loss: 2.5820
[6] train_loss: 2.5146
[6] train_loss: 2.5118
[6] train_loss: 2.4855
[6] train_loss: 2.5394
[6] train_loss: 2.5897
[6] train_loss: 2.6613
[6] train_loss: 2.7182
1.7453296184539795

Evaluating...Epoch: 6
Prec: 0.6173, Recall: 0.6914, F1: 0.6522
model saved to random1_layers3_14lap/best_model.pt
New best model saved!

[7] train_loss: 2.4838
[7] train_loss: 2.6190
[7] train_loss: 2.5154
[7] train_loss: 2.4142
[7] train_loss: 2.3755
[7] train_loss: 2.3551
[7] train_loss: 2.4096
[7] train_loss: 2.4830
[7] train_loss: 2.5248
[7] train_loss: 2.5680
1.6719954013824463

Evaluating...Epoch: 7
Prec: 0.6126, Recall: 0.6861, F1: 0.6473

[8] train_loss: 2.3851
[8] train_loss: 2.4214
[8] train_loss: 2.3323
[8] train_loss: 2.2134
[8] train_loss: 2.1782
[8] train_loss: 2.1833
[8] train_loss: 2.2265
[8] train_loss: 2.2908
[8] train_loss: 2.3366
[8] train_loss: 2.3906
1.6713471412658691

Evaluating...Epoch: 8
Prec: 0.6408, Recall: 0.6984, F1: 0.6684
model saved to random1_layers3_14lap/best_model.pt
New best model saved!

[9] train_loss: 2.1670
[9] train_loss: 2.2127
[9] train_loss: 2.2114
[9] train_loss: 2.1400
[9] train_loss: 2.1150
[9] train_loss: 2.0928
[9] train_loss: 2.1303
[9] train_loss: 2.1797
[9] train_loss: 2.2299
[9] train_loss: 2.2810
1.6762893199920654

Evaluating...Epoch: 9
Prec: 0.6316, Recall: 0.7196, F1: 0.6727
model saved to random1_layers3_14lap/best_model.pt
New best model saved!

[10] train_loss: 2.0518
[10] train_loss: 2.0225
[10] train_loss: 2.0153
[10] train_loss: 1.9613
[10] train_loss: 1.9526
[10] train_loss: 1.9175
[10] train_loss: 1.9711
[10] train_loss: 2.0211
[10] train_loss: 2.0704
[10] train_loss: 2.0881
1.6719906330108643

Evaluating...Epoch: 10
Prec: 0.6562, Recall: 0.7002, F1: 0.6775
model saved to random1_layers3_14lap/best_model.pt
New best model saved!

[11] train_loss: 1.9869
[11] train_loss: 1.9407
[11] train_loss: 1.9035
[11] train_loss: 1.8674
[11] train_loss: 1.8710
[11] train_loss: 1.8146
[11] train_loss: 1.8542
[11] train_loss: 1.8954
[11] train_loss: 1.9400
[11] train_loss: 1.9867
1.7645423412322998

Evaluating...Epoch: 11
Prec: 0.7015, Recall: 0.6755, F1: 0.6882
model saved to random1_layers3_14lap/best_model.pt
New best model saved!

[12] train_loss: 1.7060
[12] train_loss: 1.7545
[12] train_loss: 1.7091
[12] train_loss: 1.6255
[12] train_loss: 1.6447
[12] train_loss: 1.6366
[12] train_loss: 1.6856
[12] train_loss: 1.7209
[12] train_loss: 1.7868
[12] train_loss: 1.8491
1.6662046909332275

Evaluating...Epoch: 12
Prec: 0.6995, Recall: 0.6896, F1: 0.6945
model saved to random1_layers3_14lap/best_model.pt
New best model saved!

[13] train_loss: 1.6575
[13] train_loss: 1.6683
[13] train_loss: 1.6299
[13] train_loss: 1.5531
[13] train_loss: 1.5718
[13] train_loss: 1.5214
[13] train_loss: 1.5871
[13] train_loss: 1.6377
[13] train_loss: 1.6929
[13] train_loss: 1.7536
1.6727092266082764

Evaluating...Epoch: 13
Prec: 0.7240, Recall: 0.6755, F1: 0.6989
model saved to random1_layers3_14lap/best_model.pt
New best model saved!

[14] train_loss: 1.5201
[14] train_loss: 1.5565
[14] train_loss: 1.5606
[14] train_loss: 1.5243
[14] train_loss: 1.5121
[14] train_loss: 1.4925
[14] train_loss: 1.5275
[14] train_loss: 1.5676
[14] train_loss: 1.6140
[14] train_loss: 1.6720
1.681016206741333

Evaluating...Epoch: 14
Prec: 0.6904, Recall: 0.7002, F1: 0.6953

[15] train_loss: 1.4495
[15] train_loss: 1.4005
[15] train_loss: 1.3816
[15] train_loss: 1.3519
[15] train_loss: 1.3597
[15] train_loss: 1.3566
[15] train_loss: 1.4157
[15] train_loss: 1.4732
[15] train_loss: 1.5111
[15] train_loss: 1.5683
1.6744935512542725

Evaluating...Epoch: 15
Prec: 0.6741, Recall: 0.6966, F1: 0.6852

[16] train_loss: 1.4388
[16] train_loss: 1.4176
[16] train_loss: 1.3734
[16] train_loss: 1.3072
[16] train_loss: 1.3082
[16] train_loss: 1.3263
[16] train_loss: 1.3596
[16] train_loss: 1.3991
[16] train_loss: 1.4436
[16] train_loss: 1.4953
1.675459861755371

Evaluating...Epoch: 16
Prec: 0.6998, Recall: 0.7072, F1: 0.7035
model saved to random1_layers3_14lap/best_model.pt
New best model saved!

[17] train_loss: 1.3111
[17] train_loss: 1.4138
[17] train_loss: 1.3948
[17] train_loss: 1.3190
[17] train_loss: 1.3185
[17] train_loss: 1.2977
[17] train_loss: 1.3116
[17] train_loss: 1.3744
[17] train_loss: 1.4217
[17] train_loss: 1.4682
1.7357702255249023

Evaluating...Epoch: 17
Prec: 0.6855, Recall: 0.6843, F1: 0.6849

[18] train_loss: 1.1364
[18] train_loss: 1.1911
[18] train_loss: 1.1660
[18] train_loss: 1.1711
[18] train_loss: 1.1735
[18] train_loss: 1.1799
[18] train_loss: 1.2159
[18] train_loss: 1.2556
[18] train_loss: 1.2952
[18] train_loss: 1.3336
1.679887056350708

Evaluating...Epoch: 18
Prec: 0.7098, Recall: 0.7160, F1: 0.7129
model saved to random1_layers3_14lap/best_model.pt
New best model saved!

[19] train_loss: 1.2169
[19] train_loss: 1.1891
[19] train_loss: 1.1344
[19] train_loss: 1.0869
[19] train_loss: 1.0614
[19] train_loss: 1.0824
[19] train_loss: 1.1186
[19] train_loss: 1.1792
[19] train_loss: 1.2338
[19] train_loss: 1.2849
1.6773343086242676

Evaluating...Epoch: 19
Prec: 0.7256, Recall: 0.7090, F1: 0.7172
model saved to random1_layers3_14lap/best_model.pt
New best model saved!

[20] train_loss: 1.1789
[20] train_loss: 1.1935
[20] train_loss: 1.1417
[20] train_loss: 1.1117
[20] train_loss: 1.0976
[20] train_loss: 1.0733
[20] train_loss: 1.0971
[20] train_loss: 1.1379
[20] train_loss: 1.1762
[20] train_loss: 1.2237
1.675778865814209

Evaluating...Epoch: 20
Prec: 0.7029, Recall: 0.7178, F1: 0.7103

[21] train_loss: 1.1793
[21] train_loss: 1.1435
[21] train_loss: 1.1358
[21] train_loss: 1.0570
[21] train_loss: 1.0337
[21] train_loss: 1.0079
[21] train_loss: 1.0520
[21] train_loss: 1.1022
[21] train_loss: 1.1339
[21] train_loss: 1.1686
1.675405502319336

Evaluating...Epoch: 21
Prec: 0.6787, Recall: 0.7302, F1: 0.7035

[22] train_loss: 1.4338
[22] train_loss: 1.2983
[22] train_loss: 1.1618
[22] train_loss: 1.0792
[22] train_loss: 1.0685
[22] train_loss: 1.0576
[22] train_loss: 1.0880
[22] train_loss: 1.1115
[22] train_loss: 1.1463
[22] train_loss: 1.1601
1.652085304260254

Evaluating...Epoch: 22
Prec: 0.6939, Recall: 0.7196, F1: 0.7065

[23] train_loss: 1.1247
[23] train_loss: 1.0699
[23] train_loss: 1.0405
[23] train_loss: 0.9892
[23] train_loss: 0.9796
[23] train_loss: 0.9572
[23] train_loss: 0.9619
[23] train_loss: 1.0013
[23] train_loss: 1.0526
[23] train_loss: 1.1080
1.667041301727295

Evaluating...Epoch: 23
Prec: 0.7153, Recall: 0.7002, F1: 0.7077

[24] train_loss: 1.0959
[24] train_loss: 1.0694
[24] train_loss: 1.0390
[24] train_loss: 0.9832
[24] train_loss: 0.9785
[24] train_loss: 0.9679
[24] train_loss: 0.9736
[24] train_loss: 0.9887
[24] train_loss: 1.0178
[24] train_loss: 1.0474
1.676518440246582

Evaluating...Epoch: 24
Prec: 0.7140, Recall: 0.7178, F1: 0.7159

[25] train_loss: 0.9585
[25] train_loss: 0.9130
[25] train_loss: 0.9234
[25] train_loss: 0.8529
[25] train_loss: 0.8384
[25] train_loss: 0.8358
[25] train_loss: 0.8974
[25] train_loss: 0.9354
[25] train_loss: 0.9476
[25] train_loss: 0.9933
1.6866130828857422

Evaluating...Epoch: 25
Prec: 0.6814, Recall: 0.7055, F1: 0.6932

[26] train_loss: 0.8447
[26] train_loss: 0.8456
[26] train_loss: 0.8251
[26] train_loss: 0.7988
[26] train_loss: 0.8323
[26] train_loss: 0.8682
[26] train_loss: 0.8971
[26] train_loss: 0.9382
[26] train_loss: 0.9744
[26] train_loss: 1.0005
1.6760218143463135

Evaluating...Epoch: 26
Prec: 0.6911, Recall: 0.7143, F1: 0.7025

[27] train_loss: 0.8373
[27] train_loss: 0.8140
[27] train_loss: 0.8213
[27] train_loss: 0.7589
[27] train_loss: 0.7688
[27] train_loss: 0.7628
[27] train_loss: 0.8093
[27] train_loss: 0.8537
[27] train_loss: 0.8787
[27] train_loss: 0.9239
1.656620740890503

Evaluating...Epoch: 27
Prec: 0.7106, Recall: 0.7231, F1: 0.7168

[28] train_loss: 0.9109
[28] train_loss: 0.7786
[28] train_loss: 0.7711
[28] train_loss: 0.7351
[28] train_loss: 0.7320
[28] train_loss: 0.7481
[28] train_loss: 0.7953
[28] train_loss: 0.8060
[28] train_loss: 0.8398
[28] train_loss: 0.8638
1.6546359062194824

Evaluating...Epoch: 28
Prec: 0.7133, Recall: 0.7019, F1: 0.7076

[29] train_loss: 0.8740
[29] train_loss: 0.8138
[29] train_loss: 0.7608
[29] train_loss: 0.6964
[29] train_loss: 0.6899
[29] train_loss: 0.6736
[29] train_loss: 0.7104
[29] train_loss: 0.7390
[29] train_loss: 0.7810
[29] train_loss: 0.8100
1.6799142360687256

Evaluating...Epoch: 29
Prec: 0.7436, Recall: 0.7160, F1: 0.7296
model saved to random1_layers3_14lap/best_model.pt
New best model saved!

[30] train_loss: 0.8364
[30] train_loss: 0.9450
[30] train_loss: 0.8563
[30] train_loss: 0.7943
[30] train_loss: 0.7697
[30] train_loss: 0.7623
[30] train_loss: 0.7692
[30] train_loss: 0.7978
[30] train_loss: 0.8069
[30] train_loss: 0.8313
1.6660685539245605

Evaluating...Epoch: 30
Prec: 0.7252, Recall: 0.7213, F1: 0.7233

[31] train_loss: 0.9857
[31] train_loss: 0.9567
[31] train_loss: 0.8750
[31] train_loss: 0.7818
[31] train_loss: 0.7703
[31] train_loss: 0.7581
[31] train_loss: 0.7718
[31] train_loss: 0.7992
[31] train_loss: 0.8222
[31] train_loss: 0.8477
1.6752126216888428

Evaluating...Epoch: 31
Prec: 0.7401, Recall: 0.6931, F1: 0.7158

[32] train_loss: 0.8650
[32] train_loss: 0.7548
[32] train_loss: 0.6882
[32] train_loss: 0.6498
[32] train_loss: 0.6460
[32] train_loss: 0.6688
[32] train_loss: 0.6781
[32] train_loss: 0.6952
[32] train_loss: 0.7175
[32] train_loss: 0.7511
1.7432847023010254

Evaluating...Epoch: 32
Prec: 0.7301, Recall: 0.6966, F1: 0.7130

[33] train_loss: 0.7943
[33] train_loss: 0.7548
[33] train_loss: 0.7289
[33] train_loss: 0.6482
[33] train_loss: 0.6412
[33] train_loss: 0.6393
[33] train_loss: 0.6533
[33] train_loss: 0.6636
[33] train_loss: 0.6864
[33] train_loss: 0.7381
1.6740431785583496

Evaluating...Epoch: 33
Prec: 0.7355, Recall: 0.6914, F1: 0.7127

[34] train_loss: 0.7343
[34] train_loss: 0.6942
[34] train_loss: 0.6697
[34] train_loss: 0.6325
[34] train_loss: 0.6297
[34] train_loss: 0.6164
[34] train_loss: 0.6481
[34] train_loss: 0.6813
[34] train_loss: 0.7127
[34] train_loss: 0.7396
1.6727478504180908

Evaluating...Epoch: 34
Prec: 0.7263, Recall: 0.6878, F1: 0.7065

[35] train_loss: 0.9157
[35] train_loss: 0.8303
[35] train_loss: 0.7563
[35] train_loss: 0.6633
[35] train_loss: 0.6564
[35] train_loss: 0.6641
[35] train_loss: 0.6569
[35] train_loss: 0.6763
[35] train_loss: 0.6822
[35] train_loss: 0.7050
1.6775214672088623

Evaluating...Epoch: 35
Prec: 0.7316, Recall: 0.7019, F1: 0.7165

[36] train_loss: 0.7527
[36] train_loss: 0.6967
[36] train_loss: 0.6452
[36] train_loss: 0.6037
[36] train_loss: 0.5896
[36] train_loss: 0.5772
[36] train_loss: 0.5939
[36] train_loss: 0.5967
[36] train_loss: 0.6283
[36] train_loss: 0.6469
1.674950361251831

Evaluating...Epoch: 36
Prec: 0.7304, Recall: 0.7072, F1: 0.7186

[37] train_loss: 0.6033
[37] train_loss: 0.5684
[37] train_loss: 0.5297
[37] train_loss: 0.5146
[37] train_loss: 0.5521
[37] train_loss: 0.5565
[37] train_loss: 0.5682
[37] train_loss: 0.5898
[37] train_loss: 0.6122
[37] train_loss: 0.6367
1.7372181415557861

Evaluating...Epoch: 37
Prec: 0.7336, Recall: 0.7090, F1: 0.7211

[38] train_loss: 0.7036
[38] train_loss: 0.6717
[38] train_loss: 0.5975
[38] train_loss: 0.5357
[38] train_loss: 0.5369
[38] train_loss: 0.5362
[38] train_loss: 0.5658
[38] train_loss: 0.5750
[38] train_loss: 0.5847
[38] train_loss: 0.5946
1.673940896987915

Evaluating...Epoch: 38
Prec: 0.7215, Recall: 0.7037, F1: 0.7125

[39] train_loss: 0.6504
[39] train_loss: 0.5960
[39] train_loss: 0.5545
[39] train_loss: 0.5338
[39] train_loss: 0.5137
[39] train_loss: 0.5006
[39] train_loss: 0.5183
[39] train_loss: 0.5427
[39] train_loss: 0.5396
[39] train_loss: 0.5817
1.6746444702148438

Evaluating...Epoch: 39
Prec: 0.7047, Recall: 0.6861, F1: 0.6953

[40] train_loss: 0.5455
[40] train_loss: 0.6137
[40] train_loss: 0.6412
[40] train_loss: 0.5587
[40] train_loss: 0.5451
[40] train_loss: 0.5255
[40] train_loss: 0.5132
[40] train_loss: 0.5134
[40] train_loss: 0.5356
[40] train_loss: 0.5663
1.6725850105285645

Evaluating...Epoch: 40
Prec: 0.7029, Recall: 0.7302, F1: 0.7163

[41] train_loss: 0.7823
[41] train_loss: 0.6937
[41] train_loss: 0.6170
[41] train_loss: 0.5542
[41] train_loss: 0.5508
[41] train_loss: 0.5398
[41] train_loss: 0.5422
[41] train_loss: 0.5862
[41] train_loss: 0.6117
[41] train_loss: 0.6327
1.6589782238006592

Evaluating...Epoch: 41
Prec: 0.7232, Recall: 0.6914, F1: 0.7069

[42] train_loss: 0.6006
[42] train_loss: 0.6148
[42] train_loss: 0.6276
[42] train_loss: 0.5537
[42] train_loss: 0.5302
[42] train_loss: 0.5109
[42] train_loss: 0.5302
[42] train_loss: 0.5506
[42] train_loss: 0.5654
[42] train_loss: 0.5762
1.7356288433074951

Evaluating...Epoch: 42
Prec: 0.7245, Recall: 0.7143, F1: 0.7194

[43] train_loss: 0.6118
[43] train_loss: 0.5696
[43] train_loss: 0.5083
[43] train_loss: 0.5092
[43] train_loss: 0.4925
[43] train_loss: 0.4903
[43] train_loss: 0.5004
[43] train_loss: 0.5144
[43] train_loss: 0.5363
[43] train_loss: 0.5521
1.6607716083526611

Evaluating...Epoch: 43
Prec: 0.7585, Recall: 0.7090, F1: 0.7329
model saved to random1_layers3_14lap/best_model.pt
New best model saved!

[44] train_loss: 0.7553
[44] train_loss: 0.6569
[44] train_loss: 0.5831
[44] train_loss: 0.5494
[44] train_loss: 0.5402
[44] train_loss: 0.5109
[44] train_loss: 0.5087
[44] train_loss: 0.4980
[44] train_loss: 0.5115
[44] train_loss: 0.5245
1.6763978004455566

Evaluating...Epoch: 44
Prec: 0.7460, Recall: 0.7354, F1: 0.7407
model saved to random1_layers3_14lap/best_model.pt
New best model saved!

[45] train_loss: 0.6200
[45] train_loss: 0.7353
[45] train_loss: 0.6713
[45] train_loss: 0.5828
[45] train_loss: 0.5817
[45] train_loss: 0.5544
[45] train_loss: 0.5350
[45] train_loss: 0.5520
[45] train_loss: 0.5453
[45] train_loss: 0.5538
1.6818084716796875

Evaluating...Epoch: 45
Prec: 0.7399, Recall: 0.7072, F1: 0.7232

[46] train_loss: 0.5294
[46] train_loss: 0.4683
[46] train_loss: 0.4654
[46] train_loss: 0.4115
[46] train_loss: 0.4031
[46] train_loss: 0.3897
[46] train_loss: 0.4201
[46] train_loss: 0.4385
[46] train_loss: 0.4489
[46] train_loss: 0.4686
1.6704511642456055

Evaluating...Epoch: 46
Prec: 0.7384, Recall: 0.7266, F1: 0.7324

[47] train_loss: 0.5690
[47] train_loss: 0.5471
[47] train_loss: 0.5449
[47] train_loss: 0.4932
[47] train_loss: 0.4695
[47] train_loss: 0.4744
[47] train_loss: 0.4641
[47] train_loss: 0.4820
[47] train_loss: 0.4988
[47] train_loss: 0.5061
1.7305824756622314

Evaluating...Epoch: 47
Prec: 0.7500, Recall: 0.7143, F1: 0.7317

[48] train_loss: 0.4217
[48] train_loss: 0.4063
[48] train_loss: 0.3973
[48] train_loss: 0.3551
[48] train_loss: 0.3473
[48] train_loss: 0.3495
[48] train_loss: 0.3576
[48] train_loss: 0.3740
[48] train_loss: 0.3902
[48] train_loss: 0.4104
1.6620845794677734

Evaluating...Epoch: 48
Prec: 0.7251, Recall: 0.7072, F1: 0.7161

[49] train_loss: 0.5275
[49] train_loss: 0.4430
[49] train_loss: 0.4192
[49] train_loss: 0.3868
[49] train_loss: 0.3779
[49] train_loss: 0.3943
[49] train_loss: 0.4034
[49] train_loss: 0.4108
[49] train_loss: 0.4393
[49] train_loss: 0.4532
1.6666936874389648

Evaluating...Epoch: 49
Prec: 0.7495, Recall: 0.6966, F1: 0.7221

[50] train_loss: 0.3072
[50] train_loss: 0.3565
[50] train_loss: 0.3603
[50] train_loss: 0.3349
[50] train_loss: 0.3248
[50] train_loss: 0.3354
[50] train_loss: 0.3503
[50] train_loss: 0.3845
[50] train_loss: 0.4010
[50] train_loss: 0.4152
1.6715362071990967

Evaluating...Epoch: 50
Prec: 0.7557, Recall: 0.6984, F1: 0.7259

[51] train_loss: 0.4483
[51] train_loss: 0.4407
[51] train_loss: 0.4155
[51] train_loss: 0.3968
[51] train_loss: 0.3860
[51] train_loss: 0.3753
[51] train_loss: 0.3722
[51] train_loss: 0.3793
[51] train_loss: 0.3987
[51] train_loss: 0.4119
1.671949863433838

Evaluating...Epoch: 51
Prec: 0.7593, Recall: 0.7231, F1: 0.7407
model saved to random1_layers3_14lap/best_model.pt
New best model saved!

[52] train_loss: 0.3930
[52] train_loss: 0.3863
[52] train_loss: 0.3684
[52] train_loss: 0.3453
[52] train_loss: 0.3563
[52] train_loss: 0.3462
[52] train_loss: 0.3687
[52] train_loss: 0.3806
[52] train_loss: 0.3904
[52] train_loss: 0.4208
1.733292579650879

Evaluating...Epoch: 52
Prec: 0.7556, Recall: 0.7090, F1: 0.7316

[53] train_loss: 0.5580
[53] train_loss: 0.5086
[53] train_loss: 0.4434
[53] train_loss: 0.3972
[53] train_loss: 0.4001
[53] train_loss: 0.3840
[53] train_loss: 0.3976
[53] train_loss: 0.4038
[53] train_loss: 0.4211
[53] train_loss: 0.4348
1.6696951389312744

Evaluating...Epoch: 53
Prec: 0.7326, Recall: 0.6861, F1: 0.7086

[54] train_loss: 0.4065
[54] train_loss: 0.4032
[54] train_loss: 0.3689
[54] train_loss: 0.3452
[54] train_loss: 0.3237
[54] train_loss: 0.3204
[54] train_loss: 0.3194
[54] train_loss: 0.3562
[54] train_loss: 0.3812
[54] train_loss: 0.4014
1.67350172996521

Evaluating...Epoch: 54
Prec: 0.7427, Recall: 0.7178, F1: 0.7300

[55] train_loss: 0.5764
[55] train_loss: 0.4789
[55] train_loss: 0.4398
[55] train_loss: 0.3664
[55] train_loss: 0.3483
[55] train_loss: 0.3398
[55] train_loss: 0.3488
[55] train_loss: 0.3549
[55] train_loss: 0.3788
[55] train_loss: 0.3962
1.6733629703521729

Evaluating...Epoch: 55
Prec: 0.7481, Recall: 0.7072, F1: 0.7271

[56] train_loss: 0.3814
[56] train_loss: 0.3955
[56] train_loss: 0.3596
[56] train_loss: 0.3331
[56] train_loss: 0.3163
[56] train_loss: 0.3087
[56] train_loss: 0.3093
[56] train_loss: 0.3237
[56] train_loss: 0.3232
[56] train_loss: 0.3412
1.6837725639343262

Evaluating...Epoch: 56
Prec: 0.7394, Recall: 0.7055, F1: 0.7220

[57] train_loss: 0.4952
[57] train_loss: 0.4570
[57] train_loss: 0.4140
[57] train_loss: 0.3727
[57] train_loss: 0.3695
[57] train_loss: 0.3545
[57] train_loss: 0.3543
[57] train_loss: 0.3507
[57] train_loss: 0.3618
[57] train_loss: 0.3692
1.6725811958312988

Evaluating...Epoch: 57
Prec: 0.7338, Recall: 0.7196, F1: 0.7266

[58] train_loss: 0.3417
[58] train_loss: 0.2925
[58] train_loss: 0.3158
[58] train_loss: 0.2964
[58] train_loss: 0.2893
[58] train_loss: 0.3022
[58] train_loss: 0.3127
[58] train_loss: 0.3359
[58] train_loss: 0.3638
[58] train_loss: 0.3931
1.653228759765625

Evaluating...Epoch: 58
Prec: 0.7628, Recall: 0.7090, F1: 0.7349

[59] train_loss: 0.4273
[59] train_loss: 0.4353
[59] train_loss: 0.3991
[59] train_loss: 0.3770
[59] train_loss: 0.3594
[59] train_loss: 0.3510
[59] train_loss: 0.3634
[59] train_loss: 0.3623
[59] train_loss: 0.3703
[59] train_loss: 0.3767
1.6708462238311768

Evaluating...Epoch: 59
Prec: 0.7609, Recall: 0.7072, F1: 0.7331

[60] train_loss: 0.4363
[60] train_loss: 0.4092
[60] train_loss: 0.3837
[60] train_loss: 0.3501
[60] train_loss: 0.3324
[60] train_loss: 0.3406
[60] train_loss: 0.3445
[60] train_loss: 0.3720
[60] train_loss: 0.3771
[60] train_loss: 0.3971
1.6815171241760254

Evaluating...Epoch: 60
Prec: 0.7435, Recall: 0.7108, F1: 0.7268

[61] train_loss: 0.3667
[61] train_loss: 0.3503
[61] train_loss: 0.3297
[61] train_loss: 0.2955
[61] train_loss: 0.3045
[61] train_loss: 0.3031
[61] train_loss: 0.2993
[61] train_loss: 0.3197
[61] train_loss: 0.3187
[61] train_loss: 0.3255
1.6827669143676758

Evaluating...Epoch: 61
Prec: 0.7437, Recall: 0.7319, F1: 0.7378

[62] train_loss: 0.3902
[62] train_loss: 0.3449
[62] train_loss: 0.3068
[62] train_loss: 0.2814
[62] train_loss: 0.2735
[62] train_loss: 0.2637
[62] train_loss: 0.2709
[62] train_loss: 0.2909
[62] train_loss: 0.3105
[62] train_loss: 0.3402
1.7244036197662354

Evaluating...Epoch: 62
Prec: 0.7256, Recall: 0.7090, F1: 0.7172

[63] train_loss: 0.5781
[63] train_loss: 0.4172
[63] train_loss: 0.3733
[63] train_loss: 0.3292
[63] train_loss: 0.3228
[63] train_loss: 0.3087
[63] train_loss: 0.3023
[63] train_loss: 0.3083
[63] train_loss: 0.3221
[63] train_loss: 0.3273
1.64536452293396

Evaluating...Epoch: 63
Prec: 0.7505, Recall: 0.7319, F1: 0.7411
model saved to random1_layers3_14lap/best_model.pt
New best model saved!

[64] train_loss: 0.2811
[64] train_loss: 0.2970
[64] train_loss: 0.2618
[64] train_loss: 0.2458
[64] train_loss: 0.2506
[64] train_loss: 0.2478
[64] train_loss: 0.2447
[64] train_loss: 0.2518
[64] train_loss: 0.2785
[64] train_loss: 0.2926
1.6524877548217773

Evaluating...Epoch: 64
Prec: 0.7669, Recall: 0.7196, F1: 0.7425
model saved to random1_layers3_14lap/best_model.pt
New best model saved!

[65] train_loss: 0.4528
[65] train_loss: 0.3638
[65] train_loss: 0.3021
[65] train_loss: 0.2878
[65] train_loss: 0.2764
[65] train_loss: 0.2757
[65] train_loss: 0.2716
[65] train_loss: 0.2938
[65] train_loss: 0.3051
[65] train_loss: 0.3170
1.6688344478607178

Evaluating...Epoch: 65
Prec: 0.7395, Recall: 0.7160, F1: 0.7276

[66] train_loss: 0.4391
[66] train_loss: 0.3490
[66] train_loss: 0.2991
[66] train_loss: 0.2613
[66] train_loss: 0.2774
[66] train_loss: 0.2777
[66] train_loss: 0.2970
[66] train_loss: 0.2987
[66] train_loss: 0.3027
[66] train_loss: 0.3156
1.6661360263824463

Evaluating...Epoch: 66
Prec: 0.7624, Recall: 0.7302, F1: 0.7459
model saved to random1_layers3_14lap/best_model.pt
New best model saved!

[67] train_loss: 0.2715
[67] train_loss: 0.2591
[67] train_loss: 0.2724
[67] train_loss: 0.2635
[67] train_loss: 0.2620
[67] train_loss: 0.2662
[67] train_loss: 0.2563
[67] train_loss: 0.2625
[67] train_loss: 0.2754
[67] train_loss: 0.2835
1.7410879135131836

Evaluating...Epoch: 67
Prec: 0.7550, Recall: 0.7390, F1: 0.7469
model saved to random1_layers3_14lap/best_model.pt
New best model saved!

[68] train_loss: 0.3147
[68] train_loss: 0.3083
[68] train_loss: 0.3015
[68] train_loss: 0.2743
[68] train_loss: 0.2696
[68] train_loss: 0.2602
[68] train_loss: 0.2626
[68] train_loss: 0.2684
[68] train_loss: 0.2730
[68] train_loss: 0.2925
1.6781384944915771

Evaluating...Epoch: 68
Prec: 0.7162, Recall: 0.7566, F1: 0.7358

[69] train_loss: 0.3679
[69] train_loss: 0.2879
[69] train_loss: 0.2634
[69] train_loss: 0.2378
[69] train_loss: 0.2347
[69] train_loss: 0.2331
[69] train_loss: 0.2303
[69] train_loss: 0.2378
[69] train_loss: 0.2429
[69] train_loss: 0.2534
1.6758861541748047

Evaluating...Epoch: 69
Prec: 0.7587, Recall: 0.7266, F1: 0.7423

[70] train_loss: 0.3617
[70] train_loss: 0.2778
[70] train_loss: 0.2577
[70] train_loss: 0.2560
[70] train_loss: 0.2584
[70] train_loss: 0.2546
[70] train_loss: 0.2440
[70] train_loss: 0.2538
[70] train_loss: 0.2619
[70] train_loss: 0.2905
1.6779043674468994

Evaluating...Epoch: 70
Prec: 0.7369, Recall: 0.7213, F1: 0.7291

[71] train_loss: 0.2554
[71] train_loss: 0.2672
[71] train_loss: 0.2928
[71] train_loss: 0.2683
[71] train_loss: 0.2575
[71] train_loss: 0.2448
[71] train_loss: 0.2449
[71] train_loss: 0.2648
[71] train_loss: 0.2857
[71] train_loss: 0.2918
1.6838812828063965

Evaluating...Epoch: 71
Prec: 0.7223, Recall: 0.7249, F1: 0.7236

[72] train_loss: 0.4432
[72] train_loss: 0.3508
[72] train_loss: 0.2702
[72] train_loss: 0.2362
[72] train_loss: 0.2109
[72] train_loss: 0.1990
[72] train_loss: 0.2023
[72] train_loss: 0.2076
[72] train_loss: 0.2309
[72] train_loss: 0.2429
1.6798102855682373

Evaluating...Epoch: 72
Prec: 0.7509, Recall: 0.7231, F1: 0.7367

[73] train_loss: 0.2892
[73] train_loss: 0.2799
[73] train_loss: 0.2513
[73] train_loss: 0.2253
[73] train_loss: 0.2251
[73] train_loss: 0.2237
[73] train_loss: 0.2392
[73] train_loss: 0.2465
[73] train_loss: 0.2549
[73] train_loss: 0.2800
1.6767570972442627

Evaluating...Epoch: 73
Prec: 0.7513, Recall: 0.7407, F1: 0.7460

[74] train_loss: 0.2912
[74] train_loss: 0.2380
[74] train_loss: 0.2421
[74] train_loss: 0.2223
[74] train_loss: 0.2023
[74] train_loss: 0.1907
[74] train_loss: 0.1932
[74] train_loss: 0.2078
[74] train_loss: 0.2231
[74] train_loss: 0.2330
1.6730828285217285

Evaluating...Epoch: 74
Prec: 0.7582, Recall: 0.7302, F1: 0.7439

[75] train_loss: 0.3484
[75] train_loss: 0.3006
[75] train_loss: 0.2689
[75] train_loss: 0.2334
[75] train_loss: 0.2420
[75] train_loss: 0.2465
[75] train_loss: 0.2408
[75] train_loss: 0.2410
[75] train_loss: 0.2568
[75] train_loss: 0.2754
1.669952154159546

Evaluating...Epoch: 75
Prec: 0.7388, Recall: 0.7284, F1: 0.7336

[76] train_loss: 0.3241
[76] train_loss: 0.3596
[76] train_loss: 0.3082
[76] train_loss: 0.2823
[76] train_loss: 0.2567
[76] train_loss: 0.2569
[76] train_loss: 0.2750
[76] train_loss: 0.2893
[76] train_loss: 0.3012
[76] train_loss: 0.2974
1.6698267459869385

Evaluating...Epoch: 76
Prec: 0.7357, Recall: 0.7266, F1: 0.7311

[77] train_loss: 0.1776
[77] train_loss: 0.2021
[77] train_loss: 0.1932
[77] train_loss: 0.1864
[77] train_loss: 0.1813
[77] train_loss: 0.1910
[77] train_loss: 0.1988
[77] train_loss: 0.2133
[77] train_loss: 0.2082
[77] train_loss: 0.2250
1.7144041061401367

Evaluating...Epoch: 77
Prec: 0.7413, Recall: 0.7478, F1: 0.7445

[78] train_loss: 0.2445
[78] train_loss: 0.2402
[78] train_loss: 0.2137
[78] train_loss: 0.2007
[78] train_loss: 0.1957
[78] train_loss: 0.2002
[78] train_loss: 0.2048
[78] train_loss: 0.2121
[78] train_loss: 0.2280
[78] train_loss: 0.2471
1.6523358821868896

Evaluating...Epoch: 78
Prec: 0.7080, Recall: 0.7354, F1: 0.7215

[79] train_loss: 0.2945
[79] train_loss: 0.2259
[79] train_loss: 0.2165
[79] train_loss: 0.1945
[79] train_loss: 0.2027
[79] train_loss: 0.2142
[79] train_loss: 0.2162
[79] train_loss: 0.2110
[79] train_loss: 0.2172
[79] train_loss: 0.2268
1.6653642654418945

Evaluating...Epoch: 79
Prec: 0.7500, Recall: 0.7196, F1: 0.7345

[80] train_loss: 0.2546
[80] train_loss: 0.2329
[80] train_loss: 0.2220
[80] train_loss: 0.2117
[80] train_loss: 0.1960
[80] train_loss: 0.1833
[80] train_loss: 0.1820
[80] train_loss: 0.1936
[80] train_loss: 0.2036
[80] train_loss: 0.2104
1.6671178340911865

Evaluating...Epoch: 80
Prec: 0.7486, Recall: 0.7249, F1: 0.7366

[81] train_loss: 0.2097
[81] train_loss: 0.1631
[81] train_loss: 0.1739
[81] train_loss: 0.1713
[81] train_loss: 0.1809
[81] train_loss: 0.1870
[81] train_loss: 0.1939
[81] train_loss: 0.2087
[81] train_loss: 0.2180
[81] train_loss: 0.2357
1.6718571186065674

Evaluating...Epoch: 81
Prec: 0.7579, Recall: 0.7178, F1: 0.7373

[82] train_loss: 0.2089
[82] train_loss: 0.2196
[82] train_loss: 0.2175
[82] train_loss: 0.1934
[82] train_loss: 0.1887
[82] train_loss: 0.1876
[82] train_loss: 0.1905
[82] train_loss: 0.1945
[82] train_loss: 0.2198
[82] train_loss: 0.2247
1.7341647148132324

Evaluating...Epoch: 82
Prec: 0.7423, Recall: 0.7213, F1: 0.7317

[83] train_loss: 0.2812
[83] train_loss: 0.2461
[83] train_loss: 0.2712
[83] train_loss: 0.2387
[83] train_loss: 0.2310
[83] train_loss: 0.2350
[83] train_loss: 0.2285
[83] train_loss: 0.2242
[83] train_loss: 0.2241
[83] train_loss: 0.2232
1.665212869644165

Evaluating...Epoch: 83
Prec: 0.7554, Recall: 0.7354, F1: 0.7453

[84] train_loss: 0.3202
[84] train_loss: 0.2730
[84] train_loss: 0.2541
[84] train_loss: 0.2415
[84] train_loss: 0.2506
[84] train_loss: 0.2552
[84] train_loss: 0.2572
[84] train_loss: 0.2665
[84] train_loss: 0.2899
[84] train_loss: 0.3009
1.6706464290618896

Evaluating...Epoch: 84
Prec: 0.7350, Recall: 0.7337, F1: 0.7343

[85] train_loss: 0.4589
[85] train_loss: 0.3548
[85] train_loss: 0.2812
[85] train_loss: 0.2355
[85] train_loss: 0.2293
[85] train_loss: 0.2257
[85] train_loss: 0.2234
[85] train_loss: 0.2327
[85] train_loss: 0.2348
[85] train_loss: 0.2395
1.6698040962219238

Evaluating...Epoch: 85
Prec: 0.7318, Recall: 0.7460, F1: 0.7389

[86] train_loss: 0.2391
[86] train_loss: 0.2423
[86] train_loss: 0.2315
[86] train_loss: 0.2073
[86] train_loss: 0.2021
[86] train_loss: 0.2016
[86] train_loss: 0.1940
[86] train_loss: 0.2108
[86] train_loss: 0.2200
[86] train_loss: 0.2241
1.6714272499084473

Evaluating...Epoch: 86
Prec: 0.7596, Recall: 0.7354, F1: 0.7473
model saved to random1_layers3_14lap/best_model.pt
New best model saved!

[87] train_loss: 0.3931
[87] train_loss: 0.3187
[87] train_loss: 0.2580
[87] train_loss: 0.2413
[87] train_loss: 0.2256
[87] train_loss: 0.2119
[87] train_loss: 0.2084
[87] train_loss: 0.2250
[87] train_loss: 0.2197
[87] train_loss: 0.2242
1.6902272701263428

Evaluating...Epoch: 87
Prec: 0.7673, Recall: 0.7443, F1: 0.7556
model saved to random1_layers3_14lap/best_model.pt
New best model saved!

[88] train_loss: 0.2584
[88] train_loss: 0.2556
[88] train_loss: 0.2331
[88] train_loss: 0.2172
[88] train_loss: 0.2175
[88] train_loss: 0.2177
[88] train_loss: 0.2178
[88] train_loss: 0.2208
[88] train_loss: 0.2399
[88] train_loss: 0.2432
1.6717345714569092

Evaluating...Epoch: 88
Prec: 0.7721, Recall: 0.7231, F1: 0.7468

[89] train_loss: 0.3089
[89] train_loss: 0.2464
[89] train_loss: 0.2218
[89] train_loss: 0.1954
[89] train_loss: 0.1857
[89] train_loss: 0.1863
[89] train_loss: 0.1849
[89] train_loss: 0.1941
[89] train_loss: 0.1902
[89] train_loss: 0.1997
1.6692609786987305

Evaluating...Epoch: 89
Prec: 0.7558, Recall: 0.7478, F1: 0.7518

[90] train_loss: 0.2762
[90] train_loss: 0.2342
[90] train_loss: 0.1944
[90] train_loss: 0.1923
[90] train_loss: 0.1738
[90] train_loss: 0.1787
[90] train_loss: 0.1896
[90] train_loss: 0.1898
[90] train_loss: 0.1960
[90] train_loss: 0.2145
1.6761221885681152

Evaluating...Epoch: 90
Prec: 0.7301, Recall: 0.7443, F1: 0.7371

[91] train_loss: 0.2698
[91] train_loss: 0.2066
[91] train_loss: 0.1734
[91] train_loss: 0.1687
[91] train_loss: 0.1665
[91] train_loss: 0.1623
[91] train_loss: 0.1651
[91] train_loss: 0.1767
[91] train_loss: 0.1853
[91] train_loss: 0.2002
1.6814403533935547

Evaluating...Epoch: 91
Prec: 0.7812, Recall: 0.7178, F1: 0.7482

[92] train_loss: 0.2169
[92] train_loss: 0.1786
[92] train_loss: 0.1846
[92] train_loss: 0.1642
[92] train_loss: 0.1571
[92] train_loss: 0.1674
[92] train_loss: 0.1702
[92] train_loss: 0.1844
[92] train_loss: 0.2039
[92] train_loss: 0.2118
1.6762363910675049

Evaluating...Epoch: 92
Prec: 0.7518, Recall: 0.7266, F1: 0.7390

[93] train_loss: 0.2739
[93] train_loss: 0.1936
[93] train_loss: 0.2012
[93] train_loss: 0.1773
[93] train_loss: 0.1587
[93] train_loss: 0.1576
[93] train_loss: 0.1523
[93] train_loss: 0.1584
[93] train_loss: 0.1612
[93] train_loss: 0.1701
1.7397172451019287

Evaluating...Epoch: 93
Prec: 0.7782, Recall: 0.7302, F1: 0.7534

[94] train_loss: 0.2292
[94] train_loss: 0.1799
[94] train_loss: 0.1500
[94] train_loss: 0.1367
[94] train_loss: 0.1411
[94] train_loss: 0.1442
[94] train_loss: 0.1383
[94] train_loss: 0.1453
[94] train_loss: 0.1492
[94] train_loss: 0.1534
1.6741163730621338

Evaluating...Epoch: 94
Prec: 0.7709, Recall: 0.7302, F1: 0.7500

[95] train_loss: 0.1759
[95] train_loss: 0.1952
[95] train_loss: 0.1881
[95] train_loss: 0.1709
[95] train_loss: 0.1531
[95] train_loss: 0.1620
[95] train_loss: 0.1612
[95] train_loss: 0.1716
[95] train_loss: 0.1825
[95] train_loss: 0.1918
1.666287899017334

Evaluating...Epoch: 95
Prec: 0.7587, Recall: 0.7266, F1: 0.7423

[96] train_loss: 0.1200
[96] train_loss: 0.1368
[96] train_loss: 0.1089
[96] train_loss: 0.0989
[96] train_loss: 0.1199
[96] train_loss: 0.1239
[96] train_loss: 0.1204
[96] train_loss: 0.1534
[96] train_loss: 0.1570
[96] train_loss: 0.1679
1.6535260677337646

Evaluating...Epoch: 96
Prec: 0.7571, Recall: 0.7478, F1: 0.7524

[97] train_loss: 0.1882
[97] train_loss: 0.1753
[97] train_loss: 0.1553
[97] train_loss: 0.1250
[97] train_loss: 0.1270
[97] train_loss: 0.1341
[97] train_loss: 0.1363
[97] train_loss: 0.1403
[97] train_loss: 0.1532
[97] train_loss: 0.1667
1.6794240474700928

Evaluating...Epoch: 97
Prec: 0.7495, Recall: 0.7284, F1: 0.7388

[98] train_loss: 0.2706
[98] train_loss: 0.1756
[98] train_loss: 0.1981
[98] train_loss: 0.1642
[98] train_loss: 0.1589
[98] train_loss: 0.1614
[98] train_loss: 0.1568
[98] train_loss: 0.1584
[98] train_loss: 0.1633
[98] train_loss: 0.1748
1.7424910068511963

Evaluating...Epoch: 98
Prec: 0.7930, Recall: 0.7231, F1: 0.7565
model saved to random1_layers3_14lap/best_model.pt
New best model saved!

[99] train_loss: 0.1919
[99] train_loss: 0.2396
[99] train_loss: 0.2335
[99] train_loss: 0.2072
[99] train_loss: 0.1958
[99] train_loss: 0.1885
[99] train_loss: 0.1786
[99] train_loss: 0.1816
[99] train_loss: 0.1960
[99] train_loss: 0.1997
1.6774585247039795

Evaluating...Epoch: 99
Prec: 0.7747, Recall: 0.7337, F1: 0.7536

[100] train_loss: 0.1351
[100] train_loss: 0.1199
[100] train_loss: 0.1370
[100] train_loss: 0.1328
[100] train_loss: 0.1288
[100] train_loss: 0.1336
[100] train_loss: 0.1355
[100] train_loss: 0.1414
[100] train_loss: 0.1535
[100] train_loss: 0.1636
1.660395860671997

Evaluating...Epoch: 100
Prec: 0.7558, Recall: 0.7478, F1: 0.7518

Training ended with 100 epochs.
Final result:
Prec: 0.7930, Recall: 0.7231, F1: 0.7565
loading vocab and embedding matrix from ../data/14lap
size of vocab: 3463
shape of loaded embedding matrix: (3463, 300)
Generating mappings
Loading data from ../data/14lap with batch size 16...
102 batches created for ../data/14lap/train.json
31 batches created for ../data/14lap/test.json
Building model...
1577733
[1] train_loss: 13.4572
[1] train_loss: 10.5355
[1] train_loss: 8.9596
[1] train_loss: 8.1065
[1] train_loss: 7.5170
[1] train_loss: 7.1152
[1] train_loss: 6.8891
[1] train_loss: 6.7474
[1] train_loss: 6.6348
[1] train_loss: 6.5558
1.8069868087768555

Evaluating...Epoch: 1
Prec: 0.7938, Recall: 0.1358, F1: 0.2319
model saved to random1_layers4_14lap/best_model.pt
New best model saved!

[2] train_loss: 4.7204
[2] train_loss: 4.7171
[2] train_loss: 4.4853
[2] train_loss: 4.3305
[2] train_loss: 4.2096
[2] train_loss: 4.1103
[2] train_loss: 4.1135
[2] train_loss: 4.1716
[2] train_loss: 4.2452
[2] train_loss: 4.2864
1.7336294651031494

Evaluating...Epoch: 2
Prec: 0.6400, Recall: 0.5362, F1: 0.5835
model saved to random1_layers4_14lap/best_model.pt
New best model saved!

[3] train_loss: 3.6798
[3] train_loss: 3.7899
[3] train_loss: 3.6649
[3] train_loss: 3.5647
[3] train_loss: 3.5072
[3] train_loss: 3.4549
[3] train_loss: 3.5092
[3] train_loss: 3.5796
[3] train_loss: 3.6571
[3] train_loss: 3.6891
1.7236955165863037

Evaluating...Epoch: 3
Prec: 0.6007, Recall: 0.6314, F1: 0.6156
model saved to random1_layers4_14lap/best_model.pt
New best model saved!

[4] train_loss: 3.1297
[4] train_loss: 3.3006
[4] train_loss: 3.1493
[4] train_loss: 3.0691
[4] train_loss: 3.0097
[4] train_loss: 2.9879
[4] train_loss: 3.0453
[4] train_loss: 3.1294
[4] train_loss: 3.2100
[4] train_loss: 3.2612
1.7281463146209717

Evaluating...Epoch: 4
Prec: 0.6026, Recall: 0.6420, F1: 0.6217
model saved to random1_layers4_14lap/best_model.pt
New best model saved!

[5] train_loss: 3.0115
[5] train_loss: 3.1062
[5] train_loss: 2.9988
[5] train_loss: 2.9014
[5] train_loss: 2.8453
[5] train_loss: 2.7982
[5] train_loss: 2.8434
[5] train_loss: 2.9080
[5] train_loss: 2.9896
[5] train_loss: 3.0146
1.7299602031707764

Evaluating...Epoch: 5
Prec: 0.6156, Recall: 0.6808, F1: 0.6466
model saved to random1_layers4_14lap/best_model.pt
New best model saved!

[6] train_loss: 2.5394
[6] train_loss: 2.6565
[6] train_loss: 2.5756
[6] train_loss: 2.5293
[6] train_loss: 2.5232
[6] train_loss: 2.4931
[6] train_loss: 2.5366
[6] train_loss: 2.5917
[6] train_loss: 2.6800
[6] train_loss: 2.7420
1.799912452697754

Evaluating...Epoch: 6
Prec: 0.6618, Recall: 0.6384, F1: 0.6499
model saved to random1_layers4_14lap/best_model.pt
New best model saved!

[7] train_loss: 2.4411
[7] train_loss: 2.4962
[7] train_loss: 2.4630
[7] train_loss: 2.4265
[7] train_loss: 2.4208
[7] train_loss: 2.3868
[7] train_loss: 2.4099
[7] train_loss: 2.4680
[7] train_loss: 2.5400
[7] train_loss: 2.5830
1.7234318256378174

Evaluating...Epoch: 7
Prec: 0.6286, Recall: 0.6896, F1: 0.6577
model saved to random1_layers4_14lap/best_model.pt
New best model saved!

[8] train_loss: 2.1369
[8] train_loss: 2.2182
[8] train_loss: 2.2014
[8] train_loss: 2.1257
[8] train_loss: 2.1217
[8] train_loss: 2.1100
[8] train_loss: 2.1612
[8] train_loss: 2.2269
[8] train_loss: 2.3036
[8] train_loss: 2.3447
1.7276368141174316

Evaluating...Epoch: 8
Prec: 0.6655, Recall: 0.6878, F1: 0.6765
model saved to random1_layers4_14lap/best_model.pt
New best model saved!

[9] train_loss: 2.1620
[9] train_loss: 2.2091
[9] train_loss: 2.1421
[9] train_loss: 2.0649
[9] train_loss: 2.0577
[9] train_loss: 2.0098
[9] train_loss: 2.0631
[9] train_loss: 2.1123
[9] train_loss: 2.1807
[9] train_loss: 2.2319
1.7393267154693604

Evaluating...Epoch: 9
Prec: 0.6667, Recall: 0.6772, F1: 0.6719

[10] train_loss: 2.1385
[10] train_loss: 2.1131
[10] train_loss: 2.0729
[10] train_loss: 2.0111
[10] train_loss: 1.9730
[10] train_loss: 1.9339
[10] train_loss: 1.9427
[10] train_loss: 1.9945
[10] train_loss: 2.0467
[10] train_loss: 2.0951
1.7081561088562012

Evaluating...Epoch: 10
Prec: 0.6729, Recall: 0.7002, F1: 0.6863
model saved to random1_layers4_14lap/best_model.pt
New best model saved!

[11] train_loss: 1.8067
[11] train_loss: 1.9082
[11] train_loss: 1.8925
[11] train_loss: 1.8185
[11] train_loss: 1.7987
[11] train_loss: 1.7798
[11] train_loss: 1.8217
[11] train_loss: 1.8506
[11] train_loss: 1.9281
[11] train_loss: 1.9780
1.79789400100708

Evaluating...Epoch: 11
Prec: 0.6963, Recall: 0.7037, F1: 0.7000
model saved to random1_layers4_14lap/best_model.pt
New best model saved!

[12] train_loss: 1.6551
[12] train_loss: 1.7113
[12] train_loss: 1.6668
[12] train_loss: 1.6470
[12] train_loss: 1.6449
[12] train_loss: 1.6562
[12] train_loss: 1.6787
[12] train_loss: 1.7342
[12] train_loss: 1.7837
[12] train_loss: 1.8147
1.710432529449463

Evaluating...Epoch: 12
Prec: 0.7085, Recall: 0.7072, F1: 0.7079
model saved to random1_layers4_14lap/best_model.pt
New best model saved!

[13] train_loss: 1.5900
[13] train_loss: 1.5801
[13] train_loss: 1.5361
[13] train_loss: 1.5180
[13] train_loss: 1.5319
[13] train_loss: 1.5071
[13] train_loss: 1.5579
[13] train_loss: 1.6043
[13] train_loss: 1.6720
[13] train_loss: 1.7310
1.725268840789795

Evaluating...Epoch: 13
Prec: 0.7203, Recall: 0.6631, F1: 0.6905

[14] train_loss: 1.6496
[14] train_loss: 1.5881
[14] train_loss: 1.5494
[14] train_loss: 1.4924
[14] train_loss: 1.4901
[14] train_loss: 1.4812
[14] train_loss: 1.5308
[14] train_loss: 1.5761
[14] train_loss: 1.6284
[14] train_loss: 1.6690
1.7509965896606445

Evaluating...Epoch: 14
Prec: 0.6776, Recall: 0.7266, F1: 0.7013

[15] train_loss: 1.4939
[15] train_loss: 1.5024
[15] train_loss: 1.4631
[15] train_loss: 1.4111
[15] train_loss: 1.3944
[15] train_loss: 1.3831
[15] train_loss: 1.4252
[15] train_loss: 1.4575
[15] train_loss: 1.5134
[15] train_loss: 1.5771
1.736950397491455

Evaluating...Epoch: 15
Prec: 0.7203, Recall: 0.6949, F1: 0.7074

[16] train_loss: 1.2378
[16] train_loss: 1.3903
[16] train_loss: 1.4003
[16] train_loss: 1.3029
[16] train_loss: 1.3275
[16] train_loss: 1.3031
[16] train_loss: 1.3549
[16] train_loss: 1.3911
[16] train_loss: 1.4375
[16] train_loss: 1.4659
1.739527702331543

Evaluating...Epoch: 16
Prec: 0.6739, Recall: 0.7108, F1: 0.6918

[17] train_loss: 1.6064
[17] train_loss: 1.5674
[17] train_loss: 1.4979
[17] train_loss: 1.4074
[17] train_loss: 1.3780
[17] train_loss: 1.3462
[17] train_loss: 1.3709
[17] train_loss: 1.3789
[17] train_loss: 1.4344
[17] train_loss: 1.4776
1.7920165061950684

Evaluating...Epoch: 17
Prec: 0.7113, Recall: 0.7125, F1: 0.7119
model saved to random1_layers4_14lap/best_model.pt
New best model saved!

[18] train_loss: 1.2410
[18] train_loss: 1.2773
[18] train_loss: 1.2693
[18] train_loss: 1.2156
[18] train_loss: 1.1899
[18] train_loss: 1.2079
[18] train_loss: 1.2364
[18] train_loss: 1.2625
[18] train_loss: 1.3000
[18] train_loss: 1.3453
1.74125075340271

Evaluating...Epoch: 18
Prec: 0.6791, Recall: 0.7090, F1: 0.6937

[19] train_loss: 1.2294
[19] train_loss: 1.2323
[19] train_loss: 1.1731
[19] train_loss: 1.1048
[19] train_loss: 1.1153
[19] train_loss: 1.0994
[19] train_loss: 1.1527
[19] train_loss: 1.2033
[19] train_loss: 1.2594
[19] train_loss: 1.2985
1.7382206916809082

Evaluating...Epoch: 19
Prec: 0.6909, Recall: 0.7213, F1: 0.7058

[20] train_loss: 1.2033
[20] train_loss: 1.1603
[20] train_loss: 1.1933
[20] train_loss: 1.1268
[20] train_loss: 1.1379
[20] train_loss: 1.1275
[20] train_loss: 1.1534
[20] train_loss: 1.1944
[20] train_loss: 1.2400
[20] train_loss: 1.2824
1.7368195056915283

Evaluating...Epoch: 20
Prec: 0.7214, Recall: 0.7125, F1: 0.7169
model saved to random1_layers4_14lap/best_model.pt
New best model saved!

[21] train_loss: 1.2111
[21] train_loss: 1.1698
[21] train_loss: 1.1174
[21] train_loss: 1.0401
[21] train_loss: 1.0430
[21] train_loss: 1.0564
[21] train_loss: 1.0783
[21] train_loss: 1.1022
[21] train_loss: 1.1301
[21] train_loss: 1.1483
1.7389028072357178

Evaluating...Epoch: 21
Prec: 0.7162, Recall: 0.7390, F1: 0.7274
model saved to random1_layers4_14lap/best_model.pt
New best model saved!

[22] train_loss: 1.0979
[22] train_loss: 1.0886
[22] train_loss: 1.0479
[22] train_loss: 0.9685
[22] train_loss: 0.9931
[22] train_loss: 0.9529
[22] train_loss: 0.9949
[22] train_loss: 1.0196
[22] train_loss: 1.0622
[22] train_loss: 1.0960
1.8003735542297363

Evaluating...Epoch: 22
Prec: 0.7138, Recall: 0.7390, F1: 0.7262

[23] train_loss: 1.0628
[23] train_loss: 1.0235
[23] train_loss: 0.9644
[23] train_loss: 0.9031
[23] train_loss: 0.9187
[23] train_loss: 0.9120
[23] train_loss: 0.9306
[23] train_loss: 0.9666
[23] train_loss: 1.0199
[23] train_loss: 1.0556
1.737605094909668

Evaluating...Epoch: 23
Prec: 0.7253, Recall: 0.7125, F1: 0.7189

[24] train_loss: 1.0698
[24] train_loss: 1.0711
[24] train_loss: 1.0339
[24] train_loss: 0.9441
[24] train_loss: 0.9211
[24] train_loss: 0.9052
[24] train_loss: 0.9214
[24] train_loss: 0.9574
[24] train_loss: 0.9931
[24] train_loss: 1.0347
1.737619400024414

Evaluating...Epoch: 24
Prec: 0.7062, Recall: 0.7460, F1: 0.7256

[25] train_loss: 1.1601
[25] train_loss: 1.0980
[25] train_loss: 1.0468
[25] train_loss: 1.0041
[25] train_loss: 0.9717
[25] train_loss: 0.9381
[25] train_loss: 0.9560
[25] train_loss: 0.9589
[25] train_loss: 0.9867
[25] train_loss: 1.0260
1.733276605606079

Evaluating...Epoch: 25
Prec: 0.7314, Recall: 0.7637, F1: 0.7472
model saved to random1_layers4_14lap/best_model.pt
New best model saved!

[26] train_loss: 1.0849
[26] train_loss: 1.0372
[26] train_loss: 1.0045
[26] train_loss: 0.9290
[26] train_loss: 0.8953
[26] train_loss: 0.8956
[26] train_loss: 0.8911
[26] train_loss: 0.8978
[26] train_loss: 0.9224
[26] train_loss: 0.9541
1.7279284000396729

Evaluating...Epoch: 26
Prec: 0.7254, Recall: 0.7266, F1: 0.7260

[27] train_loss: 0.9944
[27] train_loss: 0.9130
[27] train_loss: 0.8945
[27] train_loss: 0.7882
[27] train_loss: 0.7786
[27] train_loss: 0.7754
[27] train_loss: 0.7933
[27] train_loss: 0.8274
[27] train_loss: 0.8700
[27] train_loss: 0.9004
1.7872695922851562

Evaluating...Epoch: 27
Prec: 0.7099, Recall: 0.7337, F1: 0.7216

[28] train_loss: 1.1718
[28] train_loss: 0.9677
[28] train_loss: 0.9090
[28] train_loss: 0.8191
[28] train_loss: 0.8043
[28] train_loss: 0.8013
[28] train_loss: 0.8224
[28] train_loss: 0.8380
[28] train_loss: 0.8653
[28] train_loss: 0.9106
1.7292132377624512

Evaluating...Epoch: 28
Prec: 0.7171, Recall: 0.7601, F1: 0.7380

[29] train_loss: 0.9346
[29] train_loss: 0.8853
[29] train_loss: 0.8206
[29] train_loss: 0.7423
[29] train_loss: 0.7310
[29] train_loss: 0.7134
[29] train_loss: 0.7481
[29] train_loss: 0.7876
[29] train_loss: 0.8160
[29] train_loss: 0.8429
1.7455239295959473

Evaluating...Epoch: 29
Prec: 0.7527, Recall: 0.7354, F1: 0.7440

[30] train_loss: 0.8787
[30] train_loss: 0.8175
[30] train_loss: 0.7564
[30] train_loss: 0.6902
[30] train_loss: 0.6991
[30] train_loss: 0.6873
[30] train_loss: 0.7205
[30] train_loss: 0.7390
[30] train_loss: 0.7920
[30] train_loss: 0.8237
1.7402572631835938

Evaluating...Epoch: 30
Prec: 0.7225, Recall: 0.7302, F1: 0.7263

[31] train_loss: 0.8981
[31] train_loss: 0.8048
[31] train_loss: 0.7676
[31] train_loss: 0.6807
[31] train_loss: 0.6613
[31] train_loss: 0.6632
[31] train_loss: 0.6952
[31] train_loss: 0.7172
[31] train_loss: 0.7465
[31] train_loss: 0.7708
1.7340912818908691

Evaluating...Epoch: 31
Prec: 0.7445, Recall: 0.7143, F1: 0.7291

[32] train_loss: 0.8651
[32] train_loss: 0.7958
[32] train_loss: 0.7785
[32] train_loss: 0.7221
[32] train_loss: 0.7178
[32] train_loss: 0.7080
[32] train_loss: 0.7169
[32] train_loss: 0.7418
[32] train_loss: 0.7551
[32] train_loss: 0.7661
1.7878673076629639

Evaluating...Epoch: 32
Prec: 0.7575, Recall: 0.7160, F1: 0.7362

[33] train_loss: 0.7233
[33] train_loss: 0.8109
[33] train_loss: 0.7283
[33] train_loss: 0.6841
[33] train_loss: 0.6425
[33] train_loss: 0.6408
[33] train_loss: 0.6741
[33] train_loss: 0.6994
[33] train_loss: 0.7125
[33] train_loss: 0.7466
1.7201054096221924

Evaluating...Epoch: 33
Prec: 0.7546, Recall: 0.7213, F1: 0.7376

[34] train_loss: 0.8544
[34] train_loss: 0.7722
[34] train_loss: 0.7330
[34] train_loss: 0.6743
[34] train_loss: 0.6583
[34] train_loss: 0.6333
[34] train_loss: 0.6411
[34] train_loss: 0.6678
[34] train_loss: 0.6901
[34] train_loss: 0.7090
1.7289395332336426

Evaluating...Epoch: 34
Prec: 0.7500, Recall: 0.7196, F1: 0.7345

[35] train_loss: 0.5394
[35] train_loss: 0.6338
[35] train_loss: 0.6425
[35] train_loss: 0.5972
[35] train_loss: 0.5734
[35] train_loss: 0.5845
[35] train_loss: 0.6145
[35] train_loss: 0.6370
[35] train_loss: 0.6472
[35] train_loss: 0.6732
1.733893632888794

Evaluating...Epoch: 35
Prec: 0.7372, Recall: 0.7372, F1: 0.7372

[36] train_loss: 0.7718
[36] train_loss: 0.6825
[36] train_loss: 0.6212
[36] train_loss: 0.5794
[36] train_loss: 0.5712
[36] train_loss: 0.5548
[36] train_loss: 0.5583
[36] train_loss: 0.5702
[36] train_loss: 0.6077
[36] train_loss: 0.6508
1.7460927963256836

Evaluating...Epoch: 36
Prec: 0.7296, Recall: 0.7090, F1: 0.7191

[37] train_loss: 0.8092
[37] train_loss: 0.6517
[37] train_loss: 0.5926
[37] train_loss: 0.5830
[37] train_loss: 0.5878
[37] train_loss: 0.5774
[37] train_loss: 0.6161
[37] train_loss: 0.6407
[37] train_loss: 0.6514
[37] train_loss: 0.6928
1.7391817569732666

Evaluating...Epoch: 37
Prec: 0.7756, Recall: 0.7072, F1: 0.7399

[38] train_loss: 0.6143
[38] train_loss: 0.7399
[38] train_loss: 0.6635
[38] train_loss: 0.6301
[38] train_loss: 0.5983
[38] train_loss: 0.5748
[38] train_loss: 0.5994
[38] train_loss: 0.6231
[38] train_loss: 0.6341
[38] train_loss: 0.6600
1.8062350749969482

Evaluating...Epoch: 38
Prec: 0.7697, Recall: 0.7249, F1: 0.7466

[39] train_loss: 0.6475
[39] train_loss: 0.5906
[39] train_loss: 0.5453
[39] train_loss: 0.5049
[39] train_loss: 0.4988
[39] train_loss: 0.5004
[39] train_loss: 0.5013
[39] train_loss: 0.5289
[39] train_loss: 0.5549
[39] train_loss: 0.5849
1.7438535690307617

Evaluating...Epoch: 39
Prec: 0.7462, Recall: 0.6949, F1: 0.7196

[40] train_loss: 0.5566
[40] train_loss: 0.5723
[40] train_loss: 0.5848
[40] train_loss: 0.5347
[40] train_loss: 0.5051
[40] train_loss: 0.5257
[40] train_loss: 0.5201
[40] train_loss: 0.5446
[40] train_loss: 0.5623
[40] train_loss: 0.5742
1.7364468574523926

Evaluating...Epoch: 40
Prec: 0.7428, Recall: 0.6825, F1: 0.7114

[41] train_loss: 0.6165
[41] train_loss: 0.5562
[41] train_loss: 0.5890
[41] train_loss: 0.5312
[41] train_loss: 0.5193
[41] train_loss: 0.5196
[41] train_loss: 0.5293
[41] train_loss: 0.5310
[41] train_loss: 0.5497
[41] train_loss: 0.5715
1.7378604412078857

Evaluating...Epoch: 41
Prec: 0.7778, Recall: 0.7037, F1: 0.7389

[42] train_loss: 0.4735
[42] train_loss: 0.5052
[42] train_loss: 0.4996
[42] train_loss: 0.4499
[42] train_loss: 0.4816
[42] train_loss: 0.4818
[42] train_loss: 0.4978
[42] train_loss: 0.5122
[42] train_loss: 0.5097
[42] train_loss: 0.5331
1.7430591583251953

Evaluating...Epoch: 42
Prec: 0.7576, Recall: 0.7055, F1: 0.7306

[43] train_loss: 0.6759
[43] train_loss: 0.5523
[43] train_loss: 0.5095
[43] train_loss: 0.4803
[43] train_loss: 0.4873
[43] train_loss: 0.4559
[43] train_loss: 0.4860
[43] train_loss: 0.4856
[43] train_loss: 0.5130
[43] train_loss: 0.5163
1.8022434711456299

Evaluating...Epoch: 43
Prec: 0.7552, Recall: 0.7019, F1: 0.7276

[44] train_loss: 0.7093
[44] train_loss: 0.6822
[44] train_loss: 0.5702
[44] train_loss: 0.5464
[44] train_loss: 0.5499
[44] train_loss: 0.5255
[44] train_loss: 0.5076
[44] train_loss: 0.5263
[44] train_loss: 0.5234
[44] train_loss: 0.5356
1.7546260356903076

Evaluating...Epoch: 44
Prec: 0.7463, Recall: 0.7108, F1: 0.7281

[45] train_loss: 0.5233
[45] train_loss: 0.5457
[45] train_loss: 0.5027
[45] train_loss: 0.4405
[45] train_loss: 0.4113
[45] train_loss: 0.4057
[45] train_loss: 0.4110
[45] train_loss: 0.4301
[45] train_loss: 0.4593
[45] train_loss: 0.4880
1.7316138744354248

Evaluating...Epoch: 45
Prec: 0.7584, Recall: 0.7143, F1: 0.7357

Training ended with 46 epochs.
Final result:
Prec: 0.7314, Recall: 0.7637, F1: 0.7472
loading vocab and embedding matrix from ../data/14lap
size of vocab: 3463
shape of loaded embedding matrix: (3463, 300)
Generating mappings
Loading data from ../data/14lap with batch size 16...
102 batches created for ../data/14lap/train.json
31 batches created for ../data/14lap/test.json
Building model...
1617933
[1] train_loss: 12.0362
[1] train_loss: 9.5013
[1] train_loss: 8.1825
[1] train_loss: 7.4755
[1] train_loss: 6.9907
[1] train_loss: 6.6583
[1] train_loss: 6.4844
[1] train_loss: 6.4250
[1] train_loss: 6.3537
[1] train_loss: 6.2867
1.8508946895599365

Evaluating...Epoch: 1
Prec: 0.7799, Recall: 0.2187, F1: 0.3416
model saved to random1_layers5_14lap/best_model.pt
New best model saved!

[2] train_loss: 4.6392
[2] train_loss: 4.6063
[2] train_loss: 4.3856
[2] train_loss: 4.3018
[2] train_loss: 4.1889
[2] train_loss: 4.1391
[2] train_loss: 4.1606
[2] train_loss: 4.2284
[2] train_loss: 4.3020
[2] train_loss: 4.3252
1.7795958518981934

Evaluating...Epoch: 2
Prec: 0.5896, Recall: 0.5802, F1: 0.5849
model saved to random1_layers5_14lap/best_model.pt
New best model saved!

[3] train_loss: 3.8767
[3] train_loss: 3.8418
[3] train_loss: 3.7018
[3] train_loss: 3.6108
[3] train_loss: 3.5485
[3] train_loss: 3.4730
[3] train_loss: 3.4851
[3] train_loss: 3.5474
[3] train_loss: 3.6104
[3] train_loss: 3.6461
1.7754309177398682

Evaluating...Epoch: 3
Prec: 0.5639, Recall: 0.6614, F1: 0.6088
model saved to random1_layers5_14lap/best_model.pt
New best model saved!

[4] train_loss: 3.2826
[4] train_loss: 3.3530
[4] train_loss: 3.2545
[4] train_loss: 3.1916
[4] train_loss: 3.1027
[4] train_loss: 3.0564
[4] train_loss: 3.1141
[4] train_loss: 3.1775
[4] train_loss: 3.2677
[4] train_loss: 3.3130
1.7757914066314697

Evaluating...Epoch: 4
Prec: 0.5950, Recall: 0.6737, F1: 0.6319
model saved to random1_layers5_14lap/best_model.pt
New best model saved!

[5] train_loss: 2.9783
[5] train_loss: 3.0017
[5] train_loss: 2.9230
[5] train_loss: 2.8148
[5] train_loss: 2.7652
[5] train_loss: 2.7470
[5] train_loss: 2.7938
[5] train_loss: 2.8608
[5] train_loss: 2.9714
[5] train_loss: 3.0259
1.7750318050384521

Evaluating...Epoch: 5
Prec: 0.6655, Recall: 0.6702, F1: 0.6678
model saved to random1_layers5_14lap/best_model.pt
New best model saved!

[6] train_loss: 2.7574
[6] train_loss: 2.7859
[6] train_loss: 2.7300
[6] train_loss: 2.6178
[6] train_loss: 2.5570
[6] train_loss: 2.5133
[6] train_loss: 2.5675
[6] train_loss: 2.6330
[6] train_loss: 2.7295
[6] train_loss: 2.7875
1.8457586765289307

Evaluating...Epoch: 6
Prec: 0.6324, Recall: 0.6949, F1: 0.6622

[7] train_loss: 2.4540
[7] train_loss: 2.5503
[7] train_loss: 2.4914
[7] train_loss: 2.4260
[7] train_loss: 2.3807
[7] train_loss: 2.3750
[7] train_loss: 2.4197
[7] train_loss: 2.4819
[7] train_loss: 2.5540
[7] train_loss: 2.6033
1.7671349048614502

Evaluating...Epoch: 7
Prec: 0.6575, Recall: 0.7143, F1: 0.6847
model saved to random1_layers5_14lap/best_model.pt
New best model saved!

[8] train_loss: 2.2470
[8] train_loss: 2.3814
[8] train_loss: 2.3302
[8] train_loss: 2.2616
[8] train_loss: 2.2114
[8] train_loss: 2.1866
[8] train_loss: 2.2494
[8] train_loss: 2.2958
[8] train_loss: 2.3673
[8] train_loss: 2.4216
1.767911434173584

Evaluating...Epoch: 8
Prec: 0.6478, Recall: 0.7460, F1: 0.6934
model saved to random1_layers5_14lap/best_model.pt
New best model saved!

[9] train_loss: 2.1827
[9] train_loss: 2.2287
[9] train_loss: 2.1783
[9] train_loss: 2.1256
[9] train_loss: 2.1120
[9] train_loss: 2.1042
[9] train_loss: 2.1240
[9] train_loss: 2.1587
[9] train_loss: 2.2288
[9] train_loss: 2.2816
1.7797763347625732

Evaluating...Epoch: 9
Prec: 0.6870, Recall: 0.6966, F1: 0.6918

[10] train_loss: 2.0595
[10] train_loss: 2.1011
[10] train_loss: 2.0255
[10] train_loss: 1.9527
[10] train_loss: 1.9632
[10] train_loss: 1.9433
[10] train_loss: 2.0129
[10] train_loss: 2.0725
[10] train_loss: 2.1335
[10] train_loss: 2.2043
1.766162395477295

Evaluating...Epoch: 10
Prec: 0.6491, Recall: 0.7178, F1: 0.6817

[11] train_loss: 1.9477
[11] train_loss: 1.9385
[11] train_loss: 1.8974
[11] train_loss: 1.8160
[11] train_loss: 1.8279
[11] train_loss: 1.8117
[11] train_loss: 1.8590
[11] train_loss: 1.8963
[11] train_loss: 1.9573
[11] train_loss: 2.0074
1.7717249393463135

Evaluating...Epoch: 11
Prec: 0.6907, Recall: 0.6931, F1: 0.6919

[12] train_loss: 1.8803
[12] train_loss: 1.7877
[12] train_loss: 1.7532
[12] train_loss: 1.7268
[12] train_loss: 1.7221
[12] train_loss: 1.6943
[12] train_loss: 1.7432
[12] train_loss: 1.7746
[12] train_loss: 1.8252
[12] train_loss: 1.8864
1.761519432067871

Evaluating...Epoch: 12
Prec: 0.6930, Recall: 0.6490, F1: 0.6703

[13] train_loss: 1.7278
[13] train_loss: 1.7791
[13] train_loss: 1.7653
[13] train_loss: 1.6862
[13] train_loss: 1.6930
[13] train_loss: 1.6631
[13] train_loss: 1.6808
[13] train_loss: 1.7023
[13] train_loss: 1.7735
[13] train_loss: 1.8353
1.7532832622528076

Evaluating...Epoch: 13
Prec: 0.6694, Recall: 0.7143, F1: 0.6911

[14] train_loss: 1.6747
[14] train_loss: 1.6806
[14] train_loss: 1.6308
[14] train_loss: 1.5725
[14] train_loss: 1.5724
[14] train_loss: 1.5627
[14] train_loss: 1.5845
[14] train_loss: 1.6364
[14] train_loss: 1.7011
[14] train_loss: 1.7319
1.7547578811645508

Evaluating...Epoch: 14
Prec: 0.6755, Recall: 0.7196, F1: 0.6968
model saved to random1_layers5_14lap/best_model.pt
New best model saved!

[15] train_loss: 1.7164
[15] train_loss: 1.5842
[15] train_loss: 1.5590
[15] train_loss: 1.4604
[15] train_loss: 1.4569
[15] train_loss: 1.4662
[15] train_loss: 1.5325
[15] train_loss: 1.5905
[15] train_loss: 1.6207
[15] train_loss: 1.6637
1.7703802585601807

Evaluating...Epoch: 15
Prec: 0.6907, Recall: 0.6931, F1: 0.6919

[16] train_loss: 1.6900
[16] train_loss: 1.6060
[16] train_loss: 1.5123
[16] train_loss: 1.4362
[16] train_loss: 1.4256
[16] train_loss: 1.3983
[16] train_loss: 1.4260
[16] train_loss: 1.4902
[16] train_loss: 1.5355
[16] train_loss: 1.5563
1.7720329761505127

Evaluating...Epoch: 16
Prec: 0.6886, Recall: 0.7213, F1: 0.7046
model saved to random1_layers5_14lap/best_model.pt
New best model saved!

[17] train_loss: 1.4488
[17] train_loss: 1.4996
[17] train_loss: 1.4291
[17] train_loss: 1.3823
[17] train_loss: 1.3629
[17] train_loss: 1.3309
[17] train_loss: 1.3727
[17] train_loss: 1.4048
[17] train_loss: 1.4363
[17] train_loss: 1.4663
1.8321685791015625

Evaluating...Epoch: 17
Prec: 0.7130, Recall: 0.7055, F1: 0.7092
model saved to random1_layers5_14lap/best_model.pt
New best model saved!

[18] train_loss: 1.3172
[18] train_loss: 1.3242
[18] train_loss: 1.3482
[18] train_loss: 1.2959
[18] train_loss: 1.2657
[18] train_loss: 1.2612
[18] train_loss: 1.3231
[18] train_loss: 1.3624
[18] train_loss: 1.4119
[18] train_loss: 1.4463
1.7605035305023193

Evaluating...Epoch: 18
Prec: 0.7202, Recall: 0.7037, F1: 0.7119
model saved to random1_layers5_14lap/best_model.pt
New best model saved!

[19] train_loss: 1.4007
[19] train_loss: 1.2831
[19] train_loss: 1.1942
[19] train_loss: 1.1379
[19] train_loss: 1.1556
[19] train_loss: 1.1650
[19] train_loss: 1.1898
[19] train_loss: 1.2234
[19] train_loss: 1.2492
[19] train_loss: 1.2777
1.7547376155853271

Evaluating...Epoch: 19
Prec: 0.7019, Recall: 0.7266, F1: 0.7140
model saved to random1_layers5_14lap/best_model.pt
New best model saved!

[20] train_loss: 1.2544
[20] train_loss: 1.3236
[20] train_loss: 1.2260
[20] train_loss: 1.1439
[20] train_loss: 1.1517
[20] train_loss: 1.1274
[20] train_loss: 1.1595
[20] train_loss: 1.1989
[20] train_loss: 1.2407
[20] train_loss: 1.2886
1.7727351188659668

Evaluating...Epoch: 20
Prec: 0.6987, Recall: 0.7319, F1: 0.7149
model saved to random1_layers5_14lap/best_model.pt
New best model saved!

[21] train_loss: 1.2879
[21] train_loss: 1.3315
[21] train_loss: 1.2579
[21] train_loss: 1.1970
[21] train_loss: 1.1811
[21] train_loss: 1.1639
[21] train_loss: 1.1835
[21] train_loss: 1.2001
[21] train_loss: 1.2256
[21] train_loss: 1.2776
1.7604620456695557

Evaluating...Epoch: 21
Prec: 0.7378, Recall: 0.6949, F1: 0.7157
model saved to random1_layers5_14lap/best_model.pt
New best model saved!

[22] train_loss: 1.2270
[22] train_loss: 1.0962
[22] train_loss: 1.1071
[22] train_loss: 1.0532
[22] train_loss: 1.0282
[22] train_loss: 1.0184
[22] train_loss: 1.0549
[22] train_loss: 1.0805
[22] train_loss: 1.1158
[22] train_loss: 1.1520
1.8298416137695312

Evaluating...Epoch: 22
Prec: 0.7092, Recall: 0.7354, F1: 0.7221
model saved to random1_layers5_14lap/best_model.pt
New best model saved!

[23] train_loss: 1.2720
[23] train_loss: 1.1805
[23] train_loss: 1.0960
[23] train_loss: 1.0221
[23] train_loss: 1.0143
[23] train_loss: 1.0145
[23] train_loss: 1.0348
[23] train_loss: 1.0496
[23] train_loss: 1.0902
[23] train_loss: 1.1190
1.7610421180725098

Evaluating...Epoch: 23
Prec: 0.7062, Recall: 0.7037, F1: 0.7049

[24] train_loss: 1.2125
[24] train_loss: 1.1008
[24] train_loss: 1.0228
[24] train_loss: 0.9441
[24] train_loss: 0.9411
[24] train_loss: 0.9394
[24] train_loss: 0.9746
[24] train_loss: 1.0086
[24] train_loss: 1.0527
[24] train_loss: 1.0872
1.7740693092346191

Evaluating...Epoch: 24
Prec: 0.6980, Recall: 0.7337, F1: 0.7154

[25] train_loss: 0.9838
[25] train_loss: 0.9454
[25] train_loss: 0.8921
[25] train_loss: 0.8673
[25] train_loss: 0.8624
[25] train_loss: 0.8588
[25] train_loss: 0.8876
[25] train_loss: 0.9214
[25] train_loss: 0.9574
[25] train_loss: 0.9849
1.7392072677612305

Evaluating...Epoch: 25
Prec: 0.7215, Recall: 0.7354, F1: 0.7284
model saved to random1_layers5_14lap/best_model.pt
New best model saved!

[26] train_loss: 0.9506
[26] train_loss: 0.9354
[26] train_loss: 0.8945
[26] train_loss: 0.8384
[26] train_loss: 0.8045
[26] train_loss: 0.8219
[26] train_loss: 0.8586
[26] train_loss: 0.8983
[26] train_loss: 0.9362
[26] train_loss: 0.9760
1.7471990585327148

Evaluating...Epoch: 26
Prec: 0.7343, Recall: 0.7407, F1: 0.7375
model saved to random1_layers5_14lap/best_model.pt
New best model saved!

[27] train_loss: 0.9875
[27] train_loss: 0.9844
[27] train_loss: 0.9814
[27] train_loss: 0.9153
[27] train_loss: 0.8866
[27] train_loss: 0.8618
[27] train_loss: 0.8840
[27] train_loss: 0.9041
[27] train_loss: 0.9336
[27] train_loss: 0.9730
1.812476396560669

Evaluating...Epoch: 27
Prec: 0.7594, Recall: 0.7125, F1: 0.7352

[28] train_loss: 0.8223
[28] train_loss: 0.7747
[28] train_loss: 0.7743
[28] train_loss: 0.7313
[28] train_loss: 0.7769
[28] train_loss: 0.7752
[28] train_loss: 0.8115
[28] train_loss: 0.8264
[28] train_loss: 0.8600
[28] train_loss: 0.8994
1.7480590343475342

Evaluating...Epoch: 28
Prec: 0.7208, Recall: 0.7284, F1: 0.7246

[29] train_loss: 0.9776
[29] train_loss: 0.8441
[29] train_loss: 0.8055
[29] train_loss: 0.7396
[29] train_loss: 0.7194
[29] train_loss: 0.7150
[29] train_loss: 0.7296
[29] train_loss: 0.7504
[29] train_loss: 0.7905
[29] train_loss: 0.8292
1.7466015815734863

Evaluating...Epoch: 29
Prec: 0.7416, Recall: 0.6984, F1: 0.7193

[30] train_loss: 0.8386
[30] train_loss: 0.7163
[30] train_loss: 0.7330
[30] train_loss: 0.6740
[30] train_loss: 0.6596
[30] train_loss: 0.6665
[30] train_loss: 0.7245
[30] train_loss: 0.7794
[30] train_loss: 0.8001
[30] train_loss: 0.8329
1.7512643337249756

Evaluating...Epoch: 30
Prec: 0.7336, Recall: 0.7284, F1: 0.7310

[31] train_loss: 0.9582
[31] train_loss: 0.8147
[31] train_loss: 0.7567
[31] train_loss: 0.7162
[31] train_loss: 0.7100
[31] train_loss: 0.7061
[31] train_loss: 0.7184
[31] train_loss: 0.7553
[31] train_loss: 0.7761
[31] train_loss: 0.8058
1.7361412048339844

Evaluating...Epoch: 31
Prec: 0.7595, Recall: 0.7407, F1: 0.7500
model saved to random1_layers5_14lap/best_model.pt
New best model saved!

[32] train_loss: 0.8337
[32] train_loss: 0.8280
[32] train_loss: 0.7867
[32] train_loss: 0.7092
[32] train_loss: 0.6853
[32] train_loss: 0.6610
[32] train_loss: 0.6779
[32] train_loss: 0.6934
[32] train_loss: 0.7224
[32] train_loss: 0.7583
1.7511765956878662

Evaluating...Epoch: 32
Prec: 0.7556, Recall: 0.7196, F1: 0.7371

[33] train_loss: 0.8816
[33] train_loss: 0.8282
[33] train_loss: 0.7692
[33] train_loss: 0.7181
[33] train_loss: 0.7068
[33] train_loss: 0.6906
[33] train_loss: 0.7202
[33] train_loss: 0.7343
[33] train_loss: 0.7594
[33] train_loss: 0.7841
1.809600591659546

Evaluating...Epoch: 33
Prec: 0.7556, Recall: 0.7196, F1: 0.7371

[34] train_loss: 0.6977
[34] train_loss: 0.7426
[34] train_loss: 0.6980
[34] train_loss: 0.6572
[34] train_loss: 0.6326
[34] train_loss: 0.6086
[34] train_loss: 0.6234
[34] train_loss: 0.6523
[34] train_loss: 0.6607
[34] train_loss: 0.7027
1.7465693950653076

Evaluating...Epoch: 34
Prec: 0.7448, Recall: 0.6949, F1: 0.7190

[35] train_loss: 0.8367
[35] train_loss: 0.7353
[35] train_loss: 0.6780
[35] train_loss: 0.6793
[35] train_loss: 0.6603
[35] train_loss: 0.6570
[35] train_loss: 0.6832
[35] train_loss: 0.6824
[35] train_loss: 0.6928
[35] train_loss: 0.7122
1.7478954792022705

Evaluating...Epoch: 35
Prec: 0.7606, Recall: 0.7284, F1: 0.7441

[36] train_loss: 0.8303
[36] train_loss: 0.7469
[36] train_loss: 0.7001
[36] train_loss: 0.6576
[36] train_loss: 0.6505
[36] train_loss: 0.6185
[36] train_loss: 0.6267
[36] train_loss: 0.6361
[36] train_loss: 0.6555
[36] train_loss: 0.6749
1.7509849071502686

Evaluating...Epoch: 36
Prec: 0.7713, Recall: 0.7196, F1: 0.7445

[37] train_loss: 0.7082
[37] train_loss: 0.6189
[37] train_loss: 0.5798
[37] train_loss: 0.5282
[37] train_loss: 0.5480
[37] train_loss: 0.5361
[37] train_loss: 0.5703
[37] train_loss: 0.5805
[37] train_loss: 0.6090
[37] train_loss: 0.6332
1.7538151741027832

Evaluating...Epoch: 37
Prec: 0.7481, Recall: 0.7072, F1: 0.7271

[38] train_loss: 0.6588
[38] train_loss: 0.6737
[38] train_loss: 0.6447
[38] train_loss: 0.6026
[38] train_loss: 0.6141
[38] train_loss: 0.6067
[38] train_loss: 0.6266
[38] train_loss: 0.6473
[38] train_loss: 0.6741
[38] train_loss: 0.6963
1.8135030269622803

Evaluating...Epoch: 38
Prec: 0.7500, Recall: 0.7037, F1: 0.7261

[39] train_loss: 0.6688
[39] train_loss: 0.6856
[39] train_loss: 0.6080
[39] train_loss: 0.5734
[39] train_loss: 0.5421
[39] train_loss: 0.5354
[39] train_loss: 0.5633
[39] train_loss: 0.5664
[39] train_loss: 0.5872
[39] train_loss: 0.6140
1.7563233375549316

Evaluating...Epoch: 39
Prec: 0.7575, Recall: 0.7160, F1: 0.7362

[40] train_loss: 0.8120
[40] train_loss: 0.6689
[40] train_loss: 0.6262
[40] train_loss: 0.5818
[40] train_loss: 0.5689
[40] train_loss: 0.5608
[40] train_loss: 0.5572
[40] train_loss: 0.5729
[40] train_loss: 0.5966
[40] train_loss: 0.6312
1.766066312789917

Evaluating...Epoch: 40
Prec: 0.7529, Recall: 0.6931, F1: 0.7218

[41] train_loss: 0.5337
[41] train_loss: 0.5286
[41] train_loss: 0.4951
[41] train_loss: 0.4719
[41] train_loss: 0.4580
[41] train_loss: 0.4520
[41] train_loss: 0.4676
[41] train_loss: 0.4887
[41] train_loss: 0.5137
[41] train_loss: 0.5165
1.7655260562896729

Evaluating...Epoch: 41
Prec: 0.7416, Recall: 0.7037, F1: 0.7222

[42] train_loss: 0.6578
[42] train_loss: 0.6210
[42] train_loss: 0.5398
[42] train_loss: 0.5052
[42] train_loss: 0.5031
[42] train_loss: 0.4896
[42] train_loss: 0.5037
[42] train_loss: 0.5281
[42] train_loss: 0.5338
[42] train_loss: 0.5496
1.7629401683807373

Evaluating...Epoch: 42
Prec: 0.7852, Recall: 0.7090, F1: 0.7451

[43] train_loss: 0.6006
[43] train_loss: 0.5968
[43] train_loss: 0.5781
[43] train_loss: 0.5430
[43] train_loss: 0.5444
[43] train_loss: 0.5305
[43] train_loss: 0.5236
[43] train_loss: 0.5211
[43] train_loss: 0.5499
[43] train_loss: 0.5582
1.8319745063781738

Evaluating...Epoch: 43
Prec: 0.7597, Recall: 0.7249, F1: 0.7419

[44] train_loss: 0.6513
[44] train_loss: 0.5998
[44] train_loss: 0.5367
[44] train_loss: 0.5044
[44] train_loss: 0.4730
[44] train_loss: 0.4539
[44] train_loss: 0.4669
[44] train_loss: 0.4645
[44] train_loss: 0.4890
[44] train_loss: 0.5120
1.765162467956543

Evaluating...Epoch: 44
Prec: 0.7561, Recall: 0.7055, F1: 0.7299

[45] train_loss: 0.5376
[45] train_loss: 0.4792
[45] train_loss: 0.4662
[45] train_loss: 0.4396
[45] train_loss: 0.4247
[45] train_loss: 0.4245
[45] train_loss: 0.4351
[45] train_loss: 0.4591
[45] train_loss: 0.4880
[45] train_loss: 0.5154
1.7671597003936768

Evaluating...Epoch: 45
Prec: 0.7707, Recall: 0.7055, F1: 0.7366

[46] train_loss: 0.5437
[46] train_loss: 0.5102
[46] train_loss: 0.4515
[46] train_loss: 0.4440
[46] train_loss: 0.4439
[46] train_loss: 0.4566
[46] train_loss: 0.4562
[46] train_loss: 0.4630
[46] train_loss: 0.4737
[46] train_loss: 0.4910
1.7660620212554932

Evaluating...Epoch: 46
Prec: 0.7717, Recall: 0.7213, F1: 0.7457

[47] train_loss: 0.6497
[47] train_loss: 0.5192
[47] train_loss: 0.4649
[47] train_loss: 0.4266
[47] train_loss: 0.4169
[47] train_loss: 0.4176
[47] train_loss: 0.4226
[47] train_loss: 0.4274
[47] train_loss: 0.4364
[47] train_loss: 0.4559
1.7689893245697021

Evaluating...Epoch: 47
Prec: 0.7608, Recall: 0.7125, F1: 0.7359

[48] train_loss: 0.5236
[48] train_loss: 0.4640
[48] train_loss: 0.4473
[48] train_loss: 0.4368
[48] train_loss: 0.4689
[48] train_loss: 0.4537
[48] train_loss: 0.4848
[48] train_loss: 0.4872
[48] train_loss: 0.4884
[48] train_loss: 0.4975
1.763282299041748

Evaluating...Epoch: 48
Prec: 0.7667, Recall: 0.6896, F1: 0.7261

[49] train_loss: 0.4788
[49] train_loss: 0.4132
[49] train_loss: 0.4103
[49] train_loss: 0.3818
[49] train_loss: 0.3851
[49] train_loss: 0.3896
[49] train_loss: 0.4083
[49] train_loss: 0.4207
[49] train_loss: 0.4409
[49] train_loss: 0.4604
1.8046786785125732

Evaluating...Epoch: 49
Prec: 0.7606, Recall: 0.6949, F1: 0.7263

[50] train_loss: 0.4855
[50] train_loss: 0.4015
[50] train_loss: 0.3937
[50] train_loss: 0.3633
[50] train_loss: 0.3437
[50] train_loss: 0.3693
[50] train_loss: 0.3977
[50] train_loss: 0.4201
[50] train_loss: 0.4437
[50] train_loss: 0.4690
1.76668381690979

Evaluating...Epoch: 50
Prec: 0.7590, Recall: 0.7055, F1: 0.7313

[51] train_loss: 0.5006
[51] train_loss: 0.4115
[51] train_loss: 0.3745
[51] train_loss: 0.3505
[51] train_loss: 0.3472
[51] train_loss: 0.3438
[51] train_loss: 0.3688
[51] train_loss: 0.4056
[51] train_loss: 0.4161
[51] train_loss: 0.4274
1.777428150177002

Evaluating...Epoch: 51
Prec: 0.7684, Recall: 0.7196, F1: 0.7432

Training ended with 52 epochs.
Final result:
Prec: 0.7595, Recall: 0.7407, F1: 0.7500
loading vocab and embedding matrix from ../data/14res
size of vocab: 4381
shape of loaded embedding matrix: (4381, 300)
Generating mappings
Loading data from ../data/14res with batch size 16...
165 batches created for ../data/14res/train.json
54 batches created for ../data/14res/test.json
Building model...
1692093
[1] train_loss: 15.8928
[1] train_loss: 11.9156
[1] train_loss: 10.1522
[1] train_loss: 8.9044
[1] train_loss: 8.1420
[1] train_loss: 7.5778
[1] train_loss: 7.0729
[1] train_loss: 6.6973
[1] train_loss: 6.3806
[1] train_loss: 6.1158
[1] train_loss: 5.8971
[1] train_loss: 5.7444
[1] train_loss: 5.5977
[1] train_loss: 5.4650
[1] train_loss: 5.3758
[1] train_loss: 5.2403
2.122685194015503

Evaluating...Epoch: 1
Prec: 0.7065, Recall: 0.5409, F1: 0.6127
model saved to random1_layers0_14res/best_model.pt
New best model saved!

[2] train_loss: 3.1807
[2] train_loss: 3.5540
[2] train_loss: 3.6737
[2] train_loss: 3.5851
[2] train_loss: 3.6137
[2] train_loss: 3.5824
[2] train_loss: 3.4929
[2] train_loss: 3.4425
[2] train_loss: 3.4038
[2] train_loss: 3.3634
[2] train_loss: 3.3455
[2] train_loss: 3.3572
[2] train_loss: 3.3394
[2] train_loss: 3.3327
[2] train_loss: 3.3316
[2] train_loss: 3.2767
2.110475778579712

Evaluating...Epoch: 2
Prec: 0.6890, Recall: 0.6790, F1: 0.6840
model saved to random1_layers0_14res/best_model.pt
New best model saved!

[3] train_loss: 2.7992
[3] train_loss: 3.0672
[3] train_loss: 3.1737
[3] train_loss: 3.0870
[3] train_loss: 3.1134
[3] train_loss: 3.1076
[3] train_loss: 3.0047
[3] train_loss: 2.9652
[3] train_loss: 2.9249
[3] train_loss: 2.9122
[3] train_loss: 2.9005
[3] train_loss: 2.9135
[3] train_loss: 2.9106
[3] train_loss: 2.8935
[3] train_loss: 2.8939
[3] train_loss: 2.8469
2.123265504837036

Evaluating...Epoch: 3
Prec: 0.7540, Recall: 0.6946, F1: 0.7230
model saved to random1_layers0_14res/best_model.pt
New best model saved!

[4] train_loss: 2.3201
[4] train_loss: 2.6446
[4] train_loss: 2.7520
[4] train_loss: 2.7048
[4] train_loss: 2.7097
[4] train_loss: 2.6958
[4] train_loss: 2.5966
[4] train_loss: 2.5664
[4] train_loss: 2.5512
[4] train_loss: 2.5203
[4] train_loss: 2.5105
[4] train_loss: 2.5204
[4] train_loss: 2.5251
[4] train_loss: 2.5231
[4] train_loss: 2.5322
[4] train_loss: 2.4902
2.1354916095733643

Evaluating...Epoch: 4
Prec: 0.8011, Recall: 0.7130, F1: 0.7545
model saved to random1_layers0_14res/best_model.pt
New best model saved!

[5] train_loss: 2.1854
[5] train_loss: 2.4134
[5] train_loss: 2.5059
[5] train_loss: 2.4294
[5] train_loss: 2.4897
[5] train_loss: 2.4724
[5] train_loss: 2.3825
[5] train_loss: 2.3497
[5] train_loss: 2.3301
[5] train_loss: 2.3001
[5] train_loss: 2.2977
[5] train_loss: 2.3182
[5] train_loss: 2.3021
[5] train_loss: 2.2994
[5] train_loss: 2.3169
[5] train_loss: 2.2814
2.1104748249053955

Evaluating...Epoch: 5
Prec: 0.8008, Recall: 0.7588, F1: 0.7792
model saved to random1_layers0_14res/best_model.pt
New best model saved!

[6] train_loss: 1.9024
[6] train_loss: 2.1021
[6] train_loss: 2.2543
[6] train_loss: 2.2141
[6] train_loss: 2.2321
[6] train_loss: 2.2355
[6] train_loss: 2.1825
[6] train_loss: 2.1417
[6] train_loss: 2.1338
[6] train_loss: 2.1110
[6] train_loss: 2.0932
[6] train_loss: 2.1204
[6] train_loss: 2.1151
[6] train_loss: 2.1044
[6] train_loss: 2.1075
[6] train_loss: 2.0754
2.1064560413360596

Evaluating...Epoch: 6
Prec: 0.8387, Recall: 0.7383, F1: 0.7853
model saved to random1_layers0_14res/best_model.pt
New best model saved!

[7] train_loss: 1.7304
[7] train_loss: 1.9562
[7] train_loss: 2.0573
[7] train_loss: 2.0210
[7] train_loss: 2.0540
[7] train_loss: 2.0482
[7] train_loss: 1.9525
[7] train_loss: 1.9450
[7] train_loss: 1.9520
[7] train_loss: 1.9366
[7] train_loss: 1.9308
[7] train_loss: 1.9342
[7] train_loss: 1.9375
[7] train_loss: 1.9218
[7] train_loss: 1.9308
[7] train_loss: 1.8999
2.116406202316284

Evaluating...Epoch: 7
Prec: 0.8274, Recall: 0.7743, F1: 0.8000
model saved to random1_layers0_14res/best_model.pt
New best model saved!

[8] train_loss: 1.5988
[8] train_loss: 1.8413
[8] train_loss: 1.9501
[8] train_loss: 1.8650
[8] train_loss: 1.9432
[8] train_loss: 1.9241
[8] train_loss: 1.8652
[8] train_loss: 1.8432
[8] train_loss: 1.8329
[8] train_loss: 1.8030
[8] train_loss: 1.7987
[8] train_loss: 1.8093
[8] train_loss: 1.7927
[8] train_loss: 1.7919
[8] train_loss: 1.7982
[8] train_loss: 1.7678
2.117598056793213

Evaluating...Epoch: 8
Prec: 0.8503, Recall: 0.7626, F1: 0.8041
model saved to random1_layers0_14res/best_model.pt
New best model saved!

[9] train_loss: 1.3537
[9] train_loss: 1.5978
[9] train_loss: 1.7166
[9] train_loss: 1.6922
[9] train_loss: 1.7246
[9] train_loss: 1.7554
[9] train_loss: 1.6910
[9] train_loss: 1.6537
[9] train_loss: 1.6556
[9] train_loss: 1.6279
[9] train_loss: 1.6234
[9] train_loss: 1.6392
[9] train_loss: 1.6227
[9] train_loss: 1.6164
[9] train_loss: 1.6258
[9] train_loss: 1.6046
2.108457088470459

Evaluating...Epoch: 9
Prec: 0.8439, Recall: 0.7675, F1: 0.8039

[10] train_loss: 1.2305
[10] train_loss: 1.4821
[10] train_loss: 1.5861
[10] train_loss: 1.5416
[10] train_loss: 1.5998
[10] train_loss: 1.6428
[10] train_loss: 1.5947
[10] train_loss: 1.5712
[10] train_loss: 1.5640
[10] train_loss: 1.5475
[10] train_loss: 1.5406
[10] train_loss: 1.5593
[10] train_loss: 1.5508
[10] train_loss: 1.5414
[10] train_loss: 1.5415
[10] train_loss: 1.5162
2.099123001098633

Evaluating...Epoch: 10
Prec: 0.8672, Recall: 0.7753, F1: 0.8187
model saved to random1_layers0_14res/best_model.pt
New best model saved!

[11] train_loss: 1.3304
[11] train_loss: 1.5259
[11] train_loss: 1.5506
[11] train_loss: 1.5331
[11] train_loss: 1.5706
[11] train_loss: 1.6172
[11] train_loss: 1.5407
[11] train_loss: 1.4908
[11] train_loss: 1.4900
[11] train_loss: 1.4725
[11] train_loss: 1.4504
[11] train_loss: 1.4636
[11] train_loss: 1.4487
[11] train_loss: 1.4533
[11] train_loss: 1.4519
[11] train_loss: 1.4372
2.1132774353027344

Evaluating...Epoch: 11
Prec: 0.8669, Recall: 0.7792, F1: 0.8207
model saved to random1_layers0_14res/best_model.pt
New best model saved!

[12] train_loss: 1.2518
[12] train_loss: 1.3938
[12] train_loss: 1.4828
[12] train_loss: 1.4435
[12] train_loss: 1.4874
[12] train_loss: 1.5027
[12] train_loss: 1.4559
[12] train_loss: 1.4147
[12] train_loss: 1.4123
[12] train_loss: 1.3925
[12] train_loss: 1.3845
[12] train_loss: 1.4050
[12] train_loss: 1.4136
[12] train_loss: 1.4050
[12] train_loss: 1.4069
[12] train_loss: 1.3814
2.116037607192993

Evaluating...Epoch: 12
Prec: 0.8545, Recall: 0.8171, F1: 0.8354
model saved to random1_layers0_14res/best_model.pt
New best model saved!

[13] train_loss: 1.1428
[13] train_loss: 1.3914
[13] train_loss: 1.4093
[13] train_loss: 1.3519
[13] train_loss: 1.3928
[13] train_loss: 1.3988
[13] train_loss: 1.3434
[13] train_loss: 1.3116
[13] train_loss: 1.2978
[13] train_loss: 1.2839
[13] train_loss: 1.2822
[13] train_loss: 1.2834
[13] train_loss: 1.2805
[13] train_loss: 1.2667
[13] train_loss: 1.2778
[13] train_loss: 1.2631
2.2013087272644043

Evaluating...Epoch: 13
Prec: 0.8612, Recall: 0.8025, F1: 0.8308

[14] train_loss: 0.9731
[14] train_loss: 1.1626
[14] train_loss: 1.2218
[14] train_loss: 1.2299
[14] train_loss: 1.3133
[14] train_loss: 1.3260
[14] train_loss: 1.2716
[14] train_loss: 1.2314
[14] train_loss: 1.2363
[14] train_loss: 1.2427
[14] train_loss: 1.2308
[14] train_loss: 1.2404
[14] train_loss: 1.2348
[14] train_loss: 1.2257
[14] train_loss: 1.2400
[14] train_loss: 1.2245
2.101594924926758

Evaluating...Epoch: 14
Prec: 0.8636, Recall: 0.8006, F1: 0.8309

[15] train_loss: 0.9327
[15] train_loss: 1.1422
[15] train_loss: 1.2186
[15] train_loss: 1.1907
[15] train_loss: 1.2069
[15] train_loss: 1.2064
[15] train_loss: 1.1763
[15] train_loss: 1.1658
[15] train_loss: 1.1671
[15] train_loss: 1.1459
[15] train_loss: 1.1401
[15] train_loss: 1.1382
[15] train_loss: 1.1521
[15] train_loss: 1.1489
[15] train_loss: 1.1542
[15] train_loss: 1.1382
2.1152169704437256

Evaluating...Epoch: 15
Prec: 0.8693, Recall: 0.8220, F1: 0.8450
model saved to random1_layers0_14res/best_model.pt
New best model saved!

[16] train_loss: 0.8821
[16] train_loss: 1.0997
[16] train_loss: 1.1388
[16] train_loss: 1.0971
[16] train_loss: 1.1482
[16] train_loss: 1.1702
[16] train_loss: 1.1345
[16] train_loss: 1.1247
[16] train_loss: 1.1300
[16] train_loss: 1.1185
[16] train_loss: 1.1076
[16] train_loss: 1.1112
[16] train_loss: 1.1180
[16] train_loss: 1.1101
[16] train_loss: 1.1160
[16] train_loss: 1.0980
2.1179027557373047

Evaluating...Epoch: 16
Prec: 0.8774, Recall: 0.7938, F1: 0.8335

[17] train_loss: 0.7088
[17] train_loss: 0.8571
[17] train_loss: 0.9718
[17] train_loss: 0.9820
[17] train_loss: 1.0485
[17] train_loss: 1.0729
[17] train_loss: 1.0519
[17] train_loss: 1.0233
[17] train_loss: 1.0334
[17] train_loss: 1.0226
[17] train_loss: 1.0296
[17] train_loss: 1.0507
[17] train_loss: 1.0558
[17] train_loss: 1.0509
[17] train_loss: 1.0544
[17] train_loss: 1.0351
2.20229172706604

Evaluating...Epoch: 17
Prec: 0.8679, Recall: 0.8054, F1: 0.8355

[18] train_loss: 0.9436
[18] train_loss: 1.0404
[18] train_loss: 1.1069
[18] train_loss: 1.0958
[18] train_loss: 1.1191
[18] train_loss: 1.1361
[18] train_loss: 1.0952
[18] train_loss: 1.0697
[18] train_loss: 1.0765
[18] train_loss: 1.0639
[18] train_loss: 1.0595
[18] train_loss: 1.0454
[18] train_loss: 1.0388
[18] train_loss: 1.0274
[18] train_loss: 1.0302
[18] train_loss: 1.0092
2.1008222103118896

Evaluating...Epoch: 18
Prec: 0.8449, Recall: 0.8375, F1: 0.8412

[19] train_loss: 0.8825
[19] train_loss: 1.0018
[19] train_loss: 0.9885
[19] train_loss: 0.9839
[19] train_loss: 1.0237
[19] train_loss: 1.0330
[19] train_loss: 0.9953
[19] train_loss: 0.9677
[19] train_loss: 0.9847
[19] train_loss: 0.9753
[19] train_loss: 0.9665
[19] train_loss: 0.9732
[19] train_loss: 0.9781
[19] train_loss: 0.9699
[19] train_loss: 0.9815
[19] train_loss: 0.9622
2.100163459777832

Evaluating...Epoch: 19
Prec: 0.8615, Recall: 0.8230, F1: 0.8418

[20] train_loss: 0.8383
[20] train_loss: 0.9074
[20] train_loss: 0.9143
[20] train_loss: 0.9455
[20] train_loss: 0.9805
[20] train_loss: 0.9920
[20] train_loss: 0.9424
[20] train_loss: 0.9248
[20] train_loss: 0.9272
[20] train_loss: 0.9133
[20] train_loss: 0.9019
[20] train_loss: 0.9113
[20] train_loss: 0.9049
[20] train_loss: 0.9050
[20] train_loss: 0.9019
[20] train_loss: 0.8877
2.1072182655334473

Evaluating...Epoch: 20
Prec: 0.8749, Recall: 0.8230, F1: 0.8481
model saved to random1_layers0_14res/best_model.pt
New best model saved!

[21] train_loss: 0.5650
[21] train_loss: 0.7363
[21] train_loss: 0.7728
[21] train_loss: 0.7794
[21] train_loss: 0.8548
[21] train_loss: 0.8730
[21] train_loss: 0.8451
[21] train_loss: 0.8658
[21] train_loss: 0.8607
[21] train_loss: 0.8449
[21] train_loss: 0.8515
[21] train_loss: 0.8556
[21] train_loss: 0.8625
[21] train_loss: 0.8631
[21] train_loss: 0.8588
[21] train_loss: 0.8513
2.1898281574249268

Evaluating...Epoch: 21
Prec: 0.8932, Recall: 0.8054, F1: 0.8471

[22] train_loss: 0.5505
[22] train_loss: 0.7095
[22] train_loss: 0.7735
[22] train_loss: 0.7797
[22] train_loss: 0.8274
[22] train_loss: 0.8415
[22] train_loss: 0.8124
[22] train_loss: 0.8089
[22] train_loss: 0.8124
[22] train_loss: 0.8240
[22] train_loss: 0.8085
[22] train_loss: 0.8198
[22] train_loss: 0.8219
[22] train_loss: 0.8190
[22] train_loss: 0.8333
[22] train_loss: 0.8169
2.0910677909851074

Evaluating...Epoch: 22
Prec: 0.8693, Recall: 0.8152, F1: 0.8414

[23] train_loss: 0.6712
[23] train_loss: 0.8785
[23] train_loss: 0.9532
[23] train_loss: 0.8976
[23] train_loss: 0.9575
[23] train_loss: 0.9405
[23] train_loss: 0.9053
[23] train_loss: 0.8761
[23] train_loss: 0.8753
[23] train_loss: 0.8683
[23] train_loss: 0.8652
[23] train_loss: 0.8693
[23] train_loss: 0.8681
[23] train_loss: 0.8621
[23] train_loss: 0.8595
[23] train_loss: 0.8440
2.0723512172698975

Evaluating...Epoch: 23
Prec: 0.8678, Recall: 0.8171, F1: 0.8417

[24] train_loss: 0.6702
[24] train_loss: 0.7069
[24] train_loss: 0.7474
[24] train_loss: 0.7675
[24] train_loss: 0.8076
[24] train_loss: 0.8219
[24] train_loss: 0.7937
[24] train_loss: 0.7744
[24] train_loss: 0.7894
[24] train_loss: 0.8017
[24] train_loss: 0.7882
[24] train_loss: 0.7916
[24] train_loss: 0.7838
[24] train_loss: 0.7803
[24] train_loss: 0.7815
[24] train_loss: 0.7723
2.090808391571045

Evaluating...Epoch: 24
Prec: 0.8805, Recall: 0.8025, F1: 0.8397

[25] train_loss: 0.5926
[25] train_loss: 0.6758
[25] train_loss: 0.6980
[25] train_loss: 0.7198
[25] train_loss: 0.7855
[25] train_loss: 0.8086
[25] train_loss: 0.7709
[25] train_loss: 0.7644
[25] train_loss: 0.7627
[25] train_loss: 0.7594
[25] train_loss: 0.7523
[25] train_loss: 0.7561
[25] train_loss: 0.7615
[25] train_loss: 0.7566
[25] train_loss: 0.7577
[25] train_loss: 0.7444
2.0970942974090576

Evaluating...Epoch: 25
Prec: 0.8756, Recall: 0.8220, F1: 0.8480

[26] train_loss: 0.6157
[26] train_loss: 0.6886
[26] train_loss: 0.7067
[26] train_loss: 0.6918
[26] train_loss: 0.7235
[26] train_loss: 0.7337
[26] train_loss: 0.7068
[26] train_loss: 0.7123
[26] train_loss: 0.7077
[26] train_loss: 0.6982
[26] train_loss: 0.7018
[26] train_loss: 0.7059
[26] train_loss: 0.7065
[26] train_loss: 0.7026
[26] train_loss: 0.7082
[26] train_loss: 0.6997
2.1711130142211914

Evaluating...Epoch: 26
Prec: 0.8531, Recall: 0.8191, F1: 0.8357

[27] train_loss: 0.5986
[27] train_loss: 0.6988
[27] train_loss: 0.6892
[27] train_loss: 0.6746
[27] train_loss: 0.7066
[27] train_loss: 0.7427
[27] train_loss: 0.7169
[27] train_loss: 0.7053
[27] train_loss: 0.7164
[27] train_loss: 0.7093
[27] train_loss: 0.6880
[27] train_loss: 0.6849
[27] train_loss: 0.6804
[27] train_loss: 0.6733
[27] train_loss: 0.6787
[27] train_loss: 0.6675
2.0518431663513184

Evaluating...Epoch: 27
Prec: 0.8721, Recall: 0.8288, F1: 0.8499
model saved to random1_layers0_14res/best_model.pt
New best model saved!

[28] train_loss: 0.5053
[28] train_loss: 0.6292
[28] train_loss: 0.6728
[28] train_loss: 0.6712
[28] train_loss: 0.7090
[28] train_loss: 0.7191
[28] train_loss: 0.7037
[28] train_loss: 0.7014
[28] train_loss: 0.7322
[28] train_loss: 0.7360
[28] train_loss: 0.7398
[28] train_loss: 0.7497
[28] train_loss: 0.7343
[28] train_loss: 0.7209
[28] train_loss: 0.7120
[28] train_loss: 0.6945
2.078618049621582

Evaluating...Epoch: 28
Prec: 0.8517, Recall: 0.8268, F1: 0.8391

[29] train_loss: 0.5183
[29] train_loss: 0.5774
[29] train_loss: 0.6697
[29] train_loss: 0.6363
[29] train_loss: 0.7028
[29] train_loss: 0.7194
[29] train_loss: 0.6890
[29] train_loss: 0.6730
[29] train_loss: 0.6839
[29] train_loss: 0.6695
[29] train_loss: 0.6681
[29] train_loss: 0.6682
[29] train_loss: 0.6666
[29] train_loss: 0.6590
[29] train_loss: 0.6643
[29] train_loss: 0.6485
2.075587272644043

Evaluating...Epoch: 29
Prec: 0.8590, Recall: 0.8181, F1: 0.8381

[30] train_loss: 0.4020
[30] train_loss: 0.5561
[30] train_loss: 0.5845
[30] train_loss: 0.5639
[30] train_loss: 0.5891
[30] train_loss: 0.6215
[30] train_loss: 0.5983
[30] train_loss: 0.6000
[30] train_loss: 0.6133
[30] train_loss: 0.6095
[30] train_loss: 0.6094
[30] train_loss: 0.6215
[30] train_loss: 0.6216
[30] train_loss: 0.6161
[30] train_loss: 0.6236
[30] train_loss: 0.6193
2.1631603240966797

Evaluating...Epoch: 30
Prec: 0.8615, Recall: 0.8230, F1: 0.8418

[31] train_loss: 0.4178
[31] train_loss: 0.5353
[31] train_loss: 0.5495
[31] train_loss: 0.5643
[31] train_loss: 0.5850
[31] train_loss: 0.6042
[31] train_loss: 0.5880
[31] train_loss: 0.5852
[31] train_loss: 0.5901
[31] train_loss: 0.6085
[31] train_loss: 0.5972
[31] train_loss: 0.6045
[31] train_loss: 0.6061
[31] train_loss: 0.6037
[31] train_loss: 0.6038
[31] train_loss: 0.5961
2.0851492881774902

Evaluating...Epoch: 31
Prec: 0.8548, Recall: 0.8191, F1: 0.8366

[32] train_loss: 0.5843
[32] train_loss: 0.5840
[32] train_loss: 0.5544
[32] train_loss: 0.5568
[32] train_loss: 0.6005
[32] train_loss: 0.6166
[32] train_loss: 0.5983
[32] train_loss: 0.5771
[32] train_loss: 0.5861
[32] train_loss: 0.5776
[32] train_loss: 0.5637
[32] train_loss: 0.5844
[32] train_loss: 0.5868
[32] train_loss: 0.5829
[32] train_loss: 0.5793
[32] train_loss: 0.5651
2.0826447010040283

Evaluating...Epoch: 32
Prec: 0.8634, Recall: 0.8113, F1: 0.8365

[33] train_loss: 0.3895
[33] train_loss: 0.4643
[33] train_loss: 0.5241
[33] train_loss: 0.5300
[33] train_loss: 0.5574
[33] train_loss: 0.5635
[33] train_loss: 0.5399
[33] train_loss: 0.5488
[33] train_loss: 0.5438
[33] train_loss: 0.5263
[33] train_loss: 0.5208
[33] train_loss: 0.5181
[33] train_loss: 0.5156
[33] train_loss: 0.5184
[33] train_loss: 0.5237
[33] train_loss: 0.5138
2.088423728942871

Evaluating...Epoch: 33
Prec: 0.8797, Recall: 0.8113, F1: 0.8441

[34] train_loss: 0.3910
[34] train_loss: 0.4448
[34] train_loss: 0.4594
[34] train_loss: 0.4824
[34] train_loss: 0.5143
[34] train_loss: 0.5510
[34] train_loss: 0.5536
[34] train_loss: 0.5664
[34] train_loss: 0.5722
[34] train_loss: 0.5686
[34] train_loss: 0.5564
[34] train_loss: 0.5613
[34] train_loss: 0.5516
[34] train_loss: 0.5408
[34] train_loss: 0.5488
[34] train_loss: 0.5385
2.176784038543701

Evaluating...Epoch: 34
Prec: 0.8649, Recall: 0.8220, F1: 0.8429

[35] train_loss: 0.4159
[35] train_loss: 0.4279
[35] train_loss: 0.4748
[35] train_loss: 0.4672
[35] train_loss: 0.4809
[35] train_loss: 0.5250
[35] train_loss: 0.5133
[35] train_loss: 0.5125
[35] train_loss: 0.5200
[35] train_loss: 0.5204
[35] train_loss: 0.5119
[35] train_loss: 0.5138
[35] train_loss: 0.5142
[35] train_loss: 0.5078
[35] train_loss: 0.5097
[35] train_loss: 0.5027
2.0827927589416504

Evaluating...Epoch: 35
Prec: 0.8804, Recall: 0.8307, F1: 0.8549
model saved to random1_layers0_14res/best_model.pt
New best model saved!

[36] train_loss: 0.2977
[36] train_loss: 0.4230
[36] train_loss: 0.4545
[36] train_loss: 0.4621
[36] train_loss: 0.4769
[36] train_loss: 0.5085
[36] train_loss: 0.5080
[36] train_loss: 0.5104
[36] train_loss: 0.5182
[36] train_loss: 0.5155
[36] train_loss: 0.5058
[36] train_loss: 0.5045
[36] train_loss: 0.5025
[36] train_loss: 0.5024
[36] train_loss: 0.4994
[36] train_loss: 0.4937
2.080768585205078

Evaluating...Epoch: 36
Prec: 0.8656, Recall: 0.8268, F1: 0.8458

[37] train_loss: 0.3577
[37] train_loss: 0.3716
[37] train_loss: 0.3886
[37] train_loss: 0.4112
[37] train_loss: 0.4395
[37] train_loss: 0.4500
[37] train_loss: 0.4340
[37] train_loss: 0.4417
[37] train_loss: 0.4551
[37] train_loss: 0.4637
[37] train_loss: 0.4577
[37] train_loss: 0.4616
[37] train_loss: 0.4676
[37] train_loss: 0.4641
[37] train_loss: 0.4684
[37] train_loss: 0.4596
2.074310541152954

Evaluating...Epoch: 37
Prec: 0.8603, Recall: 0.8327, F1: 0.8463

[38] train_loss: 0.4156
[38] train_loss: 0.4314
[38] train_loss: 0.4784
[38] train_loss: 0.4684
[38] train_loss: 0.5054
[38] train_loss: 0.5085
[38] train_loss: 0.4900
[38] train_loss: 0.4778
[38] train_loss: 0.4814
[38] train_loss: 0.4835
[38] train_loss: 0.4744
[38] train_loss: 0.4778
[38] train_loss: 0.4936
[38] train_loss: 0.4929
[38] train_loss: 0.4973
[38] train_loss: 0.4890
2.074524402618408

Evaluating...Epoch: 38
Prec: 0.8710, Recall: 0.8142, F1: 0.8416

[39] train_loss: 0.3088
[39] train_loss: 0.4315
[39] train_loss: 0.4081
[39] train_loss: 0.3926
[39] train_loss: 0.4115
[39] train_loss: 0.4313
[39] train_loss: 0.4326
[39] train_loss: 0.4306
[39] train_loss: 0.4201
[39] train_loss: 0.4393
[39] train_loss: 0.4413
[39] train_loss: 0.4558
[39] train_loss: 0.4556
[39] train_loss: 0.4548
[39] train_loss: 0.4549
[39] train_loss: 0.4425
2.0687522888183594

Evaluating...Epoch: 39
Prec: 0.8466, Recall: 0.8375, F1: 0.8421

[40] train_loss: 0.3705
[40] train_loss: 0.3633
[40] train_loss: 0.3687
[40] train_loss: 0.3930
[40] train_loss: 0.4128
[40] train_loss: 0.4346
[40] train_loss: 0.4277
[40] train_loss: 0.4328
[40] train_loss: 0.4411
[40] train_loss: 0.4380
[40] train_loss: 0.4355
[40] train_loss: 0.4429
[40] train_loss: 0.4379
[40] train_loss: 0.4376
[40] train_loss: 0.4464
[40] train_loss: 0.4387
2.0918021202087402

Evaluating...Epoch: 40
Prec: 0.8669, Recall: 0.8113, F1: 0.8382

[41] train_loss: 0.2710
[41] train_loss: 0.3489
[41] train_loss: 0.3985
[41] train_loss: 0.3783
[41] train_loss: 0.4102
[41] train_loss: 0.4300
[41] train_loss: 0.4188
[41] train_loss: 0.4234
[41] train_loss: 0.4349
[41] train_loss: 0.4374
[41] train_loss: 0.4394
[41] train_loss: 0.4334
[41] train_loss: 0.4448
[41] train_loss: 0.4400
[41] train_loss: 0.4391
[41] train_loss: 0.4293
2.0872013568878174

Evaluating...Epoch: 41
Prec: 0.8665, Recall: 0.8142, F1: 0.8395

[42] train_loss: 0.3350
[42] train_loss: 0.3729
[42] train_loss: 0.4216
[42] train_loss: 0.4257
[42] train_loss: 0.4509
[42] train_loss: 0.4657
[42] train_loss: 0.4545
[42] train_loss: 0.4433
[42] train_loss: 0.4559
[42] train_loss: 0.4530
[42] train_loss: 0.4477
[42] train_loss: 0.4497
[42] train_loss: 0.4421
[42] train_loss: 0.4413
[42] train_loss: 0.4386
[42] train_loss: 0.4336
2.1001720428466797

Evaluating...Epoch: 42
Prec: 0.8446, Recall: 0.8405, F1: 0.8425

[43] train_loss: 0.3820
[43] train_loss: 0.3794
[43] train_loss: 0.3811
[43] train_loss: 0.4028
[43] train_loss: 0.4283
[43] train_loss: 0.4146
[43] train_loss: 0.3962
[43] train_loss: 0.3869
[43] train_loss: 0.3948
[43] train_loss: 0.4026
[43] train_loss: 0.4018
[43] train_loss: 0.4030
[43] train_loss: 0.4083
[43] train_loss: 0.4062
[43] train_loss: 0.4061
[43] train_loss: 0.3995
2.083724021911621

Evaluating...Epoch: 43
Prec: 0.8669, Recall: 0.8298, F1: 0.8479

[44] train_loss: 0.2825
[44] train_loss: 0.3141
[44] train_loss: 0.3461
[44] train_loss: 0.3633
[44] train_loss: 0.4240
[44] train_loss: 0.4470
[44] train_loss: 0.4342
[44] train_loss: 0.4289
[44] train_loss: 0.4318
[44] train_loss: 0.4274
[44] train_loss: 0.4140
[44] train_loss: 0.4114
[44] train_loss: 0.4131
[44] train_loss: 0.4042
[44] train_loss: 0.4054
[44] train_loss: 0.3981
2.087496042251587

Evaluating...Epoch: 44
Prec: 0.8677, Recall: 0.8356, F1: 0.8513

[45] train_loss: 0.2498
[45] train_loss: 0.3775
[45] train_loss: 0.4253
[45] train_loss: 0.4071
[45] train_loss: 0.4193
[45] train_loss: 0.4273
[45] train_loss: 0.4137
[45] train_loss: 0.4206
[45] train_loss: 0.4150
[45] train_loss: 0.4150
[45] train_loss: 0.4039
[45] train_loss: 0.4121
[45] train_loss: 0.4072
[45] train_loss: 0.3989
[45] train_loss: 0.3995
[45] train_loss: 0.3978
2.092190742492676

Evaluating...Epoch: 45
Prec: 0.8623, Recall: 0.8288, F1: 0.8452

[46] train_loss: 0.3204
[46] train_loss: 0.3077
[46] train_loss: 0.3491
[46] train_loss: 0.3426
[46] train_loss: 0.3763
[46] train_loss: 0.4155
[46] train_loss: 0.3978
[46] train_loss: 0.3817
[46] train_loss: 0.3909
[46] train_loss: 0.3999
[46] train_loss: 0.3987
[46] train_loss: 0.4021
[46] train_loss: 0.3987
[46] train_loss: 0.3956
[46] train_loss: 0.3931
[46] train_loss: 0.3881
2.0897815227508545

Evaluating...Epoch: 46
Prec: 0.8619, Recall: 0.8259, F1: 0.8435

[47] train_loss: 0.3141
[47] train_loss: 0.3169
[47] train_loss: 0.3205
[47] train_loss: 0.3091
[47] train_loss: 0.3059
[47] train_loss: 0.3393
[47] train_loss: 0.3264
[47] train_loss: 0.3340
[47] train_loss: 0.3482
[47] train_loss: 0.3459
[47] train_loss: 0.3460
[47] train_loss: 0.3454
[47] train_loss: 0.3444
[47] train_loss: 0.3462
[47] train_loss: 0.3538
[47] train_loss: 0.3468
2.1721858978271484

Evaluating...Epoch: 47
Prec: 0.8712, Recall: 0.8161, F1: 0.8428

[48] train_loss: 0.2808
[48] train_loss: 0.3844
[48] train_loss: 0.3361
[48] train_loss: 0.3384
[48] train_loss: 0.3753
[48] train_loss: 0.3752
[48] train_loss: 0.3702
[48] train_loss: 0.3769
[48] train_loss: 0.3813
[48] train_loss: 0.3774
[48] train_loss: 0.3649
[48] train_loss: 0.3671
[48] train_loss: 0.3700
[48] train_loss: 0.3630
[48] train_loss: 0.3581
[48] train_loss: 0.3494
2.0872786045074463

Evaluating...Epoch: 48
Prec: 0.8586, Recall: 0.8268, F1: 0.8424

[49] train_loss: 0.2216
[49] train_loss: 0.3144
[49] train_loss: 0.3126
[49] train_loss: 0.3253
[49] train_loss: 0.3257
[49] train_loss: 0.3316
[49] train_loss: 0.3205
[49] train_loss: 0.3201
[49] train_loss: 0.3285
[49] train_loss: 0.3327
[49] train_loss: 0.3442
[49] train_loss: 0.3584
[49] train_loss: 0.3568
[49] train_loss: 0.3506
[49] train_loss: 0.3483
[49] train_loss: 0.3489
2.089613199234009

Evaluating...Epoch: 49
Prec: 0.8696, Recall: 0.8171, F1: 0.8425

[50] train_loss: 0.2907
[50] train_loss: 0.2658
[50] train_loss: 0.2935
[50] train_loss: 0.3081
[50] train_loss: 0.3204
[50] train_loss: 0.3368
[50] train_loss: 0.3281
[50] train_loss: 0.3263
[50] train_loss: 0.3289
[50] train_loss: 0.3206
[50] train_loss: 0.3130
[50] train_loss: 0.3257
[50] train_loss: 0.3285
[50] train_loss: 0.3265
[50] train_loss: 0.3266
[50] train_loss: 0.3225
2.07733416557312

Evaluating...Epoch: 50
Prec: 0.8689, Recall: 0.8249, F1: 0.8463

[51] train_loss: 0.2562
[51] train_loss: 0.2936
[51] train_loss: 0.3257
[51] train_loss: 0.3306
[51] train_loss: 0.3533
[51] train_loss: 0.3475
[51] train_loss: 0.3325
[51] train_loss: 0.3308
[51] train_loss: 0.3360
[51] train_loss: 0.3436
[51] train_loss: 0.3438
[51] train_loss: 0.3462
[51] train_loss: 0.3467
[51] train_loss: 0.3461
[51] train_loss: 0.3395
[51] train_loss: 0.3312
2.1397101879119873

Evaluating...Epoch: 51
Prec: 0.8667, Recall: 0.8288, F1: 0.8473

[52] train_loss: 0.1476
[52] train_loss: 0.2414
[52] train_loss: 0.2783
[52] train_loss: 0.3030
[52] train_loss: 0.3264
[52] train_loss: 0.3384
[52] train_loss: 0.3143
[52] train_loss: 0.3194
[52] train_loss: 0.3397
[52] train_loss: 0.3306
[52] train_loss: 0.3278
[52] train_loss: 0.3275
[52] train_loss: 0.3256
[52] train_loss: 0.3255
[52] train_loss: 0.3300
[52] train_loss: 0.3202
2.0876827239990234

Evaluating...Epoch: 52
Prec: 0.8664, Recall: 0.8200, F1: 0.8426

[53] train_loss: 0.2325
[53] train_loss: 0.3282
[53] train_loss: 0.3226
[53] train_loss: 0.3229
[53] train_loss: 0.3291
[53] train_loss: 0.3397
[53] train_loss: 0.3182
[53] train_loss: 0.3142
[53] train_loss: 0.3098
[53] train_loss: 0.3086
[53] train_loss: 0.3079
[53] train_loss: 0.3129
[53] train_loss: 0.3182
[53] train_loss: 0.3149
[53] train_loss: 0.3151
[53] train_loss: 0.3183
2.087609052658081

Evaluating...Epoch: 53
Prec: 0.8685, Recall: 0.8161, F1: 0.8415

[54] train_loss: 0.2364
[54] train_loss: 0.2375
[54] train_loss: 0.2485
[54] train_loss: 0.2581
[54] train_loss: 0.2615
[54] train_loss: 0.2765
[54] train_loss: 0.2795
[54] train_loss: 0.2909
[54] train_loss: 0.2948
[54] train_loss: 0.3015
[54] train_loss: 0.3057
[54] train_loss: 0.3012
[54] train_loss: 0.3039
[54] train_loss: 0.2985
[54] train_loss: 0.2973
[54] train_loss: 0.2914
2.0936739444732666

Evaluating...Epoch: 54
Prec: 0.8613, Recall: 0.8278, F1: 0.8442

[55] train_loss: 0.2498
[55] train_loss: 0.2326
[55] train_loss: 0.2670
[55] train_loss: 0.2619
[55] train_loss: 0.2914
[55] train_loss: 0.2925
[55] train_loss: 0.2767
[55] train_loss: 0.2773
[55] train_loss: 0.2937
[55] train_loss: 0.2999
[55] train_loss: 0.2925
[55] train_loss: 0.2906
[55] train_loss: 0.2972
[55] train_loss: 0.2939
[55] train_loss: 0.3052
[55] train_loss: 0.3076
2.1484436988830566

Evaluating...Epoch: 55
Prec: 0.8406, Recall: 0.8259, F1: 0.8332

Training ended with 56 epochs.
Final result:
Prec: 0.8804, Recall: 0.8307, F1: 0.8549
loading vocab and embedding matrix from ../data/14res
size of vocab: 4381
shape of loaded embedding matrix: (4381, 300)
Generating mappings
Loading data from ../data/14res with batch size 16...
165 batches created for ../data/14res/train.json
54 batches created for ../data/14res/test.json
Building model...
1732293
[1] train_loss: 14.8614
[1] train_loss: 10.9744
[1] train_loss: 9.5667
[1] train_loss: 8.5973
[1] train_loss: 7.9570
[1] train_loss: 7.4604
[1] train_loss: 7.0047
[1] train_loss: 6.6505
[1] train_loss: 6.3514
[1] train_loss: 6.1077
[1] train_loss: 5.8994
[1] train_loss: 5.7516
[1] train_loss: 5.6080
[1] train_loss: 5.4806
[1] train_loss: 5.3853
[1] train_loss: 5.2437
2.2519028186798096

Evaluating...Epoch: 1
Prec: 0.7068, Recall: 0.5535, F1: 0.6208
model saved to random1_layers1_14res/best_model.pt
New best model saved!

[2] train_loss: 3.1658
[2] train_loss: 3.4929
[2] train_loss: 3.5951
[2] train_loss: 3.5431
[2] train_loss: 3.4983
[2] train_loss: 3.4837
[2] train_loss: 3.3692
[2] train_loss: 3.3299
[2] train_loss: 3.2859
[2] train_loss: 3.2463
[2] train_loss: 3.2176
[2] train_loss: 3.2320
[2] train_loss: 3.2177
[2] train_loss: 3.2061
[2] train_loss: 3.1978
[2] train_loss: 3.1512
2.2351720333099365

Evaluating...Epoch: 2
Prec: 0.7640, Recall: 0.7023, F1: 0.7319
model saved to random1_layers1_14res/best_model.pt
New best model saved!

[3] train_loss: 2.7375
[3] train_loss: 2.8990
[3] train_loss: 2.9864
[3] train_loss: 2.9188
[3] train_loss: 2.9264
[3] train_loss: 2.9457
[3] train_loss: 2.8674
[3] train_loss: 2.8284
[3] train_loss: 2.8115
[3] train_loss: 2.7807
[3] train_loss: 2.7773
[3] train_loss: 2.7854
[3] train_loss: 2.7792
[3] train_loss: 2.7834
[3] train_loss: 2.7819
[3] train_loss: 2.7449
2.246584415435791

Evaluating...Epoch: 3
Prec: 0.7752, Recall: 0.7247, F1: 0.7491
model saved to random1_layers1_14res/best_model.pt
New best model saved!

[4] train_loss: 2.4227
[4] train_loss: 2.5389
[4] train_loss: 2.6683
[4] train_loss: 2.6057
[4] train_loss: 2.6373
[4] train_loss: 2.6305
[4] train_loss: 2.5296
[4] train_loss: 2.5125
[4] train_loss: 2.4877
[4] train_loss: 2.4512
[4] train_loss: 2.4489
[4] train_loss: 2.4708
[4] train_loss: 2.4670
[4] train_loss: 2.4553
[4] train_loss: 2.4621
[4] train_loss: 2.4305
2.2478201389312744

Evaluating...Epoch: 4
Prec: 0.7636, Recall: 0.7636, F1: 0.7636
model saved to random1_layers1_14res/best_model.pt
New best model saved!

[5] train_loss: 2.0854
[5] train_loss: 2.3118
[5] train_loss: 2.3448
[5] train_loss: 2.2821
[5] train_loss: 2.3185
[5] train_loss: 2.3284
[5] train_loss: 2.2410
[5] train_loss: 2.2290
[5] train_loss: 2.2235
[5] train_loss: 2.1971
[5] train_loss: 2.1925
[5] train_loss: 2.2152
[5] train_loss: 2.2151
[5] train_loss: 2.2081
[5] train_loss: 2.2107
[5] train_loss: 2.1831
2.235166549682617

Evaluating...Epoch: 5
Prec: 0.8258, Recall: 0.7422, F1: 0.7818
model saved to random1_layers1_14res/best_model.pt
New best model saved!

[6] train_loss: 1.9216
[6] train_loss: 2.0947
[6] train_loss: 2.1377
[6] train_loss: 2.0965
[6] train_loss: 2.1626
[6] train_loss: 2.1602
[6] train_loss: 2.0739
[6] train_loss: 2.0378
[6] train_loss: 2.0217
[6] train_loss: 2.0174
[6] train_loss: 1.9952
[6] train_loss: 2.0057
[6] train_loss: 2.0025
[6] train_loss: 2.0052
[6] train_loss: 2.0190
[6] train_loss: 1.9911
2.2371723651885986

Evaluating...Epoch: 6
Prec: 0.8241, Recall: 0.7792, F1: 0.8010
model saved to random1_layers1_14res/best_model.pt
New best model saved!

[7] train_loss: 1.7139
[7] train_loss: 1.9163
[7] train_loss: 1.9349
[7] train_loss: 1.9101
[7] train_loss: 2.0125
[7] train_loss: 2.0272
[7] train_loss: 1.9577
[7] train_loss: 1.9192
[7] train_loss: 1.8897
[7] train_loss: 1.8702
[7] train_loss: 1.8760
[7] train_loss: 1.8851
[7] train_loss: 1.8829
[7] train_loss: 1.8634
[7] train_loss: 1.8670
[7] train_loss: 1.8387
2.247647523880005

Evaluating...Epoch: 7
Prec: 0.8214, Recall: 0.7831, F1: 0.8018
model saved to random1_layers1_14res/best_model.pt
New best model saved!

[8] train_loss: 1.5287
[8] train_loss: 1.6817
[8] train_loss: 1.7937
[8] train_loss: 1.7327
[8] train_loss: 1.8132
[8] train_loss: 1.8231
[8] train_loss: 1.7356
[8] train_loss: 1.7073
[8] train_loss: 1.7200
[8] train_loss: 1.6905
[8] train_loss: 1.6735
[8] train_loss: 1.7004
[8] train_loss: 1.6920
[8] train_loss: 1.6743
[8] train_loss: 1.6862
[8] train_loss: 1.6606
2.2670023441314697

Evaluating...Epoch: 8
Prec: 0.8289, Recall: 0.7967, F1: 0.8125
model saved to random1_layers1_14res/best_model.pt
New best model saved!

[9] train_loss: 1.3948
[9] train_loss: 1.5629
[9] train_loss: 1.6442
[9] train_loss: 1.6115
[9] train_loss: 1.6597
[9] train_loss: 1.6914
[9] train_loss: 1.6254
[9] train_loss: 1.5989
[9] train_loss: 1.5910
[9] train_loss: 1.5668
[9] train_loss: 1.5727
[9] train_loss: 1.5959
[9] train_loss: 1.5827
[9] train_loss: 1.5727
[9] train_loss: 1.5854
[9] train_loss: 1.5665
2.2527554035186768

Evaluating...Epoch: 9
Prec: 0.8102, Recall: 0.8220, F1: 0.8160
model saved to random1_layers1_14res/best_model.pt
New best model saved!

[10] train_loss: 1.2681
[10] train_loss: 1.4407
[10] train_loss: 1.5476
[10] train_loss: 1.5271
[10] train_loss: 1.5310
[10] train_loss: 1.5556
[10] train_loss: 1.4894
[10] train_loss: 1.4801
[10] train_loss: 1.5128
[10] train_loss: 1.5042
[10] train_loss: 1.4927
[10] train_loss: 1.4992
[10] train_loss: 1.4928
[10] train_loss: 1.4847
[10] train_loss: 1.4941
[10] train_loss: 1.4692
2.2559173107147217

Evaluating...Epoch: 10
Prec: 0.8149, Recall: 0.8220, F1: 0.8184
model saved to random1_layers1_14res/best_model.pt
New best model saved!

[11] train_loss: 1.2824
[11] train_loss: 1.4466
[11] train_loss: 1.4395
[11] train_loss: 1.4061
[11] train_loss: 1.5091
[11] train_loss: 1.5264
[11] train_loss: 1.4573
[11] train_loss: 1.4282
[11] train_loss: 1.4253
[11] train_loss: 1.4009
[11] train_loss: 1.3978
[11] train_loss: 1.4001
[11] train_loss: 1.3935
[11] train_loss: 1.3829
[11] train_loss: 1.3869
[11] train_loss: 1.3763
2.2653214931488037

Evaluating...Epoch: 11
Prec: 0.8102, Recall: 0.8307, F1: 0.8204
model saved to random1_layers1_14res/best_model.pt
New best model saved!

[12] train_loss: 1.0872
[12] train_loss: 1.1871
[12] train_loss: 1.2612
[12] train_loss: 1.2277
[12] train_loss: 1.2940
[12] train_loss: 1.3116
[12] train_loss: 1.2691
[12] train_loss: 1.2533
[12] train_loss: 1.2560
[12] train_loss: 1.2637
[12] train_loss: 1.2511
[12] train_loss: 1.2647
[12] train_loss: 1.2628
[12] train_loss: 1.2474
[12] train_loss: 1.2631
[12] train_loss: 1.2578
2.2517547607421875

Evaluating...Epoch: 12
Prec: 0.8489, Recall: 0.8142, F1: 0.8312
model saved to random1_layers1_14res/best_model.pt
New best model saved!

[13] train_loss: 1.1241
[13] train_loss: 1.2072
[13] train_loss: 1.2135
[13] train_loss: 1.1850
[13] train_loss: 1.2522
[13] train_loss: 1.2870
[13] train_loss: 1.2491
[13] train_loss: 1.2172
[13] train_loss: 1.2213
[13] train_loss: 1.2074
[13] train_loss: 1.2000
[13] train_loss: 1.2157
[13] train_loss: 1.2138
[13] train_loss: 1.2152
[13] train_loss: 1.2231
[13] train_loss: 1.2008
2.336390972137451

Evaluating...Epoch: 13
Prec: 0.8541, Recall: 0.8084, F1: 0.8306

[14] train_loss: 1.0570
[14] train_loss: 1.1485
[14] train_loss: 1.1660
[14] train_loss: 1.1584
[14] train_loss: 1.2147
[14] train_loss: 1.2412
[14] train_loss: 1.1932
[14] train_loss: 1.1848
[14] train_loss: 1.1819
[14] train_loss: 1.1824
[14] train_loss: 1.1773
[14] train_loss: 1.1827
[14] train_loss: 1.1826
[14] train_loss: 1.1819
[14] train_loss: 1.1897
[14] train_loss: 1.1749
2.249011278152466

Evaluating...Epoch: 14
Prec: 0.8488, Recall: 0.8025, F1: 0.8250

[15] train_loss: 0.9510
[15] train_loss: 0.9974
[15] train_loss: 1.0518
[15] train_loss: 1.0655
[15] train_loss: 1.1193
[15] train_loss: 1.1696
[15] train_loss: 1.1249
[15] train_loss: 1.0845
[15] train_loss: 1.0905
[15] train_loss: 1.0917
[15] train_loss: 1.0838
[15] train_loss: 1.1070
[15] train_loss: 1.0990
[15] train_loss: 1.0850
[15] train_loss: 1.0877
[15] train_loss: 1.0704
2.2478291988372803

Evaluating...Epoch: 15
Prec: 0.8510, Recall: 0.8113, F1: 0.8307

[16] train_loss: 0.8433
[16] train_loss: 1.0287
[16] train_loss: 1.1026
[16] train_loss: 1.0718
[16] train_loss: 1.0957
[16] train_loss: 1.1198
[16] train_loss: 1.0883
[16] train_loss: 1.0766
[16] train_loss: 1.0658
[16] train_loss: 1.0487
[16] train_loss: 1.0372
[16] train_loss: 1.0516
[16] train_loss: 1.0457
[16] train_loss: 1.0350
[16] train_loss: 1.0267
[16] train_loss: 1.0131
2.239222764968872

Evaluating...Epoch: 16
Prec: 0.8737, Recall: 0.8006, F1: 0.8355
model saved to random1_layers1_14res/best_model.pt
New best model saved!

[17] train_loss: 0.7292
[17] train_loss: 0.9221
[17] train_loss: 0.9322
[17] train_loss: 0.9204
[17] train_loss: 0.9624
[17] train_loss: 0.9965
[17] train_loss: 0.9507
[17] train_loss: 0.9469
[17] train_loss: 0.9578
[17] train_loss: 0.9521
[17] train_loss: 0.9426
[17] train_loss: 0.9569
[17] train_loss: 0.9454
[17] train_loss: 0.9418
[17] train_loss: 0.9499
[17] train_loss: 0.9380
2.3282008171081543

Evaluating...Epoch: 17
Prec: 0.8419, Recall: 0.8288, F1: 0.8353

[18] train_loss: 0.7517
[18] train_loss: 0.8909
[18] train_loss: 0.9813
[18] train_loss: 0.9379
[18] train_loss: 0.9980
[18] train_loss: 1.0078
[18] train_loss: 0.9585
[18] train_loss: 0.9248
[18] train_loss: 0.9345
[18] train_loss: 0.9310
[18] train_loss: 0.9262
[18] train_loss: 0.9447
[18] train_loss: 0.9342
[18] train_loss: 0.9266
[18] train_loss: 0.9287
[18] train_loss: 0.9256
2.227426528930664

Evaluating...Epoch: 18
Prec: 0.8641, Recall: 0.7977, F1: 0.8295

[19] train_loss: 0.8100
[19] train_loss: 0.9848
[19] train_loss: 0.9673
[19] train_loss: 0.9166
[19] train_loss: 0.9683
[19] train_loss: 0.9904
[19] train_loss: 0.9466
[19] train_loss: 0.9265
[19] train_loss: 0.9134
[19] train_loss: 0.8889
[19] train_loss: 0.8900
[19] train_loss: 0.9038
[19] train_loss: 0.9004
[19] train_loss: 0.8942
[19] train_loss: 0.9023
[19] train_loss: 0.8923
2.2243471145629883

Evaluating...Epoch: 19
Prec: 0.8547, Recall: 0.8239, F1: 0.8390
model saved to random1_layers1_14res/best_model.pt
New best model saved!

[20] train_loss: 0.6803
[20] train_loss: 0.7670
[20] train_loss: 0.8378
[20] train_loss: 0.8439
[20] train_loss: 0.9511
[20] train_loss: 0.9857
[20] train_loss: 0.9483
[20] train_loss: 0.9286
[20] train_loss: 0.9273
[20] train_loss: 0.9071
[20] train_loss: 0.8962
[20] train_loss: 0.9040
[20] train_loss: 0.9004
[20] train_loss: 0.8837
[20] train_loss: 0.8876
[20] train_loss: 0.8759
2.225320816040039

Evaluating...Epoch: 20
Prec: 0.8626, Recall: 0.8064, F1: 0.8336

[21] train_loss: 0.6405
[21] train_loss: 0.7001
[21] train_loss: 0.7239
[21] train_loss: 0.7440
[21] train_loss: 0.7997
[21] train_loss: 0.8351
[21] train_loss: 0.8163
[21] train_loss: 0.7958
[21] train_loss: 0.8045
[21] train_loss: 0.8165
[21] train_loss: 0.8127
[21] train_loss: 0.8314
[21] train_loss: 0.8360
[21] train_loss: 0.8344
[21] train_loss: 0.8467
[21] train_loss: 0.8311
2.323460102081299

Evaluating...Epoch: 21
Prec: 0.8718, Recall: 0.7938, F1: 0.8310

[22] train_loss: 0.5033
[22] train_loss: 0.6099
[22] train_loss: 0.6787
[22] train_loss: 0.6946
[22] train_loss: 0.7305
[22] train_loss: 0.7549
[22] train_loss: 0.7268
[22] train_loss: 0.7133
[22] train_loss: 0.7197
[22] train_loss: 0.7330
[22] train_loss: 0.7484
[22] train_loss: 0.7523
[22] train_loss: 0.7579
[22] train_loss: 0.7576
[22] train_loss: 0.7634
[22] train_loss: 0.7543
2.244159460067749

Evaluating...Epoch: 22
Prec: 0.8454, Recall: 0.8084, F1: 0.8265

[23] train_loss: 0.5796
[23] train_loss: 0.7018
[23] train_loss: 0.7548
[23] train_loss: 0.7410
[23] train_loss: 0.7905
[23] train_loss: 0.8165
[23] train_loss: 0.8000
[23] train_loss: 0.7918
[23] train_loss: 0.7971
[23] train_loss: 0.7888
[23] train_loss: 0.7756
[23] train_loss: 0.7817
[23] train_loss: 0.7772
[23] train_loss: 0.7673
[23] train_loss: 0.7663
[23] train_loss: 0.7662
2.220438241958618

Evaluating...Epoch: 23
Prec: 0.8392, Recall: 0.8327, F1: 0.8359

[24] train_loss: 0.5980
[24] train_loss: 0.7195
[24] train_loss: 0.7202
[24] train_loss: 0.7282
[24] train_loss: 0.7560
[24] train_loss: 0.7534
[24] train_loss: 0.7210
[24] train_loss: 0.7087
[24] train_loss: 0.7079
[24] train_loss: 0.7155
[24] train_loss: 0.7091
[24] train_loss: 0.7183
[24] train_loss: 0.7154
[24] train_loss: 0.7135
[24] train_loss: 0.7177
[24] train_loss: 0.7067
2.224853754043579

Evaluating...Epoch: 24
Prec: 0.8598, Recall: 0.8230, F1: 0.8410
model saved to random1_layers1_14res/best_model.pt
New best model saved!

[25] train_loss: 0.5511
[25] train_loss: 0.6195
[25] train_loss: 0.6611
[25] train_loss: 0.6645
[25] train_loss: 0.7051
[25] train_loss: 0.7237
[25] train_loss: 0.6866
[25] train_loss: 0.6696
[25] train_loss: 0.6538
[25] train_loss: 0.6488
[25] train_loss: 0.6400
[25] train_loss: 0.6496
[25] train_loss: 0.6490
[25] train_loss: 0.6533
[25] train_loss: 0.6594
[25] train_loss: 0.6629
2.245715856552124

Evaluating...Epoch: 25
Prec: 0.8636, Recall: 0.8132, F1: 0.8377

[26] train_loss: 0.4130
[26] train_loss: 0.5395
[26] train_loss: 0.5355
[26] train_loss: 0.5514
[26] train_loss: 0.6469
[26] train_loss: 0.7021
[26] train_loss: 0.6738
[26] train_loss: 0.6527
[26] train_loss: 0.6462
[26] train_loss: 0.6548
[26] train_loss: 0.6372
[26] train_loss: 0.6284
[26] train_loss: 0.6281
[26] train_loss: 0.6388
[26] train_loss: 0.6409
[26] train_loss: 0.6330
2.2383642196655273

Evaluating...Epoch: 26
Prec: 0.8588, Recall: 0.8103, F1: 0.8338

[27] train_loss: 0.3945
[27] train_loss: 0.5305
[27] train_loss: 0.5679
[27] train_loss: 0.5928
[27] train_loss: 0.6552
[27] train_loss: 0.6811
[27] train_loss: 0.6420
[27] train_loss: 0.6396
[27] train_loss: 0.6287
[27] train_loss: 0.6329
[27] train_loss: 0.6227
[27] train_loss: 0.6350
[27] train_loss: 0.6345
[27] train_loss: 0.6331
[27] train_loss: 0.6375
[27] train_loss: 0.6316
2.249202251434326

Evaluating...Epoch: 27
Prec: 0.8612, Recall: 0.8268, F1: 0.8437
model saved to random1_layers1_14res/best_model.pt
New best model saved!

[28] train_loss: 0.5261
[28] train_loss: 0.5712
[28] train_loss: 0.6058
[28] train_loss: 0.5885
[28] train_loss: 0.6279
[28] train_loss: 0.6523
[28] train_loss: 0.6372
[28] train_loss: 0.6283
[28] train_loss: 0.6151
[28] train_loss: 0.6020
[28] train_loss: 0.6018
[28] train_loss: 0.6170
[28] train_loss: 0.6260
[28] train_loss: 0.6181
[28] train_loss: 0.6135
[28] train_loss: 0.6001
2.2332849502563477

Evaluating...Epoch: 28
Prec: 0.8665, Recall: 0.8268, F1: 0.8462
model saved to random1_layers1_14res/best_model.pt
New best model saved!

[29] train_loss: 0.4792
[29] train_loss: 0.4874
[29] train_loss: 0.5002
[29] train_loss: 0.4923
[29] train_loss: 0.5649
[29] train_loss: 0.5786
[29] train_loss: 0.5733
[29] train_loss: 0.5717
[29] train_loss: 0.5815
[29] train_loss: 0.5866
[29] train_loss: 0.5702
[29] train_loss: 0.5812
[29] train_loss: 0.5846
[29] train_loss: 0.5824
[29] train_loss: 0.5882
[29] train_loss: 0.5797
2.239018678665161

Evaluating...Epoch: 29
Prec: 0.8514, Recall: 0.8249, F1: 0.8379

[30] train_loss: 0.4795
[30] train_loss: 0.5080
[30] train_loss: 0.5085
[30] train_loss: 0.5093
[30] train_loss: 0.5162
[30] train_loss: 0.5281
[30] train_loss: 0.5149
[30] train_loss: 0.5031
[30] train_loss: 0.5111
[30] train_loss: 0.5095
[30] train_loss: 0.4986
[30] train_loss: 0.5052
[30] train_loss: 0.5054
[30] train_loss: 0.5101
[30] train_loss: 0.5192
[30] train_loss: 0.5194
2.2288076877593994

Evaluating...Epoch: 30
Prec: 0.8683, Recall: 0.8084, F1: 0.8373

[31] train_loss: 0.4413
[31] train_loss: 0.4484
[31] train_loss: 0.4691
[31] train_loss: 0.4691
[31] train_loss: 0.5136
[31] train_loss: 0.5196
[31] train_loss: 0.5052
[31] train_loss: 0.5126
[31] train_loss: 0.5074
[31] train_loss: 0.5124
[31] train_loss: 0.5012
[31] train_loss: 0.5113
[31] train_loss: 0.5257
[31] train_loss: 0.5199
[31] train_loss: 0.5205
[31] train_loss: 0.5158
2.245460271835327

Evaluating...Epoch: 31
Prec: 0.8649, Recall: 0.8161, F1: 0.8398

[32] train_loss: 0.3994
[32] train_loss: 0.4606
[32] train_loss: 0.4781
[32] train_loss: 0.4701
[32] train_loss: 0.5007
[32] train_loss: 0.5418
[32] train_loss: 0.5475
[32] train_loss: 0.5404
[32] train_loss: 0.5413
[32] train_loss: 0.5297
[32] train_loss: 0.5232
[32] train_loss: 0.5277
[32] train_loss: 0.5238
[32] train_loss: 0.5173
[32] train_loss: 0.5166
[32] train_loss: 0.5123
2.241730213165283

Evaluating...Epoch: 32
Prec: 0.8657, Recall: 0.8152, F1: 0.8397

[33] train_loss: 0.3862
[33] train_loss: 0.4809
[33] train_loss: 0.5036
[33] train_loss: 0.4877
[33] train_loss: 0.5202
[33] train_loss: 0.5209
[33] train_loss: 0.5178
[33] train_loss: 0.5175
[33] train_loss: 0.5320
[33] train_loss: 0.5338
[33] train_loss: 0.5290
[33] train_loss: 0.5526
[33] train_loss: 0.5524
[33] train_loss: 0.5459
[33] train_loss: 0.5535
[33] train_loss: 0.5533
2.226297616958618

Evaluating...Epoch: 33
Prec: 0.8650, Recall: 0.8103, F1: 0.8368

[34] train_loss: 0.3723
[34] train_loss: 0.4427
[34] train_loss: 0.5010
[34] train_loss: 0.4529
[34] train_loss: 0.4679
[34] train_loss: 0.4851
[34] train_loss: 0.4767
[34] train_loss: 0.4944
[34] train_loss: 0.4986
[34] train_loss: 0.4986
[34] train_loss: 0.4906
[34] train_loss: 0.4998
[34] train_loss: 0.5039
[34] train_loss: 0.5038
[34] train_loss: 0.5016
[34] train_loss: 0.4966
2.345322847366333

Evaluating...Epoch: 34
Prec: 0.8695, Recall: 0.8230, F1: 0.8456

[35] train_loss: 0.4176
[35] train_loss: 0.4505
[35] train_loss: 0.4828
[35] train_loss: 0.4705
[35] train_loss: 0.4922
[35] train_loss: 0.5037
[35] train_loss: 0.4877
[35] train_loss: 0.4860
[35] train_loss: 0.4930
[35] train_loss: 0.4959
[35] train_loss: 0.4825
[35] train_loss: 0.4866
[35] train_loss: 0.4871
[35] train_loss: 0.4879
[35] train_loss: 0.4983
[35] train_loss: 0.4883
2.238905906677246

Evaluating...Epoch: 35
Prec: 0.8571, Recall: 0.8171, F1: 0.8367

[36] train_loss: 0.5133
[36] train_loss: 0.4655
[36] train_loss: 0.4484
[36] train_loss: 0.4646
[36] train_loss: 0.4816
[36] train_loss: 0.5159
[36] train_loss: 0.4775
[36] train_loss: 0.4689
[36] train_loss: 0.4615
[36] train_loss: 0.4600
[36] train_loss: 0.4496
[36] train_loss: 0.4498
[36] train_loss: 0.4548
[36] train_loss: 0.4477
[36] train_loss: 0.4438
[36] train_loss: 0.4442
2.2401654720306396

Evaluating...Epoch: 36
Prec: 0.8567, Recall: 0.8259, F1: 0.8410

[37] train_loss: 0.3449
[37] train_loss: 0.4616
[37] train_loss: 0.4937
[37] train_loss: 0.4801
[37] train_loss: 0.5192
[37] train_loss: 0.5116
[37] train_loss: 0.4911
[37] train_loss: 0.4894
[37] train_loss: 0.4885
[37] train_loss: 0.4914
[37] train_loss: 0.4883
[37] train_loss: 0.4999
[37] train_loss: 0.4951
[37] train_loss: 0.4874
[37] train_loss: 0.4791
[37] train_loss: 0.4698
2.2478485107421875

Evaluating...Epoch: 37
Prec: 0.8571, Recall: 0.8230, F1: 0.8397

[38] train_loss: 0.3059
[38] train_loss: 0.4354
[38] train_loss: 0.4706
[38] train_loss: 0.4677
[38] train_loss: 0.4952
[38] train_loss: 0.5032
[38] train_loss: 0.4885
[38] train_loss: 0.4817
[38] train_loss: 0.4845
[38] train_loss: 0.4816
[38] train_loss: 0.4748
[38] train_loss: 0.4733
[38] train_loss: 0.4751
[38] train_loss: 0.4650
[38] train_loss: 0.4660
[38] train_loss: 0.4610
2.3271141052246094

Evaluating...Epoch: 38
Prec: 0.8734, Recall: 0.8123, F1: 0.8417

[39] train_loss: 0.3886
[39] train_loss: 0.4232
[39] train_loss: 0.3951
[39] train_loss: 0.3751
[39] train_loss: 0.3980
[39] train_loss: 0.4197
[39] train_loss: 0.4154
[39] train_loss: 0.4133
[39] train_loss: 0.4195
[39] train_loss: 0.4308
[39] train_loss: 0.4137
[39] train_loss: 0.4106
[39] train_loss: 0.4121
[39] train_loss: 0.4086
[39] train_loss: 0.4141
[39] train_loss: 0.4098
2.235227346420288

Evaluating...Epoch: 39
Prec: 0.8701, Recall: 0.8210, F1: 0.8448

[40] train_loss: 0.2929
[40] train_loss: 0.4161
[40] train_loss: 0.4551
[40] train_loss: 0.4235
[40] train_loss: 0.4520
[40] train_loss: 0.4627
[40] train_loss: 0.4403
[40] train_loss: 0.4289
[40] train_loss: 0.4343
[40] train_loss: 0.4402
[40] train_loss: 0.4357
[40] train_loss: 0.4295
[40] train_loss: 0.4336
[40] train_loss: 0.4227
[40] train_loss: 0.4246
[40] train_loss: 0.4153
2.2450265884399414

Evaluating...Epoch: 40
Prec: 0.8631, Recall: 0.8278, F1: 0.8451

[41] train_loss: 0.2349
[41] train_loss: 0.2653
[41] train_loss: 0.2987
[41] train_loss: 0.3016
[41] train_loss: 0.3366
[41] train_loss: 0.3495
[41] train_loss: 0.3525
[41] train_loss: 0.3466
[41] train_loss: 0.3662
[41] train_loss: 0.3744
[41] train_loss: 0.3660
[41] train_loss: 0.3743
[41] train_loss: 0.3762
[41] train_loss: 0.3736
[41] train_loss: 0.3809
[41] train_loss: 0.3807
2.25430965423584

Evaluating...Epoch: 41
Prec: 0.8601, Recall: 0.8191, F1: 0.8391

[42] train_loss: 0.3894
[42] train_loss: 0.3428
[42] train_loss: 0.3676
[42] train_loss: 0.3535
[42] train_loss: 0.4102
[42] train_loss: 0.4224
[42] train_loss: 0.4119
[42] train_loss: 0.4063
[42] train_loss: 0.4015
[42] train_loss: 0.3948
[42] train_loss: 0.3942
[42] train_loss: 0.4045
[42] train_loss: 0.4021
[42] train_loss: 0.3944
[42] train_loss: 0.3967
[42] train_loss: 0.3885
2.3255887031555176

Evaluating...Epoch: 42
Prec: 0.8543, Recall: 0.8385, F1: 0.8463
model saved to random1_layers1_14res/best_model.pt
New best model saved!

[43] train_loss: 0.2771
[43] train_loss: 0.3001
[43] train_loss: 0.3113
[43] train_loss: 0.3011
[43] train_loss: 0.3200
[43] train_loss: 0.3338
[43] train_loss: 0.3227
[43] train_loss: 0.3254
[43] train_loss: 0.3228
[43] train_loss: 0.3271
[43] train_loss: 0.3231
[43] train_loss: 0.3305
[43] train_loss: 0.3285
[43] train_loss: 0.3357
[43] train_loss: 0.3346
[43] train_loss: 0.3302
2.221781015396118

Evaluating...Epoch: 43
Prec: 0.8513, Recall: 0.8356, F1: 0.8434

[44] train_loss: 0.3661
[44] train_loss: 0.3603
[44] train_loss: 0.3468
[44] train_loss: 0.3500
[44] train_loss: 0.3950
[44] train_loss: 0.4196
[44] train_loss: 0.3974
[44] train_loss: 0.3964
[44] train_loss: 0.4103
[44] train_loss: 0.4077
[44] train_loss: 0.4031
[44] train_loss: 0.4109
[44] train_loss: 0.4093
[44] train_loss: 0.3999
[44] train_loss: 0.3900
[44] train_loss: 0.3836
2.241515636444092

Evaluating...Epoch: 44
Prec: 0.8586, Recall: 0.8268, F1: 0.8424

[45] train_loss: 0.2608
[45] train_loss: 0.2600
[45] train_loss: 0.2711
[45] train_loss: 0.2815
[45] train_loss: 0.3077
[45] train_loss: 0.3345
[45] train_loss: 0.3270
[45] train_loss: 0.3334
[45] train_loss: 0.3319
[45] train_loss: 0.3388
[45] train_loss: 0.3333
[45] train_loss: 0.3432
[45] train_loss: 0.3438
[45] train_loss: 0.3418
[45] train_loss: 0.3503
[45] train_loss: 0.3474
2.2390806674957275

Evaluating...Epoch: 45
Prec: 0.8397, Recall: 0.8307, F1: 0.8352

[46] train_loss: 0.2211
[46] train_loss: 0.2944
[46] train_loss: 0.3153
[46] train_loss: 0.3598
[46] train_loss: 0.3671
[46] train_loss: 0.3746
[46] train_loss: 0.3560
[46] train_loss: 0.3680
[46] train_loss: 0.3585
[46] train_loss: 0.3543
[46] train_loss: 0.3442
[46] train_loss: 0.3465
[46] train_loss: 0.3518
[46] train_loss: 0.3448
[46] train_loss: 0.3450
[46] train_loss: 0.3400
2.2219297885894775

Evaluating...Epoch: 46
Prec: 0.8535, Recall: 0.8385, F1: 0.8459

[47] train_loss: 0.2735
[47] train_loss: 0.2399
[47] train_loss: 0.2421
[47] train_loss: 0.2570
[47] train_loss: 0.2674
[47] train_loss: 0.2975
[47] train_loss: 0.2790
[47] train_loss: 0.2982
[47] train_loss: 0.2972
[47] train_loss: 0.2987
[47] train_loss: 0.2929
[47] train_loss: 0.2951
[47] train_loss: 0.3016
[47] train_loss: 0.2991
[47] train_loss: 0.3027
[47] train_loss: 0.3060
2.3013622760772705

Evaluating...Epoch: 47
Prec: 0.8718, Recall: 0.8200, F1: 0.8451

[48] train_loss: 0.2357
[48] train_loss: 0.3150
[48] train_loss: 0.3328
[48] train_loss: 0.3400
[48] train_loss: 0.3473
[48] train_loss: 0.3734
[48] train_loss: 0.3626
[48] train_loss: 0.3533
[48] train_loss: 0.3481
[48] train_loss: 0.3482
[48] train_loss: 0.3439
[48] train_loss: 0.3512
[48] train_loss: 0.3511
[48] train_loss: 0.3481
[48] train_loss: 0.3478
[48] train_loss: 0.3420
2.2355761528015137

Evaluating...Epoch: 48
Prec: 0.8513, Recall: 0.8239, F1: 0.8374

[49] train_loss: 0.2170
[49] train_loss: 0.2580
[49] train_loss: 0.2270
[49] train_loss: 0.2426
[49] train_loss: 0.2625
[49] train_loss: 0.2810
[49] train_loss: 0.2754
[49] train_loss: 0.2705
[49] train_loss: 0.2836
[49] train_loss: 0.2927
[49] train_loss: 0.2913
[49] train_loss: 0.2947
[49] train_loss: 0.3010
[49] train_loss: 0.3048
[49] train_loss: 0.3009
[49] train_loss: 0.2948
2.2487759590148926

Evaluating...Epoch: 49
Prec: 0.8454, Recall: 0.8191, F1: 0.8320

[50] train_loss: 0.1800
[50] train_loss: 0.2122
[50] train_loss: 0.2108
[50] train_loss: 0.2387
[50] train_loss: 0.2519
[50] train_loss: 0.2687
[50] train_loss: 0.2638
[50] train_loss: 0.2670
[50] train_loss: 0.2859
[50] train_loss: 0.3027
[50] train_loss: 0.2950
[50] train_loss: 0.2954
[50] train_loss: 0.2950
[50] train_loss: 0.2937
[50] train_loss: 0.2941
[50] train_loss: 0.2892
2.227064371109009

Evaluating...Epoch: 50
Prec: 0.8510, Recall: 0.8278, F1: 0.8393

[51] train_loss: 0.2711
[51] train_loss: 0.2938
[51] train_loss: 0.3010
[51] train_loss: 0.2843
[51] train_loss: 0.2957
[51] train_loss: 0.3056
[51] train_loss: 0.2937
[51] train_loss: 0.2872
[51] train_loss: 0.2995
[51] train_loss: 0.3043
[51] train_loss: 0.2967
[51] train_loss: 0.2976
[51] train_loss: 0.3047
[51] train_loss: 0.3054
[51] train_loss: 0.3050
[51] train_loss: 0.3030
2.2955427169799805

Evaluating...Epoch: 51
Prec: 0.8538, Recall: 0.8239, F1: 0.8386

[52] train_loss: 0.2340
[52] train_loss: 0.2747
[52] train_loss: 0.2901
[52] train_loss: 0.2754
[52] train_loss: 0.2850
[52] train_loss: 0.3173
[52] train_loss: 0.3147
[52] train_loss: 0.3068
[52] train_loss: 0.3097
[52] train_loss: 0.3113
[52] train_loss: 0.3141
[52] train_loss: 0.3314
[52] train_loss: 0.3412
[52] train_loss: 0.3334
[52] train_loss: 0.3345
[52] train_loss: 0.3213
2.2250213623046875

Evaluating...Epoch: 52
Prec: 0.8597, Recall: 0.8288, F1: 0.8440

[53] train_loss: 0.3010
[53] train_loss: 0.2935
[53] train_loss: 0.2975
[53] train_loss: 0.2743
[53] train_loss: 0.3149
[53] train_loss: 0.3203
[53] train_loss: 0.3022
[53] train_loss: 0.3010
[53] train_loss: 0.3173
[53] train_loss: 0.3131
[53] train_loss: 0.3014
[53] train_loss: 0.3104
[53] train_loss: 0.3127
[53] train_loss: 0.3092
[53] train_loss: 0.3049
[53] train_loss: 0.2975
2.238956928253174

Evaluating...Epoch: 53
Prec: 0.8576, Recall: 0.8142, F1: 0.8353

[54] train_loss: 0.1833
[54] train_loss: 0.2554
[54] train_loss: 0.2501
[54] train_loss: 0.2349
[54] train_loss: 0.2690
[54] train_loss: 0.2846
[54] train_loss: 0.2737
[54] train_loss: 0.2845
[54] train_loss: 0.2905
[54] train_loss: 0.2957
[54] train_loss: 0.2927
[54] train_loss: 0.3067
[54] train_loss: 0.3058
[54] train_loss: 0.2985
[54] train_loss: 0.2937
[54] train_loss: 0.2899
2.236668586730957

Evaluating...Epoch: 54
Prec: 0.8648, Recall: 0.8152, F1: 0.8393

[55] train_loss: 0.2367
[55] train_loss: 0.2593
[55] train_loss: 0.2725
[55] train_loss: 0.2710
[55] train_loss: 0.2891
[55] train_loss: 0.2930
[55] train_loss: 0.2780
[55] train_loss: 0.2734
[55] train_loss: 0.2752
[55] train_loss: 0.2799
[55] train_loss: 0.2749
[55] train_loss: 0.2751
[55] train_loss: 0.2668
[55] train_loss: 0.2643
[55] train_loss: 0.2596
[55] train_loss: 0.2553
2.321726083755493

Evaluating...Epoch: 55
Prec: 0.8554, Recall: 0.8288, F1: 0.8419

[56] train_loss: 0.2977
[56] train_loss: 0.2326
[56] train_loss: 0.2322
[56] train_loss: 0.2481
[56] train_loss: 0.2619
[56] train_loss: 0.2632
[56] train_loss: 0.2517
[56] train_loss: 0.2537
[56] train_loss: 0.2633
[56] train_loss: 0.2567
[56] train_loss: 0.2629
[56] train_loss: 0.2592
[56] train_loss: 0.2673
[56] train_loss: 0.2653
[56] train_loss: 0.2677
[56] train_loss: 0.2643
2.234436511993408

Evaluating...Epoch: 56
Prec: 0.8686, Recall: 0.8103, F1: 0.8384

[57] train_loss: 0.1821
[57] train_loss: 0.2220
[57] train_loss: 0.2597
[57] train_loss: 0.2870
[57] train_loss: 0.2835
[57] train_loss: 0.2817
[57] train_loss: 0.2789
[57] train_loss: 0.2735
[57] train_loss: 0.2794
[57] train_loss: 0.2812
[57] train_loss: 0.2711
[57] train_loss: 0.2674
[57] train_loss: 0.2665
[57] train_loss: 0.2636
[57] train_loss: 0.2686
[57] train_loss: 0.2671
2.2598776817321777

Evaluating...Epoch: 57
Prec: 0.8466, Recall: 0.8375, F1: 0.8421

[58] train_loss: 0.2266
[58] train_loss: 0.2192
[58] train_loss: 0.2231
[58] train_loss: 0.2231
[58] train_loss: 0.2442
[58] train_loss: 0.2582
[58] train_loss: 0.2473
[58] train_loss: 0.2456
[58] train_loss: 0.2486
[58] train_loss: 0.2502
[58] train_loss: 0.2493
[58] train_loss: 0.2636
[58] train_loss: 0.2749
[58] train_loss: 0.2701
[58] train_loss: 0.2701
[58] train_loss: 0.2681
2.2475366592407227

Evaluating...Epoch: 58
Prec: 0.8680, Recall: 0.8191, F1: 0.8428

[59] train_loss: 0.1871
[59] train_loss: 0.2257
[59] train_loss: 0.2241
[59] train_loss: 0.2193
[59] train_loss: 0.2613
[59] train_loss: 0.2802
[59] train_loss: 0.2739
[59] train_loss: 0.2785
[59] train_loss: 0.2774
[59] train_loss: 0.2700
[59] train_loss: 0.2716
[59] train_loss: 0.2783
[59] train_loss: 0.2784
[59] train_loss: 0.2736
[59] train_loss: 0.2706
[59] train_loss: 0.2610
2.243385076522827

Evaluating...Epoch: 59
Prec: 0.8590, Recall: 0.8239, F1: 0.8411

[60] train_loss: 0.1527
[60] train_loss: 0.2360
[60] train_loss: 0.2397
[60] train_loss: 0.2346
[60] train_loss: 0.2332
[60] train_loss: 0.2302
[60] train_loss: 0.2243
[60] train_loss: 0.2214
[60] train_loss: 0.2165
[60] train_loss: 0.2206
[60] train_loss: 0.2126
[60] train_loss: 0.2145
[60] train_loss: 0.2092
[60] train_loss: 0.2095
[60] train_loss: 0.2131
[60] train_loss: 0.2166
2.226759195327759

Evaluating...Epoch: 60
Prec: 0.8561, Recall: 0.8103, F1: 0.8326

[61] train_loss: 0.1858
[61] train_loss: 0.1941
[61] train_loss: 0.2065
[61] train_loss: 0.1954
[61] train_loss: 0.2193
[61] train_loss: 0.2229
[61] train_loss: 0.2231
[61] train_loss: 0.2218
[61] train_loss: 0.2194
[61] train_loss: 0.2250
[61] train_loss: 0.2199
[61] train_loss: 0.2154
[61] train_loss: 0.2121
[61] train_loss: 0.2154
[61] train_loss: 0.2253
[61] train_loss: 0.2313
2.2424607276916504

Evaluating...Epoch: 61
Prec: 0.8465, Recall: 0.8152, F1: 0.8305

[62] train_loss: 0.1421
[62] train_loss: 0.1418
[62] train_loss: 0.1723
[62] train_loss: 0.1726
[62] train_loss: 0.1867
[62] train_loss: 0.1910
[62] train_loss: 0.1890
[62] train_loss: 0.1890
[62] train_loss: 0.1963
[62] train_loss: 0.2003
[62] train_loss: 0.1988
[62] train_loss: 0.2048
[62] train_loss: 0.2122
[62] train_loss: 0.2086
[62] train_loss: 0.2076
[62] train_loss: 0.2067
2.2405130863189697

Evaluating...Epoch: 62
Prec: 0.8537, Recall: 0.8230, F1: 0.8380

Training ended with 63 epochs.
Final result:
Prec: 0.8543, Recall: 0.8385, F1: 0.8463
loading vocab and embedding matrix from ../data/14res
size of vocab: 4381
shape of loaded embedding matrix: (4381, 300)
Generating mappings
Loading data from ../data/14res with batch size 16...
165 batches created for ../data/14res/train.json
54 batches created for ../data/14res/test.json
Building model...
1772493
[1] train_loss: 13.3684
[1] train_loss: 10.2279
[1] train_loss: 8.8663
[1] train_loss: 8.0234
[1] train_loss: 7.4724
[1] train_loss: 7.0382
[1] train_loss: 6.6134
[1] train_loss: 6.3082
[1] train_loss: 6.0414
[1] train_loss: 5.8173
[1] train_loss: 5.6340
[1] train_loss: 5.5041
[1] train_loss: 5.3663
[1] train_loss: 5.2397
[1] train_loss: 5.1544
[1] train_loss: 5.0259
2.3634583950042725

Evaluating...Epoch: 1
Prec: 0.5976, Recall: 0.6907, F1: 0.6408
model saved to random1_layers2_14res/best_model.pt
New best model saved!

[2] train_loss: 3.0815
[2] train_loss: 3.2772
[2] train_loss: 3.3997
[2] train_loss: 3.3668
[2] train_loss: 3.3722
[2] train_loss: 3.3779
[2] train_loss: 3.2681
[2] train_loss: 3.2389
[2] train_loss: 3.1949
[2] train_loss: 3.1684
[2] train_loss: 3.1508
[2] train_loss: 3.1711
[2] train_loss: 3.1630
[2] train_loss: 3.1444
[2] train_loss: 3.1609
[2] train_loss: 3.1182
2.3565073013305664

Evaluating...Epoch: 2
Prec: 0.6942, Recall: 0.7442, F1: 0.7183
model saved to random1_layers2_14res/best_model.pt
New best model saved!

[3] train_loss: 2.4288
[3] train_loss: 2.7551
[3] train_loss: 2.9351
[3] train_loss: 2.9298
[3] train_loss: 2.9274
[3] train_loss: 2.9034
[3] train_loss: 2.8187
[3] train_loss: 2.7903
[3] train_loss: 2.7622
[3] train_loss: 2.7506
[3] train_loss: 2.7327
[3] train_loss: 2.7520
[3] train_loss: 2.7413
[3] train_loss: 2.7321
[3] train_loss: 2.7377
[3] train_loss: 2.7020
2.3656864166259766

Evaluating...Epoch: 3
Prec: 0.7654, Recall: 0.7364, F1: 0.7506
model saved to random1_layers2_14res/best_model.pt
New best model saved!

[4] train_loss: 2.2548
[4] train_loss: 2.4694
[4] train_loss: 2.6179
[4] train_loss: 2.5632
[4] train_loss: 2.5786
[4] train_loss: 2.5627
[4] train_loss: 2.4690
[4] train_loss: 2.4418
[4] train_loss: 2.4348
[4] train_loss: 2.4229
[4] train_loss: 2.4143
[4] train_loss: 2.4229
[4] train_loss: 2.4096
[4] train_loss: 2.4020
[4] train_loss: 2.4185
[4] train_loss: 2.3962
2.376271963119507

Evaluating...Epoch: 4
Prec: 0.7685, Recall: 0.7685, F1: 0.7685
model saved to random1_layers2_14res/best_model.pt
New best model saved!

[5] train_loss: 2.0320
[5] train_loss: 2.2649
[5] train_loss: 2.4070
[5] train_loss: 2.3600
[5] train_loss: 2.3583
[5] train_loss: 2.3788
[5] train_loss: 2.2896
[5] train_loss: 2.2412
[5] train_loss: 2.2032
[5] train_loss: 2.1822
[5] train_loss: 2.1727
[5] train_loss: 2.1911
[5] train_loss: 2.1934
[5] train_loss: 2.1853
[5] train_loss: 2.1938
[5] train_loss: 2.1707
2.3743183612823486

Evaluating...Epoch: 5
Prec: 0.8254, Recall: 0.7724, F1: 0.7980
model saved to random1_layers2_14res/best_model.pt
New best model saved!

[6] train_loss: 1.7644
[6] train_loss: 2.0476
[6] train_loss: 2.1277
[6] train_loss: 2.0917
[6] train_loss: 2.1378
[6] train_loss: 2.1391
[6] train_loss: 2.0458
[6] train_loss: 2.0158
[6] train_loss: 2.0216
[6] train_loss: 2.0102
[6] train_loss: 1.9831
[6] train_loss: 1.9963
[6] train_loss: 1.9928
[6] train_loss: 1.9867
[6] train_loss: 1.9889
[6] train_loss: 1.9642
2.391490936279297

Evaluating...Epoch: 6
Prec: 0.8132, Recall: 0.8045, F1: 0.8088
model saved to random1_layers2_14res/best_model.pt
New best model saved!

[7] train_loss: 1.7606
[7] train_loss: 1.8843
[7] train_loss: 2.0105
[7] train_loss: 1.9240
[7] train_loss: 1.9843
[7] train_loss: 1.9730
[7] train_loss: 1.8959
[7] train_loss: 1.8595
[7] train_loss: 1.8593
[7] train_loss: 1.8376
[7] train_loss: 1.8256
[7] train_loss: 1.8563
[7] train_loss: 1.8507
[7] train_loss: 1.8499
[7] train_loss: 1.8696
[7] train_loss: 1.8381
2.3901381492614746

Evaluating...Epoch: 7
Prec: 0.8470, Recall: 0.7918, F1: 0.8185
model saved to random1_layers2_14res/best_model.pt
New best model saved!

[8] train_loss: 1.6059
[8] train_loss: 1.6681
[8] train_loss: 1.7654
[8] train_loss: 1.7246
[8] train_loss: 1.7950
[8] train_loss: 1.7925
[8] train_loss: 1.7167
[8] train_loss: 1.7261
[8] train_loss: 1.7111
[8] train_loss: 1.6864
[8] train_loss: 1.6903
[8] train_loss: 1.7053
[8] train_loss: 1.6990
[8] train_loss: 1.6789
[8] train_loss: 1.6938
[8] train_loss: 1.6672
2.3794496059417725

Evaluating...Epoch: 8
Prec: 0.8427, Recall: 0.8025, F1: 0.8221
model saved to random1_layers2_14res/best_model.pt
New best model saved!

[9] train_loss: 1.3301
[9] train_loss: 1.5248
[9] train_loss: 1.5929
[9] train_loss: 1.5808
[9] train_loss: 1.6281
[9] train_loss: 1.6462
[9] train_loss: 1.5827
[9] train_loss: 1.5741
[9] train_loss: 1.5749
[9] train_loss: 1.5510
[9] train_loss: 1.5614
[9] train_loss: 1.5690
[9] train_loss: 1.5732
[9] train_loss: 1.5805
[9] train_loss: 1.5887
[9] train_loss: 1.5693
2.380577802658081

Evaluating...Epoch: 9
Prec: 0.8323, Recall: 0.8161, F1: 0.8242
model saved to random1_layers2_14res/best_model.pt
New best model saved!

[10] train_loss: 1.3067
[10] train_loss: 1.4055
[10] train_loss: 1.5524
[10] train_loss: 1.5534
[10] train_loss: 1.5953
[10] train_loss: 1.6137
[10] train_loss: 1.5641
[10] train_loss: 1.5105
[10] train_loss: 1.5147
[10] train_loss: 1.4898
[10] train_loss: 1.4790
[10] train_loss: 1.5031
[10] train_loss: 1.4906
[10] train_loss: 1.4729
[10] train_loss: 1.4762
[10] train_loss: 1.4579
2.39017653465271

Evaluating...Epoch: 10
Prec: 0.8488, Recall: 0.8249, F1: 0.8367
model saved to random1_layers2_14res/best_model.pt
New best model saved!

[11] train_loss: 1.4075
[11] train_loss: 1.4481
[11] train_loss: 1.5154
[11] train_loss: 1.5011
[11] train_loss: 1.5436
[11] train_loss: 1.5465
[11] train_loss: 1.4703
[11] train_loss: 1.4394
[11] train_loss: 1.4162
[11] train_loss: 1.3969
[11] train_loss: 1.3975
[11] train_loss: 1.4055
[11] train_loss: 1.4013
[11] train_loss: 1.3928
[11] train_loss: 1.3997
[11] train_loss: 1.3822
2.3597054481506348

Evaluating...Epoch: 11
Prec: 0.8462, Recall: 0.8298, F1: 0.8379
model saved to random1_layers2_14res/best_model.pt
New best model saved!

[12] train_loss: 1.2530
[12] train_loss: 1.4168
[12] train_loss: 1.4432
[12] train_loss: 1.3897
[12] train_loss: 1.4240
[12] train_loss: 1.4271
[12] train_loss: 1.3581
[12] train_loss: 1.3395
[12] train_loss: 1.3417
[12] train_loss: 1.3250
[12] train_loss: 1.3184
[12] train_loss: 1.3290
[12] train_loss: 1.3129
[12] train_loss: 1.2941
[12] train_loss: 1.2976
[12] train_loss: 1.2785
2.37267804145813

Evaluating...Epoch: 12
Prec: 0.8375, Recall: 0.8375, F1: 0.8375

[13] train_loss: 0.9559
[13] train_loss: 1.1680
[13] train_loss: 1.2819
[13] train_loss: 1.2387
[13] train_loss: 1.2882
[13] train_loss: 1.3200
[13] train_loss: 1.2577
[13] train_loss: 1.2290
[13] train_loss: 1.2370
[13] train_loss: 1.2254
[13] train_loss: 1.2194
[13] train_loss: 1.2251
[13] train_loss: 1.2276
[13] train_loss: 1.2186
[13] train_loss: 1.2230
[13] train_loss: 1.2033
2.458388090133667

Evaluating...Epoch: 13
Prec: 0.8269, Recall: 0.8366, F1: 0.8317

[14] train_loss: 0.8837
[14] train_loss: 1.0767
[14] train_loss: 1.0906
[14] train_loss: 1.1336
[14] train_loss: 1.1680
[14] train_loss: 1.2067
[14] train_loss: 1.1767
[14] train_loss: 1.1565
[14] train_loss: 1.1461
[14] train_loss: 1.1401
[14] train_loss: 1.1327
[14] train_loss: 1.1508
[14] train_loss: 1.1428
[14] train_loss: 1.1408
[14] train_loss: 1.1438
[14] train_loss: 1.1301
2.3902101516723633

Evaluating...Epoch: 14
Prec: 0.8327, Recall: 0.8230, F1: 0.8278

[15] train_loss: 0.8310
[15] train_loss: 0.9937
[15] train_loss: 1.0510
[15] train_loss: 1.0609
[15] train_loss: 1.1037
[15] train_loss: 1.1095
[15] train_loss: 1.0696
[15] train_loss: 1.0478
[15] train_loss: 1.0552
[15] train_loss: 1.0353
[15] train_loss: 1.0252
[15] train_loss: 1.0444
[15] train_loss: 1.0507
[15] train_loss: 1.0515
[15] train_loss: 1.0687
[15] train_loss: 1.0501
2.392989158630371

Evaluating...Epoch: 15
Prec: 0.8462, Recall: 0.8191, F1: 0.8324

[16] train_loss: 0.8525
[16] train_loss: 1.0284
[16] train_loss: 1.0558
[16] train_loss: 1.0470
[16] train_loss: 1.1109
[16] train_loss: 1.1170
[16] train_loss: 1.0650
[16] train_loss: 1.0482
[16] train_loss: 1.0496
[16] train_loss: 1.0330
[16] train_loss: 1.0232
[16] train_loss: 1.0448
[16] train_loss: 1.0443
[16] train_loss: 1.0475
[16] train_loss: 1.0437
[16] train_loss: 1.0247
2.384472131729126

Evaluating...Epoch: 16
Prec: 0.8601, Recall: 0.8375, F1: 0.8487
model saved to random1_layers2_14res/best_model.pt
New best model saved!

[17] train_loss: 0.8492
[17] train_loss: 0.9581
[17] train_loss: 0.9518
[17] train_loss: 0.9278
[17] train_loss: 0.9829
[17] train_loss: 1.0003
[17] train_loss: 0.9545
[17] train_loss: 0.9418
[17] train_loss: 0.9674
[17] train_loss: 0.9636
[17] train_loss: 0.9673
[17] train_loss: 0.9764
[17] train_loss: 0.9785
[17] train_loss: 0.9759
[17] train_loss: 0.9891
[17] train_loss: 0.9749
2.4756674766540527

Evaluating...Epoch: 17
Prec: 0.8505, Recall: 0.8356, F1: 0.8430

[18] train_loss: 0.7244
[18] train_loss: 0.8487
[18] train_loss: 0.8852
[18] train_loss: 0.8912
[18] train_loss: 1.0039
[18] train_loss: 1.0208
[18] train_loss: 0.9776
[18] train_loss: 0.9463
[18] train_loss: 0.9627
[18] train_loss: 0.9567
[18] train_loss: 0.9575
[18] train_loss: 0.9566
[18] train_loss: 0.9594
[18] train_loss: 0.9512
[18] train_loss: 0.9632
[18] train_loss: 0.9540
2.3755345344543457

Evaluating...Epoch: 18
Prec: 0.8665, Recall: 0.8337, F1: 0.8498
model saved to random1_layers2_14res/best_model.pt
New best model saved!

[19] train_loss: 0.8701
[19] train_loss: 0.8933
[19] train_loss: 0.9182
[19] train_loss: 0.9210
[19] train_loss: 0.9680
[19] train_loss: 0.9861
[19] train_loss: 0.9455
[19] train_loss: 0.9208
[19] train_loss: 0.9349
[19] train_loss: 0.9280
[19] train_loss: 0.9118
[19] train_loss: 0.9122
[19] train_loss: 0.9073
[19] train_loss: 0.9079
[19] train_loss: 0.9165
[19] train_loss: 0.9020
2.395616054534912

Evaluating...Epoch: 19
Prec: 0.8637, Recall: 0.8074, F1: 0.8346

[20] train_loss: 0.7389
[20] train_loss: 0.8655
[20] train_loss: 0.8341
[20] train_loss: 0.8569
[20] train_loss: 0.9275
[20] train_loss: 0.9425
[20] train_loss: 0.9150
[20] train_loss: 0.9001
[20] train_loss: 0.8901
[20] train_loss: 0.8885
[20] train_loss: 0.8734
[20] train_loss: 0.8794
[20] train_loss: 0.8684
[20] train_loss: 0.8601
[20] train_loss: 0.8546
[20] train_loss: 0.8401
2.3761162757873535

Evaluating...Epoch: 20
Prec: 0.8434, Recall: 0.8434, F1: 0.8434

[21] train_loss: 0.6741
[21] train_loss: 0.8118
[21] train_loss: 0.7823
[21] train_loss: 0.7693
[21] train_loss: 0.8093
[21] train_loss: 0.8437
[21] train_loss: 0.8239
[21] train_loss: 0.8281
[21] train_loss: 0.8325
[21] train_loss: 0.8220
[21] train_loss: 0.8141
[21] train_loss: 0.8222
[21] train_loss: 0.8247
[21] train_loss: 0.8133
[21] train_loss: 0.8216
[21] train_loss: 0.8056
2.4453418254852295

Evaluating...Epoch: 21
Prec: 0.8474, Recall: 0.8317, F1: 0.8395

[22] train_loss: 0.6120
[22] train_loss: 0.6841
[22] train_loss: 0.7944
[22] train_loss: 0.7770
[22] train_loss: 0.7928
[22] train_loss: 0.7875
[22] train_loss: 0.7625
[22] train_loss: 0.7652
[22] train_loss: 0.7843
[22] train_loss: 0.7739
[22] train_loss: 0.7769
[22] train_loss: 0.7894
[22] train_loss: 0.7923
[22] train_loss: 0.7793
[22] train_loss: 0.7879
[22] train_loss: 0.7819
2.3756747245788574

Evaluating...Epoch: 22
Prec: 0.8619, Recall: 0.8317, F1: 0.8465

[23] train_loss: 0.6169
[23] train_loss: 0.6152
[23] train_loss: 0.6637
[23] train_loss: 0.6671
[23] train_loss: 0.7297
[23] train_loss: 0.7558
[23] train_loss: 0.7249
[23] train_loss: 0.6946
[23] train_loss: 0.7153
[23] train_loss: 0.7228
[23] train_loss: 0.7208
[23] train_loss: 0.7200
[23] train_loss: 0.7239
[23] train_loss: 0.7150
[23] train_loss: 0.7303
[23] train_loss: 0.7190
2.3862874507904053

Evaluating...Epoch: 23
Prec: 0.8671, Recall: 0.8317, F1: 0.8491

[24] train_loss: 0.4368
[24] train_loss: 0.5182
[24] train_loss: 0.5694
[24] train_loss: 0.6137
[24] train_loss: 0.6463
[24] train_loss: 0.6659
[24] train_loss: 0.6554
[24] train_loss: 0.6748
[24] train_loss: 0.6750
[24] train_loss: 0.7013
[24] train_loss: 0.6961
[24] train_loss: 0.7109
[24] train_loss: 0.7123
[24] train_loss: 0.7145
[24] train_loss: 0.7145
[24] train_loss: 0.7053
2.3924720287323

Evaluating...Epoch: 24
Prec: 0.8695, Recall: 0.8298, F1: 0.8492

[25] train_loss: 0.4667
[25] train_loss: 0.6882
[25] train_loss: 0.6935
[25] train_loss: 0.6880
[25] train_loss: 0.7049
[25] train_loss: 0.7230
[25] train_loss: 0.7094
[25] train_loss: 0.7072
[25] train_loss: 0.7033
[25] train_loss: 0.6865
[25] train_loss: 0.6726
[25] train_loss: 0.6876
[25] train_loss: 0.6896
[25] train_loss: 0.6859
[25] train_loss: 0.6923
[25] train_loss: 0.6861
2.384465456008911

Evaluating...Epoch: 25
Prec: 0.8654, Recall: 0.8317, F1: 0.8482

[26] train_loss: 0.4480
[26] train_loss: 0.4901
[26] train_loss: 0.5846
[26] train_loss: 0.6300
[26] train_loss: 0.6627
[26] train_loss: 0.6971
[26] train_loss: 0.6767
[26] train_loss: 0.6795
[26] train_loss: 0.6887
[26] train_loss: 0.6794
[26] train_loss: 0.6659
[26] train_loss: 0.6663
[26] train_loss: 0.6732
[26] train_loss: 0.6741
[26] train_loss: 0.6788
[26] train_loss: 0.6703
2.4716928005218506

Evaluating...Epoch: 26
Prec: 0.8583, Recall: 0.8307, F1: 0.8443

[27] train_loss: 0.5228
[27] train_loss: 0.6429
[27] train_loss: 0.6472
[27] train_loss: 0.6317
[27] train_loss: 0.7026
[27] train_loss: 0.7368
[27] train_loss: 0.7079
[27] train_loss: 0.6891
[27] train_loss: 0.6799
[27] train_loss: 0.6682
[27] train_loss: 0.6575
[27] train_loss: 0.6618
[27] train_loss: 0.6600
[27] train_loss: 0.6492
[27] train_loss: 0.6601
[27] train_loss: 0.6510
2.3872616291046143

Evaluating...Epoch: 27
Prec: 0.8563, Recall: 0.8171, F1: 0.8362

[28] train_loss: 0.5254
[28] train_loss: 0.5903
[28] train_loss: 0.6113
[28] train_loss: 0.5823
[28] train_loss: 0.6159
[28] train_loss: 0.6336
[28] train_loss: 0.5951
[28] train_loss: 0.5907
[28] train_loss: 0.5953
[28] train_loss: 0.5796
[28] train_loss: 0.5772
[28] train_loss: 0.5897
[28] train_loss: 0.5805
[28] train_loss: 0.5758
[28] train_loss: 0.5900
[28] train_loss: 0.5864
2.382850408554077

Evaluating...Epoch: 28
Prec: 0.8497, Recall: 0.8356, F1: 0.8426

[29] train_loss: 0.5464
[29] train_loss: 0.5671
[29] train_loss: 0.6015
[29] train_loss: 0.6364
[29] train_loss: 0.6852
[29] train_loss: 0.7130
[29] train_loss: 0.6724
[29] train_loss: 0.6489
[29] train_loss: 0.6247
[29] train_loss: 0.6162
[29] train_loss: 0.6065
[29] train_loss: 0.6045
[29] train_loss: 0.6037
[29] train_loss: 0.6026
[29] train_loss: 0.6119
[29] train_loss: 0.6083
2.394040584564209

Evaluating...Epoch: 29
Prec: 0.8776, Recall: 0.8230, F1: 0.8494

[30] train_loss: 0.3744
[30] train_loss: 0.4151
[30] train_loss: 0.4086
[30] train_loss: 0.4198
[30] train_loss: 0.4741
[30] train_loss: 0.5222
[30] train_loss: 0.5040
[30] train_loss: 0.5118
[30] train_loss: 0.5347
[30] train_loss: 0.5404
[30] train_loss: 0.5297
[30] train_loss: 0.5319
[30] train_loss: 0.5398
[30] train_loss: 0.5374
[30] train_loss: 0.5384
[30] train_loss: 0.5271
2.4608421325683594

Evaluating...Epoch: 30
Prec: 0.8785, Recall: 0.8230, F1: 0.8498
model saved to random1_layers2_14res/best_model.pt
New best model saved!

[31] train_loss: 0.4582
[31] train_loss: 0.5081
[31] train_loss: 0.5007
[31] train_loss: 0.4824
[31] train_loss: 0.5009
[31] train_loss: 0.5254
[31] train_loss: 0.5004
[31] train_loss: 0.5073
[31] train_loss: 0.5115
[31] train_loss: 0.5047
[31] train_loss: 0.4984
[31] train_loss: 0.5095
[31] train_loss: 0.5128
[31] train_loss: 0.5124
[31] train_loss: 0.5251
[31] train_loss: 0.5203
2.3844075202941895

Evaluating...Epoch: 31
Prec: 0.8717, Recall: 0.8259, F1: 0.8482

[32] train_loss: 0.4023
[32] train_loss: 0.4134
[32] train_loss: 0.4296
[32] train_loss: 0.4238
[32] train_loss: 0.4854
[32] train_loss: 0.5117
[32] train_loss: 0.4936
[32] train_loss: 0.4827
[32] train_loss: 0.4925
[32] train_loss: 0.4896
[32] train_loss: 0.4861
[32] train_loss: 0.4970
[32] train_loss: 0.5019
[32] train_loss: 0.5029
[32] train_loss: 0.5253
[32] train_loss: 0.5159
2.3886101245880127

Evaluating...Epoch: 32
Prec: 0.8624, Recall: 0.8414, F1: 0.8518
model saved to random1_layers2_14res/best_model.pt
New best model saved!

[33] train_loss: 0.4440
[33] train_loss: 0.5066
[33] train_loss: 0.4916
[33] train_loss: 0.4783
[33] train_loss: 0.5615
[33] train_loss: 0.5561
[33] train_loss: 0.5316
[33] train_loss: 0.5271
[33] train_loss: 0.5188
[33] train_loss: 0.5264
[33] train_loss: 0.5159
[33] train_loss: 0.5223
[33] train_loss: 0.5144
[33] train_loss: 0.5077
[33] train_loss: 0.5071
[33] train_loss: 0.5011
2.3688268661499023

Evaluating...Epoch: 33
Prec: 0.8655, Recall: 0.8327, F1: 0.8488

[34] train_loss: 0.3766
[34] train_loss: 0.4202
[34] train_loss: 0.4608
[34] train_loss: 0.4526
[34] train_loss: 0.5290
[34] train_loss: 0.5107
[34] train_loss: 0.4796
[34] train_loss: 0.4745
[34] train_loss: 0.4848
[34] train_loss: 0.4753
[34] train_loss: 0.4591
[34] train_loss: 0.4710
[34] train_loss: 0.4681
[34] train_loss: 0.4653
[34] train_loss: 0.4624
[34] train_loss: 0.4631
2.4580881595611572

Evaluating...Epoch: 34
Prec: 0.8583, Recall: 0.8366, F1: 0.8473

[35] train_loss: 0.3773
[35] train_loss: 0.4110
[35] train_loss: 0.4062
[35] train_loss: 0.4164
[35] train_loss: 0.4841
[35] train_loss: 0.5229
[35] train_loss: 0.4913
[35] train_loss: 0.4808
[35] train_loss: 0.4880
[35] train_loss: 0.4757
[35] train_loss: 0.4651
[35] train_loss: 0.4708
[35] train_loss: 0.4698
[35] train_loss: 0.4714
[35] train_loss: 0.4729
[35] train_loss: 0.4648
2.384331464767456

Evaluating...Epoch: 35
Prec: 0.8512, Recall: 0.8346, F1: 0.8428

[36] train_loss: 0.4412
[36] train_loss: 0.4661
[36] train_loss: 0.4491
[36] train_loss: 0.4212
[36] train_loss: 0.5097
[36] train_loss: 0.5019
[36] train_loss: 0.4829
[36] train_loss: 0.4768
[36] train_loss: 0.4900
[36] train_loss: 0.4909
[36] train_loss: 0.4851
[36] train_loss: 0.4898
[36] train_loss: 0.4866
[36] train_loss: 0.4886
[36] train_loss: 0.4814
[36] train_loss: 0.4766
2.3836212158203125

Evaluating...Epoch: 36
Prec: 0.8712, Recall: 0.8161, F1: 0.8428

[37] train_loss: 0.3251
[37] train_loss: 0.3973
[37] train_loss: 0.4295
[37] train_loss: 0.4120
[37] train_loss: 0.4620
[37] train_loss: 0.4780
[37] train_loss: 0.4555
[37] train_loss: 0.4537
[37] train_loss: 0.4675
[37] train_loss: 0.4673
[37] train_loss: 0.4612
[37] train_loss: 0.4665
[37] train_loss: 0.4686
[37] train_loss: 0.4760
[37] train_loss: 0.4747
[37] train_loss: 0.4648
2.3678154945373535

Evaluating...Epoch: 37
Prec: 0.8628, Recall: 0.8259, F1: 0.8439

[38] train_loss: 0.4032
[38] train_loss: 0.4281
[38] train_loss: 0.3934
[38] train_loss: 0.4284
[38] train_loss: 0.4341
[38] train_loss: 0.4394
[38] train_loss: 0.4263
[38] train_loss: 0.4352
[38] train_loss: 0.4297
[38] train_loss: 0.4345
[38] train_loss: 0.4209
[38] train_loss: 0.4254
[38] train_loss: 0.4286
[38] train_loss: 0.4288
[38] train_loss: 0.4216
[38] train_loss: 0.4214
2.473421812057495

Evaluating...Epoch: 38
Prec: 0.8796, Recall: 0.8103, F1: 0.8435

[39] train_loss: 0.2471
[39] train_loss: 0.4013
[39] train_loss: 0.4017
[39] train_loss: 0.3956
[39] train_loss: 0.4355
[39] train_loss: 0.4264
[39] train_loss: 0.4140
[39] train_loss: 0.4140
[39] train_loss: 0.4151
[39] train_loss: 0.4172
[39] train_loss: 0.4167
[39] train_loss: 0.4188
[39] train_loss: 0.4130
[39] train_loss: 0.4072
[39] train_loss: 0.4142
[39] train_loss: 0.4137
2.3759591579437256

Evaluating...Epoch: 39
Prec: 0.8684, Recall: 0.8220, F1: 0.8446

[40] train_loss: 0.3273
[40] train_loss: 0.3523
[40] train_loss: 0.3479
[40] train_loss: 0.3620
[40] train_loss: 0.3697
[40] train_loss: 0.3764
[40] train_loss: 0.3650
[40] train_loss: 0.3555
[40] train_loss: 0.3579
[40] train_loss: 0.3644
[40] train_loss: 0.3539
[40] train_loss: 0.3743
[40] train_loss: 0.3771
[40] train_loss: 0.3735
[40] train_loss: 0.3740
[40] train_loss: 0.3681
2.3831615447998047

Evaluating...Epoch: 40
Prec: 0.8484, Recall: 0.8327, F1: 0.8405

[41] train_loss: 0.2891
[41] train_loss: 0.3730
[41] train_loss: 0.3681
[41] train_loss: 0.3901
[41] train_loss: 0.4160
[41] train_loss: 0.4121
[41] train_loss: 0.3978
[41] train_loss: 0.3979
[41] train_loss: 0.4010
[41] train_loss: 0.3984
[41] train_loss: 0.3863
[41] train_loss: 0.3936
[41] train_loss: 0.3975
[41] train_loss: 0.3907
[41] train_loss: 0.3914
[41] train_loss: 0.3877
2.385216474533081

Evaluating...Epoch: 41
Prec: 0.8501, Recall: 0.8220, F1: 0.8358

[42] train_loss: 0.2570
[42] train_loss: 0.2703
[42] train_loss: 0.2951
[42] train_loss: 0.3251
[42] train_loss: 0.3517
[42] train_loss: 0.3834
[42] train_loss: 0.3645
[42] train_loss: 0.3623
[42] train_loss: 0.3627
[42] train_loss: 0.3679
[42] train_loss: 0.3594
[42] train_loss: 0.3643
[42] train_loss: 0.3661
[42] train_loss: 0.3608
[42] train_loss: 0.3623
[42] train_loss: 0.3619
2.4776346683502197

Evaluating...Epoch: 42
Prec: 0.8571, Recall: 0.8346, F1: 0.8457

[43] train_loss: 0.3062
[43] train_loss: 0.3004
[43] train_loss: 0.3036
[43] train_loss: 0.3164
[43] train_loss: 0.3538
[43] train_loss: 0.3576
[43] train_loss: 0.3378
[43] train_loss: 0.3369
[43] train_loss: 0.3506
[43] train_loss: 0.3526
[43] train_loss: 0.3439
[43] train_loss: 0.3485
[43] train_loss: 0.3431
[43] train_loss: 0.3386
[43] train_loss: 0.3470
[43] train_loss: 0.3413
2.3812172412872314

Evaluating...Epoch: 43
Prec: 0.8600, Recall: 0.8249, F1: 0.8421

[44] train_loss: 0.2809
[44] train_loss: 0.3141
[44] train_loss: 0.3170
[44] train_loss: 0.3288
[44] train_loss: 0.3582
[44] train_loss: 0.3689
[44] train_loss: 0.3560
[44] train_loss: 0.3574
[44] train_loss: 0.3743
[44] train_loss: 0.3822
[44] train_loss: 0.3737
[44] train_loss: 0.3794
[44] train_loss: 0.3775
[44] train_loss: 0.3746
[44] train_loss: 0.3737
[44] train_loss: 0.3751
2.399778366088867

Evaluating...Epoch: 44
Prec: 0.8756, Recall: 0.8220, F1: 0.8480

[45] train_loss: 0.3210
[45] train_loss: 0.3029
[45] train_loss: 0.2859
[45] train_loss: 0.2928
[45] train_loss: 0.3213
[45] train_loss: 0.3368
[45] train_loss: 0.3207
[45] train_loss: 0.3219
[45] train_loss: 0.3386
[45] train_loss: 0.3451
[45] train_loss: 0.3445
[45] train_loss: 0.3525
[45] train_loss: 0.3540
[45] train_loss: 0.3594
[45] train_loss: 0.3628
[45] train_loss: 0.3624
2.3928327560424805

Evaluating...Epoch: 45
Prec: 0.8560, Recall: 0.8327, F1: 0.8442

[46] train_loss: 0.2255
[46] train_loss: 0.3478
[46] train_loss: 0.3227
[46] train_loss: 0.3139
[46] train_loss: 0.3545
[46] train_loss: 0.3596
[46] train_loss: 0.3603
[46] train_loss: 0.3558
[46] train_loss: 0.3608
[46] train_loss: 0.3572
[46] train_loss: 0.3504
[46] train_loss: 0.3536
[46] train_loss: 0.3507
[46] train_loss: 0.3473
[46] train_loss: 0.3481
[46] train_loss: 0.3394
2.367361068725586

Evaluating...Epoch: 46
Prec: 0.8535, Recall: 0.8385, F1: 0.8459

[47] train_loss: 0.2315
[47] train_loss: 0.2976
[47] train_loss: 0.3278
[47] train_loss: 0.3466
[47] train_loss: 0.3416
[47] train_loss: 0.3493
[47] train_loss: 0.3254
[47] train_loss: 0.3237
[47] train_loss: 0.3302
[47] train_loss: 0.3309
[47] train_loss: 0.3231
[47] train_loss: 0.3318
[47] train_loss: 0.3349
[47] train_loss: 0.3358
[47] train_loss: 0.3369
[47] train_loss: 0.3302
2.4544763565063477

Evaluating...Epoch: 47
Prec: 0.8526, Recall: 0.8385, F1: 0.8455

[48] train_loss: 0.3421
[48] train_loss: 0.2827
[48] train_loss: 0.2862
[48] train_loss: 0.2932
[48] train_loss: 0.3306
[48] train_loss: 0.3163
[48] train_loss: 0.3103
[48] train_loss: 0.3115
[48] train_loss: 0.3236
[48] train_loss: 0.3230
[48] train_loss: 0.3297
[48] train_loss: 0.3283
[48] train_loss: 0.3303
[48] train_loss: 0.3294
[48] train_loss: 0.3355
[48] train_loss: 0.3329
2.374485492706299

Evaluating...Epoch: 48
Prec: 0.8666, Recall: 0.8152, F1: 0.8401

[49] train_loss: 0.1852
[49] train_loss: 0.2007
[49] train_loss: 0.2135
[49] train_loss: 0.2303
[49] train_loss: 0.2891
[49] train_loss: 0.3006
[49] train_loss: 0.3062
[49] train_loss: 0.2970
[49] train_loss: 0.3006
[49] train_loss: 0.3084
[49] train_loss: 0.3080
[49] train_loss: 0.3195
[49] train_loss: 0.3247
[49] train_loss: 0.3317
[49] train_loss: 0.3325
[49] train_loss: 0.3294
2.3817636966705322

Evaluating...Epoch: 49
Prec: 0.8633, Recall: 0.8356, F1: 0.8492

[50] train_loss: 0.2695
[50] train_loss: 0.3177
[50] train_loss: 0.3246
[50] train_loss: 0.3211
[50] train_loss: 0.3396
[50] train_loss: 0.3394
[50] train_loss: 0.3294
[50] train_loss: 0.3242
[50] train_loss: 0.3242
[50] train_loss: 0.3269
[50] train_loss: 0.3180
[50] train_loss: 0.3160
[50] train_loss: 0.3128
[50] train_loss: 0.3108
[50] train_loss: 0.3049
[50] train_loss: 0.2993
2.393012762069702

Evaluating...Epoch: 50
Prec: 0.8522, Recall: 0.8414, F1: 0.8468

[51] train_loss: 0.2436
[51] train_loss: 0.2670
[51] train_loss: 0.2583
[51] train_loss: 0.2448
[51] train_loss: 0.2511
[51] train_loss: 0.2623
[51] train_loss: 0.2582
[51] train_loss: 0.2727
[51] train_loss: 0.2838
[51] train_loss: 0.2794
[51] train_loss: 0.2774
[51] train_loss: 0.2890
[51] train_loss: 0.3111
[51] train_loss: 0.3072
[51] train_loss: 0.3052
[51] train_loss: 0.2995
2.461480140686035

Evaluating...Epoch: 51
Prec: 0.8580, Recall: 0.8346, F1: 0.8462

[52] train_loss: 0.1837
[52] train_loss: 0.2473
[52] train_loss: 0.2468
[52] train_loss: 0.2631
[52] train_loss: 0.3405
[52] train_loss: 0.3423
[52] train_loss: 0.3211
[52] train_loss: 0.3140
[52] train_loss: 0.3099
[52] train_loss: 0.3196
[52] train_loss: 0.3129
[52] train_loss: 0.3224
[52] train_loss: 0.3117
[52] train_loss: 0.3047
[52] train_loss: 0.3150
[52] train_loss: 0.3096
2.3869640827178955

Evaluating...Epoch: 52
Prec: 0.8608, Recall: 0.8239, F1: 0.8419

Training ended with 53 epochs.
Final result:
Prec: 0.8624, Recall: 0.8414, F1: 0.8518
loading vocab and embedding matrix from ../data/14res
size of vocab: 4381
shape of loaded embedding matrix: (4381, 300)
Generating mappings
Loading data from ../data/14res with batch size 16...
165 batches created for ../data/14res/train.json
54 batches created for ../data/14res/test.json
Building model...
1812693
[1] train_loss: 13.9955
[1] train_loss: 10.6761
[1] train_loss: 9.2534
[1] train_loss: 8.3401
[1] train_loss: 7.7843
[1] train_loss: 7.3471
[1] train_loss: 6.9541
[1] train_loss: 6.6539
[1] train_loss: 6.3932
[1] train_loss: 6.1708
[1] train_loss: 5.9698
[1] train_loss: 5.8327
[1] train_loss: 5.7004
[1] train_loss: 5.5650
[1] train_loss: 5.4551
[1] train_loss: 5.3046
2.4883229732513428

Evaluating...Epoch: 1
Prec: 0.6360, Recall: 0.6323, F1: 0.6341
model saved to random1_layers3_14res/best_model.pt
New best model saved!

[2] train_loss: 3.1140
[2] train_loss: 3.3873
[2] train_loss: 3.5030
[2] train_loss: 3.4737
[2] train_loss: 3.4954
[2] train_loss: 3.4881
[2] train_loss: 3.3755
[2] train_loss: 3.3512
[2] train_loss: 3.3060
[2] train_loss: 3.2805
[2] train_loss: 3.2598
[2] train_loss: 3.2743
[2] train_loss: 3.2614
[2] train_loss: 3.2535
[2] train_loss: 3.2523
[2] train_loss: 3.2009
2.4481866359710693

Evaluating...Epoch: 2
Prec: 0.6579, Recall: 0.7335, F1: 0.6937
model saved to random1_layers3_14res/best_model.pt
New best model saved!

[3] train_loss: 2.5848
[3] train_loss: 2.9138
[3] train_loss: 3.0219
[3] train_loss: 2.9712
[3] train_loss: 2.9900
[3] train_loss: 2.9913
[3] train_loss: 2.8927
[3] train_loss: 2.8670
[3] train_loss: 2.8644
[3] train_loss: 2.8314
[3] train_loss: 2.8143
[3] train_loss: 2.8247
[3] train_loss: 2.8115
[3] train_loss: 2.7988
[3] train_loss: 2.7973
[3] train_loss: 2.7650
2.4726479053497314

Evaluating...Epoch: 3
Prec: 0.6955, Recall: 0.7733, F1: 0.7324
model saved to random1_layers3_14res/best_model.pt
New best model saved!

[4] train_loss: 2.3710
[4] train_loss: 2.5941
[4] train_loss: 2.7244
[4] train_loss: 2.7001
[4] train_loss: 2.6992
[4] train_loss: 2.6859
[4] train_loss: 2.6129
[4] train_loss: 2.5609
[4] train_loss: 2.5357
[4] train_loss: 2.5186
[4] train_loss: 2.5072
[4] train_loss: 2.5216
[4] train_loss: 2.5031
[4] train_loss: 2.4802
[4] train_loss: 2.4835
[4] train_loss: 2.4563
2.446117639541626

Evaluating...Epoch: 4
Prec: 0.7415, Recall: 0.7840, F1: 0.7622
model saved to random1_layers3_14res/best_model.pt
New best model saved!

[5] train_loss: 2.0236
[5] train_loss: 2.2446
[5] train_loss: 2.4059
[5] train_loss: 2.3882
[5] train_loss: 2.4388
[5] train_loss: 2.4355
[5] train_loss: 2.3557
[5] train_loss: 2.3122
[5] train_loss: 2.3056
[5] train_loss: 2.2733
[5] train_loss: 2.2587
[5] train_loss: 2.2715
[5] train_loss: 2.2627
[5] train_loss: 2.2370
[5] train_loss: 2.2449
[5] train_loss: 2.2175
2.467468738555908

Evaluating...Epoch: 5
Prec: 0.7925, Recall: 0.7763, F1: 0.7843
model saved to random1_layers3_14res/best_model.pt
New best model saved!

[6] train_loss: 1.9180
[6] train_loss: 2.1705
[6] train_loss: 2.2796
[6] train_loss: 2.1846
[6] train_loss: 2.2158
[6] train_loss: 2.2018
[6] train_loss: 2.0992
[6] train_loss: 2.0905
[6] train_loss: 2.0681
[6] train_loss: 2.0463
[6] train_loss: 2.0398
[6] train_loss: 2.0453
[6] train_loss: 2.0310
[6] train_loss: 2.0275
[6] train_loss: 2.0340
[6] train_loss: 2.0095
2.4843692779541016

Evaluating...Epoch: 6
Prec: 0.8346, Recall: 0.7607, F1: 0.7959
model saved to random1_layers3_14res/best_model.pt
New best model saved!

[7] train_loss: 1.7149
[7] train_loss: 1.9671
[7] train_loss: 2.0635
[7] train_loss: 1.9810
[7] train_loss: 2.0386
[7] train_loss: 2.0438
[7] train_loss: 1.9722
[7] train_loss: 1.9383
[7] train_loss: 1.9258
[7] train_loss: 1.9055
[7] train_loss: 1.8921
[7] train_loss: 1.8958
[7] train_loss: 1.8926
[7] train_loss: 1.8699
[7] train_loss: 1.8824
[7] train_loss: 1.8623
2.4521899223327637

Evaluating...Epoch: 7
Prec: 0.8241, Recall: 0.7840, F1: 0.8036
model saved to random1_layers3_14res/best_model.pt
New best model saved!

[8] train_loss: 1.7647
[8] train_loss: 1.7898
[8] train_loss: 1.8493
[8] train_loss: 1.7784
[8] train_loss: 1.8714
[8] train_loss: 1.8705
[8] train_loss: 1.8048
[8] train_loss: 1.7823
[8] train_loss: 1.7689
[8] train_loss: 1.7374
[8] train_loss: 1.7380
[8] train_loss: 1.7526
[8] train_loss: 1.7473
[8] train_loss: 1.7299
[8] train_loss: 1.7346
[8] train_loss: 1.7038
2.4728541374206543

Evaluating...Epoch: 8
Prec: 0.8160, Recall: 0.8152, F1: 0.8156
model saved to random1_layers3_14res/best_model.pt
New best model saved!

[9] train_loss: 1.2381
[9] train_loss: 1.5272
[9] train_loss: 1.5992
[9] train_loss: 1.5587
[9] train_loss: 1.5897
[9] train_loss: 1.6169
[9] train_loss: 1.5422
[9] train_loss: 1.5445
[9] train_loss: 1.5540
[9] train_loss: 1.5556
[9] train_loss: 1.5557
[9] train_loss: 1.5838
[9] train_loss: 1.5778
[9] train_loss: 1.5823
[9] train_loss: 1.5785
[9] train_loss: 1.5606
2.4662508964538574

Evaluating...Epoch: 9
Prec: 0.8147, Recall: 0.8210, F1: 0.8178
model saved to random1_layers3_14res/best_model.pt
New best model saved!

[10] train_loss: 1.1905
[10] train_loss: 1.4190
[10] train_loss: 1.5865
[10] train_loss: 1.5291
[10] train_loss: 1.5827
[10] train_loss: 1.5999
[10] train_loss: 1.5327
[10] train_loss: 1.5004
[10] train_loss: 1.4953
[10] train_loss: 1.4985
[10] train_loss: 1.4914
[10] train_loss: 1.4996
[10] train_loss: 1.4822
[10] train_loss: 1.4775
[10] train_loss: 1.4757
[10] train_loss: 1.4644
2.462158203125

Evaluating...Epoch: 10
Prec: 0.8210, Recall: 0.8210, F1: 0.8210
model saved to random1_layers3_14res/best_model.pt
New best model saved!

[11] train_loss: 1.1386
[11] train_loss: 1.3429
[11] train_loss: 1.4488
[11] train_loss: 1.4141
[11] train_loss: 1.4376
[11] train_loss: 1.4687
[11] train_loss: 1.4160
[11] train_loss: 1.3926
[11] train_loss: 1.3891
[11] train_loss: 1.3792
[11] train_loss: 1.3711
[11] train_loss: 1.3924
[11] train_loss: 1.3872
[11] train_loss: 1.3880
[11] train_loss: 1.3890
[11] train_loss: 1.3689
2.4665660858154297

Evaluating...Epoch: 11
Prec: 0.8195, Recall: 0.8259, F1: 0.8227
model saved to random1_layers3_14res/best_model.pt
New best model saved!

[12] train_loss: 1.1874
[12] train_loss: 1.3334
[12] train_loss: 1.3794
[12] train_loss: 1.3302
[12] train_loss: 1.3532
[12] train_loss: 1.3614
[12] train_loss: 1.3160
[12] train_loss: 1.2943
[12] train_loss: 1.3031
[12] train_loss: 1.2938
[12] train_loss: 1.3023
[12] train_loss: 1.3205
[12] train_loss: 1.3142
[12] train_loss: 1.3050
[12] train_loss: 1.3248
[12] train_loss: 1.2956
2.4776318073272705

Evaluating...Epoch: 12
Prec: 0.8340, Recall: 0.8210, F1: 0.8275
model saved to random1_layers3_14res/best_model.pt
New best model saved!

[13] train_loss: 1.0166
[13] train_loss: 1.1755
[13] train_loss: 1.2787
[13] train_loss: 1.2281
[13] train_loss: 1.2787
[13] train_loss: 1.3051
[13] train_loss: 1.2519
[13] train_loss: 1.2532
[13] train_loss: 1.2514
[13] train_loss: 1.2301
[13] train_loss: 1.2232
[13] train_loss: 1.2194
[13] train_loss: 1.2186
[13] train_loss: 1.2010
[13] train_loss: 1.2151
[13] train_loss: 1.2025
2.5653364658355713

Evaluating...Epoch: 13
Prec: 0.8327, Recall: 0.8327, F1: 0.8327
model saved to random1_layers3_14res/best_model.pt
New best model saved!

[14] train_loss: 1.0188
[14] train_loss: 1.1353
[14] train_loss: 1.1395
[14] train_loss: 1.1361
[14] train_loss: 1.1962
[14] train_loss: 1.2119
[14] train_loss: 1.1677
[14] train_loss: 1.1536
[14] train_loss: 1.1531
[14] train_loss: 1.1411
[14] train_loss: 1.1469
[14] train_loss: 1.1633
[14] train_loss: 1.1555
[14] train_loss: 1.1564
[14] train_loss: 1.1836
[14] train_loss: 1.1708
2.4747252464294434

Evaluating...Epoch: 14
Prec: 0.8413, Recall: 0.8405, F1: 0.8409
model saved to random1_layers3_14res/best_model.pt
New best model saved!

[15] train_loss: 0.8983
[15] train_loss: 1.0928
[15] train_loss: 1.1006
[15] train_loss: 1.1020
[15] train_loss: 1.1904
[15] train_loss: 1.1959
[15] train_loss: 1.1436
[15] train_loss: 1.1185
[15] train_loss: 1.1106
[15] train_loss: 1.1089
[15] train_loss: 1.1000
[15] train_loss: 1.1117
[15] train_loss: 1.1031
[15] train_loss: 1.0846
[15] train_loss: 1.0986
[15] train_loss: 1.0819
2.456789493560791

Evaluating...Epoch: 15
Prec: 0.8379, Recall: 0.8249, F1: 0.8314

[16] train_loss: 0.8228
[16] train_loss: 1.0727
[16] train_loss: 1.1409
[16] train_loss: 1.1467
[16] train_loss: 1.1600
[16] train_loss: 1.1830
[16] train_loss: 1.1359
[16] train_loss: 1.1244
[16] train_loss: 1.1336
[16] train_loss: 1.1025
[16] train_loss: 1.0852
[16] train_loss: 1.0907
[16] train_loss: 1.0883
[16] train_loss: 1.0783
[16] train_loss: 1.0866
[16] train_loss: 1.0711
2.4563679695129395

Evaluating...Epoch: 16
Prec: 0.8287, Recall: 0.8424, F1: 0.8355

[17] train_loss: 0.9888
[17] train_loss: 1.0491
[17] train_loss: 0.9903
[17] train_loss: 1.0105
[17] train_loss: 1.0101
[17] train_loss: 1.0284
[17] train_loss: 0.9877
[17] train_loss: 0.9704
[17] train_loss: 0.9729
[17] train_loss: 0.9603
[17] train_loss: 0.9436
[17] train_loss: 0.9605
[17] train_loss: 0.9537
[17] train_loss: 0.9494
[17] train_loss: 0.9637
[17] train_loss: 0.9516
2.537299394607544

Evaluating...Epoch: 17
Prec: 0.8708, Recall: 0.8132, F1: 0.8410
model saved to random1_layers3_14res/best_model.pt
New best model saved!

[18] train_loss: 0.8401
[18] train_loss: 0.9853
[18] train_loss: 0.9838
[18] train_loss: 0.9552
[18] train_loss: 0.9975
[18] train_loss: 1.0219
[18] train_loss: 0.9897
[18] train_loss: 0.9810
[18] train_loss: 0.9893
[18] train_loss: 0.9682
[18] train_loss: 0.9643
[18] train_loss: 0.9746
[18] train_loss: 0.9781
[18] train_loss: 0.9635
[18] train_loss: 0.9828
[18] train_loss: 0.9769
2.4571385383605957

Evaluating...Epoch: 18
Prec: 0.8485, Recall: 0.8171, F1: 0.8325

[19] train_loss: 0.7284
[19] train_loss: 0.8835
[19] train_loss: 0.9121
[19] train_loss: 0.9430
[19] train_loss: 0.9744
[19] train_loss: 1.0006
[19] train_loss: 0.9442
[19] train_loss: 0.9444
[19] train_loss: 0.9440
[19] train_loss: 0.9262
[19] train_loss: 0.9216
[19] train_loss: 0.9323
[19] train_loss: 0.9250
[19] train_loss: 0.9238
[19] train_loss: 0.9267
[19] train_loss: 0.9101
2.4703962802886963

Evaluating...Epoch: 19
Prec: 0.8465, Recall: 0.8317, F1: 0.8391

[20] train_loss: 0.7023
[20] train_loss: 0.7957
[20] train_loss: 0.8635
[20] train_loss: 0.8770
[20] train_loss: 0.8853
[20] train_loss: 0.9103
[20] train_loss: 0.8930
[20] train_loss: 0.8894
[20] train_loss: 0.8816
[20] train_loss: 0.8814
[20] train_loss: 0.8797
[20] train_loss: 0.8858
[20] train_loss: 0.8856
[20] train_loss: 0.8764
[20] train_loss: 0.8722
[20] train_loss: 0.8600
2.462322473526001

Evaluating...Epoch: 20
Prec: 0.8539, Recall: 0.8298, F1: 0.8416
model saved to random1_layers3_14res/best_model.pt
New best model saved!

[21] train_loss: 0.5892
[21] train_loss: 0.7724
[21] train_loss: 0.8401
[21] train_loss: 0.8078
[21] train_loss: 0.8523
[21] train_loss: 0.8684
[21] train_loss: 0.8432
[21] train_loss: 0.8283
[21] train_loss: 0.8427
[21] train_loss: 0.8305
[21] train_loss: 0.8151
[21] train_loss: 0.8192
[21] train_loss: 0.8186
[21] train_loss: 0.8170
[21] train_loss: 0.8144
[21] train_loss: 0.7969
2.552250862121582

Evaluating...Epoch: 21
Prec: 0.8636, Recall: 0.8317, F1: 0.8474
model saved to random1_layers3_14res/best_model.pt
New best model saved!

[22] train_loss: 0.6297
[22] train_loss: 0.6869
[22] train_loss: 0.6944
[22] train_loss: 0.6959
[22] train_loss: 0.7604
[22] train_loss: 0.8015
[22] train_loss: 0.7835
[22] train_loss: 0.7736
[22] train_loss: 0.7844
[22] train_loss: 0.7637
[22] train_loss: 0.7502
[22] train_loss: 0.7573
[22] train_loss: 0.7497
[22] train_loss: 0.7342
[22] train_loss: 0.7447
[22] train_loss: 0.7336
2.4376697540283203

Evaluating...Epoch: 22
Prec: 0.8448, Recall: 0.8366, F1: 0.8407

[23] train_loss: 0.7147
[23] train_loss: 0.7048
[23] train_loss: 0.7170
[23] train_loss: 0.6710
[23] train_loss: 0.7125
[23] train_loss: 0.7232
[23] train_loss: 0.6949
[23] train_loss: 0.6840
[23] train_loss: 0.6840
[23] train_loss: 0.7207
[23] train_loss: 0.7214
[23] train_loss: 0.7385
[23] train_loss: 0.7306
[23] train_loss: 0.7246
[23] train_loss: 0.7320
[23] train_loss: 0.7280
2.4557619094848633

Evaluating...Epoch: 23
Prec: 0.8621, Recall: 0.8152, F1: 0.8380

[24] train_loss: 0.5131
[24] train_loss: 0.7326
[24] train_loss: 0.7545
[24] train_loss: 0.7271
[24] train_loss: 0.7439
[24] train_loss: 0.7509
[24] train_loss: 0.7229
[24] train_loss: 0.7130
[24] train_loss: 0.7053
[24] train_loss: 0.7038
[24] train_loss: 0.7036
[24] train_loss: 0.7186
[24] train_loss: 0.7132
[24] train_loss: 0.7198
[24] train_loss: 0.7302
[24] train_loss: 0.7241
2.4697277545928955

Evaluating...Epoch: 24
Prec: 0.8642, Recall: 0.8045, F1: 0.8332

[25] train_loss: 0.4509
[25] train_loss: 0.6227
[25] train_loss: 0.6200
[25] train_loss: 0.6250
[25] train_loss: 0.6416
[25] train_loss: 0.6505
[25] train_loss: 0.6318
[25] train_loss: 0.6317
[25] train_loss: 0.6384
[25] train_loss: 0.6377
[25] train_loss: 0.6374
[25] train_loss: 0.6446
[25] train_loss: 0.6581
[25] train_loss: 0.6643
[25] train_loss: 0.6769
[25] train_loss: 0.6703
2.4770359992980957

Evaluating...Epoch: 25
Prec: 0.8588, Recall: 0.8161, F1: 0.8369

[26] train_loss: 0.5363
[26] train_loss: 0.6121
[26] train_loss: 0.6608
[26] train_loss: 0.6366
[26] train_loss: 0.7321
[26] train_loss: 0.7530
[26] train_loss: 0.7145
[26] train_loss: 0.6975
[26] train_loss: 0.6849
[26] train_loss: 0.6864
[26] train_loss: 0.6773
[26] train_loss: 0.6894
[26] train_loss: 0.6972
[26] train_loss: 0.6848
[26] train_loss: 0.6869
[26] train_loss: 0.6838
2.4653890132904053

Evaluating...Epoch: 26
Prec: 0.8697, Recall: 0.7986, F1: 0.8327

[27] train_loss: 0.5179
[27] train_loss: 0.5924
[27] train_loss: 0.5806
[27] train_loss: 0.5735
[27] train_loss: 0.6193
[27] train_loss: 0.6379
[27] train_loss: 0.6285
[27] train_loss: 0.6226
[27] train_loss: 0.6146
[27] train_loss: 0.6151
[27] train_loss: 0.6022
[27] train_loss: 0.6116
[27] train_loss: 0.6099
[27] train_loss: 0.6065
[27] train_loss: 0.6164
[27] train_loss: 0.6144
2.4464962482452393

Evaluating...Epoch: 27
Prec: 0.8405, Recall: 0.8200, F1: 0.8301

[28] train_loss: 0.3911
[28] train_loss: 0.5280
[28] train_loss: 0.5342
[28] train_loss: 0.5426
[28] train_loss: 0.5750
[28] train_loss: 0.6137
[28] train_loss: 0.5770
[28] train_loss: 0.5777
[28] train_loss: 0.5733
[28] train_loss: 0.5613
[28] train_loss: 0.5582
[28] train_loss: 0.5634
[28] train_loss: 0.5673
[28] train_loss: 0.5674
[28] train_loss: 0.5798
[28] train_loss: 0.5731
2.454704999923706

Evaluating...Epoch: 28
Prec: 0.8678, Recall: 0.8045, F1: 0.8349

[29] train_loss: 0.4047
[29] train_loss: 0.4424
[29] train_loss: 0.4624
[29] train_loss: 0.4576
[29] train_loss: 0.4928
[29] train_loss: 0.5328
[29] train_loss: 0.5059
[29] train_loss: 0.5145
[29] train_loss: 0.5123
[29] train_loss: 0.5131
[29] train_loss: 0.5197
[29] train_loss: 0.5344
[29] train_loss: 0.5341
[29] train_loss: 0.5321
[29] train_loss: 0.5331
[29] train_loss: 0.5310
2.4662516117095947

Evaluating...Epoch: 29
Prec: 0.8455, Recall: 0.8200, F1: 0.8326

[30] train_loss: 0.4838
[30] train_loss: 0.5558
[30] train_loss: 0.5581
[30] train_loss: 0.5612
[30] train_loss: 0.6095
[30] train_loss: 0.6378
[30] train_loss: 0.5992
[30] train_loss: 0.5893
[30] train_loss: 0.5951
[30] train_loss: 0.5905
[30] train_loss: 0.5914
[30] train_loss: 0.5969
[30] train_loss: 0.6010
[30] train_loss: 0.5947
[30] train_loss: 0.5991
[30] train_loss: 0.5824
2.4573566913604736

Evaluating...Epoch: 30
Prec: 0.8537, Recall: 0.8346, F1: 0.8441

[31] train_loss: 0.3973
[31] train_loss: 0.5358
[31] train_loss: 0.5464
[31] train_loss: 0.5241
[31] train_loss: 0.5404
[31] train_loss: 0.5837
[31] train_loss: 0.5802
[31] train_loss: 0.5733
[31] train_loss: 0.5761
[31] train_loss: 0.5716
[31] train_loss: 0.5688
[31] train_loss: 0.5675
[31] train_loss: 0.5641
[31] train_loss: 0.5581
[31] train_loss: 0.5633
[31] train_loss: 0.5546
2.434020519256592

Evaluating...Epoch: 31
Prec: 0.8574, Recall: 0.8249, F1: 0.8409

[32] train_loss: 0.4634
[32] train_loss: 0.4521
[32] train_loss: 0.4951
[32] train_loss: 0.5392
[32] train_loss: 0.5628
[32] train_loss: 0.5564
[32] train_loss: 0.5310
[32] train_loss: 0.5319
[32] train_loss: 0.5208
[32] train_loss: 0.5131
[32] train_loss: 0.5101
[32] train_loss: 0.5127
[32] train_loss: 0.5119
[32] train_loss: 0.5100
[32] train_loss: 0.5045
[32] train_loss: 0.4966
2.4629764556884766

Evaluating...Epoch: 32
Prec: 0.8650, Recall: 0.8103, F1: 0.8368

[33] train_loss: 0.2841
[33] train_loss: 0.4449
[33] train_loss: 0.4857
[33] train_loss: 0.5162
[33] train_loss: 0.5631
[33] train_loss: 0.5822
[33] train_loss: 0.5484
[33] train_loss: 0.5447
[33] train_loss: 0.5336
[33] train_loss: 0.5277
[33] train_loss: 0.5172
[33] train_loss: 0.5281
[33] train_loss: 0.5111
[33] train_loss: 0.5006
[33] train_loss: 0.5004
[33] train_loss: 0.4990
2.45835018157959

Evaluating...Epoch: 33
Prec: 0.8471, Recall: 0.8356, F1: 0.8413

[34] train_loss: 0.3005
[34] train_loss: 0.4787
[34] train_loss: 0.4301
[34] train_loss: 0.4400
[34] train_loss: 0.4925
[34] train_loss: 0.4821
[34] train_loss: 0.4723
[34] train_loss: 0.4613
[34] train_loss: 0.4662
[34] train_loss: 0.4642
[34] train_loss: 0.4509
[34] train_loss: 0.4563
[34] train_loss: 0.4576
[34] train_loss: 0.4544
[34] train_loss: 0.4555
[34] train_loss: 0.4501
2.546947479248047

Evaluating...Epoch: 34
Prec: 0.8419, Recall: 0.8288, F1: 0.8353

[35] train_loss: 0.4302
[35] train_loss: 0.4534
[35] train_loss: 0.4298
[35] train_loss: 0.4002
[35] train_loss: 0.4324
[35] train_loss: 0.4554
[35] train_loss: 0.4397
[35] train_loss: 0.4512
[35] train_loss: 0.4603
[35] train_loss: 0.4703
[35] train_loss: 0.4599
[35] train_loss: 0.4575
[35] train_loss: 0.4624
[35] train_loss: 0.4554
[35] train_loss: 0.4541
[35] train_loss: 0.4480
2.459050178527832

Evaluating...Epoch: 35
Prec: 0.8519, Recall: 0.8171, F1: 0.8342

[36] train_loss: 0.3244
[36] train_loss: 0.4178
[36] train_loss: 0.4404
[36] train_loss: 0.4441
[36] train_loss: 0.4698
[36] train_loss: 0.4738
[36] train_loss: 0.4746
[36] train_loss: 0.4665
[36] train_loss: 0.4561
[36] train_loss: 0.4504
[36] train_loss: 0.4407
[36] train_loss: 0.4422
[36] train_loss: 0.4503
[36] train_loss: 0.4431
[36] train_loss: 0.4427
[36] train_loss: 0.4380
2.4653160572052

Evaluating...Epoch: 36
Prec: 0.8462, Recall: 0.8239, F1: 0.8349

[37] train_loss: 0.3687
[37] train_loss: 0.4405
[37] train_loss: 0.4244
[37] train_loss: 0.4205
[37] train_loss: 0.4300
[37] train_loss: 0.4451
[37] train_loss: 0.4305
[37] train_loss: 0.4394
[37] train_loss: 0.4362
[37] train_loss: 0.4260
[37] train_loss: 0.4161
[37] train_loss: 0.4281
[37] train_loss: 0.4252
[37] train_loss: 0.4182
[37] train_loss: 0.4190
[37] train_loss: 0.4194
2.4696593284606934

Evaluating...Epoch: 37
Prec: 0.8663, Recall: 0.8259, F1: 0.8456

[38] train_loss: 0.3491
[38] train_loss: 0.3189
[38] train_loss: 0.3308
[38] train_loss: 0.3599
[38] train_loss: 0.3730
[38] train_loss: 0.3827
[38] train_loss: 0.4068
[38] train_loss: 0.4032
[38] train_loss: 0.4124
[38] train_loss: 0.4187
[38] train_loss: 0.4101
[38] train_loss: 0.4168
[38] train_loss: 0.4222
[38] train_loss: 0.4172
[38] train_loss: 0.4259
[38] train_loss: 0.4184
2.5505480766296387

Evaluating...Epoch: 38
Prec: 0.8426, Recall: 0.8434, F1: 0.8430

[39] train_loss: 0.4220
[39] train_loss: 0.3898
[39] train_loss: 0.3820
[39] train_loss: 0.3828
[39] train_loss: 0.4517
[39] train_loss: 0.4683
[39] train_loss: 0.4564
[39] train_loss: 0.4450
[39] train_loss: 0.4387
[39] train_loss: 0.4388
[39] train_loss: 0.4349
[39] train_loss: 0.4318
[39] train_loss: 0.4265
[39] train_loss: 0.4223
[39] train_loss: 0.4210
[39] train_loss: 0.4122
2.4740583896636963

Evaluating...Epoch: 39
Prec: 0.8580, Recall: 0.8171, F1: 0.8371

[40] train_loss: 0.3667
[40] train_loss: 0.3449
[40] train_loss: 0.3669
[40] train_loss: 0.3541
[40] train_loss: 0.3842
[40] train_loss: 0.3784
[40] train_loss: 0.3648
[40] train_loss: 0.3603
[40] train_loss: 0.3685
[40] train_loss: 0.3655
[40] train_loss: 0.3685
[40] train_loss: 0.3819
[40] train_loss: 0.3908
[40] train_loss: 0.3888
[40] train_loss: 0.4001
[40] train_loss: 0.3911
2.4500534534454346

Evaluating...Epoch: 40
Prec: 0.8579, Recall: 0.8161, F1: 0.8365

[41] train_loss: 0.4725
[41] train_loss: 0.5155
[41] train_loss: 0.4970
[41] train_loss: 0.4835
[41] train_loss: 0.4785
[41] train_loss: 0.4677
[41] train_loss: 0.4540
[41] train_loss: 0.4453
[41] train_loss: 0.4424
[41] train_loss: 0.4302
[41] train_loss: 0.4164
[41] train_loss: 0.4327
[41] train_loss: 0.4299
[41] train_loss: 0.4272
[41] train_loss: 0.4176
[41] train_loss: 0.4116
2.4688479900360107

Evaluating...Epoch: 41
Prec: 0.8577, Recall: 0.8152, F1: 0.8359

Training ended with 42 epochs.
Final result:
Prec: 0.8636, Recall: 0.8317, F1: 0.8474
loading vocab and embedding matrix from ../data/14res
size of vocab: 4381
shape of loaded embedding matrix: (4381, 300)
Generating mappings
Loading data from ../data/14res with batch size 16...
165 batches created for ../data/14res/train.json
54 batches created for ../data/14res/test.json
Building model...
1852893
[1] train_loss: 12.2117
[1] train_loss: 9.5557
[1] train_loss: 8.4311
[1] train_loss: 7.6688
[1] train_loss: 7.1859
[1] train_loss: 6.8056
[1] train_loss: 6.4346
[1] train_loss: 6.1690
[1] train_loss: 5.9344
[1] train_loss: 5.7337
[1] train_loss: 5.5629
[1] train_loss: 5.4391
[1] train_loss: 5.3146
[1] train_loss: 5.2167
[1] train_loss: 5.1321
[1] train_loss: 5.0114
2.5486795902252197

Evaluating...Epoch: 1
Prec: 0.5528, Recall: 0.7130, F1: 0.6228
model saved to random1_layers4_14res/best_model.pt
New best model saved!

[2] train_loss: 3.0857
[2] train_loss: 3.4340
[2] train_loss: 3.5104
[2] train_loss: 3.4655
[2] train_loss: 3.4554
[2] train_loss: 3.4566
[2] train_loss: 3.3549
[2] train_loss: 3.3002
[2] train_loss: 3.2720
[2] train_loss: 3.2380
[2] train_loss: 3.2189
[2] train_loss: 3.2374
[2] train_loss: 3.2122
[2] train_loss: 3.2030
[2] train_loss: 3.2165
[2] train_loss: 3.1792
2.5366480350494385

Evaluating...Epoch: 2
Prec: 0.6997, Recall: 0.7208, F1: 0.7101
model saved to random1_layers4_14res/best_model.pt
New best model saved!

[3] train_loss: 2.7731
[3] train_loss: 2.9266
[3] train_loss: 3.0755
[3] train_loss: 3.0012
[3] train_loss: 3.0137
[3] train_loss: 2.9735
[3] train_loss: 2.8769
[3] train_loss: 2.8426
[3] train_loss: 2.8028
[3] train_loss: 2.7734
[3] train_loss: 2.7662
[3] train_loss: 2.7869
[3] train_loss: 2.7729
[3] train_loss: 2.7612
[3] train_loss: 2.7658
[3] train_loss: 2.7369
2.5513153076171875

Evaluating...Epoch: 3
Prec: 0.6664, Recall: 0.7695, F1: 0.7142
model saved to random1_layers4_14res/best_model.pt
New best model saved!

[4] train_loss: 2.2720
[4] train_loss: 2.6046
[4] train_loss: 2.6710
[4] train_loss: 2.6241
[4] train_loss: 2.6293
[4] train_loss: 2.6313
[4] train_loss: 2.5455
[4] train_loss: 2.5398
[4] train_loss: 2.5313
[4] train_loss: 2.5070
[4] train_loss: 2.4921
[4] train_loss: 2.5208
[4] train_loss: 2.5218
[4] train_loss: 2.5185
[4] train_loss: 2.5264
[4] train_loss: 2.5012
2.5551910400390625

Evaluating...Epoch: 4
Prec: 0.7707, Recall: 0.7519, F1: 0.7612
model saved to random1_layers4_14res/best_model.pt
New best model saved!

[5] train_loss: 2.0322
[5] train_loss: 2.2863
[5] train_loss: 2.4417
[5] train_loss: 2.3569
[5] train_loss: 2.3833
[5] train_loss: 2.4117
[5] train_loss: 2.3128
[5] train_loss: 2.2894
[5] train_loss: 2.2702
[5] train_loss: 2.2532
[5] train_loss: 2.2540
[5] train_loss: 2.2786
[5] train_loss: 2.2730
[5] train_loss: 2.2722
[5] train_loss: 2.2732
[5] train_loss: 2.2410
2.5379090309143066

Evaluating...Epoch: 5
Prec: 0.7887, Recall: 0.7772, F1: 0.7829
model saved to random1_layers4_14res/best_model.pt
New best model saved!

[6] train_loss: 1.8521
[6] train_loss: 2.1404
[6] train_loss: 2.2458
[6] train_loss: 2.1895
[6] train_loss: 2.2533
[6] train_loss: 2.2807
[6] train_loss: 2.1994
[6] train_loss: 2.1714
[6] train_loss: 2.1400
[6] train_loss: 2.1068
[6] train_loss: 2.0796
[6] train_loss: 2.0952
[6] train_loss: 2.0827
[6] train_loss: 2.0669
[6] train_loss: 2.0804
[6] train_loss: 2.0573
2.543795347213745

Evaluating...Epoch: 6
Prec: 0.8654, Recall: 0.7568, F1: 0.8075
model saved to random1_layers4_14res/best_model.pt
New best model saved!

[7] train_loss: 1.8438
[7] train_loss: 1.9850
[7] train_loss: 2.0931
[7] train_loss: 2.0323
[7] train_loss: 2.0847
[7] train_loss: 2.0888
[7] train_loss: 1.9959
[7] train_loss: 1.9760
[7] train_loss: 1.9612
[7] train_loss: 1.9602
[7] train_loss: 1.9441
[7] train_loss: 1.9560
[7] train_loss: 1.9490
[7] train_loss: 1.9482
[7] train_loss: 1.9432
[7] train_loss: 1.9048
2.548651695251465

Evaluating...Epoch: 7
Prec: 0.8515, Recall: 0.7753, F1: 0.8116
model saved to random1_layers4_14res/best_model.pt
New best model saved!

[8] train_loss: 1.3921
[8] train_loss: 1.6163
[8] train_loss: 1.7459
[8] train_loss: 1.7044
[8] train_loss: 1.7697
[8] train_loss: 1.8109
[8] train_loss: 1.7561
[8] train_loss: 1.7508
[8] train_loss: 1.7456
[8] train_loss: 1.7268
[8] train_loss: 1.7057
[8] train_loss: 1.7281
[8] train_loss: 1.7218
[8] train_loss: 1.7310
[8] train_loss: 1.7363
[8] train_loss: 1.7105
2.5201025009155273

Evaluating...Epoch: 8
Prec: 0.8342, Recall: 0.7977, F1: 0.8155
model saved to random1_layers4_14res/best_model.pt
New best model saved!

[9] train_loss: 1.4821
[9] train_loss: 1.5619
[9] train_loss: 1.6507
[9] train_loss: 1.6485
[9] train_loss: 1.7398
[9] train_loss: 1.7634
[9] train_loss: 1.6924
[9] train_loss: 1.6462
[9] train_loss: 1.6431
[9] train_loss: 1.6260
[9] train_loss: 1.6161
[9] train_loss: 1.6416
[9] train_loss: 1.6366
[9] train_loss: 1.6367
[9] train_loss: 1.6351
[9] train_loss: 1.6051
2.538106918334961

Evaluating...Epoch: 9
Prec: 0.8269, Recall: 0.8084, F1: 0.8175
model saved to random1_layers4_14res/best_model.pt
New best model saved!

[10] train_loss: 1.2616
[10] train_loss: 1.5110
[10] train_loss: 1.6198
[10] train_loss: 1.5802
[10] train_loss: 1.6359
[10] train_loss: 1.6196
[10] train_loss: 1.5521
[10] train_loss: 1.5256
[10] train_loss: 1.5199
[10] train_loss: 1.5038
[10] train_loss: 1.4882
[10] train_loss: 1.4981
[10] train_loss: 1.4974
[10] train_loss: 1.4876
[10] train_loss: 1.5065
[10] train_loss: 1.4855
2.543682336807251

Evaluating...Epoch: 10
Prec: 0.8684, Recall: 0.7957, F1: 0.8305
model saved to random1_layers4_14res/best_model.pt
New best model saved!

[11] train_loss: 1.2351
[11] train_loss: 1.4136
[11] train_loss: 1.5058
[11] train_loss: 1.4777
[11] train_loss: 1.5022
[11] train_loss: 1.5306
[11] train_loss: 1.4577
[11] train_loss: 1.4441
[11] train_loss: 1.4430
[11] train_loss: 1.4156
[11] train_loss: 1.4078
[11] train_loss: 1.4278
[11] train_loss: 1.4308
[11] train_loss: 1.4137
[11] train_loss: 1.4215
[11] train_loss: 1.4002
2.5024263858795166

Evaluating...Epoch: 11
Prec: 0.8530, Recall: 0.8074, F1: 0.8296

[12] train_loss: 1.1322
[12] train_loss: 1.2842
[12] train_loss: 1.3447
[12] train_loss: 1.2865
[12] train_loss: 1.3647
[12] train_loss: 1.3883
[12] train_loss: 1.3378
[12] train_loss: 1.3141
[12] train_loss: 1.3338
[12] train_loss: 1.3158
[12] train_loss: 1.3047
[12] train_loss: 1.3292
[12] train_loss: 1.3269
[12] train_loss: 1.3230
[12] train_loss: 1.3266
[12] train_loss: 1.3139
2.5443782806396484

Evaluating...Epoch: 12
Prec: 0.8246, Recall: 0.8142, F1: 0.8194

[13] train_loss: 1.0755
[13] train_loss: 1.1852
[13] train_loss: 1.2163
[13] train_loss: 1.2173
[13] train_loss: 1.3066
[13] train_loss: 1.3111
[13] train_loss: 1.2560
[13] train_loss: 1.2429
[13] train_loss: 1.2577
[13] train_loss: 1.2424
[13] train_loss: 1.2356
[13] train_loss: 1.2561
[13] train_loss: 1.2514
[13] train_loss: 1.2456
[13] train_loss: 1.2547
[13] train_loss: 1.2417
2.6190884113311768

Evaluating...Epoch: 13
Prec: 0.8555, Recall: 0.8181, F1: 0.8364
model saved to random1_layers4_14res/best_model.pt
New best model saved!

[14] train_loss: 0.8584
[14] train_loss: 1.0175
[14] train_loss: 1.1042
[14] train_loss: 1.0811
[14] train_loss: 1.1301
[14] train_loss: 1.1875
[14] train_loss: 1.1543
[14] train_loss: 1.1405
[14] train_loss: 1.1384
[14] train_loss: 1.1338
[14] train_loss: 1.1260
[14] train_loss: 1.1500
[14] train_loss: 1.1496
[14] train_loss: 1.1425
[14] train_loss: 1.1550
[14] train_loss: 1.1362
2.5317649841308594

Evaluating...Epoch: 14
Prec: 0.8525, Recall: 0.8093, F1: 0.8303

[15] train_loss: 0.9897
[15] train_loss: 1.1228
[15] train_loss: 1.1595
[15] train_loss: 1.1861
[15] train_loss: 1.2287
[15] train_loss: 1.2560
[15] train_loss: 1.1989
[15] train_loss: 1.1743
[15] train_loss: 1.1720
[15] train_loss: 1.1503
[15] train_loss: 1.1328
[15] train_loss: 1.1582
[15] train_loss: 1.1590
[15] train_loss: 1.1467
[15] train_loss: 1.1613
[15] train_loss: 1.1482
2.540295124053955

Evaluating...Epoch: 15
Prec: 0.8541, Recall: 0.8200, F1: 0.8367
model saved to random1_layers4_14res/best_model.pt
New best model saved!

[16] train_loss: 0.8469
[16] train_loss: 1.0807
[16] train_loss: 1.0827
[16] train_loss: 1.0652
[16] train_loss: 1.1175
[16] train_loss: 1.1222
[16] train_loss: 1.0740
[16] train_loss: 1.0778
[16] train_loss: 1.0860
[16] train_loss: 1.0641
[16] train_loss: 1.0586
[16] train_loss: 1.0724
[16] train_loss: 1.0771
[16] train_loss: 1.0716
[16] train_loss: 1.0772
[16] train_loss: 1.0651
2.5348100662231445

Evaluating...Epoch: 16
Prec: 0.8755, Recall: 0.8006, F1: 0.8364

[17] train_loss: 0.8061
[17] train_loss: 0.9498
[17] train_loss: 1.0240
[17] train_loss: 1.0158
[17] train_loss: 1.0305
[17] train_loss: 1.0641
[17] train_loss: 1.0101
[17] train_loss: 0.9903
[17] train_loss: 1.0088
[17] train_loss: 1.0037
[17] train_loss: 1.0024
[17] train_loss: 1.0121
[17] train_loss: 1.0159
[17] train_loss: 1.0106
[17] train_loss: 1.0070
[17] train_loss: 0.9971
2.6245319843292236

Evaluating...Epoch: 17
Prec: 0.8461, Recall: 0.8074, F1: 0.8263

[18] train_loss: 0.7683
[18] train_loss: 0.8497
[18] train_loss: 0.9725
[18] train_loss: 0.9880
[18] train_loss: 1.0067
[18] train_loss: 1.0037
[18] train_loss: 0.9753
[18] train_loss: 0.9481
[18] train_loss: 0.9526
[18] train_loss: 0.9284
[18] train_loss: 0.9325
[18] train_loss: 0.9578
[18] train_loss: 0.9488
[18] train_loss: 0.9439
[18] train_loss: 0.9472
[18] train_loss: 0.9324
2.5356321334838867

Evaluating...Epoch: 18
Prec: 0.8517, Recall: 0.8210, F1: 0.8361

[19] train_loss: 0.7441
[19] train_loss: 0.8846
[19] train_loss: 0.8966
[19] train_loss: 0.8615
[19] train_loss: 0.9058
[19] train_loss: 0.9321
[19] train_loss: 0.8978
[19] train_loss: 0.8838
[19] train_loss: 0.8925
[19] train_loss: 0.8893
[19] train_loss: 0.8993
[19] train_loss: 0.9114
[19] train_loss: 0.9097
[19] train_loss: 0.8980
[19] train_loss: 0.9107
[19] train_loss: 0.9029
2.5405514240264893

Evaluating...Epoch: 19
Prec: 0.8586, Recall: 0.8210, F1: 0.8394
model saved to random1_layers4_14res/best_model.pt
New best model saved!

[20] train_loss: 0.8002
[20] train_loss: 0.8523
[20] train_loss: 0.9142
[20] train_loss: 0.9039
[20] train_loss: 0.9099
[20] train_loss: 0.9393
[20] train_loss: 0.9065
[20] train_loss: 0.8858
[20] train_loss: 0.8888
[20] train_loss: 0.8757
[20] train_loss: 0.8648
[20] train_loss: 0.8710
[20] train_loss: 0.8669
[20] train_loss: 0.8624
[20] train_loss: 0.8618
[20] train_loss: 0.8496
2.5213139057159424

Evaluating...Epoch: 20
Prec: 0.8437, Recall: 0.8346, F1: 0.8391

[21] train_loss: 0.6052
[21] train_loss: 0.7767
[21] train_loss: 0.7617
[21] train_loss: 0.7797
[21] train_loss: 0.7686
[21] train_loss: 0.7913
[21] train_loss: 0.7664
[21] train_loss: 0.7596
[21] train_loss: 0.7803
[21] train_loss: 0.7767
[21] train_loss: 0.7737
[21] train_loss: 0.7845
[21] train_loss: 0.7799
[21] train_loss: 0.7785
[21] train_loss: 0.7962
[21] train_loss: 0.7894
2.62419056892395

Evaluating...Epoch: 21
Prec: 0.8731, Recall: 0.8230, F1: 0.8473
model saved to random1_layers4_14res/best_model.pt
New best model saved!

[22] train_loss: 0.5443
[22] train_loss: 0.8028
[22] train_loss: 0.8543
[22] train_loss: 0.8441
[22] train_loss: 0.9051
[22] train_loss: 0.9073
[22] train_loss: 0.8739
[22] train_loss: 0.8399
[22] train_loss: 0.8428
[22] train_loss: 0.8376
[22] train_loss: 0.8218
[22] train_loss: 0.8342
[22] train_loss: 0.8269
[22] train_loss: 0.8201
[22] train_loss: 0.8160
[22] train_loss: 0.8067
2.5278818607330322

Evaluating...Epoch: 22
Prec: 0.8586, Recall: 0.8152, F1: 0.8363

[23] train_loss: 0.6841
[23] train_loss: 0.8080
[23] train_loss: 0.7621
[23] train_loss: 0.7697
[23] train_loss: 0.8049
[23] train_loss: 0.8337
[23] train_loss: 0.8036
[23] train_loss: 0.7948
[23] train_loss: 0.7947
[23] train_loss: 0.7876
[23] train_loss: 0.7754
[23] train_loss: 0.7797
[23] train_loss: 0.7801
[23] train_loss: 0.7715
[23] train_loss: 0.7813
[23] train_loss: 0.7760
2.5264854431152344

Evaluating...Epoch: 23
Prec: 0.8484, Recall: 0.8113, F1: 0.8294

[24] train_loss: 0.6138
[24] train_loss: 0.6512
[24] train_loss: 0.6087
[24] train_loss: 0.6240
[24] train_loss: 0.6611
[24] train_loss: 0.6863
[24] train_loss: 0.6548
[24] train_loss: 0.6578
[24] train_loss: 0.6727
[24] train_loss: 0.6835
[24] train_loss: 0.6995
[24] train_loss: 0.7079
[24] train_loss: 0.7059
[24] train_loss: 0.7016
[24] train_loss: 0.6977
[24] train_loss: 0.6950
2.5363335609436035

Evaluating...Epoch: 24
Prec: 0.8733, Recall: 0.8045, F1: 0.8375

[25] train_loss: 0.4618
[25] train_loss: 0.6873
[25] train_loss: 0.7410
[25] train_loss: 0.7356
[25] train_loss: 0.7765
[25] train_loss: 0.8042
[25] train_loss: 0.7806
[25] train_loss: 0.7616
[25] train_loss: 0.7664
[25] train_loss: 0.7530
[25] train_loss: 0.7420
[25] train_loss: 0.7600
[25] train_loss: 0.7606
[25] train_loss: 0.7515
[25] train_loss: 0.7457
[25] train_loss: 0.7310
2.538198947906494

Evaluating...Epoch: 25
Prec: 0.8526, Recall: 0.8161, F1: 0.8340

[26] train_loss: 0.4961
[26] train_loss: 0.5623
[26] train_loss: 0.5471
[26] train_loss: 0.5670
[26] train_loss: 0.6112
[26] train_loss: 0.6189
[26] train_loss: 0.6101
[26] train_loss: 0.6066
[26] train_loss: 0.6035
[26] train_loss: 0.6046
[26] train_loss: 0.5994
[26] train_loss: 0.6124
[26] train_loss: 0.6128
[26] train_loss: 0.6043
[26] train_loss: 0.6097
[26] train_loss: 0.6077
2.6060822010040283

Evaluating...Epoch: 26
Prec: 0.8577, Recall: 0.8210, F1: 0.8390

[27] train_loss: 0.5024
[27] train_loss: 0.6253
[27] train_loss: 0.6003
[27] train_loss: 0.6112
[27] train_loss: 0.6341
[27] train_loss: 0.6750
[27] train_loss: 0.6379
[27] train_loss: 0.6230
[27] train_loss: 0.6255
[27] train_loss: 0.6255
[27] train_loss: 0.6190
[27] train_loss: 0.6169
[27] train_loss: 0.6274
[27] train_loss: 0.6220
[27] train_loss: 0.6276
[27] train_loss: 0.6159
2.524583339691162

Evaluating...Epoch: 27
Prec: 0.8759, Recall: 0.8035, F1: 0.8382

[28] train_loss: 0.5749
[28] train_loss: 0.5791
[28] train_loss: 0.5909
[28] train_loss: 0.5931
[28] train_loss: 0.6560
[28] train_loss: 0.6757
[28] train_loss: 0.6579
[28] train_loss: 0.6444
[28] train_loss: 0.6290
[28] train_loss: 0.6213
[28] train_loss: 0.6146
[28] train_loss: 0.6179
[28] train_loss: 0.6252
[28] train_loss: 0.6150
[28] train_loss: 0.6253
[28] train_loss: 0.6167
2.5415687561035156

Evaluating...Epoch: 28
Prec: 0.8803, Recall: 0.8152, F1: 0.8465

[29] train_loss: 0.4003
[29] train_loss: 0.4675
[29] train_loss: 0.5597
[29] train_loss: 0.5681
[29] train_loss: 0.6146
[29] train_loss: 0.6461
[29] train_loss: 0.6164
[29] train_loss: 0.6016
[29] train_loss: 0.6032
[29] train_loss: 0.5947
[29] train_loss: 0.5909
[29] train_loss: 0.5926
[29] train_loss: 0.5908
[29] train_loss: 0.5953
[29] train_loss: 0.6083
[29] train_loss: 0.6057
2.5368945598602295

Evaluating...Epoch: 29
Prec: 0.8412, Recall: 0.8142, F1: 0.8275

[30] train_loss: 0.3358
[30] train_loss: 0.4168
[30] train_loss: 0.4508
[30] train_loss: 0.4649
[30] train_loss: 0.5160
[30] train_loss: 0.5311
[30] train_loss: 0.5272
[30] train_loss: 0.5334
[30] train_loss: 0.5411
[30] train_loss: 0.5495
[30] train_loss: 0.5453
[30] train_loss: 0.5618
[30] train_loss: 0.5664
[30] train_loss: 0.5618
[30] train_loss: 0.5621
[30] train_loss: 0.5580
2.6090965270996094

Evaluating...Epoch: 30
Prec: 0.8627, Recall: 0.8132, F1: 0.8373

[31] train_loss: 0.4718
[31] train_loss: 0.5073
[31] train_loss: 0.5111
[31] train_loss: 0.5162
[31] train_loss: 0.5363
[31] train_loss: 0.5424
[31] train_loss: 0.5265
[31] train_loss: 0.5217
[31] train_loss: 0.5269
[31] train_loss: 0.5232
[31] train_loss: 0.5152
[31] train_loss: 0.5235
[31] train_loss: 0.5272
[31] train_loss: 0.5229
[31] train_loss: 0.5207
[31] train_loss: 0.5189
2.5012831687927246

Evaluating...Epoch: 31
Prec: 0.8409, Recall: 0.8327, F1: 0.8368

[32] train_loss: 0.4528
[32] train_loss: 0.5124
[32] train_loss: 0.5147
[32] train_loss: 0.5118
[32] train_loss: 0.5946
[32] train_loss: 0.6073
[32] train_loss: 0.5924
[32] train_loss: 0.5833
[32] train_loss: 0.5751
[32] train_loss: 0.5628
[32] train_loss: 0.5570
[32] train_loss: 0.5639
[32] train_loss: 0.5579
[32] train_loss: 0.5523
[32] train_loss: 0.5516
[32] train_loss: 0.5416
2.521132469177246

Evaluating...Epoch: 32
Prec: 0.8513, Recall: 0.8298, F1: 0.8404

[33] train_loss: 0.4188
[33] train_loss: 0.4869
[33] train_loss: 0.4445
[33] train_loss: 0.4522
[33] train_loss: 0.4726
[33] train_loss: 0.5144
[33] train_loss: 0.5026
[33] train_loss: 0.4940
[33] train_loss: 0.4979
[33] train_loss: 0.4945
[33] train_loss: 0.4905
[33] train_loss: 0.5055
[33] train_loss: 0.5062
[33] train_loss: 0.5044
[33] train_loss: 0.5230
[33] train_loss: 0.5160
2.5432469844818115

Evaluating...Epoch: 33
Prec: 0.8645, Recall: 0.8132, F1: 0.8381

[34] train_loss: 0.3521
[34] train_loss: 0.3641
[34] train_loss: 0.4149
[34] train_loss: 0.4153
[34] train_loss: 0.4299
[34] train_loss: 0.4480
[34] train_loss: 0.4297
[34] train_loss: 0.4351
[34] train_loss: 0.4499
[34] train_loss: 0.4466
[34] train_loss: 0.4474
[34] train_loss: 0.4548
[34] train_loss: 0.4562
[34] train_loss: 0.4517
[34] train_loss: 0.4480
[34] train_loss: 0.4447
2.610675811767578

Evaluating...Epoch: 34
Prec: 0.8401, Recall: 0.8278, F1: 0.8339

[35] train_loss: 0.2841
[35] train_loss: 0.3363
[35] train_loss: 0.3489
[35] train_loss: 0.3863
[35] train_loss: 0.4425
[35] train_loss: 0.4480
[35] train_loss: 0.4442
[35] train_loss: 0.4392
[35] train_loss: 0.4295
[35] train_loss: 0.4281
[35] train_loss: 0.4270
[35] train_loss: 0.4350
[35] train_loss: 0.4366
[35] train_loss: 0.4465
[35] train_loss: 0.4460
[35] train_loss: 0.4444
2.5278780460357666

Evaluating...Epoch: 35
Prec: 0.8633, Recall: 0.8045, F1: 0.8328

[36] train_loss: 0.3224
[36] train_loss: 0.3856
[36] train_loss: 0.4295
[36] train_loss: 0.4377
[36] train_loss: 0.4742
[36] train_loss: 0.4712
[36] train_loss: 0.4641
[36] train_loss: 0.4633
[36] train_loss: 0.4810
[36] train_loss: 0.4684
[36] train_loss: 0.4750
[36] train_loss: 0.4737
[36] train_loss: 0.4868
[36] train_loss: 0.4827
[36] train_loss: 0.4942
[36] train_loss: 0.4851
2.536529302597046

Evaluating...Epoch: 36
Prec: 0.8583, Recall: 0.8249, F1: 0.8413

[37] train_loss: 0.3657
[37] train_loss: 0.4090
[37] train_loss: 0.4348
[37] train_loss: 0.4453
[37] train_loss: 0.4855
[37] train_loss: 0.5080
[37] train_loss: 0.4975
[37] train_loss: 0.5019
[37] train_loss: 0.5087
[37] train_loss: 0.5014
[37] train_loss: 0.5005
[37] train_loss: 0.4919
[37] train_loss: 0.4854
[37] train_loss: 0.4796
[37] train_loss: 0.4752
[37] train_loss: 0.4633
2.528379201889038

Evaluating...Epoch: 37
Prec: 0.8619, Recall: 0.8259, F1: 0.8435

[38] train_loss: 0.4048
[38] train_loss: 0.4267
[38] train_loss: 0.4597
[38] train_loss: 0.4752
[38] train_loss: 0.4844
[38] train_loss: 0.4763
[38] train_loss: 0.4572
[38] train_loss: 0.4545
[38] train_loss: 0.4534
[38] train_loss: 0.4566
[38] train_loss: 0.4507
[38] train_loss: 0.4561
[38] train_loss: 0.4497
[38] train_loss: 0.4522
[38] train_loss: 0.4491
[38] train_loss: 0.4415
2.5294322967529297

Evaluating...Epoch: 38
Prec: 0.8599, Recall: 0.8181, F1: 0.8385

[39] train_loss: 0.3003
[39] train_loss: 0.3795
[39] train_loss: 0.4259
[39] train_loss: 0.4225
[39] train_loss: 0.4556
[39] train_loss: 0.4662
[39] train_loss: 0.4408
[39] train_loss: 0.4317
[39] train_loss: 0.4517
[39] train_loss: 0.4514
[39] train_loss: 0.4446
[39] train_loss: 0.4485
[39] train_loss: 0.4396
[39] train_loss: 0.4403
[39] train_loss: 0.4453
[39] train_loss: 0.4399
2.537297010421753

Evaluating...Epoch: 39
Prec: 0.8730, Recall: 0.8093, F1: 0.8400

[40] train_loss: 0.3403
[40] train_loss: 0.3083
[40] train_loss: 0.3473
[40] train_loss: 0.3530
[40] train_loss: 0.3766
[40] train_loss: 0.4084
[40] train_loss: 0.3839
[40] train_loss: 0.3897
[40] train_loss: 0.3925
[40] train_loss: 0.3904
[40] train_loss: 0.3846
[40] train_loss: 0.3915
[40] train_loss: 0.3996
[40] train_loss: 0.3919
[40] train_loss: 0.3956
[40] train_loss: 0.3917
2.5292534828186035

Evaluating...Epoch: 40
Prec: 0.8468, Recall: 0.8278, F1: 0.8372

[41] train_loss: 0.2737
[41] train_loss: 0.3373
[41] train_loss: 0.3318
[41] train_loss: 0.3396
[41] train_loss: 0.3585
[41] train_loss: 0.3812
[41] train_loss: 0.3903
[41] train_loss: 0.3792
[41] train_loss: 0.3792
[41] train_loss: 0.4047
[41] train_loss: 0.3966
[41] train_loss: 0.3972
[41] train_loss: 0.3921
[41] train_loss: 0.3840
[41] train_loss: 0.3885
[41] train_loss: 0.3836
2.5420522689819336

Evaluating...Epoch: 41
Prec: 0.8356, Recall: 0.8259, F1: 0.8307

Training ended with 42 epochs.
Final result:
Prec: 0.8731, Recall: 0.8230, F1: 0.8473
loading vocab and embedding matrix from ../data/14res
size of vocab: 4381
shape of loaded embedding matrix: (4381, 300)
Generating mappings
Loading data from ../data/14res with batch size 16...
165 batches created for ../data/14res/train.json
54 batches created for ../data/14res/test.json
Building model...
1893093
[1] train_loss: 10.6667
[1] train_loss: 8.4973
[1] train_loss: 7.5828
[1] train_loss: 6.9885
[1] train_loss: 6.6727
[1] train_loss: 6.3937
[1] train_loss: 6.0993
[1] train_loss: 5.8959
[1] train_loss: 5.7172
[1] train_loss: 5.5596
[1] train_loss: 5.4129
[1] train_loss: 5.2970
[1] train_loss: 5.1838
[1] train_loss: 5.0918
[1] train_loss: 5.0182
[1] train_loss: 4.8996
2.6882994174957275

Evaluating...Epoch: 1
Prec: 0.5747, Recall: 0.6848, F1: 0.6249
model saved to random1_layers5_14res/best_model.pt
New best model saved!

[2] train_loss: 3.1899
[2] train_loss: 3.5070
[2] train_loss: 3.6011
[2] train_loss: 3.5638
[2] train_loss: 3.5489
[2] train_loss: 3.5329
[2] train_loss: 3.4466
[2] train_loss: 3.4227
[2] train_loss: 3.3908
[2] train_loss: 3.3609
[2] train_loss: 3.3289
[2] train_loss: 3.3406
[2] train_loss: 3.3276
[2] train_loss: 3.3208
[2] train_loss: 3.3246
[2] train_loss: 3.2840
2.6916961669921875

Evaluating...Epoch: 2
Prec: 0.6762, Recall: 0.7335, F1: 0.7037
model saved to random1_layers5_14res/best_model.pt
New best model saved!

[3] train_loss: 2.8745
[3] train_loss: 3.0608
[3] train_loss: 3.1232
[3] train_loss: 3.0300
[3] train_loss: 3.0547
[3] train_loss: 3.0687
[3] train_loss: 2.9655
[3] train_loss: 2.9310
[3] train_loss: 2.9036
[3] train_loss: 2.8794
[3] train_loss: 2.8625
[3] train_loss: 2.8795
[3] train_loss: 2.8745
[3] train_loss: 2.8587
[3] train_loss: 2.8597
[3] train_loss: 2.8260
2.706998348236084

Evaluating...Epoch: 3
Prec: 0.7009, Recall: 0.7568, F1: 0.7278
model saved to random1_layers5_14res/best_model.pt
New best model saved!

[4] train_loss: 2.2758
[4] train_loss: 2.5703
[4] train_loss: 2.6434
[4] train_loss: 2.5816
[4] train_loss: 2.6263
[4] train_loss: 2.6447
[4] train_loss: 2.5602
[4] train_loss: 2.5313
[4] train_loss: 2.5382
[4] train_loss: 2.5128
[4] train_loss: 2.5125
[4] train_loss: 2.5370
[4] train_loss: 2.5374
[4] train_loss: 2.5265
[4] train_loss: 2.5335
[4] train_loss: 2.4961
2.679084300994873

Evaluating...Epoch: 4
Prec: 0.7509, Recall: 0.7802, F1: 0.7653
model saved to random1_layers5_14res/best_model.pt
New best model saved!

[5] train_loss: 2.1543
[5] train_loss: 2.4033
[5] train_loss: 2.4369
[5] train_loss: 2.3339
[5] train_loss: 2.3980
[5] train_loss: 2.4371
[5] train_loss: 2.3429
[5] train_loss: 2.3267
[5] train_loss: 2.2948
[5] train_loss: 2.2796
[5] train_loss: 2.2881
[5] train_loss: 2.3069
[5] train_loss: 2.2962
[5] train_loss: 2.2751
[5] train_loss: 2.2794
[5] train_loss: 2.2531
2.6855413913726807

Evaluating...Epoch: 5
Prec: 0.7702, Recall: 0.7889, F1: 0.7794
model saved to random1_layers5_14res/best_model.pt
New best model saved!

[6] train_loss: 1.9872
[6] train_loss: 2.1392
[6] train_loss: 2.2058
[6] train_loss: 2.1645
[6] train_loss: 2.2271
[6] train_loss: 2.2194
[6] train_loss: 2.1259
[6] train_loss: 2.0877
[6] train_loss: 2.0702
[6] train_loss: 2.0507
[6] train_loss: 2.0480
[6] train_loss: 2.0623
[6] train_loss: 2.0504
[6] train_loss: 2.0465
[6] train_loss: 2.0574
[6] train_loss: 2.0298
2.689391613006592

Evaluating...Epoch: 6
Prec: 0.7851, Recall: 0.7675, F1: 0.7762

[7] train_loss: 1.8016
[7] train_loss: 2.0868
[7] train_loss: 2.0881
[7] train_loss: 2.0185
[7] train_loss: 2.1040
[7] train_loss: 2.1210
[7] train_loss: 2.0587
[7] train_loss: 2.0236
[7] train_loss: 1.9957
[7] train_loss: 1.9747
[7] train_loss: 1.9677
[7] train_loss: 1.9870
[7] train_loss: 1.9773
[7] train_loss: 1.9628
[7] train_loss: 1.9648
[7] train_loss: 1.9361
2.6870107650756836

Evaluating...Epoch: 7
Prec: 0.7792, Recall: 0.8171, F1: 0.7977
model saved to random1_layers5_14res/best_model.pt
New best model saved!

[8] train_loss: 1.6829
[8] train_loss: 1.8419
[8] train_loss: 1.8626
[8] train_loss: 1.7466
[8] train_loss: 1.7498
[8] train_loss: 1.7735
[8] train_loss: 1.7103
[8] train_loss: 1.6881
[8] train_loss: 1.6871
[8] train_loss: 1.6764
[8] train_loss: 1.6858
[8] train_loss: 1.7016
[8] train_loss: 1.6950
[8] train_loss: 1.7004
[8] train_loss: 1.7268
[8] train_loss: 1.7045
2.692560911178589

Evaluating...Epoch: 8
Prec: 0.8376, Recall: 0.7928, F1: 0.8146
model saved to random1_layers5_14res/best_model.pt
New best model saved!

[9] train_loss: 1.4529
[9] train_loss: 1.5978
[9] train_loss: 1.7065
[9] train_loss: 1.6548
[9] train_loss: 1.7145
[9] train_loss: 1.7342
[9] train_loss: 1.6640
[9] train_loss: 1.6440
[9] train_loss: 1.6645
[9] train_loss: 1.6521
[9] train_loss: 1.6380
[9] train_loss: 1.6447
[9] train_loss: 1.6422
[9] train_loss: 1.6261
[9] train_loss: 1.6385
[9] train_loss: 1.6191
2.678321599960327

Evaluating...Epoch: 9
Prec: 0.8025, Recall: 0.8220, F1: 0.8121

[10] train_loss: 1.6208
[10] train_loss: 1.7048
[10] train_loss: 1.7491
[10] train_loss: 1.6985
[10] train_loss: 1.7048
[10] train_loss: 1.6687
[10] train_loss: 1.6019
[10] train_loss: 1.5669
[10] train_loss: 1.5579
[10] train_loss: 1.5293
[10] train_loss: 1.5262
[10] train_loss: 1.5289
[10] train_loss: 1.5349
[10] train_loss: 1.5243
[10] train_loss: 1.5428
[10] train_loss: 1.5269
2.6949315071105957

Evaluating...Epoch: 10
Prec: 0.8376, Recall: 0.8181, F1: 0.8278
model saved to random1_layers5_14res/best_model.pt
New best model saved!

[11] train_loss: 1.2525
[11] train_loss: 1.4204
[11] train_loss: 1.3963
[11] train_loss: 1.3592
[11] train_loss: 1.4438
[11] train_loss: 1.4614
[11] train_loss: 1.4028
[11] train_loss: 1.3754
[11] train_loss: 1.3828
[11] train_loss: 1.3686
[11] train_loss: 1.3671
[11] train_loss: 1.4011
[11] train_loss: 1.4079
[11] train_loss: 1.4029
[11] train_loss: 1.4054
[11] train_loss: 1.3947
2.6664485931396484

Evaluating...Epoch: 11
Prec: 0.8095, Recall: 0.8268, F1: 0.8181

[12] train_loss: 1.0862
[12] train_loss: 1.3543
[12] train_loss: 1.3548
[12] train_loss: 1.3106
[12] train_loss: 1.3624
[12] train_loss: 1.4247
[12] train_loss: 1.3711
[12] train_loss: 1.3586
[12] train_loss: 1.3568
[12] train_loss: 1.3360
[12] train_loss: 1.3187
[12] train_loss: 1.3541
[12] train_loss: 1.3442
[12] train_loss: 1.3337
[12] train_loss: 1.3568
[12] train_loss: 1.3456
2.697742462158203

Evaluating...Epoch: 12
Prec: 0.8287, Recall: 0.8093, F1: 0.8189

[13] train_loss: 1.2127
[13] train_loss: 1.3378
[13] train_loss: 1.3647
[13] train_loss: 1.3039
[13] train_loss: 1.3162
[13] train_loss: 1.3337
[13] train_loss: 1.2706
[13] train_loss: 1.2665
[13] train_loss: 1.2422
[13] train_loss: 1.2365
[13] train_loss: 1.2467
[13] train_loss: 1.2503
[13] train_loss: 1.2484
[13] train_loss: 1.2459
[13] train_loss: 1.2607
[13] train_loss: 1.2404
2.787463426589966

Evaluating...Epoch: 13
Prec: 0.8592, Recall: 0.8191, F1: 0.8386
model saved to random1_layers5_14res/best_model.pt
New best model saved!

[14] train_loss: 1.0860
[14] train_loss: 1.1540
[14] train_loss: 1.2303
[14] train_loss: 1.1732
[14] train_loss: 1.2243
[14] train_loss: 1.2323
[14] train_loss: 1.1899
[14] train_loss: 1.1801
[14] train_loss: 1.1698
[14] train_loss: 1.1671
[14] train_loss: 1.1464
[14] train_loss: 1.1603
[14] train_loss: 1.1706
[14] train_loss: 1.1596
[14] train_loss: 1.1618
[14] train_loss: 1.1415
2.6602907180786133

Evaluating...Epoch: 14
Prec: 0.8560, Recall: 0.8210, F1: 0.8381

[15] train_loss: 0.9265
[15] train_loss: 1.0584
[15] train_loss: 1.1109
[15] train_loss: 1.0986
[15] train_loss: 1.1559
[15] train_loss: 1.2036
[15] train_loss: 1.1512
[15] train_loss: 1.1412
[15] train_loss: 1.1537
[15] train_loss: 1.1330
[15] train_loss: 1.1198
[15] train_loss: 1.1178
[15] train_loss: 1.1215
[15] train_loss: 1.1142
[15] train_loss: 1.1211
[15] train_loss: 1.1095
2.6868863105773926

Evaluating...Epoch: 15
Prec: 0.8674, Recall: 0.8016, F1: 0.8332

[16] train_loss: 0.9755
[16] train_loss: 1.0735
[16] train_loss: 1.1675
[16] train_loss: 1.1404
[16] train_loss: 1.1433
[16] train_loss: 1.1564
[16] train_loss: 1.1135
[16] train_loss: 1.1022
[16] train_loss: 1.1086
[16] train_loss: 1.0944
[16] train_loss: 1.0959
[16] train_loss: 1.1032
[16] train_loss: 1.1029
[16] train_loss: 1.0938
[16] train_loss: 1.1032
[16] train_loss: 1.0883
2.6844615936279297

Evaluating...Epoch: 16
Prec: 0.8556, Recall: 0.8356, F1: 0.8455
model saved to random1_layers5_14res/best_model.pt
New best model saved!

[17] train_loss: 0.7993
[17] train_loss: 1.0181
[17] train_loss: 1.0275
[17] train_loss: 0.9895
[17] train_loss: 1.0674
[17] train_loss: 1.0572
[17] train_loss: 1.0059
[17] train_loss: 1.0089
[17] train_loss: 0.9992
[17] train_loss: 0.9892
[17] train_loss: 0.9928
[17] train_loss: 1.0192
[17] train_loss: 1.0231
[17] train_loss: 1.0144
[17] train_loss: 1.0282
[17] train_loss: 1.0124
2.7647387981414795

Evaluating...Epoch: 17
Prec: 0.8519, Recall: 0.8171, F1: 0.8342

[18] train_loss: 0.8178
[18] train_loss: 0.9301
[18] train_loss: 0.9673
[18] train_loss: 0.9657
[18] train_loss: 0.9613
[18] train_loss: 0.9780
[18] train_loss: 0.9516
[18] train_loss: 0.9355
[18] train_loss: 0.9321
[18] train_loss: 0.9174
[18] train_loss: 0.9137
[18] train_loss: 0.9167
[18] train_loss: 0.9039
[18] train_loss: 0.9088
[18] train_loss: 0.9173
[18] train_loss: 0.9153
2.6783852577209473

Evaluating...Epoch: 18
Prec: 0.8567, Recall: 0.8200, F1: 0.8380

[19] train_loss: 0.7746
[19] train_loss: 0.9058
[19] train_loss: 0.9762
[19] train_loss: 0.9469
[19] train_loss: 1.0275
[19] train_loss: 1.0319
[19] train_loss: 0.9750
[19] train_loss: 0.9524
[19] train_loss: 0.9532
[19] train_loss: 0.9380
[19] train_loss: 0.9325
[19] train_loss: 0.9543
[19] train_loss: 0.9549
[19] train_loss: 0.9342
[19] train_loss: 0.9365
[19] train_loss: 0.9203
2.683278799057007

Evaluating...Epoch: 19
Prec: 0.8427, Recall: 0.8337, F1: 0.8381

[20] train_loss: 0.6103
[20] train_loss: 0.7486
[20] train_loss: 0.7813
[20] train_loss: 0.8403
[20] train_loss: 0.8855
[20] train_loss: 0.9164
[20] train_loss: 0.8956
[20] train_loss: 0.8761
[20] train_loss: 0.8614
[20] train_loss: 0.8634
[20] train_loss: 0.8592
[20] train_loss: 0.8650
[20] train_loss: 0.8587
[20] train_loss: 0.8589
[20] train_loss: 0.8757
[20] train_loss: 0.8756
2.6886298656463623

Evaluating...Epoch: 20
Prec: 0.8879, Recall: 0.8093, F1: 0.8468
model saved to random1_layers5_14res/best_model.pt
New best model saved!

[21] train_loss: 0.6772
[21] train_loss: 0.8123
[21] train_loss: 0.8314
[21] train_loss: 0.8238
[21] train_loss: 0.8700
[21] train_loss: 0.8774
[21] train_loss: 0.8478
[21] train_loss: 0.8278
[21] train_loss: 0.8165
[21] train_loss: 0.8115
[21] train_loss: 0.8039
[21] train_loss: 0.8120
[21] train_loss: 0.8069
[21] train_loss: 0.8088
[21] train_loss: 0.8103
[21] train_loss: 0.8014
2.773625135421753

Evaluating...Epoch: 21
Prec: 0.8728, Recall: 0.8142, F1: 0.8425

[22] train_loss: 0.6272
[22] train_loss: 0.7230
[22] train_loss: 0.7130
[22] train_loss: 0.7076
[22] train_loss: 0.7606
[22] train_loss: 0.8038
[22] train_loss: 0.7828
[22] train_loss: 0.7720
[22] train_loss: 0.7865
[22] train_loss: 0.7746
[22] train_loss: 0.7648
[22] train_loss: 0.7671
[22] train_loss: 0.7636
[22] train_loss: 0.7744
[22] train_loss: 0.7721
[22] train_loss: 0.7625
2.673675775527954

Evaluating...Epoch: 22
Prec: 0.8528, Recall: 0.8230, F1: 0.8376

[23] train_loss: 0.6521
[23] train_loss: 0.7880
[23] train_loss: 0.7333
[23] train_loss: 0.7347
[23] train_loss: 0.8095
[23] train_loss: 0.8164
[23] train_loss: 0.7870
[23] train_loss: 0.7706
[23] train_loss: 0.7812
[23] train_loss: 0.7709
[23] train_loss: 0.7718
[23] train_loss: 0.7780
[23] train_loss: 0.7774
[23] train_loss: 0.7666
[23] train_loss: 0.7689
[23] train_loss: 0.7600
2.672689437866211

Evaluating...Epoch: 23
Prec: 0.8622, Recall: 0.8093, F1: 0.8349

[24] train_loss: 0.5922
[24] train_loss: 0.6900
[24] train_loss: 0.6966
[24] train_loss: 0.6834
[24] train_loss: 0.7247
[24] train_loss: 0.7331
[24] train_loss: 0.7190
[24] train_loss: 0.7036
[24] train_loss: 0.7158
[24] train_loss: 0.7184
[24] train_loss: 0.7143
[24] train_loss: 0.7303
[24] train_loss: 0.7344
[24] train_loss: 0.7308
[24] train_loss: 0.7404
[24] train_loss: 0.7331
2.683919906616211

Evaluating...Epoch: 24
Prec: 0.8699, Recall: 0.8259, F1: 0.8473
model saved to random1_layers5_14res/best_model.pt
New best model saved!

[25] train_loss: 0.6425
[25] train_loss: 0.6832
[25] train_loss: 0.6886
[25] train_loss: 0.6715
[25] train_loss: 0.7389
[25] train_loss: 0.7543
[25] train_loss: 0.7255
[25] train_loss: 0.7073
[25] train_loss: 0.7037
[25] train_loss: 0.6963
[25] train_loss: 0.6992
[25] train_loss: 0.7062
[25] train_loss: 0.7118
[25] train_loss: 0.7046
[25] train_loss: 0.7218
[25] train_loss: 0.7123
2.694755792617798

Evaluating...Epoch: 25
Prec: 0.8592, Recall: 0.8249, F1: 0.8417

[26] train_loss: 0.5233
[26] train_loss: 0.6335
[26] train_loss: 0.6176
[26] train_loss: 0.6449
[26] train_loss: 0.6812
[26] train_loss: 0.6805
[26] train_loss: 0.6657
[26] train_loss: 0.6632
[26] train_loss: 0.6660
[26] train_loss: 0.6721
[26] train_loss: 0.6555
[26] train_loss: 0.6689
[26] train_loss: 0.6588
[26] train_loss: 0.6571
[26] train_loss: 0.6684
[26] train_loss: 0.6632
2.6792821884155273

Evaluating...Epoch: 26
Prec: 0.8662, Recall: 0.8123, F1: 0.8384

[27] train_loss: 0.5171
[27] train_loss: 0.6018
[27] train_loss: 0.5999
[27] train_loss: 0.6664
[27] train_loss: 0.6914
[27] train_loss: 0.7044
[27] train_loss: 0.6630
[27] train_loss: 0.6691
[27] train_loss: 0.6792
[27] train_loss: 0.6663
[27] train_loss: 0.6585
[27] train_loss: 0.6586
[27] train_loss: 0.6550
[27] train_loss: 0.6488
[27] train_loss: 0.6556
[27] train_loss: 0.6498
2.6868510246276855

Evaluating...Epoch: 27
Prec: 0.8532, Recall: 0.8200, F1: 0.8363

[28] train_loss: 0.5098
[28] train_loss: 0.6380
[28] train_loss: 0.6381
[28] train_loss: 0.6163
[28] train_loss: 0.6799
[28] train_loss: 0.7022
[28] train_loss: 0.6619
[28] train_loss: 0.6596
[28] train_loss: 0.6521
[28] train_loss: 0.6500
[28] train_loss: 0.6278
[28] train_loss: 0.6309
[28] train_loss: 0.6429
[28] train_loss: 0.6336
[28] train_loss: 0.6381
[28] train_loss: 0.6332
2.690634250640869

Evaluating...Epoch: 28
Prec: 0.8501, Recall: 0.8054, F1: 0.8272

[29] train_loss: 0.5691
[29] train_loss: 0.6116
[29] train_loss: 0.5803
[29] train_loss: 0.5664
[29] train_loss: 0.6016
[29] train_loss: 0.6256
[29] train_loss: 0.6147
[29] train_loss: 0.5935
[29] train_loss: 0.5916
[29] train_loss: 0.5911
[29] train_loss: 0.5856
[29] train_loss: 0.5879
[29] train_loss: 0.5859
[29] train_loss: 0.5900
[29] train_loss: 0.5907
[29] train_loss: 0.5862
2.6962716579437256

Evaluating...Epoch: 29
Prec: 0.8503, Recall: 0.8123, F1: 0.8308

[30] train_loss: 0.4990
[30] train_loss: 0.5645
[30] train_loss: 0.5618
[30] train_loss: 0.5529
[30] train_loss: 0.5715
[30] train_loss: 0.5932
[30] train_loss: 0.5531
[30] train_loss: 0.5519
[30] train_loss: 0.5476
[30] train_loss: 0.5394
[30] train_loss: 0.5392
[30] train_loss: 0.5442
[30] train_loss: 0.5445
[30] train_loss: 0.5405
[30] train_loss: 0.5393
[30] train_loss: 0.5278
2.6849582195281982

Evaluating...Epoch: 30
Prec: 0.8592, Recall: 0.8191, F1: 0.8386

[31] train_loss: 0.3627
[31] train_loss: 0.5222
[31] train_loss: 0.5531
[31] train_loss: 0.5260
[31] train_loss: 0.5576
[31] train_loss: 0.5782
[31] train_loss: 0.5521
[31] train_loss: 0.5353
[31] train_loss: 0.5368
[31] train_loss: 0.5516
[31] train_loss: 0.5447
[31] train_loss: 0.5541
[31] train_loss: 0.5540
[31] train_loss: 0.5548
[31] train_loss: 0.5469
[31] train_loss: 0.5406
2.6918981075286865

Evaluating...Epoch: 31
Prec: 0.8749, Recall: 0.8093, F1: 0.8408

[32] train_loss: 0.3375
[32] train_loss: 0.4156
[32] train_loss: 0.4383
[32] train_loss: 0.4918
[32] train_loss: 0.5226
[32] train_loss: 0.5365
[32] train_loss: 0.5144
[32] train_loss: 0.5249
[32] train_loss: 0.5213
[32] train_loss: 0.5263
[32] train_loss: 0.5214
[32] train_loss: 0.5194
[32] train_loss: 0.5256
[32] train_loss: 0.5239
[32] train_loss: 0.5159
[32] train_loss: 0.5132
2.7018425464630127

Evaluating...Epoch: 32
Prec: 0.8844, Recall: 0.7967, F1: 0.8383

[33] train_loss: 0.3072
[33] train_loss: 0.4036
[33] train_loss: 0.4117
[33] train_loss: 0.4424
[33] train_loss: 0.4976
[33] train_loss: 0.4938
[33] train_loss: 0.4760
[33] train_loss: 0.4899
[33] train_loss: 0.5027
[33] train_loss: 0.4994
[33] train_loss: 0.5103
[33] train_loss: 0.5210
[33] train_loss: 0.5219
[33] train_loss: 0.5189
[33] train_loss: 0.5276
[33] train_loss: 0.5254
2.667714834213257

Evaluating...Epoch: 33
Prec: 0.8642, Recall: 0.8171, F1: 0.8400

[34] train_loss: 0.3727
[34] train_loss: 0.4645
[34] train_loss: 0.4606
[34] train_loss: 0.4896
[34] train_loss: 0.5231
[34] train_loss: 0.5320
[34] train_loss: 0.5074
[34] train_loss: 0.4860
[34] train_loss: 0.4930
[34] train_loss: 0.5064
[34] train_loss: 0.5061
[34] train_loss: 0.5036
[34] train_loss: 0.5099
[34] train_loss: 0.5080
[34] train_loss: 0.5090
[34] train_loss: 0.5119
2.7755744457244873

Evaluating...Epoch: 34
Prec: 0.8397, Recall: 0.8307, F1: 0.8352

[35] train_loss: 0.4751
[35] train_loss: 0.4773
[35] train_loss: 0.4886
[35] train_loss: 0.4721
[35] train_loss: 0.5437
[35] train_loss: 0.5514
[35] train_loss: 0.5175
[35] train_loss: 0.5034
[35] train_loss: 0.5106
[35] train_loss: 0.5065
[35] train_loss: 0.5022
[35] train_loss: 0.4998
[35] train_loss: 0.5070
[35] train_loss: 0.5097
[35] train_loss: 0.5115
[35] train_loss: 0.5088
2.6772243976593018

Evaluating...Epoch: 35
Prec: 0.8875, Recall: 0.8054, F1: 0.8445

[36] train_loss: 0.3159
[36] train_loss: 0.3832
[36] train_loss: 0.3953
[36] train_loss: 0.4127
[36] train_loss: 0.4458
[36] train_loss: 0.4482
[36] train_loss: 0.4530
[36] train_loss: 0.4499
[36] train_loss: 0.4496
[36] train_loss: 0.4481
[36] train_loss: 0.4349
[36] train_loss: 0.4393
[36] train_loss: 0.4425
[36] train_loss: 0.4448
[36] train_loss: 0.4493
[36] train_loss: 0.4427
2.670804977416992

Evaluating...Epoch: 36
Prec: 0.8674, Recall: 0.8084, F1: 0.8369

[37] train_loss: 0.4333
[37] train_loss: 0.4027
[37] train_loss: 0.4209
[37] train_loss: 0.4287
[37] train_loss: 0.4666
[37] train_loss: 0.4888
[37] train_loss: 0.4861
[37] train_loss: 0.4809
[37] train_loss: 0.4898
[37] train_loss: 0.4892
[37] train_loss: 0.4839
[37] train_loss: 0.4832
[37] train_loss: 0.4720
[37] train_loss: 0.4712
[37] train_loss: 0.4735
[37] train_loss: 0.4669
2.662541151046753

Evaluating...Epoch: 37
Prec: 0.8683, Recall: 0.8084, F1: 0.8373

[38] train_loss: 0.2361
[38] train_loss: 0.3133
[38] train_loss: 0.3403
[38] train_loss: 0.3928
[38] train_loss: 0.4162
[38] train_loss: 0.4313
[38] train_loss: 0.4157
[38] train_loss: 0.4351
[38] train_loss: 0.4396
[38] train_loss: 0.4348
[38] train_loss: 0.4283
[38] train_loss: 0.4506
[38] train_loss: 0.4490
[38] train_loss: 0.4479
[38] train_loss: 0.4433
[38] train_loss: 0.4422
2.76385235786438

Evaluating...Epoch: 38
Prec: 0.8636, Recall: 0.8132, F1: 0.8377

[39] train_loss: 0.3336
[39] train_loss: 0.3790
[39] train_loss: 0.3946
[39] train_loss: 0.4201
[39] train_loss: 0.4133
[39] train_loss: 0.4239
[39] train_loss: 0.4012
[39] train_loss: 0.3917
[39] train_loss: 0.3864
[39] train_loss: 0.3967
[39] train_loss: 0.3922
[39] train_loss: 0.3900
[39] train_loss: 0.3944
[39] train_loss: 0.3892
[39] train_loss: 0.4020
[39] train_loss: 0.4006
2.6733129024505615

Evaluating...Epoch: 39
Prec: 0.8481, Recall: 0.8307, F1: 0.8393

[40] train_loss: 0.2399
[40] train_loss: 0.3396
[40] train_loss: 0.3393
[40] train_loss: 0.3396
[40] train_loss: 0.3943
[40] train_loss: 0.3964
[40] train_loss: 0.3869
[40] train_loss: 0.3804
[40] train_loss: 0.3880
[40] train_loss: 0.3914
[40] train_loss: 0.3879
[40] train_loss: 0.3945
[40] train_loss: 0.4027
[40] train_loss: 0.3984
[40] train_loss: 0.4038
[40] train_loss: 0.3989
2.675448179244995

Evaluating...Epoch: 40
Prec: 0.8781, Recall: 0.8200, F1: 0.8481
model saved to random1_layers5_14res/best_model.pt
New best model saved!

[41] train_loss: 0.2309
[41] train_loss: 0.2591
[41] train_loss: 0.2878
[41] train_loss: 0.3048
[41] train_loss: 0.3740
[41] train_loss: 0.3955
[41] train_loss: 0.3729
[41] train_loss: 0.3827
[41] train_loss: 0.3871
[41] train_loss: 0.3796
[41] train_loss: 0.3775
[41] train_loss: 0.3766
[41] train_loss: 0.3769
[41] train_loss: 0.3811
[41] train_loss: 0.3835
[41] train_loss: 0.3769
2.691455602645874

Evaluating...Epoch: 41
Prec: 0.8858, Recall: 0.7996, F1: 0.8405

[42] train_loss: 0.2492
[42] train_loss: 0.3598
[42] train_loss: 0.4105
[42] train_loss: 0.4062
[42] train_loss: 0.4270
[42] train_loss: 0.4330
[42] train_loss: 0.4163
[42] train_loss: 0.4167
[42] train_loss: 0.4113
[42] train_loss: 0.4070
[42] train_loss: 0.3979
[42] train_loss: 0.3856
[42] train_loss: 0.3838
[42] train_loss: 0.3807
[42] train_loss: 0.3795
[42] train_loss: 0.3845
2.7502591609954834

Evaluating...Epoch: 42
Prec: 0.8751, Recall: 0.8045, F1: 0.8383

[43] train_loss: 0.3273
[43] train_loss: 0.3703
[43] train_loss: 0.4252
[43] train_loss: 0.4438
[43] train_loss: 0.4374
[43] train_loss: 0.4295
[43] train_loss: 0.4115
[43] train_loss: 0.3984
[43] train_loss: 0.3992
[43] train_loss: 0.3984
[43] train_loss: 0.3938
[43] train_loss: 0.3883
[43] train_loss: 0.3942
[43] train_loss: 0.3861
[43] train_loss: 0.3868
[43] train_loss: 0.3780
2.68308424949646

Evaluating...Epoch: 43
Prec: 0.8765, Recall: 0.8288, F1: 0.8520
model saved to random1_layers5_14res/best_model.pt
New best model saved!

[44] train_loss: 0.3622
[44] train_loss: 0.3287
[44] train_loss: 0.3398
[44] train_loss: 0.3444
[44] train_loss: 0.3393
[44] train_loss: 0.3445
[44] train_loss: 0.3373
[44] train_loss: 0.3388
[44] train_loss: 0.3548
[44] train_loss: 0.3550
[44] train_loss: 0.3428
[44] train_loss: 0.3509
[44] train_loss: 0.3548
[44] train_loss: 0.3530
[44] train_loss: 0.3620
[44] train_loss: 0.3633
2.6839845180511475

Evaluating...Epoch: 44
Prec: 0.8745, Recall: 0.8132, F1: 0.8427

[45] train_loss: 0.2405
[45] train_loss: 0.2780
[45] train_loss: 0.3128
[45] train_loss: 0.3201
[45] train_loss: 0.3320
[45] train_loss: 0.3847
[45] train_loss: 0.3673
[45] train_loss: 0.3625
[45] train_loss: 0.3584
[45] train_loss: 0.3573
[45] train_loss: 0.3486
[45] train_loss: 0.3500
[45] train_loss: 0.3422
[45] train_loss: 0.3472
[45] train_loss: 0.3415
[45] train_loss: 0.3372
2.6668362617492676

Evaluating...Epoch: 45
Prec: 0.8716, Recall: 0.8191, F1: 0.8445

[46] train_loss: 0.2579
[46] train_loss: 0.2703
[46] train_loss: 0.2983
[46] train_loss: 0.3145
[46] train_loss: 0.3564
[46] train_loss: 0.3623
[46] train_loss: 0.3501
[46] train_loss: 0.3511
[46] train_loss: 0.3601
[46] train_loss: 0.3632
[46] train_loss: 0.3547
[46] train_loss: 0.3538
[46] train_loss: 0.3507
[46] train_loss: 0.3436
[46] train_loss: 0.3375
[46] train_loss: 0.3371
2.6819100379943848

Evaluating...Epoch: 46
Prec: 0.8817, Recall: 0.8268, F1: 0.8534
model saved to random1_layers5_14res/best_model.pt
New best model saved!

[47] train_loss: 0.1781
[47] train_loss: 0.2739
[47] train_loss: 0.3256
[47] train_loss: 0.3382
[47] train_loss: 0.3451
[47] train_loss: 0.3413
[47] train_loss: 0.3385
[47] train_loss: 0.3394
[47] train_loss: 0.3442
[47] train_loss: 0.3371
[47] train_loss: 0.3316
[47] train_loss: 0.3343
[47] train_loss: 0.3482
[47] train_loss: 0.3476
[47] train_loss: 0.3536
[47] train_loss: 0.3466
2.6824746131896973

Evaluating...Epoch: 47
Prec: 0.8658, Recall: 0.8161, F1: 0.8403

[48] train_loss: 0.2014
[48] train_loss: 0.2927
[48] train_loss: 0.3083
[48] train_loss: 0.2941
[48] train_loss: 0.3122
[48] train_loss: 0.3173
[48] train_loss: 0.3018
[48] train_loss: 0.2979
[48] train_loss: 0.2985
[48] train_loss: 0.3109
[48] train_loss: 0.3050
[48] train_loss: 0.3118
[48] train_loss: 0.3155
[48] train_loss: 0.3091
[48] train_loss: 0.3165
[48] train_loss: 0.3137
2.691798210144043

Evaluating...Epoch: 48
Prec: 0.8719, Recall: 0.8278, F1: 0.8493

[49] train_loss: 0.2359
[49] train_loss: 0.2461
[49] train_loss: 0.2280
[49] train_loss: 0.2411
[49] train_loss: 0.2626
[49] train_loss: 0.2708
[49] train_loss: 0.2665
[49] train_loss: 0.2735
[49] train_loss: 0.2847
[49] train_loss: 0.2861
[49] train_loss: 0.2834
[49] train_loss: 0.2892
[49] train_loss: 0.2982
[49] train_loss: 0.2917
[49] train_loss: 0.2887
[49] train_loss: 0.2825
2.682640790939331

Evaluating...Epoch: 49
Prec: 0.8635, Recall: 0.8249, F1: 0.8438

[50] train_loss: 0.1592
[50] train_loss: 0.2607
[50] train_loss: 0.2860
[50] train_loss: 0.2680
[50] train_loss: 0.2883
[50] train_loss: 0.3284
[50] train_loss: 0.3216
[50] train_loss: 0.3359
[50] train_loss: 0.3378
[50] train_loss: 0.3448
[50] train_loss: 0.3489
[50] train_loss: 0.3542
[50] train_loss: 0.3565
[50] train_loss: 0.3471
[50] train_loss: 0.3488
[50] train_loss: 0.3432
2.688732385635376

Evaluating...Epoch: 50
Prec: 0.8632, Recall: 0.8161, F1: 0.8390

[51] train_loss: 0.2884
[51] train_loss: 0.3326
[51] train_loss: 0.3581
[51] train_loss: 0.3282
[51] train_loss: 0.3441
[51] train_loss: 0.3563
[51] train_loss: 0.3405
[51] train_loss: 0.3308
[51] train_loss: 0.3222
[51] train_loss: 0.3242
[51] train_loss: 0.3106
[51] train_loss: 0.3034
[51] train_loss: 0.3114
[51] train_loss: 0.3051
[51] train_loss: 0.3085
[51] train_loss: 0.3024
2.7689208984375

Evaluating...Epoch: 51
Prec: 0.8718, Recall: 0.8074, F1: 0.8384

[52] train_loss: 0.3072
[52] train_loss: 0.3981
[52] train_loss: 0.3445
[52] train_loss: 0.3395
[52] train_loss: 0.3509
[52] train_loss: 0.3454
[52] train_loss: 0.3337
[52] train_loss: 0.3281
[52] train_loss: 0.3272
[52] train_loss: 0.3310
[52] train_loss: 0.3360
[52] train_loss: 0.3340
[52] train_loss: 0.3337
[52] train_loss: 0.3258
[52] train_loss: 0.3163
[52] train_loss: 0.3073
2.680116653442383

Evaluating...Epoch: 52
Prec: 0.8577, Recall: 0.8210, F1: 0.8390

[53] train_loss: 0.2129
[53] train_loss: 0.2470
[53] train_loss: 0.2718
[53] train_loss: 0.2579
[53] train_loss: 0.2658
[53] train_loss: 0.2982
[53] train_loss: 0.2764
[53] train_loss: 0.2760
[53] train_loss: 0.2772
[53] train_loss: 0.2732
[53] train_loss: 0.2677
[53] train_loss: 0.2634
[53] train_loss: 0.2641
[53] train_loss: 0.2641
[53] train_loss: 0.2633
[53] train_loss: 0.2659
2.669092893600464

Evaluating...Epoch: 53
Prec: 0.8624, Recall: 0.8230, F1: 0.8422

[54] train_loss: 0.2064
[54] train_loss: 0.2391
[54] train_loss: 0.2532
[54] train_loss: 0.2486
[54] train_loss: 0.2493
[54] train_loss: 0.2783
[54] train_loss: 0.2599
[54] train_loss: 0.2749
[54] train_loss: 0.2755
[54] train_loss: 0.2801
[54] train_loss: 0.2745
[54] train_loss: 0.2852
[54] train_loss: 0.2891
[54] train_loss: 0.2879
[54] train_loss: 0.2907
[54] train_loss: 0.2837
2.660116195678711

Evaluating...Epoch: 54
Prec: 0.8586, Recall: 0.8210, F1: 0.8394

[55] train_loss: 0.1838
[55] train_loss: 0.1715
[55] train_loss: 0.1914
[55] train_loss: 0.2118
[55] train_loss: 0.2125
[55] train_loss: 0.2186
[55] train_loss: 0.2124
[55] train_loss: 0.2205
[55] train_loss: 0.2277
[55] train_loss: 0.2361
[55] train_loss: 0.2332
[55] train_loss: 0.2513
[55] train_loss: 0.2542
[55] train_loss: 0.2521
[55] train_loss: 0.2494
[55] train_loss: 0.2489
2.720623731613159

Evaluating...Epoch: 55
Prec: 0.8693, Recall: 0.8220, F1: 0.8450

[56] train_loss: 0.1691
[56] train_loss: 0.2382
[56] train_loss: 0.2640
[56] train_loss: 0.2643
[56] train_loss: 0.2731
[56] train_loss: 0.2842
[56] train_loss: 0.2680
[56] train_loss: 0.2511
[56] train_loss: 0.2550
[56] train_loss: 0.2446
[56] train_loss: 0.2387
[56] train_loss: 0.2499
[56] train_loss: 0.2439
[56] train_loss: 0.2530
[56] train_loss: 0.2514
[56] train_loss: 0.2487
2.63698410987854

Evaluating...Epoch: 56
Prec: 0.8550, Recall: 0.8142, F1: 0.8341

[57] train_loss: 0.1918
[57] train_loss: 0.2456
[57] train_loss: 0.2301
[57] train_loss: 0.2506
[57] train_loss: 0.2779
[57] train_loss: 0.3119
[57] train_loss: 0.2886
[57] train_loss: 0.2782
[57] train_loss: 0.2787
[57] train_loss: 0.2736
[57] train_loss: 0.2659
[57] train_loss: 0.2563
[57] train_loss: 0.2595
[57] train_loss: 0.2582
[57] train_loss: 0.2601
[57] train_loss: 0.2540
2.666539192199707

Evaluating...Epoch: 57
Prec: 0.8412, Recall: 0.8298, F1: 0.8355

[58] train_loss: 0.1468
[58] train_loss: 0.2582
[58] train_loss: 0.2625
[58] train_loss: 0.2413
[58] train_loss: 0.2656
[58] train_loss: 0.2751
[58] train_loss: 0.2570
[58] train_loss: 0.2704
[58] train_loss: 0.2869
[58] train_loss: 0.2876
[58] train_loss: 0.2818
[58] train_loss: 0.2923
[58] train_loss: 0.2894
[58] train_loss: 0.2875
[58] train_loss: 0.2857
[58] train_loss: 0.2875
2.6693532466888428

Evaluating...Epoch: 58
Prec: 0.8465, Recall: 0.8259, F1: 0.8360

[59] train_loss: 0.2196
[59] train_loss: 0.2157
[59] train_loss: 0.2027
[59] train_loss: 0.2131
[59] train_loss: 0.2393
[59] train_loss: 0.2455
[59] train_loss: 0.2320
[59] train_loss: 0.2232
[59] train_loss: 0.2323
[59] train_loss: 0.2393
[59] train_loss: 0.2324
[59] train_loss: 0.2322
[59] train_loss: 0.2385
[59] train_loss: 0.2357
[59] train_loss: 0.2397
[59] train_loss: 0.2384
2.7019999027252197

Evaluating...Epoch: 59
Prec: 0.8690, Recall: 0.8132, F1: 0.8402

[60] train_loss: 0.1878
[60] train_loss: 0.2588
[60] train_loss: 0.2502
[60] train_loss: 0.2465
[60] train_loss: 0.2815
[60] train_loss: 0.2740
[60] train_loss: 0.2578
[60] train_loss: 0.2485
[60] train_loss: 0.2442
[60] train_loss: 0.2453
[60] train_loss: 0.2423
[60] train_loss: 0.2424
[60] train_loss: 0.2497
[60] train_loss: 0.2429
[60] train_loss: 0.2470
[60] train_loss: 0.2445
2.654757261276245

Evaluating...Epoch: 60
Prec: 0.8551, Recall: 0.8035, F1: 0.8285

[61] train_loss: 0.1006
[61] train_loss: 0.1293
[61] train_loss: 0.2168
[61] train_loss: 0.2179
[61] train_loss: 0.2321
[61] train_loss: 0.2445
[61] train_loss: 0.2310
[61] train_loss: 0.2287
[61] train_loss: 0.2339
[61] train_loss: 0.2310
[61] train_loss: 0.2324
[61] train_loss: 0.2407
[61] train_loss: 0.2434
[61] train_loss: 0.2411
[61] train_loss: 0.2446
[61] train_loss: 0.2408
2.6468772888183594

Evaluating...Epoch: 61
Prec: 0.8462, Recall: 0.8298, F1: 0.8379

[62] train_loss: 0.1543
[62] train_loss: 0.2398
[62] train_loss: 0.2141
[62] train_loss: 0.2073
[62] train_loss: 0.2213
[62] train_loss: 0.2263
[62] train_loss: 0.2206
[62] train_loss: 0.2100
[62] train_loss: 0.2178
[62] train_loss: 0.2245
[62] train_loss: 0.2278
[62] train_loss: 0.2406
[62] train_loss: 0.2501
[62] train_loss: 0.2522
[62] train_loss: 0.2563
[62] train_loss: 0.2572
2.654430389404297

Evaluating...Epoch: 62
Prec: 0.8550, Recall: 0.8259, F1: 0.8402

[63] train_loss: 0.1465
[63] train_loss: 0.2748
[63] train_loss: 0.2414
[63] train_loss: 0.2661
[63] train_loss: 0.2620
[63] train_loss: 0.2581
[63] train_loss: 0.2511
[63] train_loss: 0.2417
[63] train_loss: 0.2427
[63] train_loss: 0.2427
[63] train_loss: 0.2432
[63] train_loss: 0.2421
[63] train_loss: 0.2429
[63] train_loss: 0.2386
[63] train_loss: 0.2402
[63] train_loss: 0.2323
2.73930287361145

Evaluating...Epoch: 63
Prec: 0.8340, Recall: 0.8405, F1: 0.8372

[64] train_loss: 0.1350
[64] train_loss: 0.2030
[64] train_loss: 0.2029
[64] train_loss: 0.2010
[64] train_loss: 0.2202
[64] train_loss: 0.2143
[64] train_loss: 0.2127
[64] train_loss: 0.2081
[64] train_loss: 0.2263
[64] train_loss: 0.2295
[64] train_loss: 0.2247
[64] train_loss: 0.2234
[64] train_loss: 0.2251
[64] train_loss: 0.2250
[64] train_loss: 0.2308
[64] train_loss: 0.2314
2.646023988723755

Evaluating...Epoch: 64
Prec: 0.8759, Recall: 0.8103, F1: 0.8418

[65] train_loss: 0.1243
[65] train_loss: 0.1667
[65] train_loss: 0.1604
[65] train_loss: 0.1735
[65] train_loss: 0.1982
[65] train_loss: 0.2098
[65] train_loss: 0.1980
[65] train_loss: 0.1922
[65] train_loss: 0.1991
[65] train_loss: 0.1994
[65] train_loss: 0.2014
[65] train_loss: 0.2071
[65] train_loss: 0.2073
[65] train_loss: 0.2032
[65] train_loss: 0.1991
[65] train_loss: 0.1963
2.6646366119384766

Evaluating...Epoch: 65
Prec: 0.8346, Recall: 0.8395, F1: 0.8371

[66] train_loss: 0.1689
[66] train_loss: 0.1739
[66] train_loss: 0.1866
[66] train_loss: 0.1942
[66] train_loss: 0.2289
[66] train_loss: 0.2249
[66] train_loss: 0.2235
[66] train_loss: 0.2255
[66] train_loss: 0.2254
[66] train_loss: 0.2210
[66] train_loss: 0.2101
[66] train_loss: 0.2177
[66] train_loss: 0.2187
[66] train_loss: 0.2145
[66] train_loss: 0.2119
[66] train_loss: 0.2090
2.6568515300750732

Evaluating...Epoch: 66
Prec: 0.8481, Recall: 0.8307, F1: 0.8393

Training ended with 67 epochs.
Final result:
Prec: 0.8817, Recall: 0.8268, F1: 0.8534
loading vocab and embedding matrix from ../data/15res
size of vocab: 2715
shape of loaded embedding matrix: (2715, 300)
Generating mappings
Loading data from ../data/15res with batch size 16...
68 batches created for ../data/15res/train.json
28 batches created for ../data/15res/test.json
Building model...
1192203
[1] train_loss: 14.3737
[1] train_loss: 10.5326
[1] train_loss: 9.0705
[1] train_loss: 7.9818
[1] train_loss: 7.3491
[1] train_loss: 6.8192
0.8574864864349365

Evaluating...Epoch: 1
Prec: 1.0000, Recall: 0.0122, F1: 0.0240
model saved to random1_layers0_15res/best_model.pt
New best model saved!

[2] train_loss: 4.8765
[2] train_loss: 4.3749
[2] train_loss: 4.3690
[2] train_loss: 4.1468
[2] train_loss: 4.0290
[2] train_loss: 3.8967
0.8563401699066162

Evaluating...Epoch: 2
Prec: 0.8068, Recall: 0.4320, F1: 0.5627
model saved to random1_layers0_15res/best_model.pt
New best model saved!

[3] train_loss: 4.4098
[3] train_loss: 3.8547
[3] train_loss: 3.8977
[3] train_loss: 3.6909
[3] train_loss: 3.6066
[3] train_loss: 3.5148
0.8547985553741455

Evaluating...Epoch: 3
Prec: 0.8412, Recall: 0.4726, F1: 0.6052
model saved to random1_layers0_15res/best_model.pt
New best model saved!

[4] train_loss: 3.7223
[4] train_loss: 3.3883
[4] train_loss: 3.4170
[4] train_loss: 3.2185
[4] train_loss: 3.1746
[4] train_loss: 3.0831
0.8657932281494141

Evaluating...Epoch: 4
Prec: 0.8421, Recall: 0.5193, F1: 0.6424
model saved to random1_layers0_15res/best_model.pt
New best model saved!

[5] train_loss: 3.3964
[5] train_loss: 3.0274
[5] train_loss: 3.1475
[5] train_loss: 2.9903
[5] train_loss: 2.9468
[5] train_loss: 2.8736
0.8570547103881836

Evaluating...Epoch: 5
Prec: 0.8459, Recall: 0.5680, F1: 0.6796
model saved to random1_layers0_15res/best_model.pt
New best model saved!

[6] train_loss: 3.0973
[6] train_loss: 2.8044
[6] train_loss: 2.9345
[6] train_loss: 2.7767
[6] train_loss: 2.7654
[6] train_loss: 2.6812
0.8563399314880371

Evaluating...Epoch: 6
Prec: 0.8496, Recall: 0.5842, F1: 0.6923
model saved to random1_layers0_15res/best_model.pt
New best model saved!

[7] train_loss: 3.1456
[7] train_loss: 2.7489
[7] train_loss: 2.7505
[7] train_loss: 2.6063
[7] train_loss: 2.5661
[7] train_loss: 2.4924
0.9126367568969727

Evaluating...Epoch: 7
Prec: 0.8081, Recall: 0.6065, F1: 0.6929
model saved to random1_layers0_15res/best_model.pt
New best model saved!

[8] train_loss: 2.9348
[8] train_loss: 2.5690
[8] train_loss: 2.5620
[8] train_loss: 2.4039
[8] train_loss: 2.3545
[8] train_loss: 2.2796
0.8513975143432617

Evaluating...Epoch: 8
Prec: 0.7387, Recall: 0.6653, F1: 0.7001
model saved to random1_layers0_15res/best_model.pt
New best model saved!

[9] train_loss: 2.6744
[9] train_loss: 2.3030
[9] train_loss: 2.3095
[9] train_loss: 2.1862
[9] train_loss: 2.1569
[9] train_loss: 2.1152
0.8586900234222412

Evaluating...Epoch: 9
Prec: 0.7597, Recall: 0.6349, F1: 0.6917

[10] train_loss: 2.3644
[10] train_loss: 2.1277
[10] train_loss: 2.1332
[10] train_loss: 2.0425
[10] train_loss: 2.0188
[10] train_loss: 1.9653
0.8618893623352051

Evaluating...Epoch: 10
Prec: 0.7518, Recall: 0.6511, F1: 0.6978

[11] train_loss: 2.3146
[11] train_loss: 2.0059
[11] train_loss: 2.0582
[11] train_loss: 1.8639
[11] train_loss: 1.8746
[11] train_loss: 1.8288
0.8533811569213867

Evaluating...Epoch: 11
Prec: 0.7551, Recall: 0.6755, F1: 0.7131
model saved to random1_layers0_15res/best_model.pt
New best model saved!

[12] train_loss: 2.1333
[12] train_loss: 1.9196
[12] train_loss: 1.9588
[12] train_loss: 1.8302
[12] train_loss: 1.8187
[12] train_loss: 1.7707
0.8563194274902344

Evaluating...Epoch: 12
Prec: 0.7555, Recall: 0.6957, F1: 0.7244
model saved to random1_layers0_15res/best_model.pt
New best model saved!

[13] train_loss: 1.9466
[13] train_loss: 1.7952
[13] train_loss: 1.7756
[13] train_loss: 1.6477
[13] train_loss: 1.6372
[13] train_loss: 1.6011
0.8522446155548096

Evaluating...Epoch: 13
Prec: 0.7505, Recall: 0.7018, F1: 0.7254
model saved to random1_layers0_15res/best_model.pt
New best model saved!

[14] train_loss: 1.8298
[14] train_loss: 1.6546
[14] train_loss: 1.6582
[14] train_loss: 1.5146
[14] train_loss: 1.5214
[14] train_loss: 1.4710
0.8565809726715088

Evaluating...Epoch: 14
Prec: 0.7765, Recall: 0.6836, F1: 0.7271
model saved to random1_layers0_15res/best_model.pt
New best model saved!

[15] train_loss: 1.8102
[15] train_loss: 1.5361
[15] train_loss: 1.6218
[15] train_loss: 1.4724
[15] train_loss: 1.4620
[15] train_loss: 1.4104
0.8544790744781494

Evaluating...Epoch: 15
Prec: 0.7565, Recall: 0.7120, F1: 0.7335
model saved to random1_layers0_15res/best_model.pt
New best model saved!

[16] train_loss: 1.5060
[16] train_loss: 1.4208
[16] train_loss: 1.4335
[16] train_loss: 1.3324
[16] train_loss: 1.3387
[16] train_loss: 1.3325
0.8627171516418457

Evaluating...Epoch: 16
Prec: 0.7879, Recall: 0.7160, F1: 0.7503
model saved to random1_layers0_15res/best_model.pt
New best model saved!

[17] train_loss: 1.3994
[17] train_loss: 1.3212
[17] train_loss: 1.3951
[17] train_loss: 1.2983
[17] train_loss: 1.2594
[17] train_loss: 1.2432
0.853851318359375

Evaluating...Epoch: 17
Prec: 0.7430, Recall: 0.7505, F1: 0.7467

[18] train_loss: 1.5009
[18] train_loss: 1.4430
[18] train_loss: 1.3600
[18] train_loss: 1.2430
[18] train_loss: 1.2776
[18] train_loss: 1.2403
0.8561816215515137

Evaluating...Epoch: 18
Prec: 0.7790, Recall: 0.7363, F1: 0.7570
model saved to random1_layers0_15res/best_model.pt
New best model saved!

[19] train_loss: 1.1713
[19] train_loss: 1.1397
[19] train_loss: 1.1857
[19] train_loss: 1.1105
[19] train_loss: 1.1228
[19] train_loss: 1.0871
0.8567728996276855

Evaluating...Epoch: 19
Prec: 0.7578, Recall: 0.7363, F1: 0.7469

[20] train_loss: 1.4267
[20] train_loss: 1.2362
[20] train_loss: 1.2192
[20] train_loss: 1.1173
[20] train_loss: 1.1231
[20] train_loss: 1.1159
0.8503875732421875

Evaluating...Epoch: 20
Prec: 0.7749, Recall: 0.7404, F1: 0.7573
model saved to random1_layers0_15res/best_model.pt
New best model saved!

[21] train_loss: 1.2699
[21] train_loss: 1.1834
[21] train_loss: 1.1565
[21] train_loss: 1.0361
[21] train_loss: 1.0245
[21] train_loss: 0.9715
0.8520681858062744

Evaluating...Epoch: 21
Prec: 0.7982, Recall: 0.7302, F1: 0.7627
model saved to random1_layers0_15res/best_model.pt
New best model saved!

[22] train_loss: 1.1534
[22] train_loss: 1.1162
[22] train_loss: 1.0576
[22] train_loss: 0.9411
[22] train_loss: 0.9509
[22] train_loss: 0.9120
0.8453903198242188

Evaluating...Epoch: 22
Prec: 0.7675, Recall: 0.7566, F1: 0.7620

[23] train_loss: 1.1707
[23] train_loss: 0.9965
[23] train_loss: 0.9964
[23] train_loss: 0.9051
[23] train_loss: 0.9290
[23] train_loss: 0.9192
0.8590545654296875

Evaluating...Epoch: 23
Prec: 0.7540, Recall: 0.7647, F1: 0.7593

[24] train_loss: 0.9233
[24] train_loss: 0.8667
[24] train_loss: 0.8699
[24] train_loss: 0.7846
[24] train_loss: 0.8363
[24] train_loss: 0.8102
0.8531398773193359

Evaluating...Epoch: 24
Prec: 0.7659, Recall: 0.7566, F1: 0.7612

[25] train_loss: 0.8987
[25] train_loss: 0.8109
[25] train_loss: 0.8674
[25] train_loss: 0.8240
[25] train_loss: 0.8187
[25] train_loss: 0.8057
0.8560662269592285

Evaluating...Epoch: 25
Prec: 0.7919, Recall: 0.7566, F1: 0.7739
model saved to random1_layers0_15res/best_model.pt
New best model saved!

[26] train_loss: 0.9681
[26] train_loss: 0.8926
[26] train_loss: 0.9264
[26] train_loss: 0.8326
[26] train_loss: 0.8532
[26] train_loss: 0.8318
0.8559732437133789

Evaluating...Epoch: 26
Prec: 0.7626, Recall: 0.7688, F1: 0.7657

[27] train_loss: 0.8024
[27] train_loss: 0.6779
[27] train_loss: 0.6893
[27] train_loss: 0.6568
[27] train_loss: 0.6848
[27] train_loss: 0.6839
0.8461670875549316

Evaluating...Epoch: 27
Prec: 0.7901, Recall: 0.7485, F1: 0.7687

[28] train_loss: 0.9855
[28] train_loss: 0.8351
[28] train_loss: 0.7881
[28] train_loss: 0.7069
[28] train_loss: 0.7364
[28] train_loss: 0.7270
0.8976104259490967

Evaluating...Epoch: 28
Prec: 0.7495, Recall: 0.7708, F1: 0.7600

[29] train_loss: 0.6492
[29] train_loss: 0.5610
[29] train_loss: 0.5954
[29] train_loss: 0.5702
[29] train_loss: 0.6308
[29] train_loss: 0.6347
0.8368051052093506

Evaluating...Epoch: 29
Prec: 0.7978, Recall: 0.7525, F1: 0.7745
model saved to random1_layers0_15res/best_model.pt
New best model saved!

[30] train_loss: 0.7007
[30] train_loss: 0.6861
[30] train_loss: 0.7059
[30] train_loss: 0.6420
[30] train_loss: 0.6475
[30] train_loss: 0.6517
0.8465008735656738

Evaluating...Epoch: 30
Prec: 0.7451, Recall: 0.7769, F1: 0.7607

[31] train_loss: 0.5480
[31] train_loss: 0.5440
[31] train_loss: 0.5935
[31] train_loss: 0.5634
[31] train_loss: 0.5943
[31] train_loss: 0.5808
0.8540499210357666

Evaluating...Epoch: 31
Prec: 0.7746, Recall: 0.7667, F1: 0.7706

[32] train_loss: 0.6163
[32] train_loss: 0.5773
[32] train_loss: 0.5723
[32] train_loss: 0.5391
[32] train_loss: 0.5739
[32] train_loss: 0.5607
0.8597283363342285

Evaluating...Epoch: 32
Prec: 0.7853, Recall: 0.7566, F1: 0.7707

[33] train_loss: 0.6230
[33] train_loss: 0.5839
[33] train_loss: 0.5938
[33] train_loss: 0.5407
[33] train_loss: 0.5651
[33] train_loss: 0.5668
0.8526296615600586

Evaluating...Epoch: 33
Prec: 0.7739, Recall: 0.7566, F1: 0.7651

[34] train_loss: 0.6677
[34] train_loss: 0.6194
[34] train_loss: 0.5846
[34] train_loss: 0.5348
[34] train_loss: 0.5695
[34] train_loss: 0.5360
0.8587648868560791

Evaluating...Epoch: 34
Prec: 0.7848, Recall: 0.7769, F1: 0.7808
model saved to random1_layers0_15res/best_model.pt
New best model saved!

[35] train_loss: 0.6307
[35] train_loss: 0.5141
[35] train_loss: 0.5241
[35] train_loss: 0.4714
[35] train_loss: 0.4799
[35] train_loss: 0.4941
0.8493387699127197

Evaluating...Epoch: 35
Prec: 0.7753, Recall: 0.7627, F1: 0.7689

[36] train_loss: 0.5378
[36] train_loss: 0.5207
[36] train_loss: 0.5192
[36] train_loss: 0.4862
[36] train_loss: 0.5018
[36] train_loss: 0.4814
0.8593292236328125

Evaluating...Epoch: 36
Prec: 0.7829, Recall: 0.7606, F1: 0.7716

[37] train_loss: 0.7623
[37] train_loss: 0.6309
[37] train_loss: 0.5790
[37] train_loss: 0.5461
[37] train_loss: 0.5327
[37] train_loss: 0.5084
0.8382143974304199

Evaluating...Epoch: 37
Prec: 0.7560, Recall: 0.7728, F1: 0.7643

[38] train_loss: 0.5263
[38] train_loss: 0.5424
[38] train_loss: 0.4884
[38] train_loss: 0.4731
[38] train_loss: 0.4473
[38] train_loss: 0.4348
0.8397994041442871

Evaluating...Epoch: 38
Prec: 0.7773, Recall: 0.7647, F1: 0.7710

[39] train_loss: 0.4901
[39] train_loss: 0.4542
[39] train_loss: 0.4452
[39] train_loss: 0.4144
[39] train_loss: 0.4507
[39] train_loss: 0.4469
0.8365457057952881

Evaluating...Epoch: 39
Prec: 0.7937, Recall: 0.7647, F1: 0.7789

[40] train_loss: 0.4667
[40] train_loss: 0.4109
[40] train_loss: 0.4069
[40] train_loss: 0.4306
[40] train_loss: 0.4432
[40] train_loss: 0.4379
0.8452465534210205

Evaluating...Epoch: 40
Prec: 0.7683, Recall: 0.7667, F1: 0.7675

[41] train_loss: 0.4404
[41] train_loss: 0.4218
[41] train_loss: 0.4532
[41] train_loss: 0.4222
[41] train_loss: 0.4326
[41] train_loss: 0.4238
0.8413596153259277

Evaluating...Epoch: 41
Prec: 0.7845, Recall: 0.7606, F1: 0.7724

[42] train_loss: 0.3680
[42] train_loss: 0.3784
[42] train_loss: 0.4099
[42] train_loss: 0.3859
[42] train_loss: 0.4271
[42] train_loss: 0.4024
0.8536477088928223

Evaluating...Epoch: 42
Prec: 0.7705, Recall: 0.7627, F1: 0.7666

[43] train_loss: 0.4151
[43] train_loss: 0.3620
[43] train_loss: 0.3583
[43] train_loss: 0.3390
[43] train_loss: 0.3552
[43] train_loss: 0.3493
0.8494601249694824

Evaluating...Epoch: 43
Prec: 0.7975, Recall: 0.7667, F1: 0.7818
model saved to random1_layers0_15res/best_model.pt
New best model saved!

[44] train_loss: 0.4964
[44] train_loss: 0.4403
[44] train_loss: 0.3985
[44] train_loss: 0.3710
[44] train_loss: 0.3843
[44] train_loss: 0.3721
0.843796968460083

Evaluating...Epoch: 44
Prec: 0.7866, Recall: 0.7627, F1: 0.7745

[45] train_loss: 0.3883
[45] train_loss: 0.3533
[45] train_loss: 0.3431
[45] train_loss: 0.3237
[45] train_loss: 0.3470
[45] train_loss: 0.3535
0.8579137325286865

Evaluating...Epoch: 45
Prec: 0.7856, Recall: 0.7728, F1: 0.7791

[46] train_loss: 0.3336
[46] train_loss: 0.3355
[46] train_loss: 0.3455
[46] train_loss: 0.3342
[46] train_loss: 0.3396
[46] train_loss: 0.3154
0.8500986099243164

Evaluating...Epoch: 46
Prec: 0.7871, Recall: 0.7647, F1: 0.7757

[47] train_loss: 0.3755
[47] train_loss: 0.3358
[47] train_loss: 0.3445
[47] train_loss: 0.3153
[47] train_loss: 0.3300
[47] train_loss: 0.3280
0.8602573871612549

Evaluating...Epoch: 47
Prec: 0.7785, Recall: 0.7627, F1: 0.7705

[48] train_loss: 0.4072
[48] train_loss: 0.3798
[48] train_loss: 0.4138
[48] train_loss: 0.4002
[48] train_loss: 0.3840
[48] train_loss: 0.3647
0.8497908115386963

Evaluating...Epoch: 48
Prec: 0.8013, Recall: 0.7525, F1: 0.7762

[49] train_loss: 0.2361
[49] train_loss: 0.2672
[49] train_loss: 0.2888
[49] train_loss: 0.2796
[49] train_loss: 0.2906
[49] train_loss: 0.2860
0.8597028255462646

Evaluating...Epoch: 49
Prec: 0.7928, Recall: 0.7606, F1: 0.7764

[50] train_loss: 0.4061
[50] train_loss: 0.3213
[50] train_loss: 0.2888
[50] train_loss: 0.2768
[50] train_loss: 0.2703
[50] train_loss: 0.2685
0.8456759452819824

Evaluating...Epoch: 50
Prec: 0.7822, Recall: 0.7647, F1: 0.7733

[51] train_loss: 0.3041
[51] train_loss: 0.2502
[51] train_loss: 0.2850
[51] train_loss: 0.2709
[51] train_loss: 0.2819
[51] train_loss: 0.2912
0.8606607913970947

Evaluating...Epoch: 51
Prec: 0.7962, Recall: 0.7688, F1: 0.7822
model saved to random1_layers0_15res/best_model.pt
New best model saved!

[52] train_loss: 0.3318
[52] train_loss: 0.3194
[52] train_loss: 0.2880
[52] train_loss: 0.2732
[52] train_loss: 0.2648
[52] train_loss: 0.2691
0.846337080001831

Evaluating...Epoch: 52
Prec: 0.7725, Recall: 0.7647, F1: 0.7686

[53] train_loss: 0.2979
[53] train_loss: 0.2983
[53] train_loss: 0.2821
[53] train_loss: 0.2483
[53] train_loss: 0.2575
[53] train_loss: 0.2640
0.8596024513244629

Evaluating...Epoch: 53
Prec: 0.7798, Recall: 0.7688, F1: 0.7743

[54] train_loss: 0.3904
[54] train_loss: 0.3129
[54] train_loss: 0.2755
[54] train_loss: 0.2807
[54] train_loss: 0.2707
[54] train_loss: 0.2621
0.853370189666748

Evaluating...Epoch: 54
Prec: 0.7610, Recall: 0.7688, F1: 0.7649

[55] train_loss: 0.2692
[55] train_loss: 0.2148
[55] train_loss: 0.2227
[55] train_loss: 0.2063
[55] train_loss: 0.2103
[55] train_loss: 0.2187
0.8552372455596924

Evaluating...Epoch: 55
Prec: 0.7920, Recall: 0.7647, F1: 0.7781

[56] train_loss: 0.1973
[56] train_loss: 0.2372
[56] train_loss: 0.2368
[56] train_loss: 0.2296
[56] train_loss: 0.2401
[56] train_loss: 0.2263
0.8552615642547607

Evaluating...Epoch: 56
Prec: 0.7842, Recall: 0.7667, F1: 0.7754

[57] train_loss: 0.2783
[57] train_loss: 0.2482
[57] train_loss: 0.2584
[57] train_loss: 0.2297
[57] train_loss: 0.2397
[57] train_loss: 0.2270
0.8442649841308594

Evaluating...Epoch: 57
Prec: 0.7879, Recall: 0.7688, F1: 0.7782

[58] train_loss: 0.2840
[58] train_loss: 0.2137
[58] train_loss: 0.2156
[58] train_loss: 0.2214
[58] train_loss: 0.2278
[58] train_loss: 0.2333
0.850654125213623

Evaluating...Epoch: 58
Prec: 0.7757, Recall: 0.7647, F1: 0.7702

[59] train_loss: 0.2118
[59] train_loss: 0.2040
[59] train_loss: 0.2107
[59] train_loss: 0.2081
[59] train_loss: 0.2207
[59] train_loss: 0.2296
0.8477554321289062

Evaluating...Epoch: 59
Prec: 0.7760, Recall: 0.7728, F1: 0.7744

[60] train_loss: 0.2534
[60] train_loss: 0.2241
[60] train_loss: 0.2886
[60] train_loss: 0.2627
[60] train_loss: 0.2724
[60] train_loss: 0.2765
0.8514783382415771

Evaluating...Epoch: 60
Prec: 0.7911, Recall: 0.7606, F1: 0.7756

[61] train_loss: 0.2301
[61] train_loss: 0.2469
[61] train_loss: 0.2359
[61] train_loss: 0.2192
[61] train_loss: 0.2403
[61] train_loss: 0.2443
0.8478333950042725

Evaluating...Epoch: 61
Prec: 0.7751, Recall: 0.7688, F1: 0.7719

[62] train_loss: 0.2657
[62] train_loss: 0.2448
[62] train_loss: 0.2269
[62] train_loss: 0.2020
[62] train_loss: 0.2176
[62] train_loss: 0.2380
0.8553190231323242

Evaluating...Epoch: 62
Prec: 0.7904, Recall: 0.7647, F1: 0.7773

[63] train_loss: 0.3474
[63] train_loss: 0.2713
[63] train_loss: 0.2370
[63] train_loss: 0.2114
[63] train_loss: 0.1886
[63] train_loss: 0.1859
0.8461258411407471

Evaluating...Epoch: 63
Prec: 0.7595, Recall: 0.7688, F1: 0.7641

[64] train_loss: 0.1956
[64] train_loss: 0.2096
[64] train_loss: 0.2137
[64] train_loss: 0.2135
[64] train_loss: 0.2037
[64] train_loss: 0.1915
0.8998401165008545

Evaluating...Epoch: 64
Prec: 0.7646, Recall: 0.7708, F1: 0.7677

[65] train_loss: 0.2894
[65] train_loss: 0.2288
[65] train_loss: 0.2107
[65] train_loss: 0.1849
[65] train_loss: 0.1768
[65] train_loss: 0.1719
0.8521163463592529

Evaluating...Epoch: 65
Prec: 0.7739, Recall: 0.7708, F1: 0.7724

[66] train_loss: 0.1571
[66] train_loss: 0.1437
[66] train_loss: 0.1603
[66] train_loss: 0.1509
[66] train_loss: 0.1616
[66] train_loss: 0.1657
0.8488142490386963

Evaluating...Epoch: 66
Prec: 0.7854, Recall: 0.7647, F1: 0.7749

[67] train_loss: 0.1796
[67] train_loss: 0.1642
[67] train_loss: 0.1640
[67] train_loss: 0.1472
[67] train_loss: 0.1572
[67] train_loss: 0.1680
0.8451316356658936

Evaluating...Epoch: 67
Prec: 0.7941, Recall: 0.7667, F1: 0.7802

[68] train_loss: 0.2424
[68] train_loss: 0.2293
[68] train_loss: 0.2212
[68] train_loss: 0.2061
[68] train_loss: 0.1903
[68] train_loss: 0.1904
0.8462560176849365

Evaluating...Epoch: 68
Prec: 0.7945, Recall: 0.7606, F1: 0.7772

[69] train_loss: 0.2651
[69] train_loss: 0.2243
[69] train_loss: 0.2197
[69] train_loss: 0.2064
[69] train_loss: 0.2004
[69] train_loss: 0.1818
0.8506779670715332

Evaluating...Epoch: 69
Prec: 0.7869, Recall: 0.7566, F1: 0.7715

[70] train_loss: 0.1418
[70] train_loss: 0.1494
[70] train_loss: 0.1407
[70] train_loss: 0.1308
[70] train_loss: 0.1348
[70] train_loss: 0.1427
0.8562977313995361

Evaluating...Epoch: 70
Prec: 0.7724, Recall: 0.7708, F1: 0.7716

[71] train_loss: 0.1690
[71] train_loss: 0.1406
[71] train_loss: 0.1579
[71] train_loss: 0.1573
[71] train_loss: 0.1670
[71] train_loss: 0.1661
0.8969173431396484

Evaluating...Epoch: 71
Prec: 0.7800, Recall: 0.7769, F1: 0.7785

Training ended with 72 epochs.
Final result:
Prec: 0.7962, Recall: 0.7688, F1: 0.7822
loading vocab and embedding matrix from ../data/15res
size of vocab: 2715
shape of loaded embedding matrix: (2715, 300)
Generating mappings
Loading data from ../data/15res with batch size 16...
68 batches created for ../data/15res/train.json
28 batches created for ../data/15res/test.json
Building model...
1232403
[1] train_loss: 13.8637
[1] train_loss: 10.1202
[1] train_loss: 8.7567
[1] train_loss: 7.8137
[1] train_loss: 7.2610
[1] train_loss: 6.7596
0.8935110569000244

Evaluating...Epoch: 1
Prec: 0.9130, Recall: 0.0426, F1: 0.0814
model saved to random1_layers1_15res/best_model.pt
New best model saved!

[2] train_loss: 4.9025
[2] train_loss: 4.4217
[2] train_loss: 4.3979
[2] train_loss: 4.1650
[2] train_loss: 4.0788
[2] train_loss: 3.9246
0.8812682628631592

Evaluating...Epoch: 2
Prec: 0.8597, Recall: 0.3854, F1: 0.5322
model saved to random1_layers1_15res/best_model.pt
New best model saved!

[3] train_loss: 4.2159
[3] train_loss: 3.7429
[3] train_loss: 3.7440
[3] train_loss: 3.5348
[3] train_loss: 3.5117
[3] train_loss: 3.4048
0.8837788105010986

Evaluating...Epoch: 3
Prec: 0.8702, Recall: 0.5030, F1: 0.6375
model saved to random1_layers1_15res/best_model.pt
New best model saved!

[4] train_loss: 3.8046
[4] train_loss: 3.3642
[4] train_loss: 3.3836
[4] train_loss: 3.1717
[4] train_loss: 3.1213
[4] train_loss: 3.0194
0.8795347213745117

Evaluating...Epoch: 4
Prec: 0.8455, Recall: 0.5882, F1: 0.6938
model saved to random1_layers1_15res/best_model.pt
New best model saved!

[5] train_loss: 3.3971
[5] train_loss: 2.9666
[5] train_loss: 3.0213
[5] train_loss: 2.8680
[5] train_loss: 2.8482
[5] train_loss: 2.7692
0.8899328708648682

Evaluating...Epoch: 5
Prec: 0.8437, Recall: 0.5801, F1: 0.6875

[6] train_loss: 3.2278
[6] train_loss: 2.8584
[6] train_loss: 2.8748
[6] train_loss: 2.6810
[6] train_loss: 2.6647
[6] train_loss: 2.5628
0.8747854232788086

Evaluating...Epoch: 6
Prec: 0.8131, Recall: 0.6531, F1: 0.7244
model saved to random1_layers1_15res/best_model.pt
New best model saved!

[7] train_loss: 2.8715
[7] train_loss: 2.5580
[7] train_loss: 2.5914
[7] train_loss: 2.4141
[7] train_loss: 2.4054
[7] train_loss: 2.3416
0.9450318813323975

Evaluating...Epoch: 7
Prec: 0.8055, Recall: 0.6552, F1: 0.7226

[8] train_loss: 2.6094
[8] train_loss: 2.3738
[8] train_loss: 2.4359
[8] train_loss: 2.2751
[8] train_loss: 2.2900
[8] train_loss: 2.2260
0.8759398460388184

Evaluating...Epoch: 8
Prec: 0.8065, Recall: 0.6592, F1: 0.7254
model saved to random1_layers1_15res/best_model.pt
New best model saved!

[9] train_loss: 2.5763
[9] train_loss: 2.2413
[9] train_loss: 2.3367
[9] train_loss: 2.1618
[9] train_loss: 2.1717
[9] train_loss: 2.1074
0.8829200267791748

Evaluating...Epoch: 9
Prec: 0.7678, Recall: 0.6775, F1: 0.7198

[10] train_loss: 2.3467
[10] train_loss: 2.0161
[10] train_loss: 2.0465
[10] train_loss: 1.8794
[10] train_loss: 1.9429
[10] train_loss: 1.8889
0.8748865127563477

Evaluating...Epoch: 10
Prec: 0.7775, Recall: 0.6734, F1: 0.7217

[11] train_loss: 2.0761
[11] train_loss: 1.9129
[11] train_loss: 1.9068
[11] train_loss: 1.7892
[11] train_loss: 1.8048
[11] train_loss: 1.7540
0.8863005638122559

Evaluating...Epoch: 11
Prec: 0.7798, Recall: 0.7039, F1: 0.7399
model saved to random1_layers1_15res/best_model.pt
New best model saved!

[12] train_loss: 2.0721
[12] train_loss: 1.7828
[12] train_loss: 1.7962
[12] train_loss: 1.6540
[12] train_loss: 1.6474
[12] train_loss: 1.6088
0.8838422298431396

Evaluating...Epoch: 12
Prec: 0.7569, Recall: 0.7262, F1: 0.7412
model saved to random1_layers1_15res/best_model.pt
New best model saved!

[13] train_loss: 1.7546
[13] train_loss: 1.6385
[13] train_loss: 1.6074
[13] train_loss: 1.4889
[13] train_loss: 1.4769
[13] train_loss: 1.4220
0.8760955333709717

Evaluating...Epoch: 13
Prec: 0.7490, Recall: 0.7262, F1: 0.7374

[14] train_loss: 1.5768
[14] train_loss: 1.4301
[14] train_loss: 1.5247
[14] train_loss: 1.4040
[14] train_loss: 1.4297
[14] train_loss: 1.3971
0.8785369396209717

Evaluating...Epoch: 14
Prec: 0.7697, Recall: 0.7120, F1: 0.7397

[15] train_loss: 1.5108
[15] train_loss: 1.3593
[15] train_loss: 1.3871
[15] train_loss: 1.2691
[15] train_loss: 1.2877
[15] train_loss: 1.2601
0.8724365234375

Evaluating...Epoch: 15
Prec: 0.7672, Recall: 0.7221, F1: 0.7440
model saved to random1_layers1_15res/best_model.pt
New best model saved!

[16] train_loss: 1.4308
[16] train_loss: 1.2877
[16] train_loss: 1.3235
[16] train_loss: 1.2075
[16] train_loss: 1.2389
[16] train_loss: 1.1900
0.8744158744812012

Evaluating...Epoch: 16
Prec: 0.7298, Recall: 0.7505, F1: 0.7400

[17] train_loss: 1.2597
[17] train_loss: 1.2230
[17] train_loss: 1.2067
[17] train_loss: 1.0819
[17] train_loss: 1.1059
[17] train_loss: 1.0689
0.88201904296875

Evaluating...Epoch: 17
Prec: 0.7536, Recall: 0.7383, F1: 0.7459
model saved to random1_layers1_15res/best_model.pt
New best model saved!

[18] train_loss: 1.2895
[18] train_loss: 1.1002
[18] train_loss: 1.1244
[18] train_loss: 1.0245
[18] train_loss: 1.0582
[18] train_loss: 1.0153
0.8920645713806152

Evaluating...Epoch: 18
Prec: 0.7485, Recall: 0.7363, F1: 0.7423

[19] train_loss: 1.2337
[19] train_loss: 1.0619
[19] train_loss: 1.0239
[19] train_loss: 0.9383
[19] train_loss: 0.9867
[19] train_loss: 0.9379
0.8839459419250488

Evaluating...Epoch: 19
Prec: 0.7691, Recall: 0.7566, F1: 0.7628
model saved to random1_layers1_15res/best_model.pt
New best model saved!

[20] train_loss: 1.1547
[20] train_loss: 1.0789
[20] train_loss: 1.0298
[20] train_loss: 0.9252
[20] train_loss: 0.9493
[20] train_loss: 0.8974
0.8799872398376465

Evaluating...Epoch: 20
Prec: 0.7900, Recall: 0.7404, F1: 0.7644
model saved to random1_layers1_15res/best_model.pt
New best model saved!

[21] train_loss: 1.1219
[21] train_loss: 0.9866
[21] train_loss: 0.9610
[21] train_loss: 0.8571
[21] train_loss: 0.8767
[21] train_loss: 0.8436
0.894829511642456

Evaluating...Epoch: 21
Prec: 0.7761, Recall: 0.7383, F1: 0.7568

[22] train_loss: 0.9276
[22] train_loss: 0.9173
[22] train_loss: 0.8749
[22] train_loss: 0.8135
[22] train_loss: 0.8360
[22] train_loss: 0.8036
0.8839905261993408

Evaluating...Epoch: 22
Prec: 0.7545, Recall: 0.7667, F1: 0.7606

[23] train_loss: 0.7806
[23] train_loss: 0.7574
[23] train_loss: 0.8192
[23] train_loss: 0.7590
[23] train_loss: 0.7657
[23] train_loss: 0.7351
0.8762884140014648

Evaluating...Epoch: 23
Prec: 0.7380, Recall: 0.7485, F1: 0.7432

[24] train_loss: 0.9875
[24] train_loss: 0.8175
[24] train_loss: 0.8475
[24] train_loss: 0.7706
[24] train_loss: 0.8139
[24] train_loss: 0.7887
0.8683738708496094

Evaluating...Epoch: 24
Prec: 0.8048, Recall: 0.7444, F1: 0.7734
model saved to random1_layers1_15res/best_model.pt
New best model saved!

[25] train_loss: 0.6562
[25] train_loss: 0.6258
[25] train_loss: 0.6636
[25] train_loss: 0.6017
[25] train_loss: 0.6348
[25] train_loss: 0.6231
0.8760340213775635

Evaluating...Epoch: 25
Prec: 0.7877, Recall: 0.7525, F1: 0.7697

[26] train_loss: 0.7874
[26] train_loss: 0.6967
[26] train_loss: 0.7213
[26] train_loss: 0.6806
[26] train_loss: 0.7184
[26] train_loss: 0.6823
0.8735752105712891

Evaluating...Epoch: 26
Prec: 0.7931, Recall: 0.7465, F1: 0.7691

[27] train_loss: 0.8967
[27] train_loss: 0.6861
[27] train_loss: 0.6744
[27] train_loss: 0.6233
[27] train_loss: 0.6585
[27] train_loss: 0.6404
0.8810505867004395

Evaluating...Epoch: 27
Prec: 0.7789, Recall: 0.7647, F1: 0.7718

[28] train_loss: 0.6028
[28] train_loss: 0.5944
[28] train_loss: 0.5573
[28] train_loss: 0.5327
[28] train_loss: 0.5406
[28] train_loss: 0.5231
0.934617280960083

Evaluating...Epoch: 28
Prec: 0.8147, Recall: 0.7404, F1: 0.7758
model saved to random1_layers1_15res/best_model.pt
New best model saved!

[29] train_loss: 0.7237
[29] train_loss: 0.6342
[29] train_loss: 0.6507
[29] train_loss: 0.6046
[29] train_loss: 0.6290
[29] train_loss: 0.6010
0.8681025505065918

Evaluating...Epoch: 29
Prec: 0.7663, Recall: 0.7647, F1: 0.7655

[30] train_loss: 0.6785
[30] train_loss: 0.6261
[30] train_loss: 0.6248
[30] train_loss: 0.5685
[30] train_loss: 0.5793
[30] train_loss: 0.5737
0.8847620487213135

Evaluating...Epoch: 30
Prec: 0.8047, Recall: 0.7606, F1: 0.7821
model saved to random1_layers1_15res/best_model.pt
New best model saved!

[31] train_loss: 0.6585
[31] train_loss: 0.5987
[31] train_loss: 0.5768
[31] train_loss: 0.5218
[31] train_loss: 0.5375
[31] train_loss: 0.5313
0.8810374736785889

Evaluating...Epoch: 31
Prec: 0.7705, Recall: 0.7627, F1: 0.7666

[32] train_loss: 0.5013
[32] train_loss: 0.4850
[32] train_loss: 0.5557
[32] train_loss: 0.4965
[32] train_loss: 0.5113
[32] train_loss: 0.4945
0.8927531242370605

Evaluating...Epoch: 32
Prec: 0.7871, Recall: 0.7647, F1: 0.7757

[33] train_loss: 0.5624
[33] train_loss: 0.4924
[33] train_loss: 0.4767
[33] train_loss: 0.4544
[33] train_loss: 0.4705
[33] train_loss: 0.4577
0.8876957893371582

Evaluating...Epoch: 33
Prec: 0.7754, Recall: 0.7424, F1: 0.7585

[34] train_loss: 0.3608
[34] train_loss: 0.3714
[34] train_loss: 0.4312
[34] train_loss: 0.3997
[34] train_loss: 0.4147
[34] train_loss: 0.4082
0.8884623050689697

Evaluating...Epoch: 34
Prec: 0.7707, Recall: 0.7566, F1: 0.7636

[35] train_loss: 0.6089
[35] train_loss: 0.5903
[35] train_loss: 0.5391
[35] train_loss: 0.4927
[35] train_loss: 0.5116
[35] train_loss: 0.4991
0.8687715530395508

Evaluating...Epoch: 35
Prec: 0.7757, Recall: 0.7505, F1: 0.7629

[36] train_loss: 0.5832
[36] train_loss: 0.4716
[36] train_loss: 0.4521
[36] train_loss: 0.4278
[36] train_loss: 0.4319
[36] train_loss: 0.4304
0.8877959251403809

Evaluating...Epoch: 36
Prec: 0.7713, Recall: 0.7728, F1: 0.7720

[37] train_loss: 0.5519
[37] train_loss: 0.4666
[37] train_loss: 0.4587
[37] train_loss: 0.4225
[37] train_loss: 0.4267
[37] train_loss: 0.4268
0.8748199939727783

Evaluating...Epoch: 37
Prec: 0.7684, Recall: 0.7606, F1: 0.7645

[38] train_loss: 0.4617
[38] train_loss: 0.3983
[38] train_loss: 0.3895
[38] train_loss: 0.3880
[38] train_loss: 0.4084
[38] train_loss: 0.4149
0.8884551525115967

Evaluating...Epoch: 38
Prec: 0.7681, Recall: 0.7525, F1: 0.7602

[39] train_loss: 0.3525
[39] train_loss: 0.3065
[39] train_loss: 0.3742
[39] train_loss: 0.3540
[39] train_loss: 0.3829
[39] train_loss: 0.3730
0.876089334487915

Evaluating...Epoch: 39
Prec: 0.7773, Recall: 0.7789, F1: 0.7781

[40] train_loss: 0.5557
[40] train_loss: 0.5046
[40] train_loss: 0.4671
[40] train_loss: 0.4240
[40] train_loss: 0.4164
[40] train_loss: 0.4136
0.8857228755950928

Evaluating...Epoch: 40
Prec: 0.7734, Recall: 0.7890, F1: 0.7811

[41] train_loss: 0.3129
[41] train_loss: 0.3430
[41] train_loss: 0.3348
[41] train_loss: 0.3157
[41] train_loss: 0.3314
[41] train_loss: 0.3111
0.8915257453918457

Evaluating...Epoch: 41
Prec: 0.8099, Recall: 0.7606, F1: 0.7845
model saved to random1_layers1_15res/best_model.pt
New best model saved!

[42] train_loss: 0.4474
[42] train_loss: 0.4122
[42] train_loss: 0.4291
[42] train_loss: 0.3982
[42] train_loss: 0.3956
[42] train_loss: 0.3931
0.9364094734191895

Evaluating...Epoch: 42
Prec: 0.7927, Recall: 0.7444, F1: 0.7678

[43] train_loss: 0.2799
[43] train_loss: 0.2957
[43] train_loss: 0.3079
[43] train_loss: 0.3092
[43] train_loss: 0.3161
[43] train_loss: 0.3283
0.883089542388916

Evaluating...Epoch: 43
Prec: 0.7622, Recall: 0.7606, F1: 0.7614

[44] train_loss: 0.3603
[44] train_loss: 0.3474
[44] train_loss: 0.3205
[44] train_loss: 0.3009
[44] train_loss: 0.3077
[44] train_loss: 0.3227
0.8772449493408203

Evaluating...Epoch: 44
Prec: 0.7917, Recall: 0.7708, F1: 0.7811

[45] train_loss: 0.2367
[45] train_loss: 0.2636
[45] train_loss: 0.3012
[45] train_loss: 0.2805
[45] train_loss: 0.3033
[45] train_loss: 0.2845
0.8885502815246582

Evaluating...Epoch: 45
Prec: 0.8034, Recall: 0.7708, F1: 0.7867
model saved to random1_layers1_15res/best_model.pt
New best model saved!

[46] train_loss: 0.2986
[46] train_loss: 0.2965
[46] train_loss: 0.2736
[46] train_loss: 0.2530
[46] train_loss: 0.2739
[46] train_loss: 0.2920
0.8743281364440918

Evaluating...Epoch: 46
Prec: 0.7647, Recall: 0.7647, F1: 0.7647

[47] train_loss: 0.3149
[47] train_loss: 0.2815
[47] train_loss: 0.3176
[47] train_loss: 0.2995
[47] train_loss: 0.2989
[47] train_loss: 0.2855
0.8866763114929199

Evaluating...Epoch: 47
Prec: 0.8293, Recall: 0.7586, F1: 0.7924
model saved to random1_layers1_15res/best_model.pt
New best model saved!

[48] train_loss: 0.3496
[48] train_loss: 0.2880
[48] train_loss: 0.2948
[48] train_loss: 0.2772
[48] train_loss: 0.2882
[48] train_loss: 0.2777
0.8721656799316406

Evaluating...Epoch: 48
Prec: 0.8258, Recall: 0.7404, F1: 0.7807

[49] train_loss: 0.2365
[49] train_loss: 0.2349
[49] train_loss: 0.2333
[49] train_loss: 0.2192
[49] train_loss: 0.2321
[49] train_loss: 0.2307
0.8716881275177002

Evaluating...Epoch: 49
Prec: 0.8069, Recall: 0.7627, F1: 0.7842

[50] train_loss: 0.3140
[50] train_loss: 0.2540
[50] train_loss: 0.2578
[50] train_loss: 0.2494
[50] train_loss: 0.2655
[50] train_loss: 0.2650
0.8713986873626709

Evaluating...Epoch: 50
Prec: 0.8047, Recall: 0.7688, F1: 0.7863

[51] train_loss: 0.3256
[51] train_loss: 0.2843
[51] train_loss: 0.2560
[51] train_loss: 0.2424
[51] train_loss: 0.2526
[51] train_loss: 0.2435
0.8879132270812988

Evaluating...Epoch: 51
Prec: 0.7837, Recall: 0.7789, F1: 0.7813

[52] train_loss: 0.3366
[52] train_loss: 0.3103
[52] train_loss: 0.3134
[52] train_loss: 0.2855
[52] train_loss: 0.2726
[52] train_loss: 0.2516
0.8738365173339844

Evaluating...Epoch: 52
Prec: 0.7918, Recall: 0.7789, F1: 0.7853

[53] train_loss: 0.2653
[53] train_loss: 0.2332
[53] train_loss: 0.2504
[53] train_loss: 0.2205
[53] train_loss: 0.2273
[53] train_loss: 0.2282
0.8782832622528076

Evaluating...Epoch: 53
Prec: 0.8042, Recall: 0.7748, F1: 0.7893

[54] train_loss: 0.1945
[54] train_loss: 0.1825
[54] train_loss: 0.1652
[54] train_loss: 0.1559
[54] train_loss: 0.1809
[54] train_loss: 0.1808
0.8881721496582031

Evaluating...Epoch: 54
Prec: 0.7983, Recall: 0.7708, F1: 0.7843

[55] train_loss: 0.1848
[55] train_loss: 0.1893
[55] train_loss: 0.2089
[55] train_loss: 0.2207
[55] train_loss: 0.2126
[55] train_loss: 0.1983
0.8765897750854492

Evaluating...Epoch: 55
Prec: 0.8117, Recall: 0.7606, F1: 0.7853

[56] train_loss: 0.1766
[56] train_loss: 0.1588
[56] train_loss: 0.1711
[56] train_loss: 0.1807
[56] train_loss: 0.1929
[56] train_loss: 0.2070
0.8817331790924072

Evaluating...Epoch: 56
Prec: 0.7872, Recall: 0.7728, F1: 0.7799

[57] train_loss: 0.2131
[57] train_loss: 0.2095
[57] train_loss: 0.2099
[57] train_loss: 0.1938
[57] train_loss: 0.1955
[57] train_loss: 0.1920
0.8737373352050781

Evaluating...Epoch: 57
Prec: 0.8044, Recall: 0.7424, F1: 0.7722

[58] train_loss: 0.3027
[58] train_loss: 0.3126
[58] train_loss: 0.2635
[58] train_loss: 0.2347
[58] train_loss: 0.2335
[58] train_loss: 0.2179
0.8799605369567871

Evaluating...Epoch: 58
Prec: 0.7894, Recall: 0.7525, F1: 0.7705

[59] train_loss: 0.1783
[59] train_loss: 0.1854
[59] train_loss: 0.1710
[59] train_loss: 0.1635
[59] train_loss: 0.1776
[59] train_loss: 0.1733
0.8766231536865234

Evaluating...Epoch: 59
Prec: 0.8047, Recall: 0.7688, F1: 0.7863

[60] train_loss: 0.2697
[60] train_loss: 0.2445
[60] train_loss: 0.2407
[60] train_loss: 0.2235
[60] train_loss: 0.2099
[60] train_loss: 0.1937
0.8813302516937256

Evaluating...Epoch: 60
Prec: 0.7983, Recall: 0.7789, F1: 0.7885

[61] train_loss: 0.2182
[61] train_loss: 0.2021
[61] train_loss: 0.1942
[61] train_loss: 0.1818
[61] train_loss: 0.1791
[61] train_loss: 0.1687
0.8803467750549316

Evaluating...Epoch: 61
Prec: 0.7823, Recall: 0.7870, F1: 0.7846

[62] train_loss: 0.1544
[62] train_loss: 0.1306
[62] train_loss: 0.1529
[62] train_loss: 0.1426
[62] train_loss: 0.1502
[62] train_loss: 0.1432
0.8808763027191162

Evaluating...Epoch: 62
Prec: 0.7791, Recall: 0.7870, F1: 0.7830

[63] train_loss: 0.1658
[63] train_loss: 0.1601
[63] train_loss: 0.1623
[63] train_loss: 0.1523
[63] train_loss: 0.1451
[63] train_loss: 0.1524
0.8881003856658936

Evaluating...Epoch: 63
Prec: 0.8047, Recall: 0.7606, F1: 0.7821

[64] train_loss: 0.2381
[64] train_loss: 0.2178
[64] train_loss: 0.2177
[64] train_loss: 0.1883
[64] train_loss: 0.1826
[64] train_loss: 0.1711
0.8819668292999268

Evaluating...Epoch: 64
Prec: 0.7805, Recall: 0.7647, F1: 0.7725

[65] train_loss: 0.2036
[65] train_loss: 0.1634
[65] train_loss: 0.1841
[65] train_loss: 0.1564
[65] train_loss: 0.1505
[65] train_loss: 0.1413
0.8884081840515137

Evaluating...Epoch: 65
Prec: 0.8145, Recall: 0.7748, F1: 0.7942
model saved to random1_layers1_15res/best_model.pt
New best model saved!

[66] train_loss: 0.1524
[66] train_loss: 0.1568
[66] train_loss: 0.1421
[66] train_loss: 0.1359
[66] train_loss: 0.1393
[66] train_loss: 0.1367
0.87788987159729

Evaluating...Epoch: 66
Prec: 0.8106, Recall: 0.7728, F1: 0.7913

[67] train_loss: 0.1867
[67] train_loss: 0.1630
[67] train_loss: 0.1774
[67] train_loss: 0.1764
[67] train_loss: 0.1830
[67] train_loss: 0.1873
0.8863978385925293

Evaluating...Epoch: 67
Prec: 0.8110, Recall: 0.7748, F1: 0.7925

[68] train_loss: 0.1647
[68] train_loss: 0.1700
[68] train_loss: 0.1554
[68] train_loss: 0.1426
[68] train_loss: 0.1571
[68] train_loss: 0.1464
0.8804969787597656

Evaluating...Epoch: 68
Prec: 0.8144, Recall: 0.7566, F1: 0.7844

[69] train_loss: 0.1803
[69] train_loss: 0.1684
[69] train_loss: 0.1611
[69] train_loss: 0.1589
[69] train_loss: 0.1518
[69] train_loss: 0.1391
0.8883063793182373

Evaluating...Epoch: 69
Prec: 0.8157, Recall: 0.7809, F1: 0.7979
model saved to random1_layers1_15res/best_model.pt
New best model saved!

[70] train_loss: 0.2091
[70] train_loss: 0.1818
[70] train_loss: 0.1591
[70] train_loss: 0.1408
[70] train_loss: 0.1505
[70] train_loss: 0.1433
0.8812520503997803

Evaluating...Epoch: 70
Prec: 0.8137, Recall: 0.7444, F1: 0.7775

[71] train_loss: 0.1551
[71] train_loss: 0.1390
[71] train_loss: 0.1325
[71] train_loss: 0.1338
[71] train_loss: 0.1290
[71] train_loss: 0.1328
0.8826980590820312

Evaluating...Epoch: 71
Prec: 0.8047, Recall: 0.7606, F1: 0.7821

[72] train_loss: 0.1490
[72] train_loss: 0.1557
[72] train_loss: 0.1393
[72] train_loss: 0.1252
[72] train_loss: 0.1298
[72] train_loss: 0.1266
0.8850171566009521

Evaluating...Epoch: 72
Prec: 0.7941, Recall: 0.7667, F1: 0.7802

[73] train_loss: 0.1004
[73] train_loss: 0.1366
[73] train_loss: 0.1361
[73] train_loss: 0.1163
[73] train_loss: 0.1128
[73] train_loss: 0.1119
0.8749237060546875

Evaluating...Epoch: 73
Prec: 0.8074, Recall: 0.7485, F1: 0.7768

[74] train_loss: 0.1281
[74] train_loss: 0.1209
[74] train_loss: 0.1245
[74] train_loss: 0.1189
[74] train_loss: 0.1224
[74] train_loss: 0.1191
0.8815963268280029

Evaluating...Epoch: 74
Prec: 0.7918, Recall: 0.7485, F1: 0.7696

[75] train_loss: 0.0983
[75] train_loss: 0.0958
[75] train_loss: 0.0947
[75] train_loss: 0.0900
[75] train_loss: 0.0905
[75] train_loss: 0.0912
0.8770058155059814

Evaluating...Epoch: 75
Prec: 0.7570, Recall: 0.7647, F1: 0.7608

[76] train_loss: 0.1798
[76] train_loss: 0.1407
[76] train_loss: 0.1349
[76] train_loss: 0.1220
[76] train_loss: 0.1328
[76] train_loss: 0.1212
0.8854291439056396

Evaluating...Epoch: 76
Prec: 0.7970, Recall: 0.7566, F1: 0.7763

[77] train_loss: 0.1661
[77] train_loss: 0.1560
[77] train_loss: 0.1571
[77] train_loss: 0.1332
[77] train_loss: 0.1310
[77] train_loss: 0.1214
0.9150984287261963

Evaluating...Epoch: 77
Prec: 0.8086, Recall: 0.7627, F1: 0.7850

[78] train_loss: 0.0842
[78] train_loss: 0.0705
[78] train_loss: 0.0883
[78] train_loss: 0.1086
[78] train_loss: 0.1118
[78] train_loss: 0.1107
0.8798515796661377

Evaluating...Epoch: 78
Prec: 0.7983, Recall: 0.7627, F1: 0.7801

[79] train_loss: 0.0750
[79] train_loss: 0.0939
[79] train_loss: 0.1090
[79] train_loss: 0.1052
[79] train_loss: 0.1115
[79] train_loss: 0.1115
0.8625912666320801

Evaluating...Epoch: 79
Prec: 0.7966, Recall: 0.7627, F1: 0.7793

[80] train_loss: 0.1186
[80] train_loss: 0.1130
[80] train_loss: 0.1244
[80] train_loss: 0.1115
[80] train_loss: 0.1141
[80] train_loss: 0.1130
0.8717725276947021

Evaluating...Epoch: 80
Prec: 0.8034, Recall: 0.7708, F1: 0.7867

[81] train_loss: 0.1148
[81] train_loss: 0.0828
[81] train_loss: 0.1083
[81] train_loss: 0.1101
[81] train_loss: 0.1096
[81] train_loss: 0.1144
0.8787853717803955

Evaluating...Epoch: 81
Prec: 0.7967, Recall: 0.7789, F1: 0.7877

[82] train_loss: 0.1955
[82] train_loss: 0.1394
[82] train_loss: 0.1719
[82] train_loss: 0.1567
[82] train_loss: 0.1735
[82] train_loss: 0.1711
0.8812720775604248

Evaluating...Epoch: 82
Prec: 0.8013, Recall: 0.7769, F1: 0.7889

[83] train_loss: 0.1203
[83] train_loss: 0.1165
[83] train_loss: 0.1184
[83] train_loss: 0.1242
[83] train_loss: 0.1174
[83] train_loss: 0.1184
0.8837611675262451

Evaluating...Epoch: 83
Prec: 0.7874, Recall: 0.7890, F1: 0.7882

[84] train_loss: 0.1596
[84] train_loss: 0.1336
[84] train_loss: 0.1299
[84] train_loss: 0.1149
[84] train_loss: 0.1101
[84] train_loss: 0.1096
0.9302923679351807

Evaluating...Epoch: 84
Prec: 0.8071, Recall: 0.7809, F1: 0.7938

[85] train_loss: 0.1002
[85] train_loss: 0.1136
[85] train_loss: 0.1011
[85] train_loss: 0.0927
[85] train_loss: 0.0976
[85] train_loss: 0.0959
0.8825781345367432

Evaluating...Epoch: 85
Prec: 0.8143, Recall: 0.7647, F1: 0.7887

[86] train_loss: 0.0949
[86] train_loss: 0.1167
[86] train_loss: 0.1368
[86] train_loss: 0.1202
[86] train_loss: 0.1180
[86] train_loss: 0.1186
0.8816866874694824

Evaluating...Epoch: 86
Prec: 0.8072, Recall: 0.7728, F1: 0.7896

[87] train_loss: 0.0792
[87] train_loss: 0.0720
[87] train_loss: 0.0736
[87] train_loss: 0.0735
[87] train_loss: 0.0799
[87] train_loss: 0.0855
0.882814884185791

Evaluating...Epoch: 87
Prec: 0.7936, Recall: 0.8032, F1: 0.7984
model saved to random1_layers1_15res/best_model.pt
New best model saved!

[88] train_loss: 0.1040
[88] train_loss: 0.1049
[88] train_loss: 0.0965
[88] train_loss: 0.0879
[88] train_loss: 0.0880
[88] train_loss: 0.0953
0.8678643703460693

Evaluating...Epoch: 88
Prec: 0.8042, Recall: 0.7748, F1: 0.7893

[89] train_loss: 0.0888
[89] train_loss: 0.0778
[89] train_loss: 0.0725
[89] train_loss: 0.0764
[89] train_loss: 0.0783
[89] train_loss: 0.0798
0.8750829696655273

Evaluating...Epoch: 89
Prec: 0.8194, Recall: 0.7546, F1: 0.7856

[90] train_loss: 0.0985
[90] train_loss: 0.1069
[90] train_loss: 0.1420
[90] train_loss: 0.1336
[90] train_loss: 0.1347
[90] train_loss: 0.1269
0.8718752861022949

Evaluating...Epoch: 90
Prec: 0.8147, Recall: 0.7667, F1: 0.7900

[91] train_loss: 0.1470
[91] train_loss: 0.0934
[91] train_loss: 0.0977
[91] train_loss: 0.1012
[91] train_loss: 0.1038
[91] train_loss: 0.1007
0.9214799404144287

Evaluating...Epoch: 91
Prec: 0.8072, Recall: 0.7728, F1: 0.7896

[92] train_loss: 0.0627
[92] train_loss: 0.0803
[92] train_loss: 0.0695
[92] train_loss: 0.0709
[92] train_loss: 0.0792
[92] train_loss: 0.0787
0.8757281303405762

Evaluating...Epoch: 92
Prec: 0.8210, Recall: 0.7627, F1: 0.7907

[93] train_loss: 0.0819
[93] train_loss: 0.0668
[93] train_loss: 0.0655
[93] train_loss: 0.0607
[93] train_loss: 0.0640
[93] train_loss: 0.0698
0.8783078193664551

Evaluating...Epoch: 93
Prec: 0.8145, Recall: 0.7748, F1: 0.7942

[94] train_loss: 0.0773
[94] train_loss: 0.0734
[94] train_loss: 0.0852
[94] train_loss: 0.0768
[94] train_loss: 0.0754
[94] train_loss: 0.0728
0.8763267993927002

Evaluating...Epoch: 94
Prec: 0.8164, Recall: 0.7485, F1: 0.7810

[95] train_loss: 0.1364
[95] train_loss: 0.1286
[95] train_loss: 0.1154
[95] train_loss: 0.1038
[95] train_loss: 0.1151
[95] train_loss: 0.1028
0.8761758804321289

Evaluating...Epoch: 95
Prec: 0.7933, Recall: 0.7708, F1: 0.7819

[96] train_loss: 0.0735
[96] train_loss: 0.0705
[96] train_loss: 0.0961
[96] train_loss: 0.0803
[96] train_loss: 0.0742
[96] train_loss: 0.0790
0.8832743167877197

Evaluating...Epoch: 96
Prec: 0.8129, Recall: 0.7667, F1: 0.7891

[97] train_loss: 0.0770
[97] train_loss: 0.0798
[97] train_loss: 0.0818
[97] train_loss: 0.0688
[97] train_loss: 0.0841
[97] train_loss: 0.0818
0.8811852931976318

Evaluating...Epoch: 97
Prec: 0.7897, Recall: 0.7769, F1: 0.7832

[98] train_loss: 0.0762
[98] train_loss: 0.0869
[98] train_loss: 0.0878
[98] train_loss: 0.0869
[98] train_loss: 0.0812
[98] train_loss: 0.0791
0.9356334209442139

Evaluating...Epoch: 98
Prec: 0.7895, Recall: 0.7911, F1: 0.7903

[99] train_loss: 0.0693
[99] train_loss: 0.0731
[99] train_loss: 0.0745
[99] train_loss: 0.0639
[99] train_loss: 0.0602
[99] train_loss: 0.0682
0.8789019584655762

Evaluating...Epoch: 99
Prec: 0.8067, Recall: 0.7789, F1: 0.7926

[100] train_loss: 0.1484
[100] train_loss: 0.1184
[100] train_loss: 0.1171
[100] train_loss: 0.1019
[100] train_loss: 0.1001
[100] train_loss: 0.1146
0.8928613662719727

Evaluating...Epoch: 100
Prec: 0.7932, Recall: 0.7546, F1: 0.7734

Training ended with 100 epochs.
Final result:
Prec: 0.7936, Recall: 0.8032, F1: 0.7984
loading vocab and embedding matrix from ../data/15res
size of vocab: 2715
shape of loaded embedding matrix: (2715, 300)
Generating mappings
Loading data from ../data/15res with batch size 16...
68 batches created for ../data/15res/train.json
28 batches created for ../data/15res/test.json
Building model...
1272603
[1] train_loss: 11.8019
[1] train_loss: 9.0260
[1] train_loss: 7.9378
[1] train_loss: 7.1208
[1] train_loss: 6.6879
[1] train_loss: 6.2628
0.9838461875915527

Evaluating...Epoch: 1
Prec: 0.8857, Recall: 0.0629, F1: 0.1174
model saved to random1_layers2_15res/best_model.pt
New best model saved!

[2] train_loss: 4.8047
[2] train_loss: 4.4054
[2] train_loss: 4.3216
[2] train_loss: 4.1077
[2] train_loss: 4.0387
[2] train_loss: 3.8903
0.9528007507324219

Evaluating...Epoch: 2
Prec: 0.8604, Recall: 0.3874, F1: 0.5343
model saved to random1_layers2_15res/best_model.pt
New best model saved!

[3] train_loss: 4.0510
[3] train_loss: 3.6975
[3] train_loss: 3.6687
[3] train_loss: 3.4752
[3] train_loss: 3.4142
[3] train_loss: 3.2926
0.9589717388153076

Evaluating...Epoch: 3
Prec: 0.8596, Recall: 0.4970, F1: 0.6298
model saved to random1_layers2_15res/best_model.pt
New best model saved!

[4] train_loss: 3.9272
[4] train_loss: 3.4396
[4] train_loss: 3.4237
[4] train_loss: 3.2333
[4] train_loss: 3.2353
[4] train_loss: 3.1255
0.9682371616363525

Evaluating...Epoch: 4
Prec: 0.8746, Recall: 0.5233, F1: 0.6548
model saved to random1_layers2_15res/best_model.pt
New best model saved!

[5] train_loss: 3.5477
[5] train_loss: 3.1436
[5] train_loss: 3.1345
[5] train_loss: 2.9528
[5] train_loss: 2.9067
[5] train_loss: 2.8253
0.9441051483154297

Evaluating...Epoch: 5
Prec: 0.8280, Recall: 0.6247, F1: 0.7121
model saved to random1_layers2_15res/best_model.pt
New best model saved!

[6] train_loss: 3.2696
[6] train_loss: 2.9084
[6] train_loss: 2.9086
[6] train_loss: 2.7188
[6] train_loss: 2.6968
[6] train_loss: 2.6097
0.9612932205200195

Evaluating...Epoch: 6
Prec: 0.8259, Recall: 0.6349, F1: 0.7179
model saved to random1_layers2_15res/best_model.pt
New best model saved!

[7] train_loss: 2.8697
[7] train_loss: 2.5401
[7] train_loss: 2.6558
[7] train_loss: 2.4869
[7] train_loss: 2.4489
[7] train_loss: 2.3694
1.0063886642456055

Evaluating...Epoch: 7
Prec: 0.7866, Recall: 0.6653, F1: 0.7209
model saved to random1_layers2_15res/best_model.pt
New best model saved!

[8] train_loss: 2.4659
[8] train_loss: 2.2105
[8] train_loss: 2.3101
[8] train_loss: 2.1602
[8] train_loss: 2.1620
[8] train_loss: 2.1061
0.9595205783843994

Evaluating...Epoch: 8
Prec: 0.8156, Recall: 0.6369, F1: 0.7153

[9] train_loss: 2.4180
[9] train_loss: 2.2437
[9] train_loss: 2.2906
[9] train_loss: 2.1583
[9] train_loss: 2.1552
[9] train_loss: 2.1222
0.9550991058349609

Evaluating...Epoch: 9
Prec: 0.7862, Recall: 0.6714, F1: 0.7243
model saved to random1_layers2_15res/best_model.pt
New best model saved!

[10] train_loss: 2.1037
[10] train_loss: 2.0002
[10] train_loss: 2.0482
[10] train_loss: 1.9016
[10] train_loss: 1.8999
[10] train_loss: 1.8480
0.9561984539031982

Evaluating...Epoch: 10
Prec: 0.7731, Recall: 0.6775, F1: 0.7222

[11] train_loss: 2.1250
[11] train_loss: 1.8491
[11] train_loss: 1.8674
[11] train_loss: 1.7298
[11] train_loss: 1.7181
[11] train_loss: 1.6616
0.954887866973877

Evaluating...Epoch: 11
Prec: 0.7648, Recall: 0.7059, F1: 0.7342
model saved to random1_layers2_15res/best_model.pt
New best model saved!

[12] train_loss: 1.7514
[12] train_loss: 1.6930
[12] train_loss: 1.6984
[12] train_loss: 1.5796
[12] train_loss: 1.5773
[12] train_loss: 1.5620
0.9662020206451416

Evaluating...Epoch: 12
Prec: 0.7908, Recall: 0.6978, F1: 0.7414
model saved to random1_layers2_15res/best_model.pt
New best model saved!

[13] train_loss: 1.7452
[13] train_loss: 1.6089
[13] train_loss: 1.6324
[13] train_loss: 1.5085
[13] train_loss: 1.5227
[13] train_loss: 1.4941
0.9572591781616211

Evaluating...Epoch: 13
Prec: 0.7346, Recall: 0.7241, F1: 0.7293

[14] train_loss: 1.7228
[14] train_loss: 1.5215
[14] train_loss: 1.5120
[14] train_loss: 1.3770
[14] train_loss: 1.4301
[14] train_loss: 1.3711
1.0211057662963867

Evaluating...Epoch: 14
Prec: 0.7662, Recall: 0.7181, F1: 0.7414

[15] train_loss: 1.5773
[15] train_loss: 1.4074
[15] train_loss: 1.4827
[15] train_loss: 1.3863
[15] train_loss: 1.3761
[15] train_loss: 1.3244
0.9566032886505127

Evaluating...Epoch: 15
Prec: 0.7734, Recall: 0.7201, F1: 0.7458
model saved to random1_layers2_15res/best_model.pt
New best model saved!

[16] train_loss: 1.3355
[16] train_loss: 1.3115
[16] train_loss: 1.3553
[16] train_loss: 1.2077
[16] train_loss: 1.2143
[16] train_loss: 1.2206
0.9610135555267334

Evaluating...Epoch: 16
Prec: 0.8180, Recall: 0.7201, F1: 0.7659
model saved to random1_layers2_15res/best_model.pt
New best model saved!

[17] train_loss: 1.4393
[17] train_loss: 1.2752
[17] train_loss: 1.2987
[17] train_loss: 1.1549
[17] train_loss: 1.1907
[17] train_loss: 1.1518
0.967458963394165

Evaluating...Epoch: 17
Prec: 0.8088, Recall: 0.7120, F1: 0.7573

[18] train_loss: 1.1706
[18] train_loss: 1.0966
[18] train_loss: 1.1001
[18] train_loss: 0.9963
[18] train_loss: 1.0898
[18] train_loss: 1.0859
0.965954065322876

Evaluating...Epoch: 18
Prec: 0.8349, Recall: 0.7181, F1: 0.7721
model saved to random1_layers2_15res/best_model.pt
New best model saved!

[19] train_loss: 1.2217
[19] train_loss: 1.1423
[19] train_loss: 1.1435
[19] train_loss: 1.0878
[19] train_loss: 1.0553
[19] train_loss: 1.0389
0.9638078212738037

Evaluating...Epoch: 19
Prec: 0.7983, Recall: 0.7627, F1: 0.7801
model saved to random1_layers2_15res/best_model.pt
New best model saved!

[20] train_loss: 1.1211
[20] train_loss: 0.9793
[20] train_loss: 1.0855
[20] train_loss: 0.9880
[20] train_loss: 0.9941
[20] train_loss: 0.9412
0.9609506130218506

Evaluating...Epoch: 20
Prec: 0.7953, Recall: 0.7485, F1: 0.7712

[21] train_loss: 1.0463
[21] train_loss: 0.9946
[21] train_loss: 1.0113
[21] train_loss: 0.9060
[21] train_loss: 0.9098
[21] train_loss: 0.8907
0.9594461917877197

Evaluating...Epoch: 21
Prec: 0.8203, Recall: 0.7221, F1: 0.7681

[22] train_loss: 1.0329
[22] train_loss: 0.9875
[22] train_loss: 0.9648
[22] train_loss: 0.8847
[22] train_loss: 0.9182
[22] train_loss: 0.8834
0.9628262519836426

Evaluating...Epoch: 22
Prec: 0.7899, Recall: 0.7323, F1: 0.7600

[23] train_loss: 0.8755
[23] train_loss: 0.8552
[23] train_loss: 0.9003
[23] train_loss: 0.8428
[23] train_loss: 0.8519
[23] train_loss: 0.8244
0.9524424076080322

Evaluating...Epoch: 23
Prec: 0.8081, Recall: 0.7688, F1: 0.7879
model saved to random1_layers2_15res/best_model.pt
New best model saved!

[24] train_loss: 1.1104
[24] train_loss: 0.9461
[24] train_loss: 0.9337
[24] train_loss: 0.9045
[24] train_loss: 0.9105
[24] train_loss: 0.9060
0.9565105438232422

Evaluating...Epoch: 24
Prec: 0.8022, Recall: 0.7404, F1: 0.7700

[25] train_loss: 0.9437
[25] train_loss: 0.8274
[25] train_loss: 0.8083
[25] train_loss: 0.7335
[25] train_loss: 0.7577
[25] train_loss: 0.7713
0.9649393558502197

Evaluating...Epoch: 25
Prec: 0.8337, Recall: 0.7424, F1: 0.7854

[26] train_loss: 0.8435
[26] train_loss: 0.7349
[26] train_loss: 0.7349
[26] train_loss: 0.6845
[26] train_loss: 0.7135
[26] train_loss: 0.7197
0.9568326473236084

Evaluating...Epoch: 26
Prec: 0.8047, Recall: 0.7688, F1: 0.7863

[27] train_loss: 0.7263
[27] train_loss: 0.7146
[27] train_loss: 0.7288
[27] train_loss: 0.6490
[27] train_loss: 0.6572
[27] train_loss: 0.6277
0.9612119197845459

Evaluating...Epoch: 27
Prec: 0.8105, Recall: 0.7546, F1: 0.7815

[28] train_loss: 0.7641
[28] train_loss: 0.6814
[28] train_loss: 0.6874
[28] train_loss: 0.6578
[28] train_loss: 0.6821
[28] train_loss: 0.6612
0.9579417705535889

Evaluating...Epoch: 28
Prec: 0.8074, Recall: 0.7566, F1: 0.7812

[29] train_loss: 0.6159
[29] train_loss: 0.7046
[29] train_loss: 0.7102
[29] train_loss: 0.6609
[29] train_loss: 0.7106
[29] train_loss: 0.6908
0.9557890892028809

Evaluating...Epoch: 29
Prec: 0.8056, Recall: 0.7647, F1: 0.7846

[30] train_loss: 0.7338
[30] train_loss: 0.6359
[30] train_loss: 0.6079
[30] train_loss: 0.5711
[30] train_loss: 0.6222
[30] train_loss: 0.6071
0.9563419818878174

Evaluating...Epoch: 30
Prec: 0.8196, Recall: 0.7647, F1: 0.7912
model saved to random1_layers2_15res/best_model.pt
New best model saved!

[31] train_loss: 0.7724
[31] train_loss: 0.6512
[31] train_loss: 0.6184
[31] train_loss: 0.5831
[31] train_loss: 0.5701
[31] train_loss: 0.5540
0.9545993804931641

Evaluating...Epoch: 31
Prec: 0.8025, Recall: 0.7667, F1: 0.7842

[32] train_loss: 0.6444
[32] train_loss: 0.5900
[32] train_loss: 0.5683
[32] train_loss: 0.4965
[32] train_loss: 0.5276
[32] train_loss: 0.5235
0.9606294631958008

Evaluating...Epoch: 32
Prec: 0.8262, Recall: 0.7424, F1: 0.7821

[33] train_loss: 0.8123
[33] train_loss: 0.5985
[33] train_loss: 0.5623
[33] train_loss: 0.5391
[33] train_loss: 0.5532
[33] train_loss: 0.5175
0.9397823810577393

Evaluating...Epoch: 33
Prec: 0.8054, Recall: 0.7809, F1: 0.7930
model saved to random1_layers2_15res/best_model.pt
New best model saved!

[34] train_loss: 0.4716
[34] train_loss: 0.4567
[34] train_loss: 0.5034
[34] train_loss: 0.4764
[34] train_loss: 0.4683
[34] train_loss: 0.4901
0.960076093673706

Evaluating...Epoch: 34
Prec: 0.8197, Recall: 0.7748, F1: 0.7967
model saved to random1_layers2_15res/best_model.pt
New best model saved!

[35] train_loss: 0.5401
[35] train_loss: 0.5023
[35] train_loss: 0.5035
[35] train_loss: 0.4613
[35] train_loss: 0.4552
[35] train_loss: 0.4504
0.9692814350128174

Evaluating...Epoch: 35
Prec: 0.8074, Recall: 0.7566, F1: 0.7812

[36] train_loss: 0.4591
[36] train_loss: 0.4611
[36] train_loss: 0.4406
[36] train_loss: 0.4195
[36] train_loss: 0.4307
[36] train_loss: 0.4183
1.0125269889831543

Evaluating...Epoch: 36
Prec: 0.8174, Recall: 0.7627, F1: 0.7891

[37] train_loss: 0.5085
[37] train_loss: 0.4382
[37] train_loss: 0.4413
[37] train_loss: 0.3894
[37] train_loss: 0.4034
[37] train_loss: 0.3973
0.9648082256317139

Evaluating...Epoch: 37
Prec: 0.7757, Recall: 0.7647, F1: 0.7702

[38] train_loss: 0.4685
[38] train_loss: 0.4191
[38] train_loss: 0.4224
[38] train_loss: 0.4151
[38] train_loss: 0.4309
[38] train_loss: 0.4054
0.9524734020233154

Evaluating...Epoch: 38
Prec: 0.8129, Recall: 0.7667, F1: 0.7891

[39] train_loss: 0.2992
[39] train_loss: 0.3121
[39] train_loss: 0.3637
[39] train_loss: 0.3370
[39] train_loss: 0.3460
[39] train_loss: 0.3448
0.9604482650756836

Evaluating...Epoch: 39
Prec: 0.8470, Recall: 0.7525, F1: 0.7970
model saved to random1_layers2_15res/best_model.pt
New best model saved!

[40] train_loss: 0.5546
[40] train_loss: 0.4215
[40] train_loss: 0.4707
[40] train_loss: 0.4464
[40] train_loss: 0.5457
[40] train_loss: 0.5357
0.9486713409423828

Evaluating...Epoch: 40
Prec: 0.8188, Recall: 0.7606, F1: 0.7886

[41] train_loss: 0.3514
[41] train_loss: 0.3432
[41] train_loss: 0.3666
[41] train_loss: 0.3650
[41] train_loss: 0.4206
[41] train_loss: 0.4378
0.9516799449920654

Evaluating...Epoch: 41
Prec: 0.7796, Recall: 0.7748, F1: 0.7772

[42] train_loss: 0.5439
[42] train_loss: 0.4431
[42] train_loss: 0.4364
[42] train_loss: 0.3869
[42] train_loss: 0.3927
[42] train_loss: 0.4007
1.0003290176391602

Evaluating...Epoch: 42
Prec: 0.8021, Recall: 0.7728, F1: 0.7872

[43] train_loss: 0.3058
[43] train_loss: 0.3292
[43] train_loss: 0.3536
[43] train_loss: 0.3200
[43] train_loss: 0.3227
[43] train_loss: 0.3178
0.9446561336517334

Evaluating...Epoch: 43
Prec: 0.8152, Recall: 0.7606, F1: 0.7870

[44] train_loss: 0.3627
[44] train_loss: 0.3287
[44] train_loss: 0.3451
[44] train_loss: 0.3518
[44] train_loss: 0.3373
[44] train_loss: 0.3230
0.9722182750701904

Evaluating...Epoch: 44
Prec: 0.8047, Recall: 0.7688, F1: 0.7863

[45] train_loss: 0.3926
[45] train_loss: 0.3724
[45] train_loss: 0.4091
[45] train_loss: 0.3683
[45] train_loss: 0.3750
[45] train_loss: 0.3442
0.9469969272613525

Evaluating...Epoch: 45
Prec: 0.8359, Recall: 0.7647, F1: 0.7987
model saved to random1_layers2_15res/best_model.pt
New best model saved!

[46] train_loss: 0.3877
[46] train_loss: 0.2906
[46] train_loss: 0.2601
[46] train_loss: 0.2476
[46] train_loss: 0.2738
[46] train_loss: 0.2718
0.9584596157073975

Evaluating...Epoch: 46
Prec: 0.8162, Recall: 0.7566, F1: 0.7853

[47] train_loss: 0.3313
[47] train_loss: 0.2952
[47] train_loss: 0.2974
[47] train_loss: 0.2739
[47] train_loss: 0.2802
[47] train_loss: 0.2983
0.9624741077423096

Evaluating...Epoch: 47
Prec: 0.8021, Recall: 0.7647, F1: 0.7830

[48] train_loss: 0.3628
[48] train_loss: 0.3312
[48] train_loss: 0.3014
[48] train_loss: 0.2793
[48] train_loss: 0.2979
[48] train_loss: 0.2943
0.9599721431732178

Evaluating...Epoch: 48
Prec: 0.8188, Recall: 0.7606, F1: 0.7886

[49] train_loss: 0.2644
[49] train_loss: 0.2368
[49] train_loss: 0.2445
[49] train_loss: 0.2152
[49] train_loss: 0.2190
[49] train_loss: 0.2191
0.9607172012329102

Evaluating...Epoch: 49
Prec: 0.7958, Recall: 0.7667, F1: 0.7810

[50] train_loss: 0.2615
[50] train_loss: 0.2899
[50] train_loss: 0.2668
[50] train_loss: 0.2433
[50] train_loss: 0.2509
[50] train_loss: 0.2409
0.9561681747436523

Evaluating...Epoch: 50
Prec: 0.7901, Recall: 0.7789, F1: 0.7845

[51] train_loss: 0.3321
[51] train_loss: 0.2618
[51] train_loss: 0.2591
[51] train_loss: 0.2492
[51] train_loss: 0.2980
[51] train_loss: 0.2855
0.9565701484680176

Evaluating...Epoch: 51
Prec: 0.8259, Recall: 0.7505, F1: 0.7864

[52] train_loss: 0.2329
[52] train_loss: 0.2053
[52] train_loss: 0.2048
[52] train_loss: 0.2049
[52] train_loss: 0.2057
[52] train_loss: 0.1979
0.9653666019439697

Evaluating...Epoch: 52
Prec: 0.8285, Recall: 0.7546, F1: 0.7898

[53] train_loss: 0.2089
[53] train_loss: 0.1927
[53] train_loss: 0.2284
[53] train_loss: 0.2263
[53] train_loss: 0.2393
[53] train_loss: 0.2291
0.9513883590698242

Evaluating...Epoch: 53
Prec: 0.8096, Recall: 0.7505, F1: 0.7789

[54] train_loss: 0.1818
[54] train_loss: 0.1548
[54] train_loss: 0.2214
[54] train_loss: 0.1905
[54] train_loss: 0.1910
[54] train_loss: 0.1909
0.970177412033081

Evaluating...Epoch: 54
Prec: 0.7921, Recall: 0.7728, F1: 0.7823

[55] train_loss: 0.1976
[55] train_loss: 0.2192
[55] train_loss: 0.2284
[55] train_loss: 0.2029
[55] train_loss: 0.2157
[55] train_loss: 0.1979
0.9573328495025635

Evaluating...Epoch: 55
Prec: 0.8207, Recall: 0.7708, F1: 0.7950

[56] train_loss: 0.2835
[56] train_loss: 0.2326
[56] train_loss: 0.2466
[56] train_loss: 0.2425
[56] train_loss: 0.2367
[56] train_loss: 0.2196
0.9633359909057617

Evaluating...Epoch: 56
Prec: 0.8164, Recall: 0.7485, F1: 0.7810

[57] train_loss: 0.2197
[57] train_loss: 0.1945
[57] train_loss: 0.1878
[57] train_loss: 0.1772
[57] train_loss: 0.1757
[57] train_loss: 0.1773
0.959338903427124

Evaluating...Epoch: 57
Prec: 0.8130, Recall: 0.7586, F1: 0.7849

[58] train_loss: 0.2633
[58] train_loss: 0.2626
[58] train_loss: 0.2392
[58] train_loss: 0.2065
[58] train_loss: 0.2061
[58] train_loss: 0.2083
0.9562764167785645

Evaluating...Epoch: 58
Prec: 0.8125, Recall: 0.7647, F1: 0.7879

[59] train_loss: 0.3263
[59] train_loss: 0.2350
[59] train_loss: 0.2342
[59] train_loss: 0.2187
[59] train_loss: 0.2384
[59] train_loss: 0.2315
0.9670844078063965

Evaluating...Epoch: 59
Prec: 0.8345, Recall: 0.7566, F1: 0.7936

[60] train_loss: 0.2818
[60] train_loss: 0.2410
[60] train_loss: 0.2032
[60] train_loss: 0.2093
[60] train_loss: 0.2094
[60] train_loss: 0.2351
0.9585695266723633

Evaluating...Epoch: 60
Prec: 0.7987, Recall: 0.7647, F1: 0.7813

[61] train_loss: 0.2986
[61] train_loss: 0.2436
[61] train_loss: 0.2024
[61] train_loss: 0.1829
[61] train_loss: 0.1863
[61] train_loss: 0.1819
0.9618213176727295

Evaluating...Epoch: 61
Prec: 0.8151, Recall: 0.7688, F1: 0.7912

[62] train_loss: 0.1045
[62] train_loss: 0.1710
[62] train_loss: 0.1692
[62] train_loss: 0.1887
[62] train_loss: 0.1831
[62] train_loss: 0.1843
0.9578075408935547

Evaluating...Epoch: 62
Prec: 0.8326, Recall: 0.7566, F1: 0.7928

[63] train_loss: 0.2786
[63] train_loss: 0.2253
[63] train_loss: 0.2227
[63] train_loss: 0.2032
[63] train_loss: 0.2325
[63] train_loss: 0.2210
0.9499807357788086

Evaluating...Epoch: 63
Prec: 0.8242, Recall: 0.7606, F1: 0.7911

[64] train_loss: 0.1360
[64] train_loss: 0.1480
[64] train_loss: 0.1741
[64] train_loss: 0.1590
[64] train_loss: 0.1687
[64] train_loss: 0.1643
0.9997315406799316

Evaluating...Epoch: 64
Prec: 0.8425, Recall: 0.7485, F1: 0.7927

[65] train_loss: 0.1406
[65] train_loss: 0.1705
[65] train_loss: 0.1789
[65] train_loss: 0.1684
[65] train_loss: 0.1700
[65] train_loss: 0.1728
0.9466779232025146

Evaluating...Epoch: 65
Prec: 0.8201, Recall: 0.7769, F1: 0.7979

Training ended with 66 epochs.
Final result:
Prec: 0.8359, Recall: 0.7647, F1: 0.7987
loading vocab and embedding matrix from ../data/15res
size of vocab: 2715
shape of loaded embedding matrix: (2715, 300)
Generating mappings
Loading data from ../data/15res with batch size 16...
68 batches created for ../data/15res/train.json
28 batches created for ../data/15res/test.json
Building model...
1312803
[1] train_loss: 11.6891
[1] train_loss: 8.8479
[1] train_loss: 7.8761
[1] train_loss: 7.0698
[1] train_loss: 6.6193
[1] train_loss: 6.1996
1.0224337577819824

Evaluating...Epoch: 1
Prec: 0.8941, Recall: 0.1542, F1: 0.2630
model saved to random1_layers3_15res/best_model.pt
New best model saved!

[2] train_loss: 4.7508
[2] train_loss: 4.3259
[2] train_loss: 4.2598
[2] train_loss: 3.9988
[2] train_loss: 3.9092
[2] train_loss: 3.7774
1.0040946006774902

Evaluating...Epoch: 2
Prec: 0.7208, Recall: 0.6126, F1: 0.6623
model saved to random1_layers3_15res/best_model.pt
New best model saved!

[3] train_loss: 3.9977
[3] train_loss: 3.5169
[3] train_loss: 3.4893
[3] train_loss: 3.3140
[3] train_loss: 3.2917
[3] train_loss: 3.2071
1.0125789642333984

Evaluating...Epoch: 3
Prec: 0.7130, Recall: 0.6552, F1: 0.6829
model saved to random1_layers3_15res/best_model.pt
New best model saved!

[4] train_loss: 3.7661
[4] train_loss: 3.3781
[4] train_loss: 3.3700
[4] train_loss: 3.1703
[4] train_loss: 3.1125
[4] train_loss: 3.0180
1.001760721206665

Evaluating...Epoch: 4
Prec: 0.7700, Recall: 0.6450, F1: 0.7020
model saved to random1_layers3_15res/best_model.pt
New best model saved!

[5] train_loss: 3.4057
[5] train_loss: 2.9880
[5] train_loss: 3.0966
[5] train_loss: 2.9145
[5] train_loss: 2.8867
[5] train_loss: 2.7949
1.006791591644287

Evaluating...Epoch: 5
Prec: 0.7472, Recall: 0.6836, F1: 0.7140
model saved to random1_layers3_15res/best_model.pt
New best model saved!

[6] train_loss: 3.0244
[6] train_loss: 2.6497
[6] train_loss: 2.7415
[6] train_loss: 2.6083
[6] train_loss: 2.5807
[6] train_loss: 2.5120
1.0110201835632324

Evaluating...Epoch: 6
Prec: 0.7904, Recall: 0.6653, F1: 0.7225
model saved to random1_layers3_15res/best_model.pt
New best model saved!

[7] train_loss: 2.8093
[7] train_loss: 2.5731
[7] train_loss: 2.5509
[7] train_loss: 2.4163
[7] train_loss: 2.4043
[7] train_loss: 2.3338
1.0645666122436523

Evaluating...Epoch: 7
Prec: 0.7415, Recall: 0.7099, F1: 0.7254
model saved to random1_layers3_15res/best_model.pt
New best model saved!

[8] train_loss: 2.6003
[8] train_loss: 2.3331
[8] train_loss: 2.3931
[8] train_loss: 2.2280
[8] train_loss: 2.2159
[8] train_loss: 2.1757
1.005293607711792

Evaluating...Epoch: 8
Prec: 0.7511, Recall: 0.6673, F1: 0.7068

[9] train_loss: 2.4407
[9] train_loss: 2.1960
[9] train_loss: 2.2315
[9] train_loss: 2.0882
[9] train_loss: 2.0770
[9] train_loss: 2.0155
1.0051555633544922

Evaluating...Epoch: 9
Prec: 0.7838, Recall: 0.6694, F1: 0.7221

[10] train_loss: 2.4411
[10] train_loss: 2.2142
[10] train_loss: 2.2266
[10] train_loss: 2.0797
[10] train_loss: 2.0724
[10] train_loss: 2.0157
1.0002450942993164

Evaluating...Epoch: 10
Prec: 0.7799, Recall: 0.6613, F1: 0.7157

[11] train_loss: 2.2827
[11] train_loss: 2.0194
[11] train_loss: 2.0062
[11] train_loss: 1.8479
[11] train_loss: 1.8463
[11] train_loss: 1.7916
1.0134539604187012

Evaluating...Epoch: 11
Prec: 0.7806, Recall: 0.6856, F1: 0.7300
model saved to random1_layers3_15res/best_model.pt
New best model saved!

[12] train_loss: 2.1602
[12] train_loss: 1.9062
[12] train_loss: 1.8844
[12] train_loss: 1.7278
[12] train_loss: 1.7530
[12] train_loss: 1.6921
1.0037384033203125

Evaluating...Epoch: 12
Prec: 0.7587, Recall: 0.7079, F1: 0.7324
model saved to random1_layers3_15res/best_model.pt
New best model saved!

[13] train_loss: 1.8624
[13] train_loss: 1.6603
[13] train_loss: 1.6913
[13] train_loss: 1.5610
[13] train_loss: 1.5726
[13] train_loss: 1.5197
1.002415418624878

Evaluating...Epoch: 13
Prec: 0.7569, Recall: 0.7201, F1: 0.7380
model saved to random1_layers3_15res/best_model.pt
New best model saved!

[14] train_loss: 1.8662
[14] train_loss: 1.5892
[14] train_loss: 1.5584
[14] train_loss: 1.4583
[14] train_loss: 1.4391
[14] train_loss: 1.4352
1.0656824111938477

Evaluating...Epoch: 14
Prec: 0.7531, Recall: 0.7485, F1: 0.7508
model saved to random1_layers3_15res/best_model.pt
New best model saved!

[15] train_loss: 1.6536
[15] train_loss: 1.5303
[15] train_loss: 1.5005
[15] train_loss: 1.3538
[15] train_loss: 1.3897
[15] train_loss: 1.3545
1.0079233646392822

Evaluating...Epoch: 15
Prec: 0.7568, Recall: 0.7383, F1: 0.7474

[16] train_loss: 1.6137
[16] train_loss: 1.4363
[16] train_loss: 1.4137
[16] train_loss: 1.2761
[16] train_loss: 1.3168
[16] train_loss: 1.2693
1.0089504718780518

Evaluating...Epoch: 16
Prec: 0.7495, Recall: 0.7586, F1: 0.7540
model saved to random1_layers3_15res/best_model.pt
New best model saved!

[17] train_loss: 1.4497
[17] train_loss: 1.3291
[17] train_loss: 1.3277
[17] train_loss: 1.1886
[17] train_loss: 1.1916
[17] train_loss: 1.1654
1.0112500190734863

Evaluating...Epoch: 17
Prec: 0.7729, Recall: 0.7525, F1: 0.7626
model saved to random1_layers3_15res/best_model.pt
New best model saved!

[18] train_loss: 1.2461
[18] train_loss: 1.0607
[18] train_loss: 1.0965
[18] train_loss: 1.0363
[18] train_loss: 1.0949
[18] train_loss: 1.0822
1.0036332607269287

Evaluating...Epoch: 18
Prec: 0.7870, Recall: 0.7343, F1: 0.7597

[19] train_loss: 1.3303
[19] train_loss: 1.1557
[19] train_loss: 1.1717
[19] train_loss: 1.0750
[19] train_loss: 1.1090
[19] train_loss: 1.0671
1.0054326057434082

Evaluating...Epoch: 19
Prec: 0.7717, Recall: 0.7404, F1: 0.7557

[20] train_loss: 1.1509
[20] train_loss: 1.0235
[20] train_loss: 0.9600
[20] train_loss: 0.8868
[20] train_loss: 0.9099
[20] train_loss: 0.8592
0.9936072826385498

Evaluating...Epoch: 20
Prec: 0.7814, Recall: 0.7688, F1: 0.7751
model saved to random1_layers3_15res/best_model.pt
New best model saved!

[21] train_loss: 1.1234
[21] train_loss: 0.9404
[21] train_loss: 0.9873
[21] train_loss: 0.9152
[21] train_loss: 0.9485
[21] train_loss: 0.9392
1.0608136653900146

Evaluating...Epoch: 21
Prec: 0.7821, Recall: 0.7424, F1: 0.7617

[22] train_loss: 1.0603
[22] train_loss: 0.9943
[22] train_loss: 0.9801
[22] train_loss: 0.9007
[22] train_loss: 0.9404
[22] train_loss: 0.8932
1.0105888843536377

Evaluating...Epoch: 22
Prec: 0.8075, Recall: 0.7404, F1: 0.7725

[23] train_loss: 0.9615
[23] train_loss: 0.8566
[23] train_loss: 0.8676
[23] train_loss: 0.7996
[23] train_loss: 0.7983
[23] train_loss: 0.7703
1.0076982975006104

Evaluating...Epoch: 23
Prec: 0.7996, Recall: 0.7525, F1: 0.7753
model saved to random1_layers3_15res/best_model.pt
New best model saved!

[24] train_loss: 0.8034
[24] train_loss: 0.8276
[24] train_loss: 0.7762
[24] train_loss: 0.7597
[24] train_loss: 0.7766
[24] train_loss: 0.7555
1.0061330795288086

Evaluating...Epoch: 24
Prec: 0.8148, Recall: 0.7586, F1: 0.7857
model saved to random1_layers3_15res/best_model.pt
New best model saved!

[25] train_loss: 1.0727
[25] train_loss: 0.9089
[25] train_loss: 0.8622
[25] train_loss: 0.7672
[25] train_loss: 0.7835
[25] train_loss: 0.7579
1.018296718597412

Evaluating...Epoch: 25
Prec: 0.7791, Recall: 0.7870, F1: 0.7830

[26] train_loss: 0.8076
[26] train_loss: 0.7353
[26] train_loss: 0.7208
[26] train_loss: 0.6983
[26] train_loss: 0.7311
[26] train_loss: 0.7217
0.9933018684387207

Evaluating...Epoch: 26
Prec: 0.7796, Recall: 0.7748, F1: 0.7772

[27] train_loss: 0.7446
[27] train_loss: 0.6723
[27] train_loss: 0.7499
[27] train_loss: 0.7010
[27] train_loss: 0.7183
[27] train_loss: 0.6918
0.9942562580108643

Evaluating...Epoch: 27
Prec: 0.7796, Recall: 0.7748, F1: 0.7772

[28] train_loss: 0.6993
[28] train_loss: 0.7151
[28] train_loss: 0.6848
[28] train_loss: 0.6040
[28] train_loss: 0.6327
[28] train_loss: 0.6027
0.9973545074462891

Evaluating...Epoch: 28
Prec: 0.7854, Recall: 0.7647, F1: 0.7749

[29] train_loss: 0.7135
[29] train_loss: 0.6834
[29] train_loss: 0.6599
[29] train_loss: 0.5972
[29] train_loss: 0.6203
[29] train_loss: 0.6026
0.9925532341003418

Evaluating...Epoch: 29
Prec: 0.8337, Recall: 0.7525, F1: 0.7910
model saved to random1_layers3_15res/best_model.pt
New best model saved!

[30] train_loss: 0.6452
[30] train_loss: 0.5524
[30] train_loss: 0.5871
[30] train_loss: 0.5435
[30] train_loss: 0.5661
[30] train_loss: 0.5528
1.0138084888458252

Evaluating...Epoch: 30
Prec: 0.7899, Recall: 0.7627, F1: 0.7761

[31] train_loss: 0.5901
[31] train_loss: 0.5456
[31] train_loss: 0.5674
[31] train_loss: 0.5411
[31] train_loss: 0.5251
[31] train_loss: 0.5105
0.9997859001159668

Evaluating...Epoch: 31
Prec: 0.8084, Recall: 0.7789, F1: 0.7934
model saved to random1_layers3_15res/best_model.pt
New best model saved!

[32] train_loss: 0.5681
[32] train_loss: 0.5066
[32] train_loss: 0.5337
[32] train_loss: 0.4939
[32] train_loss: 0.5017
[32] train_loss: 0.4855
1.009986400604248

Evaluating...Epoch: 32
Prec: 0.8009, Recall: 0.7586, F1: 0.7792

[33] train_loss: 0.5950
[33] train_loss: 0.5475
[33] train_loss: 0.5958
[33] train_loss: 0.5434
[33] train_loss: 0.5312
[33] train_loss: 0.5241
1.0121736526489258

Evaluating...Epoch: 33
Prec: 0.8289, Recall: 0.7667, F1: 0.7966
model saved to random1_layers3_15res/best_model.pt
New best model saved!

[34] train_loss: 0.4771
[34] train_loss: 0.5009
[34] train_loss: 0.5191
[34] train_loss: 0.4701
[34] train_loss: 0.5031
[34] train_loss: 0.4980
0.9998800754547119

Evaluating...Epoch: 34
Prec: 0.8345, Recall: 0.7465, F1: 0.7880

[35] train_loss: 0.6596
[35] train_loss: 0.5635
[35] train_loss: 0.5415
[35] train_loss: 0.4946
[35] train_loss: 0.5123
[35] train_loss: 0.4956
0.9991035461425781

Evaluating...Epoch: 35
Prec: 0.8147, Recall: 0.7850, F1: 0.7996
model saved to random1_layers3_15res/best_model.pt
New best model saved!

[36] train_loss: 0.5922
[36] train_loss: 0.5311
[36] train_loss: 0.5092
[36] train_loss: 0.4500
[36] train_loss: 0.4758
[36] train_loss: 0.4535
1.0082221031188965

Evaluating...Epoch: 36
Prec: 0.8058, Recall: 0.7911, F1: 0.7984

[37] train_loss: 0.5847
[37] train_loss: 0.4779
[37] train_loss: 0.4551
[37] train_loss: 0.4226
[37] train_loss: 0.4502
[37] train_loss: 0.4388
1.0072908401489258

Evaluating...Epoch: 37
Prec: 0.8269, Recall: 0.7850, F1: 0.8054
model saved to random1_layers3_15res/best_model.pt
New best model saved!

[38] train_loss: 0.4411
[38] train_loss: 0.4349
[38] train_loss: 0.4503
[38] train_loss: 0.4118
[38] train_loss: 0.4286
[38] train_loss: 0.4145
0.9987592697143555

Evaluating...Epoch: 38
Prec: 0.7691, Recall: 0.7972, F1: 0.7829

[39] train_loss: 0.4387
[39] train_loss: 0.4479
[39] train_loss: 0.4304
[39] train_loss: 0.4114
[39] train_loss: 0.4250
[39] train_loss: 0.4103
1.0038328170776367

Evaluating...Epoch: 39
Prec: 0.8470, Recall: 0.7525, F1: 0.7970

[40] train_loss: 0.4102
[40] train_loss: 0.4046
[40] train_loss: 0.4203
[40] train_loss: 0.4172
[40] train_loss: 0.4506
[40] train_loss: 0.4259
1.003936529159546

Evaluating...Epoch: 40
Prec: 0.8289, Recall: 0.7566, F1: 0.7911

[41] train_loss: 0.3659
[41] train_loss: 0.3310
[41] train_loss: 0.3565
[41] train_loss: 0.3423
[41] train_loss: 0.3368
[41] train_loss: 0.3553
1.0080468654632568

Evaluating...Epoch: 41
Prec: 0.8199, Recall: 0.7850, F1: 0.8021

[42] train_loss: 0.3670
[42] train_loss: 0.3087
[42] train_loss: 0.3972
[42] train_loss: 0.3866
[42] train_loss: 0.3781
[42] train_loss: 0.3612
0.9996287822723389

Evaluating...Epoch: 42
Prec: 0.8366, Recall: 0.7688, F1: 0.8013

[43] train_loss: 0.4367
[43] train_loss: 0.3523
[43] train_loss: 0.3417
[43] train_loss: 0.3099
[43] train_loss: 0.3222
[43] train_loss: 0.3291
1.0083820819854736

Evaluating...Epoch: 43
Prec: 0.8308, Recall: 0.7769, F1: 0.8029

[44] train_loss: 0.3371
[44] train_loss: 0.2928
[44] train_loss: 0.3296
[44] train_loss: 0.2952
[44] train_loss: 0.3061
[44] train_loss: 0.3042
0.9975676536560059

Evaluating...Epoch: 44
Prec: 0.8004, Recall: 0.7728, F1: 0.7864

[45] train_loss: 0.3658
[45] train_loss: 0.3347
[45] train_loss: 0.3561
[45] train_loss: 0.3270
[45] train_loss: 0.3460
[45] train_loss: 0.3226
1.0108513832092285

Evaluating...Epoch: 45
Prec: 0.8004, Recall: 0.7809, F1: 0.7906

[46] train_loss: 0.3035
[46] train_loss: 0.3208
[46] train_loss: 0.2959
[46] train_loss: 0.2879
[46] train_loss: 0.2940
[46] train_loss: 0.2673
1.00640869140625

Evaluating...Epoch: 46
Prec: 0.8118, Recall: 0.7789, F1: 0.7950

[47] train_loss: 0.4073
[47] train_loss: 0.3404
[47] train_loss: 0.3186
[47] train_loss: 0.2912
[47] train_loss: 0.3055
[47] train_loss: 0.2839
0.9999794960021973

Evaluating...Epoch: 47
Prec: 0.8246, Recall: 0.7627, F1: 0.7924

[48] train_loss: 0.2902
[48] train_loss: 0.3338
[48] train_loss: 0.3019
[48] train_loss: 0.2765
[48] train_loss: 0.2839
[48] train_loss: 0.2878
1.039461374282837

Evaluating...Epoch: 48
Prec: 0.8400, Recall: 0.7667, F1: 0.8017

[49] train_loss: 0.3174
[49] train_loss: 0.2978
[49] train_loss: 0.2966
[49] train_loss: 0.2757
[49] train_loss: 0.3016
[49] train_loss: 0.3117
0.9965758323669434

Evaluating...Epoch: 49
Prec: 0.7821, Recall: 0.7789, F1: 0.7805

[50] train_loss: 0.3292
[50] train_loss: 0.2915
[50] train_loss: 0.2884
[50] train_loss: 0.2531
[50] train_loss: 0.2589
[50] train_loss: 0.2445
1.0070362091064453

Evaluating...Epoch: 50
Prec: 0.8280, Recall: 0.7809, F1: 0.8038

[51] train_loss: 0.2562
[51] train_loss: 0.2677
[51] train_loss: 0.2515
[51] train_loss: 0.2924
[51] train_loss: 0.3039
[51] train_loss: 0.2876
0.9918379783630371

Evaluating...Epoch: 51
Prec: 0.8217, Recall: 0.7667, F1: 0.7933

[52] train_loss: 0.3005
[52] train_loss: 0.2441
[52] train_loss: 0.2630
[52] train_loss: 0.2447
[52] train_loss: 0.2380
[52] train_loss: 0.2234
1.0049598217010498

Evaluating...Epoch: 52
Prec: 0.8259, Recall: 0.7890, F1: 0.8071
model saved to random1_layers3_15res/best_model.pt
New best model saved!

[53] train_loss: 0.3611
[53] train_loss: 0.2985
[53] train_loss: 0.2790
[53] train_loss: 0.2705
[53] train_loss: 0.2700
[53] train_loss: 0.2670
0.999321699142456

Evaluating...Epoch: 53
Prec: 0.8205, Recall: 0.7789, F1: 0.7992

[54] train_loss: 0.2712
[54] train_loss: 0.2093
[54] train_loss: 0.2107
[54] train_loss: 0.2103
[54] train_loss: 0.2122
[54] train_loss: 0.2079
1.0090737342834473

Evaluating...Epoch: 54
Prec: 0.8021, Recall: 0.7728, F1: 0.7872

[55] train_loss: 0.3936
[55] train_loss: 0.3187
[55] train_loss: 0.2859
[55] train_loss: 0.2485
[55] train_loss: 0.2429
[55] train_loss: 0.2377
1.0522997379302979

Evaluating...Epoch: 55
Prec: 0.8130, Recall: 0.7850, F1: 0.7988

[56] train_loss: 0.2506
[56] train_loss: 0.2237
[56] train_loss: 0.2246
[56] train_loss: 0.2331
[56] train_loss: 0.2463
[56] train_loss: 0.2340
1.0028064250946045

Evaluating...Epoch: 56
Prec: 0.8348, Recall: 0.7688, F1: 0.8004

[57] train_loss: 0.2281
[57] train_loss: 0.2120
[57] train_loss: 0.2109
[57] train_loss: 0.1863
[57] train_loss: 0.1992
[57] train_loss: 0.2049
1.003638744354248

Evaluating...Epoch: 57
Prec: 0.8370, Recall: 0.7708, F1: 0.8025

[58] train_loss: 0.3276
[58] train_loss: 0.2240
[58] train_loss: 0.2281
[58] train_loss: 0.1964
[58] train_loss: 0.1917
[58] train_loss: 0.1932
0.9988913536071777

Evaluating...Epoch: 58
Prec: 0.8205, Recall: 0.7789, F1: 0.7992

[59] train_loss: 0.2078
[59] train_loss: 0.1953
[59] train_loss: 0.2031
[59] train_loss: 0.1971
[59] train_loss: 0.1985
[59] train_loss: 0.1886
1.0110299587249756

Evaluating...Epoch: 59
Prec: 0.8058, Recall: 0.7911, F1: 0.7984

[60] train_loss: 0.1908
[60] train_loss: 0.2028
[60] train_loss: 0.2220
[60] train_loss: 0.1996
[60] train_loss: 0.2099
[60] train_loss: 0.2123
1.004021406173706

Evaluating...Epoch: 60
Prec: 0.8348, Recall: 0.7789, F1: 0.8059

[61] train_loss: 0.1736
[61] train_loss: 0.1807
[61] train_loss: 0.1785
[61] train_loss: 0.1764
[61] train_loss: 0.2082
[61] train_loss: 0.2065
1.0026240348815918

Evaluating...Epoch: 61
Prec: 0.8351, Recall: 0.7911, F1: 0.8125
model saved to random1_layers3_15res/best_model.pt
New best model saved!

[62] train_loss: 0.1419
[62] train_loss: 0.1176
[62] train_loss: 0.1395
[62] train_loss: 0.1500
[62] train_loss: 0.1553
[62] train_loss: 0.1540
1.0675203800201416

Evaluating...Epoch: 62
Prec: 0.8450, Recall: 0.7850, F1: 0.8139
model saved to random1_layers3_15res/best_model.pt
New best model saved!

[63] train_loss: 0.2772
[63] train_loss: 0.2402
[63] train_loss: 0.2102
[63] train_loss: 0.2008
[63] train_loss: 0.1965
[63] train_loss: 0.1800
1.0016534328460693

Evaluating...Epoch: 63
Prec: 0.8403, Recall: 0.7789, F1: 0.8084

[64] train_loss: 0.3023
[64] train_loss: 0.2610
[64] train_loss: 0.2681
[64] train_loss: 0.2185
[64] train_loss: 0.2148
[64] train_loss: 0.2025
1.0064163208007812

Evaluating...Epoch: 64
Prec: 0.8138, Recall: 0.7890, F1: 0.8012

[65] train_loss: 0.1385
[65] train_loss: 0.1617
[65] train_loss: 0.1590
[65] train_loss: 0.1439
[65] train_loss: 0.1478
[65] train_loss: 0.1396
1.0096712112426758

Evaluating...Epoch: 65
Prec: 0.8304, Recall: 0.7748, F1: 0.8017

[66] train_loss: 0.1660
[66] train_loss: 0.1779
[66] train_loss: 0.1573
[66] train_loss: 0.1604
[66] train_loss: 0.1546
[66] train_loss: 0.1503
1.0026538372039795

Evaluating...Epoch: 66
Prec: 0.8217, Recall: 0.7850, F1: 0.8029

[67] train_loss: 0.0945
[67] train_loss: 0.1139
[67] train_loss: 0.1285
[67] train_loss: 0.1400
[67] train_loss: 0.1494
[67] train_loss: 0.1473
1.0150296688079834

Evaluating...Epoch: 67
Prec: 0.8242, Recall: 0.7890, F1: 0.8062

[68] train_loss: 0.0982
[68] train_loss: 0.1129
[68] train_loss: 0.1244
[68] train_loss: 0.1299
[68] train_loss: 0.1233
[68] train_loss: 0.1459
1.00569486618042

Evaluating...Epoch: 68
Prec: 0.8333, Recall: 0.7708, F1: 0.8008

[69] train_loss: 0.0853
[69] train_loss: 0.1205
[69] train_loss: 0.1292
[69] train_loss: 0.1320
[69] train_loss: 0.1260
[69] train_loss: 0.1267
1.0060577392578125

Evaluating...Epoch: 69
Prec: 0.8415, Recall: 0.7647, F1: 0.8013

[70] train_loss: 0.1455
[70] train_loss: 0.1182
[70] train_loss: 0.1276
[70] train_loss: 0.1096
[70] train_loss: 0.1101
[70] train_loss: 0.1130
1.013720989227295

Evaluating...Epoch: 70
Prec: 0.8199, Recall: 0.7850, F1: 0.8021

[71] train_loss: 0.0884
[71] train_loss: 0.0897
[71] train_loss: 0.1153
[71] train_loss: 0.1278
[71] train_loss: 0.1382
[71] train_loss: 0.1284
1.0001955032348633

Evaluating...Epoch: 71
Prec: 0.8286, Recall: 0.7748, F1: 0.8008

[72] train_loss: 0.1824
[72] train_loss: 0.1795
[72] train_loss: 0.1760
[72] train_loss: 0.1661
[72] train_loss: 0.1931
[72] train_loss: 0.1770
1.017683744430542

Evaluating...Epoch: 72
Prec: 0.8161, Recall: 0.7830, F1: 0.7992

[73] train_loss: 0.1140
[73] train_loss: 0.1203
[73] train_loss: 0.1383
[73] train_loss: 0.1233
[73] train_loss: 0.1337
[73] train_loss: 0.1282
1.001680612564087

Evaluating...Epoch: 73
Prec: 0.8188, Recall: 0.7789, F1: 0.7983

[74] train_loss: 0.1071
[74] train_loss: 0.1075
[74] train_loss: 0.1026
[74] train_loss: 0.0988
[74] train_loss: 0.1049
[74] train_loss: 0.1025
0.9940245151519775

Evaluating...Epoch: 74
Prec: 0.8475, Recall: 0.7667, F1: 0.8051

[75] train_loss: 0.3180
[75] train_loss: 0.2206
[75] train_loss: 0.1717
[75] train_loss: 0.1677
[75] train_loss: 0.1560
[75] train_loss: 0.1620
0.995495080947876

Evaluating...Epoch: 75
Prec: 0.8458, Recall: 0.7789, F1: 0.8110

[76] train_loss: 0.1257
[76] train_loss: 0.1358
[76] train_loss: 0.1546
[76] train_loss: 0.1468
[76] train_loss: 0.1406
[76] train_loss: 0.1321
0.9900553226470947

Evaluating...Epoch: 76
Prec: 0.8426, Recall: 0.7708, F1: 0.8051

[77] train_loss: 0.1647
[77] train_loss: 0.1770
[77] train_loss: 0.1810
[77] train_loss: 0.1485
[77] train_loss: 0.1460
[77] train_loss: 0.1422
1.0524427890777588

Evaluating...Epoch: 77
Prec: 0.8297, Recall: 0.7708, F1: 0.7992

[78] train_loss: 0.1678
[78] train_loss: 0.1974
[78] train_loss: 0.1904
[78] train_loss: 0.1633
[78] train_loss: 0.1686
[78] train_loss: 0.1608
1.0078790187835693

Evaluating...Epoch: 78
Prec: 0.8174, Recall: 0.7809, F1: 0.7988

[79] train_loss: 0.0883
[79] train_loss: 0.1125
[79] train_loss: 0.1341
[79] train_loss: 0.1232
[79] train_loss: 0.1235
[79] train_loss: 0.1205
1.0054001808166504

Evaluating...Epoch: 79
Prec: 0.8116, Recall: 0.7951, F1: 0.8033

[80] train_loss: 0.1665
[80] train_loss: 0.1244
[80] train_loss: 0.1121
[80] train_loss: 0.1180
[80] train_loss: 0.1145
[80] train_loss: 0.1253
1.0090973377227783

Evaluating...Epoch: 80
Prec: 0.8266, Recall: 0.7830, F1: 0.8042

[81] train_loss: 0.1540
[81] train_loss: 0.1389
[81] train_loss: 0.1401
[81] train_loss: 0.1229
[81] train_loss: 0.1334
[81] train_loss: 0.1337
1.0003211498260498

Evaluating...Epoch: 81
Prec: 0.8581, Recall: 0.7485, F1: 0.7996

[82] train_loss: 0.1243
[82] train_loss: 0.1032
[82] train_loss: 0.1253
[82] train_loss: 0.1158
[82] train_loss: 0.1089
[82] train_loss: 0.1227
1.003331184387207

Evaluating...Epoch: 82
Prec: 0.8291, Recall: 0.7870, F1: 0.8075

Training ended with 83 epochs.
Final result:
Prec: 0.8450, Recall: 0.7850, F1: 0.8139
loading vocab and embedding matrix from ../data/15res
size of vocab: 2715
shape of loaded embedding matrix: (2715, 300)
Generating mappings
Loading data from ../data/15res with batch size 16...
68 batches created for ../data/15res/train.json
28 batches created for ../data/15res/test.json
Building model...
1353003
[1] train_loss: 11.7727
[1] train_loss: 8.9202
[1] train_loss: 7.9169
[1] train_loss: 7.1127
[1] train_loss: 6.6964
[1] train_loss: 6.2942
1.0437054634094238

Evaluating...Epoch: 1
Prec: 0.9355, Recall: 0.0588, F1: 0.1107
model saved to random1_layers4_15res/best_model.pt
New best model saved!

[2] train_loss: 4.8641
[2] train_loss: 4.3963
[2] train_loss: 4.3548
[2] train_loss: 4.0986
[2] train_loss: 3.9988
[2] train_loss: 3.8826
1.0321879386901855

Evaluating...Epoch: 2
Prec: 0.7809, Recall: 0.5132, F1: 0.6193
model saved to random1_layers4_15res/best_model.pt
New best model saved!

[3] train_loss: 4.0094
[3] train_loss: 3.5895
[3] train_loss: 3.6244
[3] train_loss: 3.4660
[3] train_loss: 3.4239
[3] train_loss: 3.3351
1.027768611907959

Evaluating...Epoch: 3
Prec: 0.8028, Recall: 0.5862, F1: 0.6776
model saved to random1_layers4_15res/best_model.pt
New best model saved!

[4] train_loss: 3.6960
[4] train_loss: 3.2695
[4] train_loss: 3.2686
[4] train_loss: 3.1136
[4] train_loss: 3.0982
[4] train_loss: 3.0106
1.0321245193481445

Evaluating...Epoch: 4
Prec: 0.7658, Recall: 0.6633, F1: 0.7109
model saved to random1_layers4_15res/best_model.pt
New best model saved!

[5] train_loss: 3.2946
[5] train_loss: 2.9653
[5] train_loss: 3.0123
[5] train_loss: 2.8566
[5] train_loss: 2.8450
[5] train_loss: 2.7856
1.0273728370666504

Evaluating...Epoch: 5
Prec: 0.7985, Recall: 0.6592, F1: 0.7222
model saved to random1_layers4_15res/best_model.pt
New best model saved!

[6] train_loss: 3.0639
[6] train_loss: 2.7830
[6] train_loss: 2.8343
[6] train_loss: 2.6519
[6] train_loss: 2.6601
[6] train_loss: 2.5820
1.0307121276855469

Evaluating...Epoch: 6
Prec: 0.7957, Recall: 0.6795, F1: 0.7330
model saved to random1_layers4_15res/best_model.pt
New best model saved!

[7] train_loss: 3.0588
[7] train_loss: 2.6965
[7] train_loss: 2.7476
[7] train_loss: 2.5652
[7] train_loss: 2.5267
[7] train_loss: 2.4263
1.087127923965454

Evaluating...Epoch: 7
Prec: 0.7059, Recall: 0.7302, F1: 0.7178

[8] train_loss: 2.6314
[8] train_loss: 2.4087
[8] train_loss: 2.4812
[8] train_loss: 2.2894
[8] train_loss: 2.2806
[8] train_loss: 2.2052
1.0306634902954102

Evaluating...Epoch: 8
Prec: 0.7203, Recall: 0.6998, F1: 0.7099

[9] train_loss: 2.6992
[9] train_loss: 2.2725
[9] train_loss: 2.2716
[9] train_loss: 2.1395
[9] train_loss: 2.1323
[9] train_loss: 2.0443
1.0242588520050049

Evaluating...Epoch: 9
Prec: 0.7018, Recall: 0.7160, F1: 0.7088

[10] train_loss: 2.3505
[10] train_loss: 2.0362
[10] train_loss: 2.0753
[10] train_loss: 1.9242
[10] train_loss: 1.9013
[10] train_loss: 1.8741
1.0400233268737793

Evaluating...Epoch: 10
Prec: 0.7617, Recall: 0.6937, F1: 0.7261

[11] train_loss: 2.0201
[11] train_loss: 1.9259
[11] train_loss: 1.9694
[11] train_loss: 1.8101
[11] train_loss: 1.8082
[11] train_loss: 1.7550
1.0296311378479004

Evaluating...Epoch: 11
Prec: 0.8005, Recall: 0.6511, F1: 0.7181

[12] train_loss: 2.1239
[12] train_loss: 1.8187
[12] train_loss: 1.8619
[12] train_loss: 1.7129
[12] train_loss: 1.7006
[12] train_loss: 1.6497
1.032642126083374

Evaluating...Epoch: 12
Prec: 0.7995, Recall: 0.6795, F1: 0.7346
model saved to random1_layers4_15res/best_model.pt
New best model saved!

[13] train_loss: 1.8216
[13] train_loss: 1.6930
[13] train_loss: 1.6382
[13] train_loss: 1.5409
[13] train_loss: 1.5635
[13] train_loss: 1.5079
1.029428243637085

Evaluating...Epoch: 13
Prec: 0.7807, Recall: 0.7221, F1: 0.7503
model saved to random1_layers4_15res/best_model.pt
New best model saved!

[14] train_loss: 1.7476
[14] train_loss: 1.6313
[14] train_loss: 1.5554
[14] train_loss: 1.4450
[14] train_loss: 1.4657
[14] train_loss: 1.4303
1.0786571502685547

Evaluating...Epoch: 14
Prec: 0.8096, Recall: 0.6815, F1: 0.7401

[15] train_loss: 1.6829
[15] train_loss: 1.5842
[15] train_loss: 1.5544
[15] train_loss: 1.4203
[15] train_loss: 1.4123
[15] train_loss: 1.3879
1.0256421566009521

Evaluating...Epoch: 15
Prec: 0.7942, Recall: 0.7201, F1: 0.7553
model saved to random1_layers4_15res/best_model.pt
New best model saved!

[16] train_loss: 1.4250
[16] train_loss: 1.3588
[16] train_loss: 1.3523
[16] train_loss: 1.2465
[16] train_loss: 1.2540
[16] train_loss: 1.2200
1.0270659923553467

Evaluating...Epoch: 16
Prec: 0.8082, Recall: 0.7181, F1: 0.7605
model saved to random1_layers4_15res/best_model.pt
New best model saved!

[17] train_loss: 1.4658
[17] train_loss: 1.2586
[17] train_loss: 1.2840
[17] train_loss: 1.1697
[17] train_loss: 1.1530
[17] train_loss: 1.1373
1.0225515365600586

Evaluating...Epoch: 17
Prec: 0.8462, Recall: 0.6694, F1: 0.7475

[18] train_loss: 1.4533
[18] train_loss: 1.3030
[18] train_loss: 1.2736
[18] train_loss: 1.1460
[18] train_loss: 1.1369
[18] train_loss: 1.0792
1.031541347503662

Evaluating...Epoch: 18
Prec: 0.7885, Recall: 0.7485, F1: 0.7680
model saved to random1_layers4_15res/best_model.pt
New best model saved!

[19] train_loss: 1.3039
[19] train_loss: 1.1113
[19] train_loss: 1.1076
[19] train_loss: 1.0307
[19] train_loss: 1.0336
[19] train_loss: 1.0150
1.0215203762054443

Evaluating...Epoch: 19
Prec: 0.8035, Recall: 0.7546, F1: 0.7782
model saved to random1_layers4_15res/best_model.pt
New best model saved!

[20] train_loss: 1.1210
[20] train_loss: 1.0523
[20] train_loss: 1.0125
[20] train_loss: 0.9296
[20] train_loss: 0.9841
[20] train_loss: 0.9418
1.0357000827789307

Evaluating...Epoch: 20
Prec: 0.7648, Recall: 0.7586, F1: 0.7617

[21] train_loss: 1.0296
[21] train_loss: 0.9979
[21] train_loss: 0.9745
[21] train_loss: 0.9006
[21] train_loss: 0.8894
[21] train_loss: 0.8476
1.0243301391601562

Evaluating...Epoch: 21
Prec: 0.7908, Recall: 0.7667, F1: 0.7786
model saved to random1_layers4_15res/best_model.pt
New best model saved!

[22] train_loss: 0.8079
[22] train_loss: 0.7610
[22] train_loss: 0.8405
[22] train_loss: 0.7815
[22] train_loss: 0.8325
[22] train_loss: 0.8192
1.0361552238464355

Evaluating...Epoch: 22
Prec: 0.7863, Recall: 0.7241, F1: 0.7540

[23] train_loss: 0.9919
[23] train_loss: 0.9485
[23] train_loss: 0.9919
[23] train_loss: 0.8796
[23] train_loss: 0.8746
[23] train_loss: 0.8584
1.0306334495544434

Evaluating...Epoch: 23
Prec: 0.7854, Recall: 0.7647, F1: 0.7749

[24] train_loss: 1.1039
[24] train_loss: 0.9037
[24] train_loss: 0.8873
[24] train_loss: 0.7849
[24] train_loss: 0.8249
[24] train_loss: 0.7880
1.0241568088531494

Evaluating...Epoch: 24
Prec: 0.7996, Recall: 0.7606, F1: 0.7796
model saved to random1_layers4_15res/best_model.pt
New best model saved!

[25] train_loss: 0.8820
[25] train_loss: 0.8123
[25] train_loss: 0.8186
[25] train_loss: 0.7247
[25] train_loss: 0.7213
[25] train_loss: 0.6849
1.0345063209533691

Evaluating...Epoch: 25
Prec: 0.8093, Recall: 0.7404, F1: 0.7733

[26] train_loss: 0.7676
[26] train_loss: 0.8264
[26] train_loss: 0.8505
[26] train_loss: 0.7570
[26] train_loss: 0.7934
[26] train_loss: 0.7558
1.0295379161834717

Evaluating...Epoch: 26
Prec: 0.8322, Recall: 0.7546, F1: 0.7915
model saved to random1_layers4_15res/best_model.pt
New best model saved!

[27] train_loss: 0.7506
[27] train_loss: 0.7183
[27] train_loss: 0.7823
[27] train_loss: 0.7106
[27] train_loss: 0.7048
[27] train_loss: 0.6752
1.0867841243743896

Evaluating...Epoch: 27
Prec: 0.8017, Recall: 0.7627, F1: 0.7817

[28] train_loss: 0.8377
[28] train_loss: 0.6653
[28] train_loss: 0.6728
[28] train_loss: 0.6364
[28] train_loss: 0.6384
[28] train_loss: 0.6350
1.0362114906311035

Evaluating...Epoch: 28
Prec: 0.7905, Recall: 0.7728, F1: 0.7815

[29] train_loss: 0.6521
[29] train_loss: 0.6282
[29] train_loss: 0.6496
[29] train_loss: 0.5946
[29] train_loss: 0.5940
[29] train_loss: 0.5767
1.0295510292053223

Evaluating...Epoch: 29
Prec: 0.7955, Recall: 0.7809, F1: 0.7881

[30] train_loss: 0.7928
[30] train_loss: 0.6840
[30] train_loss: 0.6840
[30] train_loss: 0.5933
[30] train_loss: 0.6165
[30] train_loss: 0.6121
1.0299365520477295

Evaluating...Epoch: 30
Prec: 0.7867, Recall: 0.7708, F1: 0.7787

[31] train_loss: 0.7831
[31] train_loss: 0.7044
[31] train_loss: 0.6681
[31] train_loss: 0.6223
[31] train_loss: 0.6305
[31] train_loss: 0.6304
1.0392515659332275

Evaluating...Epoch: 31
Prec: 0.8004, Recall: 0.7647, F1: 0.7822

[32] train_loss: 0.7458
[32] train_loss: 0.6040
[32] train_loss: 0.6053
[32] train_loss: 0.5301
[32] train_loss: 0.5289
[32] train_loss: 0.5104
1.0278360843658447

Evaluating...Epoch: 32
Prec: 0.7934, Recall: 0.7789, F1: 0.7861

[33] train_loss: 0.5218
[33] train_loss: 0.4945
[33] train_loss: 0.5440
[33] train_loss: 0.5052
[33] train_loss: 0.5167
[33] train_loss: 0.5060
1.030165433883667

Evaluating...Epoch: 33
Prec: 0.7764, Recall: 0.7890, F1: 0.7827

[34] train_loss: 0.5707
[34] train_loss: 0.5253
[34] train_loss: 0.5636
[34] train_loss: 0.5190
[34] train_loss: 0.5300
[34] train_loss: 0.5336
1.0886750221252441

Evaluating...Epoch: 34
Prec: 0.7823, Recall: 0.7870, F1: 0.7846

[35] train_loss: 0.5824
[35] train_loss: 0.4897
[35] train_loss: 0.4799
[35] train_loss: 0.4974
[35] train_loss: 0.5006
[35] train_loss: 0.4820
1.0267536640167236

Evaluating...Epoch: 35
Prec: 0.7917, Recall: 0.7708, F1: 0.7811

[36] train_loss: 0.5156
[36] train_loss: 0.4367
[36] train_loss: 0.4235
[36] train_loss: 0.3919
[36] train_loss: 0.4194
[36] train_loss: 0.4156
1.0370476245880127

Evaluating...Epoch: 36
Prec: 0.7963, Recall: 0.7850, F1: 0.7906

[37] train_loss: 0.4567
[37] train_loss: 0.4610
[37] train_loss: 0.4679
[37] train_loss: 0.4543
[37] train_loss: 0.4493
[37] train_loss: 0.4508
1.0269579887390137

Evaluating...Epoch: 37
Prec: 0.7942, Recall: 0.7830, F1: 0.7886

[38] train_loss: 0.4058
[38] train_loss: 0.4091
[38] train_loss: 0.4226
[38] train_loss: 0.3957
[38] train_loss: 0.4269
[38] train_loss: 0.4192
1.027405023574829

Evaluating...Epoch: 38
Prec: 0.7882, Recall: 0.7850, F1: 0.7866

[39] train_loss: 0.5344
[39] train_loss: 0.4596
[39] train_loss: 0.4263
[39] train_loss: 0.4008
[39] train_loss: 0.4206
[39] train_loss: 0.4179
1.0333354473114014

Evaluating...Epoch: 39
Prec: 0.8352, Recall: 0.7505, F1: 0.7906

[40] train_loss: 0.6035
[40] train_loss: 0.5170
[40] train_loss: 0.4535
[40] train_loss: 0.3983
[40] train_loss: 0.3801
[40] train_loss: 0.3718
1.0201308727264404

Evaluating...Epoch: 40
Prec: 0.8102, Recall: 0.7708, F1: 0.7900

[41] train_loss: 0.4617
[41] train_loss: 0.4171
[41] train_loss: 0.4245
[41] train_loss: 0.3973
[41] train_loss: 0.4159
[41] train_loss: 0.4083
1.0737254619598389

Evaluating...Epoch: 41
Prec: 0.8176, Recall: 0.7728, F1: 0.7946
model saved to random1_layers4_15res/best_model.pt
New best model saved!

[42] train_loss: 0.4293
[42] train_loss: 0.3855
[42] train_loss: 0.3900
[42] train_loss: 0.3412
[42] train_loss: 0.3408
[42] train_loss: 0.3211
1.0147490501403809

Evaluating...Epoch: 42
Prec: 0.7987, Recall: 0.7566, F1: 0.7771

[43] train_loss: 0.4302
[43] train_loss: 0.3732
[43] train_loss: 0.3718
[43] train_loss: 0.3270
[43] train_loss: 0.3379
[43] train_loss: 0.3287
1.0224580764770508

Evaluating...Epoch: 43
Prec: 0.8050, Recall: 0.7789, F1: 0.7918

[44] train_loss: 0.4402
[44] train_loss: 0.3978
[44] train_loss: 0.3782
[44] train_loss: 0.3515
[44] train_loss: 0.3602
[44] train_loss: 0.3785
1.0294249057769775

Evaluating...Epoch: 44
Prec: 0.7991, Recall: 0.7586, F1: 0.7784

[45] train_loss: 0.4814
[45] train_loss: 0.3753
[45] train_loss: 0.3787
[45] train_loss: 0.3449
[45] train_loss: 0.3385
[45] train_loss: 0.3140
1.0270841121673584

Evaluating...Epoch: 45
Prec: 0.7913, Recall: 0.7769, F1: 0.7840

[46] train_loss: 0.3435
[46] train_loss: 0.3012
[46] train_loss: 0.3190
[46] train_loss: 0.2888
[46] train_loss: 0.2955
[46] train_loss: 0.3016
1.0307364463806152

Evaluating...Epoch: 46
Prec: 0.8051, Recall: 0.7708, F1: 0.7876

[47] train_loss: 0.3169
[47] train_loss: 0.3661
[47] train_loss: 0.3385
[47] train_loss: 0.3247
[47] train_loss: 0.3188
[47] train_loss: 0.3025
1.0816526412963867

Evaluating...Epoch: 47
Prec: 0.8159, Recall: 0.7911, F1: 0.8033
model saved to random1_layers4_15res/best_model.pt
New best model saved!

[48] train_loss: 0.3729
[48] train_loss: 0.3267
[48] train_loss: 0.2872
[48] train_loss: 0.2905
[48] train_loss: 0.2796
[48] train_loss: 0.2727
1.0273728370666504

Evaluating...Epoch: 48
Prec: 0.7979, Recall: 0.7688, F1: 0.7831

[49] train_loss: 0.3704
[49] train_loss: 0.3226
[49] train_loss: 0.2968
[49] train_loss: 0.2683
[49] train_loss: 0.2878
[49] train_loss: 0.2804
1.0191569328308105

Evaluating...Epoch: 49
Prec: 0.7826, Recall: 0.7667, F1: 0.7746

[50] train_loss: 0.4197
[50] train_loss: 0.3347
[50] train_loss: 0.3243
[50] train_loss: 0.3118
[50] train_loss: 0.3426
[50] train_loss: 0.3232
1.0142383575439453

Evaluating...Epoch: 50
Prec: 0.8101, Recall: 0.7789, F1: 0.7942

[51] train_loss: 0.2862
[51] train_loss: 0.2251
[51] train_loss: 0.2861
[51] train_loss: 0.2517
[51] train_loss: 0.2284
[51] train_loss: 0.2300
1.0172159671783447

Evaluating...Epoch: 51
Prec: 0.7820, Recall: 0.7931, F1: 0.7875

[52] train_loss: 0.2586
[52] train_loss: 0.2680
[52] train_loss: 0.2904
[52] train_loss: 0.2540
[52] train_loss: 0.2681
[52] train_loss: 0.2621
1.0275201797485352

Evaluating...Epoch: 52
Prec: 0.8296, Recall: 0.7505, F1: 0.7881

[53] train_loss: 0.2437
[53] train_loss: 0.1950
[53] train_loss: 0.1947
[53] train_loss: 0.2025
[53] train_loss: 0.2239
[53] train_loss: 0.2407
1.0279943943023682

Evaluating...Epoch: 53
Prec: 0.8133, Recall: 0.7688, F1: 0.7904

[54] train_loss: 0.2755
[54] train_loss: 0.2099
[54] train_loss: 0.2626
[54] train_loss: 0.2414
[54] train_loss: 0.2262
[54] train_loss: 0.2337
1.0321285724639893

Evaluating...Epoch: 54
Prec: 0.7971, Recall: 0.7890, F1: 0.7931

[55] train_loss: 0.1598
[55] train_loss: 0.1409
[55] train_loss: 0.1573
[55] train_loss: 0.1585
[55] train_loss: 0.1652
[55] train_loss: 0.1744
1.0293710231781006

Evaluating...Epoch: 55
Prec: 0.8033, Recall: 0.7870, F1: 0.7951

[56] train_loss: 0.2830
[56] train_loss: 0.3180
[56] train_loss: 0.2958
[56] train_loss: 0.2714
[56] train_loss: 0.2572
[56] train_loss: 0.2615
1.02205491065979

Evaluating...Epoch: 56
Prec: 0.8147, Recall: 0.7667, F1: 0.7900

[57] train_loss: 0.2382
[57] train_loss: 0.2211
[57] train_loss: 0.2195
[57] train_loss: 0.1955
[57] train_loss: 0.2185
[57] train_loss: 0.2145
1.0261950492858887

Evaluating...Epoch: 57
Prec: 0.8182, Recall: 0.7850, F1: 0.8012

[58] train_loss: 0.3481
[58] train_loss: 0.2673
[58] train_loss: 0.2529
[58] train_loss: 0.2249
[58] train_loss: 0.2319
[58] train_loss: 0.2234
1.026031494140625

Evaluating...Epoch: 58
Prec: 0.7963, Recall: 0.7931, F1: 0.7947

[59] train_loss: 0.2415
[59] train_loss: 0.2153
[59] train_loss: 0.2454
[59] train_loss: 0.2236
[59] train_loss: 0.2241
[59] train_loss: 0.2289
1.0217370986938477

Evaluating...Epoch: 59
Prec: 0.8110, Recall: 0.7485, F1: 0.7785

[60] train_loss: 0.1951
[60] train_loss: 0.1981
[60] train_loss: 0.1876
[60] train_loss: 0.1746
[60] train_loss: 0.1908
[60] train_loss: 0.1912
1.033022403717041

Evaluating...Epoch: 60
Prec: 0.8113, Recall: 0.7850, F1: 0.7979

[61] train_loss: 0.5326
[61] train_loss: 0.3724
[61] train_loss: 0.3141
[61] train_loss: 0.2637
[61] train_loss: 0.2687
[61] train_loss: 0.2553
1.024366855621338

Evaluating...Epoch: 61
Prec: 0.7844, Recall: 0.7748, F1: 0.7796

[62] train_loss: 0.2661
[62] train_loss: 0.2356
[62] train_loss: 0.2166
[62] train_loss: 0.1917
[62] train_loss: 0.1748
[62] train_loss: 0.1653
1.0751392841339111

Evaluating...Epoch: 62
Prec: 0.8102, Recall: 0.7708, F1: 0.7900

[63] train_loss: 0.1437
[63] train_loss: 0.1867
[63] train_loss: 0.1857
[63] train_loss: 0.1785
[63] train_loss: 0.1617
[63] train_loss: 0.1647
1.0291121006011963

Evaluating...Epoch: 63
Prec: 0.8025, Recall: 0.7830, F1: 0.7926

[64] train_loss: 0.4053
[64] train_loss: 0.2987
[64] train_loss: 0.2820
[64] train_loss: 0.2448
[64] train_loss: 0.2235
[64] train_loss: 0.2045
1.0198614597320557

Evaluating...Epoch: 64
Prec: 0.8051, Recall: 0.7708, F1: 0.7876

[65] train_loss: 0.2240
[65] train_loss: 0.1669
[65] train_loss: 0.1616
[65] train_loss: 0.1508
[65] train_loss: 0.1636
[65] train_loss: 0.1717
1.0309579372406006

Evaluating...Epoch: 65
Prec: 0.8371, Recall: 0.7606, F1: 0.7970

[66] train_loss: 0.2190
[66] train_loss: 0.1713
[66] train_loss: 0.1738
[66] train_loss: 0.1614
[66] train_loss: 0.1560
[66] train_loss: 0.1620
1.0282633304595947

Evaluating...Epoch: 66
Prec: 0.7951, Recall: 0.7870, F1: 0.7910

[67] train_loss: 0.1500
[67] train_loss: 0.1022
[67] train_loss: 0.1164
[67] train_loss: 0.1177
[67] train_loss: 0.1297
[67] train_loss: 0.1307
1.0241248607635498

Evaluating...Epoch: 67
Prec: 0.8352, Recall: 0.7505, F1: 0.7906

Training ended with 68 epochs.
Final result:
Prec: 0.8159, Recall: 0.7911, F1: 0.8033
loading vocab and embedding matrix from ../data/15res
size of vocab: 2715
shape of loaded embedding matrix: (2715, 300)
Generating mappings
Loading data from ../data/15res with batch size 16...
68 batches created for ../data/15res/train.json
28 batches created for ../data/15res/test.json
Building model...
1393203
[1] train_loss: 10.5526
[1] train_loss: 8.1967
[1] train_loss: 7.3953
[1] train_loss: 6.7566
[1] train_loss: 6.4041
[1] train_loss: 6.0681
1.0811100006103516

Evaluating...Epoch: 1
Prec: 1.0000, Recall: 0.0649, F1: 0.1219
model saved to random1_layers5_15res/best_model.pt
New best model saved!

[2] train_loss: 4.9763
[2] train_loss: 4.5196
[2] train_loss: 4.4686
[2] train_loss: 4.2114
[2] train_loss: 4.1079
[2] train_loss: 3.9603
1.0777721405029297

Evaluating...Epoch: 2
Prec: 0.7771, Recall: 0.5375, F1: 0.6355
model saved to random1_layers5_15res/best_model.pt
New best model saved!

[3] train_loss: 3.9588
[3] train_loss: 3.7181
[3] train_loss: 3.6944
[3] train_loss: 3.5008
[3] train_loss: 3.4493
[3] train_loss: 3.3171
1.0748438835144043

Evaluating...Epoch: 3
Prec: 0.8232, Recall: 0.5761, F1: 0.6778
model saved to random1_layers5_15res/best_model.pt
New best model saved!

[4] train_loss: 3.8318
[4] train_loss: 3.3533
[4] train_loss: 3.4195
[4] train_loss: 3.2150
[4] train_loss: 3.1666
[4] train_loss: 3.0478
1.070227861404419

Evaluating...Epoch: 4
Prec: 0.7822, Recall: 0.6410, F1: 0.7046
model saved to random1_layers5_15res/best_model.pt
New best model saved!

[5] train_loss: 3.4031
[5] train_loss: 3.0571
[5] train_loss: 3.0499
[5] train_loss: 2.8759
[5] train_loss: 2.8313
[5] train_loss: 2.7177
1.0786919593811035

Evaluating...Epoch: 5
Prec: 0.8090, Recall: 0.6187, F1: 0.7011

[6] train_loss: 3.3035
[6] train_loss: 2.8687
[6] train_loss: 2.8777
[6] train_loss: 2.6934
[6] train_loss: 2.6852
[6] train_loss: 2.5880
1.0769405364990234

Evaluating...Epoch: 6
Prec: 0.7936, Recall: 0.6552, F1: 0.7178
model saved to random1_layers5_15res/best_model.pt
New best model saved!

[7] train_loss: 3.0893
[7] train_loss: 2.7454
[7] train_loss: 2.7337
[7] train_loss: 2.5480
[7] train_loss: 2.5324
[7] train_loss: 2.4689
1.1324121952056885

Evaluating...Epoch: 7
Prec: 0.7638, Recall: 0.6755, F1: 0.7169

[8] train_loss: 2.7465
[8] train_loss: 2.5137
[8] train_loss: 2.5435
[8] train_loss: 2.3580
[8] train_loss: 2.3304
[8] train_loss: 2.2652
1.0749874114990234

Evaluating...Epoch: 8
Prec: 0.7522, Recall: 0.6957, F1: 0.7229
model saved to random1_layers5_15res/best_model.pt
New best model saved!

[9] train_loss: 2.4721
[9] train_loss: 2.2481
[9] train_loss: 2.3649
[9] train_loss: 2.2239
[9] train_loss: 2.2218
[9] train_loss: 2.1638
1.070038080215454

Evaluating...Epoch: 9
Prec: 0.8039, Recall: 0.6734, F1: 0.7329
model saved to random1_layers5_15res/best_model.pt
New best model saved!

[10] train_loss: 2.2692
[10] train_loss: 2.0447
[10] train_loss: 2.1671
[10] train_loss: 2.0029
[10] train_loss: 2.0076
[10] train_loss: 1.9606
1.0654628276824951

Evaluating...Epoch: 10
Prec: 0.7837, Recall: 0.6613, F1: 0.7173

[11] train_loss: 2.2376
[11] train_loss: 2.0181
[11] train_loss: 2.0454
[11] train_loss: 1.9095
[11] train_loss: 1.8860
[11] train_loss: 1.8093
1.0835087299346924

Evaluating...Epoch: 11
Prec: 0.7562, Recall: 0.6795, F1: 0.7158

[12] train_loss: 2.1120
[12] train_loss: 1.9700
[12] train_loss: 1.8575
[12] train_loss: 1.7593
[12] train_loss: 1.7571
[12] train_loss: 1.7022
1.0710344314575195

Evaluating...Epoch: 12
Prec: 0.7670, Recall: 0.6876, F1: 0.7251

[13] train_loss: 1.8713
[13] train_loss: 1.8563
[13] train_loss: 1.8836
[13] train_loss: 1.7179
[13] train_loss: 1.6815
[13] train_loss: 1.6177
1.0747013092041016

Evaluating...Epoch: 13
Prec: 0.7564, Recall: 0.7181, F1: 0.7367
model saved to random1_layers5_15res/best_model.pt
New best model saved!

[14] train_loss: 1.6471
[14] train_loss: 1.4830
[14] train_loss: 1.4942
[14] train_loss: 1.3882
[14] train_loss: 1.4239
[14] train_loss: 1.3728
1.1397900581359863

Evaluating...Epoch: 14
Prec: 0.7422, Recall: 0.7241, F1: 0.7331

[15] train_loss: 1.5521
[15] train_loss: 1.4482
[15] train_loss: 1.4404
[15] train_loss: 1.3312
[15] train_loss: 1.3655
[15] train_loss: 1.3522
1.0717391967773438

Evaluating...Epoch: 15
Prec: 0.7933, Recall: 0.7241, F1: 0.7572
model saved to random1_layers5_15res/best_model.pt
New best model saved!

[16] train_loss: 1.3264
[16] train_loss: 1.2638
[16] train_loss: 1.3400
[16] train_loss: 1.2410
[16] train_loss: 1.2856
[16] train_loss: 1.2459
1.066040277481079

Evaluating...Epoch: 16
Prec: 0.7982, Recall: 0.7059, F1: 0.7492

[17] train_loss: 1.7253
[17] train_loss: 1.4293
[17] train_loss: 1.4026
[17] train_loss: 1.2812
[17] train_loss: 1.2761
[17] train_loss: 1.2376
1.0787944793701172

Evaluating...Epoch: 17
Prec: 0.7952, Recall: 0.7323, F1: 0.7624
model saved to random1_layers5_15res/best_model.pt
New best model saved!

[18] train_loss: 1.4108
[18] train_loss: 1.2875
[18] train_loss: 1.2651
[18] train_loss: 1.1463
[18] train_loss: 1.1770
[18] train_loss: 1.1271
1.0785088539123535

Evaluating...Epoch: 18
Prec: 0.7470, Recall: 0.7485, F1: 0.7477

[19] train_loss: 1.2489
[19] train_loss: 1.1487
[19] train_loss: 1.1199
[19] train_loss: 1.0004
[19] train_loss: 1.0351
[19] train_loss: 1.0202
1.0725507736206055

Evaluating...Epoch: 19
Prec: 0.7965, Recall: 0.7302, F1: 0.7619

[20] train_loss: 1.1565
[20] train_loss: 1.1592
[20] train_loss: 1.1208
[20] train_loss: 1.0191
[20] train_loss: 1.0107
[20] train_loss: 0.9745
1.079268455505371

Evaluating...Epoch: 20
Prec: 0.7665, Recall: 0.7525, F1: 0.7595

[21] train_loss: 1.0816
[21] train_loss: 0.9990
[21] train_loss: 0.9936
[21] train_loss: 0.8746
[21] train_loss: 0.9294
[21] train_loss: 0.9030
1.1188020706176758

Evaluating...Epoch: 21
Prec: 0.7889, Recall: 0.7505, F1: 0.7692
model saved to random1_layers5_15res/best_model.pt
New best model saved!

[22] train_loss: 1.1851
[22] train_loss: 0.9920
[22] train_loss: 1.0531
[22] train_loss: 0.9313
[22] train_loss: 0.9722
[22] train_loss: 0.9236
1.0630905628204346

Evaluating...Epoch: 22
Prec: 0.7957, Recall: 0.7586, F1: 0.7767
model saved to random1_layers5_15res/best_model.pt
New best model saved!

[23] train_loss: 0.9967
[23] train_loss: 0.8737
[23] train_loss: 0.9144
[23] train_loss: 0.8345
[23] train_loss: 0.8125
[23] train_loss: 0.8190
1.0613460540771484

Evaluating...Epoch: 23
Prec: 0.7705, Recall: 0.7627, F1: 0.7666

[24] train_loss: 0.8232
[24] train_loss: 0.8185
[24] train_loss: 0.8457
[24] train_loss: 0.7704
[24] train_loss: 0.7956
[24] train_loss: 0.7617
1.0729265213012695

Evaluating...Epoch: 24
Prec: 0.7897, Recall: 0.7465, F1: 0.7675

[25] train_loss: 0.8600
[25] train_loss: 0.8748
[25] train_loss: 0.8673
[25] train_loss: 0.7850
[25] train_loss: 0.7864
[25] train_loss: 0.7749
1.0731325149536133

Evaluating...Epoch: 25
Prec: 0.7808, Recall: 0.7586, F1: 0.7695

[26] train_loss: 0.9805
[26] train_loss: 0.8268
[26] train_loss: 0.8111
[26] train_loss: 0.7187
[26] train_loss: 0.7481
[26] train_loss: 0.7240
1.084923505783081

Evaluating...Epoch: 26
Prec: 0.7724, Recall: 0.7505, F1: 0.7613

[27] train_loss: 0.7390
[27] train_loss: 0.6917
[27] train_loss: 0.7057
[27] train_loss: 0.6484
[27] train_loss: 0.6566
[27] train_loss: 0.6537
1.0807342529296875

Evaluating...Epoch: 27
Prec: 0.7822, Recall: 0.7647, F1: 0.7733

[28] train_loss: 0.8345
[28] train_loss: 0.7017
[28] train_loss: 0.7615
[28] train_loss: 0.7093
[28] train_loss: 0.6962
[28] train_loss: 0.6622
1.0694177150726318

Evaluating...Epoch: 28
Prec: 0.7834, Recall: 0.7485, F1: 0.7656

[29] train_loss: 0.6803
[29] train_loss: 0.6048
[29] train_loss: 0.6495
[29] train_loss: 0.6059
[29] train_loss: 0.6254
[29] train_loss: 0.6029
1.0797274112701416

Evaluating...Epoch: 29
Prec: 0.7600, Recall: 0.7708, F1: 0.7654

[30] train_loss: 0.5715
[30] train_loss: 0.5462
[30] train_loss: 0.5622
[30] train_loss: 0.5223
[30] train_loss: 0.5512
[30] train_loss: 0.5591
1.062696933746338

Evaluating...Epoch: 30
Prec: 0.8114, Recall: 0.7505, F1: 0.7798
model saved to random1_layers5_15res/best_model.pt
New best model saved!

[31] train_loss: 0.6317
[31] train_loss: 0.5457
[31] train_loss: 0.5238
[31] train_loss: 0.4953
[31] train_loss: 0.5191
[31] train_loss: 0.4761
1.0630345344543457

Evaluating...Epoch: 31
Prec: 0.8143, Recall: 0.7647, F1: 0.7887
model saved to random1_layers5_15res/best_model.pt
New best model saved!

[32] train_loss: 0.8165
[32] train_loss: 0.6678
[32] train_loss: 0.6834
[32] train_loss: 0.5920
[32] train_loss: 0.5810
[32] train_loss: 0.5521
1.0689277648925781

Evaluating...Epoch: 32
Prec: 0.8281, Recall: 0.7424, F1: 0.7829

[33] train_loss: 0.5056
[33] train_loss: 0.4795
[33] train_loss: 0.4862
[33] train_loss: 0.4709
[33] train_loss: 0.4744
[33] train_loss: 0.4651
1.0819816589355469

Evaluating...Epoch: 33
Prec: 0.7962, Recall: 0.7606, F1: 0.7780

[34] train_loss: 0.5056
[34] train_loss: 0.4775
[34] train_loss: 0.4856
[34] train_loss: 0.4683
[34] train_loss: 0.5098
[34] train_loss: 0.5064
1.0687425136566162

Evaluating...Epoch: 34
Prec: 0.7955, Recall: 0.7809, F1: 0.7881

[35] train_loss: 0.5321
[35] train_loss: 0.5261
[35] train_loss: 0.5053
[35] train_loss: 0.5173
[35] train_loss: 0.5301
[35] train_loss: 0.4971
1.071993112564087

Evaluating...Epoch: 35
Prec: 0.7932, Recall: 0.7546, F1: 0.7734

[36] train_loss: 0.4463
[36] train_loss: 0.3902
[36] train_loss: 0.4421
[36] train_loss: 0.4194
[36] train_loss: 0.4416
[36] train_loss: 0.4413
1.0796542167663574

Evaluating...Epoch: 36
Prec: 0.7822, Recall: 0.7505, F1: 0.7660

[37] train_loss: 0.4772
[37] train_loss: 0.4106
[37] train_loss: 0.4289
[37] train_loss: 0.3986
[37] train_loss: 0.4062
[37] train_loss: 0.4008
1.0678715705871582

Evaluating...Epoch: 37
Prec: 0.7954, Recall: 0.7647, F1: 0.7797

[38] train_loss: 0.3920
[38] train_loss: 0.4501
[38] train_loss: 0.4404
[38] train_loss: 0.4419
[38] train_loss: 0.4284
[38] train_loss: 0.4227
1.0794506072998047

Evaluating...Epoch: 38
Prec: 0.7805, Recall: 0.7789, F1: 0.7797

[39] train_loss: 0.3209
[39] train_loss: 0.3592
[39] train_loss: 0.3564
[39] train_loss: 0.3689
[39] train_loss: 0.3769
[39] train_loss: 0.3615
1.069620132446289

Evaluating...Epoch: 39
Prec: 0.8229, Recall: 0.7444, F1: 0.7817

[40] train_loss: 0.4515
[40] train_loss: 0.4079
[40] train_loss: 0.3870
[40] train_loss: 0.3528
[40] train_loss: 0.3689
[40] train_loss: 0.3598
1.067251205444336

Evaluating...Epoch: 40
Prec: 0.7971, Recall: 0.7728, F1: 0.7848

[41] train_loss: 0.4469
[41] train_loss: 0.4322
[41] train_loss: 0.4033
[41] train_loss: 0.3528
[41] train_loss: 0.3851
[41] train_loss: 0.3620
1.0739574432373047

Evaluating...Epoch: 41
Prec: 0.7888, Recall: 0.7728, F1: 0.7807

[42] train_loss: 0.3975
[42] train_loss: 0.3572
[42] train_loss: 0.3736
[42] train_loss: 0.3486
[42] train_loss: 0.3820
[42] train_loss: 0.3667
1.11126708984375

Evaluating...Epoch: 42
Prec: 0.7919, Recall: 0.7566, F1: 0.7739

[43] train_loss: 0.5160
[43] train_loss: 0.4008
[43] train_loss: 0.3747
[43] train_loss: 0.3456
[43] train_loss: 0.3556
[43] train_loss: 0.3588
1.0695912837982178

Evaluating...Epoch: 43
Prec: 0.8055, Recall: 0.7728, F1: 0.7888
model saved to random1_layers5_15res/best_model.pt
New best model saved!

[44] train_loss: 0.4099
[44] train_loss: 0.3969
[44] train_loss: 0.3656
[44] train_loss: 0.3396
[44] train_loss: 0.3250
[44] train_loss: 0.3017
1.070281982421875

Evaluating...Epoch: 44
Prec: 0.7878, Recall: 0.7606, F1: 0.7740

[45] train_loss: 0.4009
[45] train_loss: 0.3166
[45] train_loss: 0.3383
[45] train_loss: 0.3044
[45] train_loss: 0.3034
[45] train_loss: 0.3105
1.0631258487701416

Evaluating...Epoch: 45
Prec: 0.7958, Recall: 0.7667, F1: 0.7810

[46] train_loss: 0.4273
[46] train_loss: 0.3778
[46] train_loss: 0.3667
[46] train_loss: 0.3126
[46] train_loss: 0.3206
[46] train_loss: 0.3084
1.0769567489624023

Evaluating...Epoch: 46
Prec: 0.7851, Recall: 0.7708, F1: 0.7779

[47] train_loss: 0.3551
[47] train_loss: 0.2921
[47] train_loss: 0.2794
[47] train_loss: 0.2409
[47] train_loss: 0.2382
[47] train_loss: 0.2268
1.077610969543457

Evaluating...Epoch: 47
Prec: 0.7950, Recall: 0.7789, F1: 0.7869

[48] train_loss: 0.3084
[48] train_loss: 0.2727
[48] train_loss: 0.2914
[48] train_loss: 0.2909
[48] train_loss: 0.3086
[48] train_loss: 0.3079
1.0807998180389404

Evaluating...Epoch: 48
Prec: 0.7776, Recall: 0.7870, F1: 0.7823

[49] train_loss: 0.3916
[49] train_loss: 0.2991
[49] train_loss: 0.3020
[49] train_loss: 0.2853
[49] train_loss: 0.2878
[49] train_loss: 0.2829
1.0729374885559082

Evaluating...Epoch: 49
Prec: 0.8085, Recall: 0.7708, F1: 0.7892
model saved to random1_layers5_15res/best_model.pt
New best model saved!

[50] train_loss: 0.3330
[50] train_loss: 0.3053
[50] train_loss: 0.2678
[50] train_loss: 0.2542
[50] train_loss: 0.2432
[50] train_loss: 0.2433
1.0612483024597168

Evaluating...Epoch: 50
Prec: 0.8156, Recall: 0.7444, F1: 0.7784

[51] train_loss: 0.3001
[51] train_loss: 0.2428
[51] train_loss: 0.2667
[51] train_loss: 0.2409
[51] train_loss: 0.2388
[51] train_loss: 0.2300
1.059206485748291

Evaluating...Epoch: 51
Prec: 0.7792, Recall: 0.7586, F1: 0.7688

[52] train_loss: 0.2775
[52] train_loss: 0.2215
[52] train_loss: 0.2082
[52] train_loss: 0.2049
[52] train_loss: 0.2242
[52] train_loss: 0.2241
1.068429708480835

Evaluating...Epoch: 52
Prec: 0.7760, Recall: 0.7728, F1: 0.7744

[53] train_loss: 0.2975
[53] train_loss: 0.3097
[53] train_loss: 0.2825
[53] train_loss: 0.2522
[53] train_loss: 0.2405
[53] train_loss: 0.2566
1.0690276622772217

Evaluating...Epoch: 53
Prec: 0.7987, Recall: 0.7647, F1: 0.7813

[54] train_loss: 0.3083
[54] train_loss: 0.2220
[54] train_loss: 0.2368
[54] train_loss: 0.2183
[54] train_loss: 0.2093
[54] train_loss: 0.2114
1.0638117790222168

Evaluating...Epoch: 54
Prec: 0.8259, Recall: 0.7505, F1: 0.7864

[55] train_loss: 0.2433
[55] train_loss: 0.2178
[55] train_loss: 0.2031
[55] train_loss: 0.1825
[55] train_loss: 0.1880
[55] train_loss: 0.2140
1.0811514854431152

Evaluating...Epoch: 55
Prec: 0.8147, Recall: 0.7667, F1: 0.7900
model saved to random1_layers5_15res/best_model.pt
New best model saved!

[56] train_loss: 0.3648
[56] train_loss: 0.2882
[56] train_loss: 0.2460
[56] train_loss: 0.2393
[56] train_loss: 0.2212
[56] train_loss: 0.2085
1.0781028270721436

Evaluating...Epoch: 56
Prec: 0.7918, Recall: 0.7789, F1: 0.7853

[57] train_loss: 0.2197
[57] train_loss: 0.1893
[57] train_loss: 0.1989
[57] train_loss: 0.1840
[57] train_loss: 0.1977
[57] train_loss: 0.1937
1.068373441696167

Evaluating...Epoch: 57
Prec: 0.8013, Recall: 0.7769, F1: 0.7889

[58] train_loss: 0.1616
[58] train_loss: 0.1597
[58] train_loss: 0.1869
[58] train_loss: 0.1954
[58] train_loss: 0.1885
[58] train_loss: 0.1983
1.0737686157226562

Evaluating...Epoch: 58
Prec: 0.8090, Recall: 0.7647, F1: 0.7862

[59] train_loss: 0.1825
[59] train_loss: 0.1634
[59] train_loss: 0.1387
[59] train_loss: 0.1416
[59] train_loss: 0.1565
[59] train_loss: 0.1579
1.0733981132507324

Evaluating...Epoch: 59
Prec: 0.8051, Recall: 0.7708, F1: 0.7876

[60] train_loss: 0.2303
[60] train_loss: 0.1767
[60] train_loss: 0.1657
[60] train_loss: 0.1484
[60] train_loss: 0.1538
[60] train_loss: 0.1608
1.0636188983917236

Evaluating...Epoch: 60
Prec: 0.8119, Recall: 0.7444, F1: 0.7767

[61] train_loss: 0.1906
[61] train_loss: 0.1502
[61] train_loss: 0.1613
[61] train_loss: 0.1531
[61] train_loss: 0.1606
[61] train_loss: 0.1692
1.0773651599884033

Evaluating...Epoch: 61
Prec: 0.7851, Recall: 0.7485, F1: 0.7664

[62] train_loss: 0.1571
[62] train_loss: 0.1327
[62] train_loss: 0.1708
[62] train_loss: 0.1696
[62] train_loss: 0.1615
[62] train_loss: 0.1596
1.0738842487335205

Evaluating...Epoch: 62
Prec: 0.8148, Recall: 0.7586, F1: 0.7857

[63] train_loss: 0.2063
[63] train_loss: 0.1627
[63] train_loss: 0.1603
[63] train_loss: 0.1532
[63] train_loss: 0.1551
[63] train_loss: 0.1535
1.0625293254852295

Evaluating...Epoch: 63
Prec: 0.8065, Recall: 0.7606, F1: 0.7829

[64] train_loss: 0.1749
[64] train_loss: 0.1509
[64] train_loss: 0.1691
[64] train_loss: 0.1667
[64] train_loss: 0.1633
[64] train_loss: 0.1856
1.0802829265594482

Evaluating...Epoch: 64
Prec: 0.7932, Recall: 0.7627, F1: 0.7777

[65] train_loss: 0.1730
[65] train_loss: 0.1330
[65] train_loss: 0.1277
[65] train_loss: 0.1158
[65] train_loss: 0.1217
[65] train_loss: 0.1387
1.0686161518096924

Evaluating...Epoch: 65
Prec: 0.8047, Recall: 0.7606, F1: 0.7821

[66] train_loss: 0.1912
[66] train_loss: 0.2016
[66] train_loss: 0.2054
[66] train_loss: 0.1822
[66] train_loss: 0.1854
[66] train_loss: 0.1777
1.0729305744171143

Evaluating...Epoch: 66
Prec: 0.8065, Recall: 0.7606, F1: 0.7829

[67] train_loss: 0.1497
[67] train_loss: 0.1192
[67] train_loss: 0.1248
[67] train_loss: 0.1225
[67] train_loss: 0.1332
[67] train_loss: 0.1451
1.0725910663604736

Evaluating...Epoch: 67
Prec: 0.8043, Recall: 0.7586, F1: 0.7808

[68] train_loss: 0.2832
[68] train_loss: 0.2108
[68] train_loss: 0.2078
[68] train_loss: 0.1870
[68] train_loss: 0.1807
[68] train_loss: 0.1843
1.065183401107788

Evaluating...Epoch: 68
Prec: 0.8463, Recall: 0.7485, F1: 0.7944
model saved to random1_layers5_15res/best_model.pt
New best model saved!

[69] train_loss: 0.1535
[69] train_loss: 0.1458
[69] train_loss: 0.1481
[69] train_loss: 0.1345
[69] train_loss: 0.1261
[69] train_loss: 0.1429
1.0789451599121094

Evaluating...Epoch: 69
Prec: 0.8033, Recall: 0.7789, F1: 0.7909

[70] train_loss: 0.1979
[70] train_loss: 0.1798
[70] train_loss: 0.1686
[70] train_loss: 0.1487
[70] train_loss: 0.1770
[70] train_loss: 0.1975
1.0780518054962158

Evaluating...Epoch: 70
Prec: 0.8038, Recall: 0.7647, F1: 0.7838

[71] train_loss: 0.2122
[71] train_loss: 0.1940
[71] train_loss: 0.1738
[71] train_loss: 0.1611
[71] train_loss: 0.1704
[71] train_loss: 0.1680
1.0686290264129639

Evaluating...Epoch: 71
Prec: 0.8013, Recall: 0.7769, F1: 0.7889

[72] train_loss: 0.1739
[72] train_loss: 0.1312
[72] train_loss: 0.1252
[72] train_loss: 0.1153
[72] train_loss: 0.1248
[72] train_loss: 0.1168
1.0778388977050781

Evaluating...Epoch: 72
Prec: 0.8033, Recall: 0.7951, F1: 0.7992
model saved to random1_layers5_15res/best_model.pt
New best model saved!

[73] train_loss: 0.2079
[73] train_loss: 0.1452
[73] train_loss: 0.1464
[73] train_loss: 0.1294
[73] train_loss: 0.1389
[73] train_loss: 0.1344
1.077282428741455

Evaluating...Epoch: 73
Prec: 0.7946, Recall: 0.7769, F1: 0.7856

[74] train_loss: 0.1645
[74] train_loss: 0.1503
[74] train_loss: 0.1286
[74] train_loss: 0.1340
[74] train_loss: 0.1455
[74] train_loss: 0.1454
1.0678610801696777

Evaluating...Epoch: 74
Prec: 0.8198, Recall: 0.7566, F1: 0.7869

[75] train_loss: 0.1500
[75] train_loss: 0.1226
[75] train_loss: 0.1237
[75] train_loss: 0.1274
[75] train_loss: 0.1323
[75] train_loss: 0.1451
1.0685200691223145

Evaluating...Epoch: 75
Prec: 0.8078, Recall: 0.7586, F1: 0.7824

[76] train_loss: 0.1461
[76] train_loss: 0.1162
[76] train_loss: 0.1313
[76] train_loss: 0.1073
[76] train_loss: 0.1026
[76] train_loss: 0.1137
1.0696015357971191

Evaluating...Epoch: 76
Prec: 0.7979, Recall: 0.7688, F1: 0.7831

[77] train_loss: 0.1226
[77] train_loss: 0.1197
[77] train_loss: 0.1312
[77] train_loss: 0.1162
[77] train_loss: 0.1119
[77] train_loss: 0.1324
1.054438591003418

Evaluating...Epoch: 77
Prec: 0.8039, Recall: 0.7566, F1: 0.7795

[78] train_loss: 0.1226
[78] train_loss: 0.0950
[78] train_loss: 0.1246
[78] train_loss: 0.1227
[78] train_loss: 0.1179
[78] train_loss: 0.1247
1.0720133781433105

Evaluating...Epoch: 78
Prec: 0.7762, Recall: 0.7809, F1: 0.7786

[79] train_loss: 0.0982
[79] train_loss: 0.0922
[79] train_loss: 0.0951
[79] train_loss: 0.1021
[79] train_loss: 0.1000
[79] train_loss: 0.1201
1.0728678703308105

Evaluating...Epoch: 79
Prec: 0.8122, Recall: 0.7809, F1: 0.7963

[80] train_loss: 0.1037
[80] train_loss: 0.1197
[80] train_loss: 0.1250
[80] train_loss: 0.1184
[80] train_loss: 0.1166
[80] train_loss: 0.1122
1.0656232833862305

Evaluating...Epoch: 80
Prec: 0.8017, Recall: 0.7708, F1: 0.7859

[81] train_loss: 0.0683
[81] train_loss: 0.0904
[81] train_loss: 0.0803
[81] train_loss: 0.0923
[81] train_loss: 0.0949
[81] train_loss: 0.0980
1.0759084224700928

Evaluating...Epoch: 81
Prec: 0.7908, Recall: 0.7667, F1: 0.7786

[82] train_loss: 0.1543
[82] train_loss: 0.1332
[82] train_loss: 0.1376
[82] train_loss: 0.1283
[82] train_loss: 0.1207
[82] train_loss: 0.1189
1.0730564594268799

Evaluating...Epoch: 82
Prec: 0.8056, Recall: 0.7566, F1: 0.7803

[83] train_loss: 0.1157
[83] train_loss: 0.0937
[83] train_loss: 0.1130
[83] train_loss: 0.1125
[83] train_loss: 0.1192
[83] train_loss: 0.1119
1.0608549118041992

Evaluating...Epoch: 83
Prec: 0.7896, Recall: 0.7688, F1: 0.7790

[84] train_loss: 0.0832
[84] train_loss: 0.0925
[84] train_loss: 0.0848
[84] train_loss: 0.0782
[84] train_loss: 0.1202
[84] train_loss: 0.1152
1.0611844062805176

Evaluating...Epoch: 84
Prec: 0.7863, Recall: 0.7688, F1: 0.7774

[85] train_loss: 0.1373
[85] train_loss: 0.1210
[85] train_loss: 0.1185
[85] train_loss: 0.1052
[85] train_loss: 0.1050
[85] train_loss: 0.1146
1.057586669921875

Evaluating...Epoch: 85
Prec: 0.7520, Recall: 0.7688, F1: 0.7603

[86] train_loss: 0.2308
[86] train_loss: 0.1798
[86] train_loss: 0.1885
[86] train_loss: 0.1616
[86] train_loss: 0.1520
[86] train_loss: 0.1435
1.0580341815948486

Evaluating...Epoch: 86
Prec: 0.7817, Recall: 0.7992, F1: 0.7904

[87] train_loss: 0.0893
[87] train_loss: 0.0777
[87] train_loss: 0.1017
[87] train_loss: 0.0913
[87] train_loss: 0.0908
[87] train_loss: 0.0966
1.078019380569458

Evaluating...Epoch: 87
Prec: 0.7854, Recall: 0.7647, F1: 0.7749

[88] train_loss: 0.1463
[88] train_loss: 0.1144
[88] train_loss: 0.1217
[88] train_loss: 0.1042
[88] train_loss: 0.1059
[88] train_loss: 0.1097
1.0659587383270264

Evaluating...Epoch: 88
Prec: 0.8088, Recall: 0.7809, F1: 0.7946

[89] train_loss: 0.0538
[89] train_loss: 0.0821
[89] train_loss: 0.0720
[89] train_loss: 0.0744
[89] train_loss: 0.0946
[89] train_loss: 0.0846
1.0749907493591309

Evaluating...Epoch: 89
Prec: 0.7971, Recall: 0.7728, F1: 0.7848

[90] train_loss: 0.0791
[90] train_loss: 0.0901
[90] train_loss: 0.0863
[90] train_loss: 0.0743
[90] train_loss: 0.0740
[90] train_loss: 0.0717
1.0775437355041504

Evaluating...Epoch: 90
Prec: 0.7946, Recall: 0.7769, F1: 0.7856

[91] train_loss: 0.1625
[91] train_loss: 0.1175
[91] train_loss: 0.1045
[91] train_loss: 0.0863
[91] train_loss: 0.0845
[91] train_loss: 0.0955
1.1195282936096191

Evaluating...Epoch: 91
Prec: 0.7701, Recall: 0.7951, F1: 0.7824

[92] train_loss: 0.1263
[92] train_loss: 0.0999
[92] train_loss: 0.0907
[92] train_loss: 0.1029
[92] train_loss: 0.0963
[92] train_loss: 0.0886
1.075796127319336

Evaluating...Epoch: 92
Prec: 0.7992, Recall: 0.7667, F1: 0.7826

Training ended with 93 epochs.
Final result:
Prec: 0.8033, Recall: 0.7951, F1: 0.7992
loading vocab and embedding matrix from ../data/16res
size of vocab: 3214
shape of loaded embedding matrix: (3214, 300)
Generating mappings
Loading data from ../data/16res with batch size 16...
95 batches created for ../data/16res/train.json
29 batches created for ../data/16res/test.json
Building model...
1341903
[1] train_loss: 13.4980
[1] train_loss: 9.8537
[1] train_loss: 8.5139
[1] train_loss: 7.5717
[1] train_loss: 6.9969
[1] train_loss: 6.5186
[1] train_loss: 6.0937
[1] train_loss: 5.8857
[1] train_loss: 5.6831
1.2212858200073242

Evaluating...Epoch: 1
Prec: 0.8500, Recall: 0.4218, F1: 0.5638
model saved to random1_layers0_16res/best_model.pt
New best model saved!

[2] train_loss: 4.5569
[2] train_loss: 4.0547
[2] train_loss: 4.0632
[2] train_loss: 3.9028
[2] train_loss: 3.8373
[2] train_loss: 3.7280
[2] train_loss: 3.6042
[2] train_loss: 3.6273
[2] train_loss: 3.6161
1.2567191123962402

Evaluating...Epoch: 2
Prec: 0.8580, Recall: 0.5649, F1: 0.6812
model saved to random1_layers0_16res/best_model.pt
New best model saved!

[3] train_loss: 3.8420
[3] train_loss: 3.3915
[3] train_loss: 3.4478
[3] train_loss: 3.3212
[3] train_loss: 3.3037
[3] train_loss: 3.2032
[3] train_loss: 3.0868
[3] train_loss: 3.1108
[3] train_loss: 3.1194
1.2093844413757324

Evaluating...Epoch: 3
Prec: 0.8082, Recall: 0.6756, F1: 0.7360
model saved to random1_layers0_16res/best_model.pt
New best model saved!

[4] train_loss: 3.4932
[4] train_loss: 3.1397
[4] train_loss: 3.1855
[4] train_loss: 3.0087
[4] train_loss: 2.9536
[4] train_loss: 2.8925
[4] train_loss: 2.7801
[4] train_loss: 2.8204
[4] train_loss: 2.8041
1.2093546390533447

Evaluating...Epoch: 4
Prec: 0.8089, Recall: 0.7271, F1: 0.7658
model saved to random1_layers0_16res/best_model.pt
New best model saved!

[5] train_loss: 3.1554
[5] train_loss: 2.7905
[5] train_loss: 2.8509
[5] train_loss: 2.6845
[5] train_loss: 2.6351
[5] train_loss: 2.5736
[5] train_loss: 2.4719
[5] train_loss: 2.4965
[5] train_loss: 2.5098
1.2136223316192627

Evaluating...Epoch: 5
Prec: 0.8694, Recall: 0.6985, F1: 0.7746
model saved to random1_layers0_16res/best_model.pt
New best model saved!

[6] train_loss: 2.9166
[6] train_loss: 2.6616
[6] train_loss: 2.6625
[6] train_loss: 2.4587
[6] train_loss: 2.4335
[6] train_loss: 2.3737
[6] train_loss: 2.2884
[6] train_loss: 2.3038
[6] train_loss: 2.2946
1.1980595588684082

Evaluating...Epoch: 6
Prec: 0.8462, Recall: 0.7137, F1: 0.7743

[7] train_loss: 2.5787
[7] train_loss: 2.3100
[7] train_loss: 2.3212
[7] train_loss: 2.1666
[7] train_loss: 2.1589
[7] train_loss: 2.1545
[7] train_loss: 2.0859
[7] train_loss: 2.1112
[7] train_loss: 2.1246
1.1992528438568115

Evaluating...Epoch: 7
Prec: 0.8565, Recall: 0.7634, F1: 0.8073
model saved to random1_layers0_16res/best_model.pt
New best model saved!

[8] train_loss: 2.4703
[8] train_loss: 2.2218
[8] train_loss: 2.2510
[8] train_loss: 2.0983
[8] train_loss: 2.0905
[8] train_loss: 2.0347
[8] train_loss: 1.9660
[8] train_loss: 1.9698
[8] train_loss: 1.9668
1.267326831817627

Evaluating...Epoch: 8
Prec: 0.8483, Recall: 0.7576, F1: 0.8004

[9] train_loss: 2.2895
[9] train_loss: 2.1040
[9] train_loss: 2.0651
[9] train_loss: 1.9090
[9] train_loss: 1.8916
[9] train_loss: 1.8367
[9] train_loss: 1.7574
[9] train_loss: 1.7932
[9] train_loss: 1.8040
1.1936514377593994

Evaluating...Epoch: 9
Prec: 0.8559, Recall: 0.7595, F1: 0.8049

[10] train_loss: 2.0602
[10] train_loss: 1.9222
[10] train_loss: 1.9312
[10] train_loss: 1.7915
[10] train_loss: 1.7866
[10] train_loss: 1.7484
[10] train_loss: 1.6831
[10] train_loss: 1.7076
[10] train_loss: 1.7108
1.2065811157226562

Evaluating...Epoch: 10
Prec: 0.8613, Recall: 0.7824, F1: 0.8200
model saved to random1_layers0_16res/best_model.pt
New best model saved!

[11] train_loss: 1.9318
[11] train_loss: 1.7616
[11] train_loss: 1.7807
[11] train_loss: 1.6093
[11] train_loss: 1.6002
[11] train_loss: 1.5633
[11] train_loss: 1.5077
[11] train_loss: 1.5192
[11] train_loss: 1.5341
1.2100615501403809

Evaluating...Epoch: 11
Prec: 0.8586, Recall: 0.8111, F1: 0.8342
model saved to random1_layers0_16res/best_model.pt
New best model saved!

[12] train_loss: 1.7762
[12] train_loss: 1.6178
[12] train_loss: 1.5907
[12] train_loss: 1.4866
[12] train_loss: 1.4584
[12] train_loss: 1.4549
[12] train_loss: 1.4157
[12] train_loss: 1.4433
[12] train_loss: 1.4584
1.214709758758545

Evaluating...Epoch: 12
Prec: 0.8401, Recall: 0.8321, F1: 0.8360
model saved to random1_layers0_16res/best_model.pt
New best model saved!

[13] train_loss: 1.5607
[13] train_loss: 1.4988
[13] train_loss: 1.5959
[13] train_loss: 1.4904
[13] train_loss: 1.4766
[13] train_loss: 1.4420
[13] train_loss: 1.3771
[13] train_loss: 1.4105
[13] train_loss: 1.4142
1.2099299430847168

Evaluating...Epoch: 13
Prec: 0.8589, Recall: 0.8130, F1: 0.8353

[14] train_loss: 1.4550
[14] train_loss: 1.3709
[14] train_loss: 1.3767
[14] train_loss: 1.3007
[14] train_loss: 1.3380
[14] train_loss: 1.3139
[14] train_loss: 1.2603
[14] train_loss: 1.2726
[14] train_loss: 1.2744
1.2120163440704346

Evaluating...Epoch: 14
Prec: 0.8525, Recall: 0.8053, F1: 0.8283

[15] train_loss: 1.4100
[15] train_loss: 1.3069
[15] train_loss: 1.4229
[15] train_loss: 1.3104
[15] train_loss: 1.2759
[15] train_loss: 1.2659
[15] train_loss: 1.2076
[15] train_loss: 1.2056
[15] train_loss: 1.2124
1.2138690948486328

Evaluating...Epoch: 15
Prec: 0.8497, Recall: 0.8092, F1: 0.8289

[16] train_loss: 1.3969
[16] train_loss: 1.2584
[16] train_loss: 1.2719
[16] train_loss: 1.1601
[16] train_loss: 1.2034
[16] train_loss: 1.2016
[16] train_loss: 1.1588
[16] train_loss: 1.1689
[16] train_loss: 1.1763
1.1993210315704346

Evaluating...Epoch: 16
Prec: 0.8405, Recall: 0.8244, F1: 0.8324

[17] train_loss: 1.3412
[17] train_loss: 1.2477
[17] train_loss: 1.2484
[17] train_loss: 1.1418
[17] train_loss: 1.1498
[17] train_loss: 1.1321
[17] train_loss: 1.1022
[17] train_loss: 1.1079
[17] train_loss: 1.1120
1.2097163200378418

Evaluating...Epoch: 17
Prec: 0.8506, Recall: 0.8149, F1: 0.8324

[18] train_loss: 1.2209
[18] train_loss: 1.1469
[18] train_loss: 1.1273
[18] train_loss: 1.0407
[18] train_loss: 1.0570
[18] train_loss: 1.0197
[18] train_loss: 0.9676
[18] train_loss: 0.9822
[18] train_loss: 0.9862
1.2132539749145508

Evaluating...Epoch: 18
Prec: 0.8376, Recall: 0.8168, F1: 0.8271

[19] train_loss: 1.2509
[19] train_loss: 1.1566
[19] train_loss: 1.0945
[19] train_loss: 1.0068
[19] train_loss: 1.0286
[19] train_loss: 1.0001
[19] train_loss: 0.9559
[19] train_loss: 0.9688
[19] train_loss: 0.9730
1.2049243450164795

Evaluating...Epoch: 19
Prec: 0.8333, Recall: 0.8302, F1: 0.8317

[20] train_loss: 1.1417
[20] train_loss: 1.0033
[20] train_loss: 1.0091
[20] train_loss: 0.9187
[20] train_loss: 0.9864
[20] train_loss: 0.9788
[20] train_loss: 0.9648
[20] train_loss: 0.9795
[20] train_loss: 0.9619
1.20627760887146

Evaluating...Epoch: 20
Prec: 0.8450, Recall: 0.8321, F1: 0.8385
model saved to random1_layers0_16res/best_model.pt
New best model saved!

[21] train_loss: 1.1004
[21] train_loss: 0.9270
[21] train_loss: 0.9310
[21] train_loss: 0.8579
[21] train_loss: 0.8725
[21] train_loss: 0.8569
[21] train_loss: 0.8217
[21] train_loss: 0.8490
[21] train_loss: 0.8738
1.2099683284759521

Evaluating...Epoch: 21
Prec: 0.8282, Recall: 0.8282, F1: 0.8282

[22] train_loss: 1.1378
[22] train_loss: 1.0099
[22] train_loss: 0.9871
[22] train_loss: 0.9009
[22] train_loss: 0.9185
[22] train_loss: 0.9121
[22] train_loss: 0.8791
[22] train_loss: 0.8841
[22] train_loss: 0.8979
1.2067039012908936

Evaluating...Epoch: 22
Prec: 0.8619, Recall: 0.8340, F1: 0.8477
model saved to random1_layers0_16res/best_model.pt
New best model saved!

[23] train_loss: 0.9441
[23] train_loss: 0.8515
[23] train_loss: 0.7927
[23] train_loss: 0.7631
[23] train_loss: 0.8245
[23] train_loss: 0.8214
[23] train_loss: 0.8017
[23] train_loss: 0.8098
[23] train_loss: 0.8110
1.206355333328247

Evaluating...Epoch: 23
Prec: 0.8668, Recall: 0.8321, F1: 0.8491
model saved to random1_layers0_16res/best_model.pt
New best model saved!

[24] train_loss: 0.8390
[24] train_loss: 0.7974
[24] train_loss: 0.8171
[24] train_loss: 0.7324
[24] train_loss: 0.7644
[24] train_loss: 0.7397
[24] train_loss: 0.7218
[24] train_loss: 0.7467
[24] train_loss: 0.7409
1.2110729217529297

Evaluating...Epoch: 24
Prec: 0.8439, Recall: 0.8149, F1: 0.8291

[25] train_loss: 0.8309
[25] train_loss: 0.7263
[25] train_loss: 0.7610
[25] train_loss: 0.7004
[25] train_loss: 0.7218
[25] train_loss: 0.6924
[25] train_loss: 0.6583
[25] train_loss: 0.6623
[25] train_loss: 0.6659
1.266512155532837

Evaluating...Epoch: 25
Prec: 0.8362, Recall: 0.8282, F1: 0.8322

[26] train_loss: 0.7590
[26] train_loss: 0.6835
[26] train_loss: 0.6861
[26] train_loss: 0.6424
[26] train_loss: 0.6473
[26] train_loss: 0.6615
[26] train_loss: 0.6306
[26] train_loss: 0.6434
[26] train_loss: 0.6652
1.2084052562713623

Evaluating...Epoch: 26
Prec: 0.8632, Recall: 0.8187, F1: 0.8404

[27] train_loss: 0.7007
[27] train_loss: 0.6807
[27] train_loss: 0.6713
[27] train_loss: 0.6324
[27] train_loss: 0.6802
[27] train_loss: 0.6701
[27] train_loss: 0.6448
[27] train_loss: 0.6665
[27] train_loss: 0.6740
1.205594778060913

Evaluating...Epoch: 27
Prec: 0.8753, Recall: 0.8302, F1: 0.8521
model saved to random1_layers0_16res/best_model.pt
New best model saved!

[28] train_loss: 0.6045
[28] train_loss: 0.5400
[28] train_loss: 0.6093
[28] train_loss: 0.5604
[28] train_loss: 0.6027
[28] train_loss: 0.6094
[28] train_loss: 0.5879
[28] train_loss: 0.5948
[28] train_loss: 0.6099
1.210474967956543

Evaluating...Epoch: 28
Prec: 0.8665, Recall: 0.8053, F1: 0.8348

[29] train_loss: 0.6262
[29] train_loss: 0.5928
[29] train_loss: 0.6236
[29] train_loss: 0.5739
[29] train_loss: 0.5848
[29] train_loss: 0.5676
[29] train_loss: 0.5484
[29] train_loss: 0.5609
[29] train_loss: 0.5695
1.197261095046997

Evaluating...Epoch: 29
Prec: 0.8716, Recall: 0.8034, F1: 0.8361

[30] train_loss: 0.6631
[30] train_loss: 0.6115
[30] train_loss: 0.6180
[30] train_loss: 0.5939
[30] train_loss: 0.6087
[30] train_loss: 0.5945
[30] train_loss: 0.5756
[30] train_loss: 0.5785
[30] train_loss: 0.5808
1.1986112594604492

Evaluating...Epoch: 30
Prec: 0.8606, Recall: 0.8130, F1: 0.8361

[31] train_loss: 0.5206
[31] train_loss: 0.5230
[31] train_loss: 0.5249
[31] train_loss: 0.4888
[31] train_loss: 0.5458
[31] train_loss: 0.5170
[31] train_loss: 0.4943
[31] train_loss: 0.4906
[31] train_loss: 0.5190
1.2715351581573486

Evaluating...Epoch: 31
Prec: 0.8665, Recall: 0.8302, F1: 0.8480

[32] train_loss: 0.6150
[32] train_loss: 0.5593
[32] train_loss: 0.5805
[32] train_loss: 0.5150
[32] train_loss: 0.5397
[32] train_loss: 0.5306
[32] train_loss: 0.5122
[32] train_loss: 0.5121
[32] train_loss: 0.5460
1.2143909931182861

Evaluating...Epoch: 32
Prec: 0.8513, Recall: 0.8302, F1: 0.8406

[33] train_loss: 0.6476
[33] train_loss: 0.5356
[33] train_loss: 0.5366
[33] train_loss: 0.5117
[33] train_loss: 0.5102
[33] train_loss: 0.4951
[33] train_loss: 0.4803
[33] train_loss: 0.4870
[33] train_loss: 0.5033
1.2078468799591064

Evaluating...Epoch: 33
Prec: 0.8577, Recall: 0.8397, F1: 0.8486

[34] train_loss: 0.5837
[34] train_loss: 0.4869
[34] train_loss: 0.4827
[34] train_loss: 0.4276
[34] train_loss: 0.4396
[34] train_loss: 0.4257
[34] train_loss: 0.4026
[34] train_loss: 0.4007
[34] train_loss: 0.4070
1.2134976387023926

Evaluating...Epoch: 34
Prec: 0.8773, Recall: 0.8187, F1: 0.8470

[35] train_loss: 0.5004
[35] train_loss: 0.4239
[35] train_loss: 0.4404
[35] train_loss: 0.4081
[35] train_loss: 0.4259
[35] train_loss: 0.4346
[35] train_loss: 0.4158
[35] train_loss: 0.4145
[35] train_loss: 0.4285
1.205561876296997

Evaluating...Epoch: 35
Prec: 0.8653, Recall: 0.8092, F1: 0.8363

[36] train_loss: 0.5550
[36] train_loss: 0.4664
[36] train_loss: 0.4709
[36] train_loss: 0.4293
[36] train_loss: 0.4373
[36] train_loss: 0.4457
[36] train_loss: 0.4440
[36] train_loss: 0.4401
[36] train_loss: 0.4488
1.2003114223480225

Evaluating...Epoch: 36
Prec: 0.8780, Recall: 0.8244, F1: 0.8504

[37] train_loss: 0.4867
[37] train_loss: 0.4059
[37] train_loss: 0.3994
[37] train_loss: 0.3921
[37] train_loss: 0.3909
[37] train_loss: 0.3939
[37] train_loss: 0.3721
[37] train_loss: 0.3800
[37] train_loss: 0.3830
1.247257947921753

Evaluating...Epoch: 37
Prec: 0.8723, Recall: 0.8340, F1: 0.8527
model saved to random1_layers0_16res/best_model.pt
New best model saved!

[38] train_loss: 0.5216
[38] train_loss: 0.4155
[38] train_loss: 0.4449
[38] train_loss: 0.4009
[38] train_loss: 0.4341
[38] train_loss: 0.4276
[38] train_loss: 0.4117
[38] train_loss: 0.4072
[38] train_loss: 0.4109
1.2134513854980469

Evaluating...Epoch: 38
Prec: 0.8931, Recall: 0.8130, F1: 0.8511

[39] train_loss: 0.5650
[39] train_loss: 0.4602
[39] train_loss: 0.4951
[39] train_loss: 0.4522
[39] train_loss: 0.4339
[39] train_loss: 0.4192
[39] train_loss: 0.3924
[39] train_loss: 0.4002
[39] train_loss: 0.4263
1.2136619091033936

Evaluating...Epoch: 39
Prec: 0.8680, Recall: 0.8282, F1: 0.8477

[40] train_loss: 0.4143
[40] train_loss: 0.3803
[40] train_loss: 0.3837
[40] train_loss: 0.3516
[40] train_loss: 0.3803
[40] train_loss: 0.3660
[40] train_loss: 0.3515
[40] train_loss: 0.3467
[40] train_loss: 0.3484
1.199397087097168

Evaluating...Epoch: 40
Prec: 0.8891, Recall: 0.8263, F1: 0.8566
model saved to random1_layers0_16res/best_model.pt
New best model saved!

[41] train_loss: 0.3836
[41] train_loss: 0.3633
[41] train_loss: 0.3411
[41] train_loss: 0.3138
[41] train_loss: 0.3325
[41] train_loss: 0.3185
[41] train_loss: 0.3233
[41] train_loss: 0.3271
[41] train_loss: 0.3302
1.2048094272613525

Evaluating...Epoch: 41
Prec: 0.8998, Recall: 0.8225, F1: 0.8594
model saved to random1_layers0_16res/best_model.pt
New best model saved!

[42] train_loss: 0.2862
[42] train_loss: 0.3578
[42] train_loss: 0.3401
[42] train_loss: 0.3248
[42] train_loss: 0.3129
[42] train_loss: 0.3112
[42] train_loss: 0.2870
[42] train_loss: 0.2965
[42] train_loss: 0.2987
1.2149910926818848

Evaluating...Epoch: 42
Prec: 0.8951, Recall: 0.8302, F1: 0.8614
model saved to random1_layers0_16res/best_model.pt
New best model saved!

[43] train_loss: 0.3771
[43] train_loss: 0.3673
[43] train_loss: 0.3708
[43] train_loss: 0.3546
[43] train_loss: 0.3510
[43] train_loss: 0.3464
[43] train_loss: 0.3550
[43] train_loss: 0.3511
[43] train_loss: 0.3517
1.2584753036499023

Evaluating...Epoch: 43
Prec: 0.8854, Recall: 0.8111, F1: 0.8466

[44] train_loss: 0.3180
[44] train_loss: 0.3111
[44] train_loss: 0.3339
[44] train_loss: 0.3083
[44] train_loss: 0.3080
[44] train_loss: 0.3044
[44] train_loss: 0.2983
[44] train_loss: 0.3194
[44] train_loss: 0.3237
1.2059454917907715

Evaluating...Epoch: 44
Prec: 0.8905, Recall: 0.8225, F1: 0.8552

[45] train_loss: 0.3614
[45] train_loss: 0.3128
[45] train_loss: 0.3253
[45] train_loss: 0.3041
[45] train_loss: 0.3137
[45] train_loss: 0.3049
[45] train_loss: 0.2910
[45] train_loss: 0.2873
[45] train_loss: 0.2911
1.2165634632110596

Evaluating...Epoch: 45
Prec: 0.8973, Recall: 0.8340, F1: 0.8645
model saved to random1_layers0_16res/best_model.pt
New best model saved!

[46] train_loss: 0.3586
[46] train_loss: 0.3134
[46] train_loss: 0.3146
[46] train_loss: 0.2985
[46] train_loss: 0.3144
[46] train_loss: 0.3200
[46] train_loss: 0.3036
[46] train_loss: 0.3090
[46] train_loss: 0.3123
1.2171401977539062

Evaluating...Epoch: 46
Prec: 0.8876, Recall: 0.8435, F1: 0.8650
model saved to random1_layers0_16res/best_model.pt
New best model saved!

[47] train_loss: 0.3611
[47] train_loss: 0.3102
[47] train_loss: 0.3501
[47] train_loss: 0.3215
[47] train_loss: 0.3297
[47] train_loss: 0.3420
[47] train_loss: 0.3234
[47] train_loss: 0.3251
[47] train_loss: 0.3221
1.2105107307434082

Evaluating...Epoch: 47
Prec: 0.9131, Recall: 0.8225, F1: 0.8655
model saved to random1_layers0_16res/best_model.pt
New best model saved!

[48] train_loss: 0.3282
[48] train_loss: 0.3203
[48] train_loss: 0.2986
[48] train_loss: 0.2919
[48] train_loss: 0.2946
[48] train_loss: 0.2800
[48] train_loss: 0.2633
[48] train_loss: 0.2549
[48] train_loss: 0.2721
1.2089686393737793

Evaluating...Epoch: 48
Prec: 0.9021, Recall: 0.8263, F1: 0.8625

[49] train_loss: 0.2371
[49] train_loss: 0.2679
[49] train_loss: 0.2532
[49] train_loss: 0.2482
[49] train_loss: 0.2420
[49] train_loss: 0.2384
[49] train_loss: 0.2389
[49] train_loss: 0.2286
[49] train_loss: 0.2425
1.2014307975769043

Evaluating...Epoch: 49
Prec: 0.8887, Recall: 0.8225, F1: 0.8543

[50] train_loss: 0.2625
[50] train_loss: 0.2420
[50] train_loss: 0.2857
[50] train_loss: 0.2597
[50] train_loss: 0.2770
[50] train_loss: 0.2703
[50] train_loss: 0.2598
[50] train_loss: 0.2563
[50] train_loss: 0.2620
1.2049880027770996

Evaluating...Epoch: 50
Prec: 0.9002, Recall: 0.8092, F1: 0.8523

[51] train_loss: 0.3451
[51] train_loss: 0.3296
[51] train_loss: 0.3236
[51] train_loss: 0.2814
[51] train_loss: 0.3008
[51] train_loss: 0.3010
[51] train_loss: 0.2807
[51] train_loss: 0.2768
[51] train_loss: 0.2865
1.210451364517212

Evaluating...Epoch: 51
Prec: 0.9068, Recall: 0.8168, F1: 0.8594

[52] train_loss: 0.3443
[52] train_loss: 0.2657
[52] train_loss: 0.2604
[52] train_loss: 0.2320
[52] train_loss: 0.2306
[52] train_loss: 0.2338
[52] train_loss: 0.2290
[52] train_loss: 0.2176
[52] train_loss: 0.2268
1.2002122402191162

Evaluating...Epoch: 52
Prec: 0.8979, Recall: 0.8225, F1: 0.8586

[53] train_loss: 0.2283
[53] train_loss: 0.1996
[53] train_loss: 0.2005
[53] train_loss: 0.1892
[53] train_loss: 0.1917
[53] train_loss: 0.2043
[53] train_loss: 0.2058
[53] train_loss: 0.2231
[53] train_loss: 0.2190
1.2098162174224854

Evaluating...Epoch: 53
Prec: 0.9030, Recall: 0.8168, F1: 0.8577

[54] train_loss: 0.3500
[54] train_loss: 0.2612
[54] train_loss: 0.2761
[54] train_loss: 0.2527
[54] train_loss: 0.2582
[54] train_loss: 0.2561
[54] train_loss: 0.2387
[54] train_loss: 0.2652
[54] train_loss: 0.2703
1.2562038898468018

Evaluating...Epoch: 54
Prec: 0.8896, Recall: 0.8149, F1: 0.8506

[55] train_loss: 0.2494
[55] train_loss: 0.2091
[55] train_loss: 0.2058
[55] train_loss: 0.1970
[55] train_loss: 0.2297
[55] train_loss: 0.2282
[55] train_loss: 0.2192
[55] train_loss: 0.2150
[55] train_loss: 0.2200
1.1976957321166992

Evaluating...Epoch: 55
Prec: 0.8811, Recall: 0.8206, F1: 0.8498

[56] train_loss: 0.2153
[56] train_loss: 0.2325
[56] train_loss: 0.2248
[56] train_loss: 0.2279
[56] train_loss: 0.2384
[56] train_loss: 0.2424
[56] train_loss: 0.2322
[56] train_loss: 0.2303
[56] train_loss: 0.2193
1.1944987773895264

Evaluating...Epoch: 56
Prec: 0.8768, Recall: 0.8149, F1: 0.8447

[57] train_loss: 0.2883
[57] train_loss: 0.2148
[57] train_loss: 0.2133
[57] train_loss: 0.2114
[57] train_loss: 0.2125
[57] train_loss: 0.2039
[57] train_loss: 0.1930
[57] train_loss: 0.2013
[57] train_loss: 0.2041
1.2053005695343018

Evaluating...Epoch: 57
Prec: 0.9006, Recall: 0.8130, F1: 0.8546

[58] train_loss: 0.2829
[58] train_loss: 0.2533
[58] train_loss: 0.2484
[58] train_loss: 0.2379
[58] train_loss: 0.2303
[58] train_loss: 0.2302
[58] train_loss: 0.2194
[58] train_loss: 0.2162
[58] train_loss: 0.2139
1.2067360877990723

Evaluating...Epoch: 58
Prec: 0.8896, Recall: 0.8149, F1: 0.8506

[59] train_loss: 0.2087
[59] train_loss: 0.2047
[59] train_loss: 0.2361
[59] train_loss: 0.2102
[59] train_loss: 0.1996
[59] train_loss: 0.1916
[59] train_loss: 0.1789
[59] train_loss: 0.1897
[59] train_loss: 0.1939
1.2061536312103271

Evaluating...Epoch: 59
Prec: 0.8839, Recall: 0.8282, F1: 0.8552

[60] train_loss: 0.2951
[60] train_loss: 0.2561
[60] train_loss: 0.2317
[60] train_loss: 0.2097
[60] train_loss: 0.1949
[60] train_loss: 0.2017
[60] train_loss: 0.1927
[60] train_loss: 0.1899
[60] train_loss: 0.1902
1.2678577899932861

Evaluating...Epoch: 60
Prec: 0.8940, Recall: 0.8206, F1: 0.8557

[61] train_loss: 0.2786
[61] train_loss: 0.2258
[61] train_loss: 0.2285
[61] train_loss: 0.2194
[61] train_loss: 0.2172
[61] train_loss: 0.2113
[61] train_loss: 0.1985
[61] train_loss: 0.2018
[61] train_loss: 0.1954
1.2124159336090088

Evaluating...Epoch: 61
Prec: 0.8794, Recall: 0.8073, F1: 0.8418

[62] train_loss: 0.2501
[62] train_loss: 0.2228
[62] train_loss: 0.2111
[62] train_loss: 0.2048
[62] train_loss: 0.2140
[62] train_loss: 0.2028
[62] train_loss: 0.1993
[62] train_loss: 0.1945
[62] train_loss: 0.1909
1.1997127532958984

Evaluating...Epoch: 62
Prec: 0.8910, Recall: 0.8111, F1: 0.8492

[63] train_loss: 0.3097
[63] train_loss: 0.2222
[63] train_loss: 0.1842
[63] train_loss: 0.1832
[63] train_loss: 0.1838
[63] train_loss: 0.1851
[63] train_loss: 0.1840
[63] train_loss: 0.1862
[63] train_loss: 0.1812
1.205948829650879

Evaluating...Epoch: 63
Prec: 0.8977, Recall: 0.8206, F1: 0.8574

[64] train_loss: 0.1783
[64] train_loss: 0.1498
[64] train_loss: 0.1717
[64] train_loss: 0.1714
[64] train_loss: 0.1710
[64] train_loss: 0.1709
[64] train_loss: 0.1594
[64] train_loss: 0.1576
[64] train_loss: 0.1660
1.2107419967651367

Evaluating...Epoch: 64
Prec: 0.9002, Recall: 0.8263, F1: 0.8617

[65] train_loss: 0.1603
[65] train_loss: 0.1648
[65] train_loss: 0.1479
[65] train_loss: 0.1513
[65] train_loss: 0.1534
[65] train_loss: 0.1735
[65] train_loss: 0.1754
[65] train_loss: 0.1743
[65] train_loss: 0.1744
1.2064268589019775

Evaluating...Epoch: 65
Prec: 0.9023, Recall: 0.8282, F1: 0.8637

[66] train_loss: 0.1907
[66] train_loss: 0.1645
[66] train_loss: 0.1452
[66] train_loss: 0.1527
[66] train_loss: 0.1819
[66] train_loss: 0.1683
[66] train_loss: 0.1725
[66] train_loss: 0.1693
[66] train_loss: 0.1744
1.2542564868927002

Evaluating...Epoch: 66
Prec: 0.9047, Recall: 0.8149, F1: 0.8574

[67] train_loss: 0.3148
[67] train_loss: 0.2335
[67] train_loss: 0.2046
[67] train_loss: 0.2134
[67] train_loss: 0.2133
[67] train_loss: 0.1946
[67] train_loss: 0.1868
[67] train_loss: 0.1823
[67] train_loss: 0.1782
1.2073962688446045

Evaluating...Epoch: 67
Prec: 0.9074, Recall: 0.8225, F1: 0.8629

Training ended with 68 epochs.
Final result:
Prec: 0.9131, Recall: 0.8225, F1: 0.8655
loading vocab and embedding matrix from ../data/16res
size of vocab: 3214
shape of loaded embedding matrix: (3214, 300)
Generating mappings
Loading data from ../data/16res with batch size 16...
95 batches created for ../data/16res/train.json
29 batches created for ../data/16res/test.json
Building model...
1382103
[1] train_loss: 14.2946
[1] train_loss: 10.3929
[1] train_loss: 8.9997
[1] train_loss: 8.0158
[1] train_loss: 7.4209
[1] train_loss: 6.9079
[1] train_loss: 6.4836
[1] train_loss: 6.2540
[1] train_loss: 6.0356
1.3409290313720703

Evaluating...Epoch: 1
Prec: 0.9420, Recall: 0.2481, F1: 0.3927
model saved to random1_layers1_16res/best_model.pt
New best model saved!

[2] train_loss: 4.6879
[2] train_loss: 4.2023
[2] train_loss: 4.1780
[2] train_loss: 3.9423
[2] train_loss: 3.8823
[2] train_loss: 3.7288
[2] train_loss: 3.6063
[2] train_loss: 3.6043
[2] train_loss: 3.5748
1.345818281173706

Evaluating...Epoch: 2
Prec: 0.8824, Recall: 0.5725, F1: 0.6944
model saved to random1_layers1_16res/best_model.pt
New best model saved!

[3] train_loss: 4.0006
[3] train_loss: 3.5206
[3] train_loss: 3.4987
[3] train_loss: 3.3112
[3] train_loss: 3.2715
[3] train_loss: 3.1806
[3] train_loss: 3.0675
[3] train_loss: 3.0943
[3] train_loss: 3.0791
1.3006727695465088

Evaluating...Epoch: 3
Prec: 0.8600, Recall: 0.6679, F1: 0.7519
model saved to random1_layers1_16res/best_model.pt
New best model saved!

[4] train_loss: 3.2950
[4] train_loss: 2.9360
[4] train_loss: 3.0055
[4] train_loss: 2.8604
[4] train_loss: 2.8453
[4] train_loss: 2.7568
[4] train_loss: 2.6708
[4] train_loss: 2.6881
[4] train_loss: 2.7037
1.3078927993774414

Evaluating...Epoch: 4
Prec: 0.8238, Recall: 0.7672, F1: 0.7945
model saved to random1_layers1_16res/best_model.pt
New best model saved!

[5] train_loss: 2.9791
[5] train_loss: 2.7098
[5] train_loss: 2.8083
[5] train_loss: 2.6285
[5] train_loss: 2.6252
[5] train_loss: 2.5555
[5] train_loss: 2.4479
[5] train_loss: 2.4532
[5] train_loss: 2.4524
1.3059568405151367

Evaluating...Epoch: 5
Prec: 0.8368, Recall: 0.7729, F1: 0.8036
model saved to random1_layers1_16res/best_model.pt
New best model saved!

[6] train_loss: 2.5625
[6] train_loss: 2.3437
[6] train_loss: 2.4565
[6] train_loss: 2.3306
[6] train_loss: 2.3652
[6] train_loss: 2.3139
[6] train_loss: 2.2229
[6] train_loss: 2.2651
[6] train_loss: 2.2745
1.2796716690063477

Evaluating...Epoch: 6
Prec: 0.8421, Recall: 0.7939, F1: 0.8173
model saved to random1_layers1_16res/best_model.pt
New best model saved!

[7] train_loss: 2.5472
[7] train_loss: 2.3015
[7] train_loss: 2.3524
[7] train_loss: 2.1939
[7] train_loss: 2.1571
[7] train_loss: 2.0996
[7] train_loss: 2.0327
[7] train_loss: 2.0654
[7] train_loss: 2.0646
1.3218212127685547

Evaluating...Epoch: 7
Prec: 0.8668, Recall: 0.8073, F1: 0.8360
model saved to random1_layers1_16res/best_model.pt
New best model saved!

[8] train_loss: 2.2761
[8] train_loss: 2.0551
[8] train_loss: 2.1231
[8] train_loss: 1.9834
[8] train_loss: 1.9900
[8] train_loss: 1.9381
[8] train_loss: 1.8509
[8] train_loss: 1.8821
[8] train_loss: 1.8926
1.369283676147461

Evaluating...Epoch: 8
Prec: 0.8201, Recall: 0.8092, F1: 0.8146

[9] train_loss: 1.9810
[9] train_loss: 1.8345
[9] train_loss: 1.8938
[9] train_loss: 1.7297
[9] train_loss: 1.7041
[9] train_loss: 1.6870
[9] train_loss: 1.6528
[9] train_loss: 1.6678
[9] train_loss: 1.6929
1.299259901046753

Evaluating...Epoch: 9
Prec: 0.8761, Recall: 0.7958, F1: 0.8340

[10] train_loss: 1.7404
[10] train_loss: 1.7707
[10] train_loss: 1.8453
[10] train_loss: 1.7258
[10] train_loss: 1.6786
[10] train_loss: 1.6118
[10] train_loss: 1.5650
[10] train_loss: 1.5789
[10] train_loss: 1.5919
1.2939555644989014

Evaluating...Epoch: 10
Prec: 0.8621, Recall: 0.8111, F1: 0.8358

[11] train_loss: 1.7161
[11] train_loss: 1.5650
[11] train_loss: 1.5814
[11] train_loss: 1.4936
[11] train_loss: 1.5007
[11] train_loss: 1.4461
[11] train_loss: 1.4066
[11] train_loss: 1.4307
[11] train_loss: 1.4400
1.2989366054534912

Evaluating...Epoch: 11
Prec: 0.8723, Recall: 0.8340, F1: 0.8527
model saved to random1_layers1_16res/best_model.pt
New best model saved!

[12] train_loss: 1.6172
[12] train_loss: 1.4764
[12] train_loss: 1.4894
[12] train_loss: 1.3930
[12] train_loss: 1.3896
[12] train_loss: 1.3473
[12] train_loss: 1.3010
[12] train_loss: 1.3153
[12] train_loss: 1.3359
1.2876560688018799

Evaluating...Epoch: 12
Prec: 0.8487, Recall: 0.8244, F1: 0.8364

[13] train_loss: 1.6519
[13] train_loss: 1.4478
[13] train_loss: 1.4474
[13] train_loss: 1.3678
[13] train_loss: 1.3955
[13] train_loss: 1.3481
[13] train_loss: 1.2942
[13] train_loss: 1.3081
[13] train_loss: 1.3198
1.295135259628296

Evaluating...Epoch: 13
Prec: 0.8591, Recall: 0.8378, F1: 0.8483

[14] train_loss: 1.4023
[14] train_loss: 1.3046
[14] train_loss: 1.2875
[14] train_loss: 1.1851
[14] train_loss: 1.2065
[14] train_loss: 1.1570
[14] train_loss: 1.1329
[14] train_loss: 1.1584
[14] train_loss: 1.1814
1.2823498249053955

Evaluating...Epoch: 14
Prec: 0.8903, Recall: 0.8206, F1: 0.8540
model saved to random1_layers1_16res/best_model.pt
New best model saved!

[15] train_loss: 1.4825
[15] train_loss: 1.2655
[15] train_loss: 1.2362
[15] train_loss: 1.1190
[15] train_loss: 1.1363
[15] train_loss: 1.1105
[15] train_loss: 1.0774
[15] train_loss: 1.0808
[15] train_loss: 1.0904
1.2895197868347168

Evaluating...Epoch: 15
Prec: 0.8390, Recall: 0.8550, F1: 0.8469

[16] train_loss: 1.0562
[16] train_loss: 1.0073
[16] train_loss: 1.1272
[16] train_loss: 1.0207
[16] train_loss: 1.0903
[16] train_loss: 1.0825
[16] train_loss: 1.0411
[16] train_loss: 1.0409
[16] train_loss: 1.0525
1.3026347160339355

Evaluating...Epoch: 16
Prec: 0.8688, Recall: 0.8340, F1: 0.8510

[17] train_loss: 1.0627
[17] train_loss: 0.9837
[17] train_loss: 0.9823
[17] train_loss: 0.9301
[17] train_loss: 0.9537
[17] train_loss: 0.9219
[17] train_loss: 0.9123
[17] train_loss: 0.9355
[17] train_loss: 0.9568
1.3036177158355713

Evaluating...Epoch: 17
Prec: 0.8243, Recall: 0.8416, F1: 0.8329

[18] train_loss: 1.1788
[18] train_loss: 1.0144
[18] train_loss: 0.9408
[18] train_loss: 0.8719
[18] train_loss: 0.9285
[18] train_loss: 0.9129
[18] train_loss: 0.8803
[18] train_loss: 0.8955
[18] train_loss: 0.9055
1.2972276210784912

Evaluating...Epoch: 18
Prec: 0.8671, Recall: 0.8340, F1: 0.8502

[19] train_loss: 0.8857
[19] train_loss: 0.8381
[19] train_loss: 0.9718
[19] train_loss: 0.8877
[19] train_loss: 0.8941
[19] train_loss: 0.8825
[19] train_loss: 0.8451
[19] train_loss: 0.8575
[19] train_loss: 0.8694
1.2987422943115234

Evaluating...Epoch: 19
Prec: 0.8280, Recall: 0.8359, F1: 0.8319

[20] train_loss: 0.8348
[20] train_loss: 0.7777
[20] train_loss: 0.8586
[20] train_loss: 0.7841
[20] train_loss: 0.8187
[20] train_loss: 0.7900
[20] train_loss: 0.7536
[20] train_loss: 0.7510
[20] train_loss: 0.7781
1.2919409275054932

Evaluating...Epoch: 20
Prec: 0.8453, Recall: 0.8550, F1: 0.8501

[21] train_loss: 0.7676
[21] train_loss: 0.7016
[21] train_loss: 0.7900
[21] train_loss: 0.7231
[21] train_loss: 0.7964
[21] train_loss: 0.7726
[21] train_loss: 0.7676
[21] train_loss: 0.7863
[21] train_loss: 0.8041
1.2956676483154297

Evaluating...Epoch: 21
Prec: 0.8648, Recall: 0.8664, F1: 0.8656
model saved to random1_layers1_16res/best_model.pt
New best model saved!

[22] train_loss: 1.1113
[22] train_loss: 0.9546
[22] train_loss: 0.9209
[22] train_loss: 0.8413
[22] train_loss: 0.8383
[22] train_loss: 0.7966
[22] train_loss: 0.7581
[22] train_loss: 0.7524
[22] train_loss: 0.7619
1.311650276184082

Evaluating...Epoch: 22
Prec: 0.8651, Recall: 0.8569, F1: 0.8610

[23] train_loss: 0.8708
[23] train_loss: 0.7964
[23] train_loss: 0.7548
[23] train_loss: 0.7157
[23] train_loss: 0.7615
[23] train_loss: 0.7617
[23] train_loss: 0.7204
[23] train_loss: 0.7415
[23] train_loss: 0.7636
1.2961597442626953

Evaluating...Epoch: 23
Prec: 0.8552, Recall: 0.8569, F1: 0.8561

[24] train_loss: 0.7054
[24] train_loss: 0.7077
[24] train_loss: 0.7428
[24] train_loss: 0.6824
[24] train_loss: 0.6887
[24] train_loss: 0.6693
[24] train_loss: 0.6568
[24] train_loss: 0.6629
[24] train_loss: 0.6845
1.3003692626953125

Evaluating...Epoch: 24
Prec: 0.8315, Recall: 0.8760, F1: 0.8532

[25] train_loss: 0.9003
[25] train_loss: 0.7045
[25] train_loss: 0.6954
[25] train_loss: 0.6328
[25] train_loss: 0.6767
[25] train_loss: 0.6580
[25] train_loss: 0.6391
[25] train_loss: 0.6455
[25] train_loss: 0.6410
1.3620615005493164

Evaluating...Epoch: 25
Prec: 0.8580, Recall: 0.8645, F1: 0.8612

[26] train_loss: 0.6174
[26] train_loss: 0.5624
[26] train_loss: 0.6198
[26] train_loss: 0.5737
[26] train_loss: 0.6369
[26] train_loss: 0.6073
[26] train_loss: 0.6035
[26] train_loss: 0.6402
[26] train_loss: 0.6385
1.3025267124176025

Evaluating...Epoch: 26
Prec: 0.8550, Recall: 0.8664, F1: 0.8607

[27] train_loss: 0.7243
[27] train_loss: 0.5836
[27] train_loss: 0.6371
[27] train_loss: 0.5596
[27] train_loss: 0.6014
[27] train_loss: 0.5681
[27] train_loss: 0.5609
[27] train_loss: 0.5691
[27] train_loss: 0.5777
1.302119255065918

Evaluating...Epoch: 27
Prec: 0.8389, Recall: 0.8645, F1: 0.8515

[28] train_loss: 0.5828
[28] train_loss: 0.5917
[28] train_loss: 0.6065
[28] train_loss: 0.5518
[28] train_loss: 0.5895
[28] train_loss: 0.5665
[28] train_loss: 0.5478
[28] train_loss: 0.5497
[28] train_loss: 0.5542
1.2981650829315186

Evaluating...Epoch: 28
Prec: 0.8794, Recall: 0.8492, F1: 0.8641

[29] train_loss: 0.5363
[29] train_loss: 0.5002
[29] train_loss: 0.4932
[29] train_loss: 0.4768
[29] train_loss: 0.5034
[29] train_loss: 0.4838
[29] train_loss: 0.4642
[29] train_loss: 0.4539
[29] train_loss: 0.4647
1.2936046123504639

Evaluating...Epoch: 29
Prec: 0.8767, Recall: 0.8550, F1: 0.8657
model saved to random1_layers1_16res/best_model.pt
New best model saved!

[30] train_loss: 0.5220
[30] train_loss: 0.4661
[30] train_loss: 0.4853
[30] train_loss: 0.4752
[30] train_loss: 0.4903
[30] train_loss: 0.4732
[30] train_loss: 0.4613
[30] train_loss: 0.4743
[30] train_loss: 0.4761
1.2994208335876465

Evaluating...Epoch: 30
Prec: 0.8821, Recall: 0.8569, F1: 0.8693
model saved to random1_layers1_16res/best_model.pt
New best model saved!

[31] train_loss: 0.5988
[31] train_loss: 0.4654
[31] train_loss: 0.4966
[31] train_loss: 0.4853
[31] train_loss: 0.4905
[31] train_loss: 0.4700
[31] train_loss: 0.4488
[31] train_loss: 0.4455
[31] train_loss: 0.4641
1.3581531047821045

Evaluating...Epoch: 31
Prec: 0.8723, Recall: 0.8473, F1: 0.8596

[32] train_loss: 0.5640
[32] train_loss: 0.4660
[32] train_loss: 0.4807
[32] train_loss: 0.4252
[32] train_loss: 0.4444
[32] train_loss: 0.4450
[32] train_loss: 0.4337
[32] train_loss: 0.4303
[32] train_loss: 0.4577
1.2794358730316162

Evaluating...Epoch: 32
Prec: 0.8862, Recall: 0.8473, F1: 0.8663

[33] train_loss: 0.3636
[33] train_loss: 0.3322
[33] train_loss: 0.4494
[33] train_loss: 0.4043
[33] train_loss: 0.4132
[33] train_loss: 0.4019
[33] train_loss: 0.3955
[33] train_loss: 0.4009
[33] train_loss: 0.4160
1.3052875995635986

Evaluating...Epoch: 33
Prec: 0.8752, Recall: 0.8569, F1: 0.8660

[34] train_loss: 0.4329
[34] train_loss: 0.3797
[34] train_loss: 0.3641
[34] train_loss: 0.3314
[34] train_loss: 0.3687
[34] train_loss: 0.3681
[34] train_loss: 0.3582
[34] train_loss: 0.3664
[34] train_loss: 0.3776
1.3037021160125732

Evaluating...Epoch: 34
Prec: 0.8622, Recall: 0.8359, F1: 0.8488

[35] train_loss: 0.3876
[35] train_loss: 0.3801
[35] train_loss: 0.3764
[35] train_loss: 0.3558
[35] train_loss: 0.3883
[35] train_loss: 0.3897
[35] train_loss: 0.3896
[35] train_loss: 0.3904
[35] train_loss: 0.3895
1.3072154521942139

Evaluating...Epoch: 35
Prec: 0.8826, Recall: 0.8321, F1: 0.8566

[36] train_loss: 0.5445
[36] train_loss: 0.5153
[36] train_loss: 0.4911
[36] train_loss: 0.4276
[36] train_loss: 0.4537
[36] train_loss: 0.4294
[36] train_loss: 0.4033
[36] train_loss: 0.4081
[36] train_loss: 0.4109
1.304626703262329

Evaluating...Epoch: 36
Prec: 0.8755, Recall: 0.8454, F1: 0.8602

[37] train_loss: 0.4340
[37] train_loss: 0.3879
[37] train_loss: 0.3954
[37] train_loss: 0.3472
[37] train_loss: 0.3636
[37] train_loss: 0.3646
[37] train_loss: 0.3643
[37] train_loss: 0.3801
[37] train_loss: 0.3808
1.360996961593628

Evaluating...Epoch: 37
Prec: 0.8547, Recall: 0.8760, F1: 0.8652

[38] train_loss: 0.4308
[38] train_loss: 0.4225
[38] train_loss: 0.4164
[38] train_loss: 0.3876
[38] train_loss: 0.3898
[38] train_loss: 0.3785
[38] train_loss: 0.3759
[38] train_loss: 0.3658
[38] train_loss: 0.3730
1.3024623394012451

Evaluating...Epoch: 38
Prec: 0.8822, Recall: 0.8435, F1: 0.8624

[39] train_loss: 0.2834
[39] train_loss: 0.3079
[39] train_loss: 0.3698
[39] train_loss: 0.3310
[39] train_loss: 0.3396
[39] train_loss: 0.3263
[39] train_loss: 0.3238
[39] train_loss: 0.3216
[39] train_loss: 0.3235
1.3044254779815674

Evaluating...Epoch: 39
Prec: 0.8900, Recall: 0.8492, F1: 0.8691

[40] train_loss: 0.4227
[40] train_loss: 0.3809
[40] train_loss: 0.3729
[40] train_loss: 0.3359
[40] train_loss: 0.3327
[40] train_loss: 0.3315
[40] train_loss: 0.3307
[40] train_loss: 0.3237
[40] train_loss: 0.3242
1.3008325099945068

Evaluating...Epoch: 40
Prec: 0.8705, Recall: 0.8721, F1: 0.8713
model saved to random1_layers1_16res/best_model.pt
New best model saved!

[41] train_loss: 0.3204
[41] train_loss: 0.3026
[41] train_loss: 0.3017
[41] train_loss: 0.2865
[41] train_loss: 0.2797
[41] train_loss: 0.2649
[41] train_loss: 0.2649
[41] train_loss: 0.2688
[41] train_loss: 0.2873
1.3063647747039795

Evaluating...Epoch: 41
Prec: 0.8854, Recall: 0.8702, F1: 0.8778
model saved to random1_layers1_16res/best_model.pt
New best model saved!

[42] train_loss: 0.4750
[42] train_loss: 0.3683
[42] train_loss: 0.3505
[42] train_loss: 0.3136
[42] train_loss: 0.3265
[42] train_loss: 0.3174
[42] train_loss: 0.3096
[42] train_loss: 0.2983
[42] train_loss: 0.2962
1.3085227012634277

Evaluating...Epoch: 42
Prec: 0.8889, Recall: 0.8550, F1: 0.8716

[43] train_loss: 0.2394
[43] train_loss: 0.2238
[43] train_loss: 0.2796
[43] train_loss: 0.2591
[43] train_loss: 0.2874
[43] train_loss: 0.2976
[43] train_loss: 0.2804
[43] train_loss: 0.3042
[43] train_loss: 0.3183
1.3591334819793701

Evaluating...Epoch: 43
Prec: 0.8952, Recall: 0.8473, F1: 0.8706

[44] train_loss: 0.2784
[44] train_loss: 0.2284
[44] train_loss: 0.2575
[44] train_loss: 0.2571
[44] train_loss: 0.2670
[44] train_loss: 0.2701
[44] train_loss: 0.2627
[44] train_loss: 0.2647
[44] train_loss: 0.2671
1.3033294677734375

Evaluating...Epoch: 44
Prec: 0.8824, Recall: 0.8588, F1: 0.8704

[45] train_loss: 0.2968
[45] train_loss: 0.2941
[45] train_loss: 0.2813
[45] train_loss: 0.2548
[45] train_loss: 0.2589
[45] train_loss: 0.2569
[45] train_loss: 0.2582
[45] train_loss: 0.2663
[45] train_loss: 0.3053
1.3067247867584229

Evaluating...Epoch: 45
Prec: 0.8524, Recall: 0.8378, F1: 0.8450

[46] train_loss: 0.3506
[46] train_loss: 0.3187
[46] train_loss: 0.3075
[46] train_loss: 0.2959
[46] train_loss: 0.2933
[46] train_loss: 0.3227
[46] train_loss: 0.3205
[46] train_loss: 0.3174
[46] train_loss: 0.3175
1.3078505992889404

Evaluating...Epoch: 46
Prec: 0.8629, Recall: 0.8531, F1: 0.8580

[47] train_loss: 0.2538
[47] train_loss: 0.2714
[47] train_loss: 0.2756
[47] train_loss: 0.2708
[47] train_loss: 0.2774
[47] train_loss: 0.2693
[47] train_loss: 0.2632
[47] train_loss: 0.2564
[47] train_loss: 0.2659
1.308884620666504

Evaluating...Epoch: 47
Prec: 0.8720, Recall: 0.8454, F1: 0.8585

[48] train_loss: 0.2655
[48] train_loss: 0.2383
[48] train_loss: 0.2311
[48] train_loss: 0.2084
[48] train_loss: 0.2213
[48] train_loss: 0.2068
[48] train_loss: 0.1990
[48] train_loss: 0.1946
[48] train_loss: 0.2032
1.3048148155212402

Evaluating...Epoch: 48
Prec: 0.9047, Recall: 0.8511, F1: 0.8771

[49] train_loss: 0.2550
[49] train_loss: 0.2635
[49] train_loss: 0.2807
[49] train_loss: 0.2630
[49] train_loss: 0.2603
[49] train_loss: 0.2693
[49] train_loss: 0.2713
[49] train_loss: 0.2721
[49] train_loss: 0.2875
1.2992258071899414

Evaluating...Epoch: 49
Prec: 0.8787, Recall: 0.8435, F1: 0.8608

[50] train_loss: 0.2263
[50] train_loss: 0.3131
[50] train_loss: 0.3044
[50] train_loss: 0.2625
[50] train_loss: 0.2668
[50] train_loss: 0.2419
[50] train_loss: 0.2452
[50] train_loss: 0.2562
[50] train_loss: 0.2620
1.2931933403015137

Evaluating...Epoch: 50
Prec: 0.8854, Recall: 0.8550, F1: 0.8699

[51] train_loss: 0.2909
[51] train_loss: 0.2469
[51] train_loss: 0.2465
[51] train_loss: 0.2298
[51] train_loss: 0.2375
[51] train_loss: 0.2370
[51] train_loss: 0.2277
[51] train_loss: 0.2254
[51] train_loss: 0.2306
1.2826008796691895

Evaluating...Epoch: 51
Prec: 0.8896, Recall: 0.8454, F1: 0.8669

[52] train_loss: 0.1413
[52] train_loss: 0.1506
[52] train_loss: 0.1606
[52] train_loss: 0.1609
[52] train_loss: 0.1900
[52] train_loss: 0.2040
[52] train_loss: 0.2013
[52] train_loss: 0.2010
[52] train_loss: 0.2206
1.2782695293426514

Evaluating...Epoch: 52
Prec: 0.9153, Recall: 0.8244, F1: 0.8675

[53] train_loss: 0.3184
[53] train_loss: 0.2276
[53] train_loss: 0.2261
[53] train_loss: 0.1947
[53] train_loss: 0.2010
[53] train_loss: 0.2019
[53] train_loss: 0.1977
[53] train_loss: 0.1986
[53] train_loss: 0.2075
1.2963385581970215

Evaluating...Epoch: 53
Prec: 0.8875, Recall: 0.8282, F1: 0.8569

[54] train_loss: 0.2202
[54] train_loss: 0.2193
[54] train_loss: 0.2317
[54] train_loss: 0.2116
[54] train_loss: 0.1989
[54] train_loss: 0.1943
[54] train_loss: 0.1825
[54] train_loss: 0.1789
[54] train_loss: 0.1873
1.3605141639709473

Evaluating...Epoch: 54
Prec: 0.8748, Recall: 0.8531, F1: 0.8638

[55] train_loss: 0.2853
[55] train_loss: 0.2223
[55] train_loss: 0.2065
[55] train_loss: 0.2132
[55] train_loss: 0.1964
[55] train_loss: 0.1938
[55] train_loss: 0.2003
[55] train_loss: 0.1940
[55] train_loss: 0.1962
1.3015058040618896

Evaluating...Epoch: 55
Prec: 0.8656, Recall: 0.8359, F1: 0.8505

[56] train_loss: 0.1940
[56] train_loss: 0.1497
[56] train_loss: 0.1682
[56] train_loss: 0.1697
[56] train_loss: 0.1655
[56] train_loss: 0.1644
[56] train_loss: 0.1582
[56] train_loss: 0.1698
[56] train_loss: 0.1788
1.2920827865600586

Evaluating...Epoch: 56
Prec: 0.9014, Recall: 0.8378, F1: 0.8684

[57] train_loss: 0.2148
[57] train_loss: 0.1970
[57] train_loss: 0.1953
[57] train_loss: 0.1675
[57] train_loss: 0.1802
[57] train_loss: 0.1805
[57] train_loss: 0.1818
[57] train_loss: 0.1801
[57] train_loss: 0.1829
1.2831823825836182

Evaluating...Epoch: 57
Prec: 0.8896, Recall: 0.8302, F1: 0.8588

[58] train_loss: 0.2085
[58] train_loss: 0.1651
[58] train_loss: 0.1665
[58] train_loss: 0.1524
[58] train_loss: 0.1693
[58] train_loss: 0.1714
[58] train_loss: 0.1688
[58] train_loss: 0.1761
[58] train_loss: 0.1766
1.2788429260253906

Evaluating...Epoch: 58
Prec: 0.8940, Recall: 0.8206, F1: 0.8557

[59] train_loss: 0.1600
[59] train_loss: 0.1617
[59] train_loss: 0.1717
[59] train_loss: 0.1504
[59] train_loss: 0.1654
[59] train_loss: 0.1580
[59] train_loss: 0.1479
[59] train_loss: 0.1465
[59] train_loss: 0.1611
1.289417028427124

Evaluating...Epoch: 59
Prec: 0.8963, Recall: 0.8244, F1: 0.8588

[60] train_loss: 0.1303
[60] train_loss: 0.1270
[60] train_loss: 0.1438
[60] train_loss: 0.1482
[60] train_loss: 0.1436
[60] train_loss: 0.1490
[60] train_loss: 0.1428
[60] train_loss: 0.1440
[60] train_loss: 0.1607
1.3577852249145508

Evaluating...Epoch: 60
Prec: 0.8702, Recall: 0.8187, F1: 0.8437

[61] train_loss: 0.2006
[61] train_loss: 0.1818
[61] train_loss: 0.2057
[61] train_loss: 0.1791
[61] train_loss: 0.1885
[61] train_loss: 0.1896
[61] train_loss: 0.1829
[61] train_loss: 0.1879
[61] train_loss: 0.1798
1.2777540683746338

Evaluating...Epoch: 61
Prec: 0.8907, Recall: 0.8244, F1: 0.8563

Training ended with 62 epochs.
Final result:
Prec: 0.8854, Recall: 0.8702, F1: 0.8778
loading vocab and embedding matrix from ../data/16res
size of vocab: 3214
shape of loaded embedding matrix: (3214, 300)
Generating mappings
Loading data from ../data/16res with batch size 16...
95 batches created for ../data/16res/train.json
29 batches created for ../data/16res/test.json
Building model...
1422303
[1] train_loss: 13.0265
[1] train_loss: 9.7147
[1] train_loss: 8.4670
[1] train_loss: 7.6013
[1] train_loss: 7.1119
[1] train_loss: 6.6629
[1] train_loss: 6.2619
[1] train_loss: 6.0555
[1] train_loss: 5.8574
1.4029738903045654

Evaluating...Epoch: 1
Prec: 0.9320, Recall: 0.2615, F1: 0.4083
model saved to random1_layers2_16res/best_model.pt
New best model saved!

[2] train_loss: 4.4153
[2] train_loss: 4.0066
[2] train_loss: 3.9826
[2] train_loss: 3.7737
[2] train_loss: 3.7132
[2] train_loss: 3.5846
[2] train_loss: 3.4665
[2] train_loss: 3.4698
[2] train_loss: 3.4413
1.4272677898406982

Evaluating...Epoch: 2
Prec: 0.8621, Recall: 0.6202, F1: 0.7214
model saved to random1_layers2_16res/best_model.pt
New best model saved!

[3] train_loss: 3.8186
[3] train_loss: 3.3749
[3] train_loss: 3.3667
[3] train_loss: 3.2047
[3] train_loss: 3.1724
[3] train_loss: 3.0874
[3] train_loss: 2.9790
[3] train_loss: 2.9949
[3] train_loss: 2.9937
1.3834807872772217

Evaluating...Epoch: 3
Prec: 0.8024, Recall: 0.7595, F1: 0.7804
model saved to random1_layers2_16res/best_model.pt
New best model saved!

[4] train_loss: 3.2554
[4] train_loss: 2.9548
[4] train_loss: 3.0568
[4] train_loss: 2.8998
[4] train_loss: 2.8542
[4] train_loss: 2.7443
[4] train_loss: 2.6331
[4] train_loss: 2.6715
[4] train_loss: 2.6871
1.390113115310669

Evaluating...Epoch: 4
Prec: 0.7657, Recall: 0.8168, F1: 0.7904
model saved to random1_layers2_16res/best_model.pt
New best model saved!

[5] train_loss: 2.8882
[5] train_loss: 2.5975
[5] train_loss: 2.6766
[5] train_loss: 2.5502
[5] train_loss: 2.5329
[5] train_loss: 2.4597
[5] train_loss: 2.3760
[5] train_loss: 2.3895
[5] train_loss: 2.3955
1.3998615741729736

Evaluating...Epoch: 5
Prec: 0.7981, Recall: 0.8073, F1: 0.8027
model saved to random1_layers2_16res/best_model.pt
New best model saved!

[6] train_loss: 2.6834
[6] train_loss: 2.4705
[6] train_loss: 2.5391
[6] train_loss: 2.3868
[6] train_loss: 2.3641
[6] train_loss: 2.2979
[6] train_loss: 2.2126
[6] train_loss: 2.2181
[6] train_loss: 2.2364
1.386786937713623

Evaluating...Epoch: 6
Prec: 0.7644, Recall: 0.8359, F1: 0.7985

[7] train_loss: 2.3809
[7] train_loss: 2.1865
[7] train_loss: 2.3199
[7] train_loss: 2.1740
[7] train_loss: 2.1457
[7] train_loss: 2.0492
[7] train_loss: 1.9519
[7] train_loss: 1.9776
[7] train_loss: 1.9908
1.3867998123168945

Evaluating...Epoch: 7
Prec: 0.7892, Recall: 0.8359, F1: 0.8119
model saved to random1_layers2_16res/best_model.pt
New best model saved!

[8] train_loss: 2.1330
[8] train_loss: 1.9528
[8] train_loss: 2.1165
[8] train_loss: 1.9976
[8] train_loss: 2.0269
[8] train_loss: 1.9538
[8] train_loss: 1.8776
[8] train_loss: 1.9096
[8] train_loss: 1.9144
1.4433777332305908

Evaluating...Epoch: 8
Prec: 0.8497, Recall: 0.8092, F1: 0.8289
model saved to random1_layers2_16res/best_model.pt
New best model saved!

[9] train_loss: 2.0957
[9] train_loss: 1.9773
[9] train_loss: 1.9185
[9] train_loss: 1.7703
[9] train_loss: 1.7784
[9] train_loss: 1.7400
[9] train_loss: 1.6750
[9] train_loss: 1.6956
[9] train_loss: 1.7081
1.370905876159668

Evaluating...Epoch: 9
Prec: 0.8577, Recall: 0.8282, F1: 0.8427
model saved to random1_layers2_16res/best_model.pt
New best model saved!

[10] train_loss: 1.8391
[10] train_loss: 1.7189
[10] train_loss: 1.7314
[10] train_loss: 1.6320
[10] train_loss: 1.6586
[10] train_loss: 1.6466
[10] train_loss: 1.5897
[10] train_loss: 1.6014
[10] train_loss: 1.6278
1.3859601020812988

Evaluating...Epoch: 10
Prec: 0.8671, Recall: 0.8092, F1: 0.8371

[11] train_loss: 1.7772
[11] train_loss: 1.6297
[11] train_loss: 1.6448
[11] train_loss: 1.5437
[11] train_loss: 1.5537
[11] train_loss: 1.4974
[11] train_loss: 1.4647
[11] train_loss: 1.4678
[11] train_loss: 1.4819
1.373661994934082

Evaluating...Epoch: 11
Prec: 0.8778, Recall: 0.8092, F1: 0.8421

[12] train_loss: 1.5748
[12] train_loss: 1.4862
[12] train_loss: 1.5124
[12] train_loss: 1.4216
[12] train_loss: 1.4259
[12] train_loss: 1.3989
[12] train_loss: 1.3552
[12] train_loss: 1.3680
[12] train_loss: 1.3778
1.3931500911712646

Evaluating...Epoch: 12
Prec: 0.8877, Recall: 0.7996, F1: 0.8414

[13] train_loss: 1.5249
[13] train_loss: 1.3620
[13] train_loss: 1.4626
[13] train_loss: 1.3473
[13] train_loss: 1.3618
[13] train_loss: 1.3207
[13] train_loss: 1.2881
[13] train_loss: 1.2710
[13] train_loss: 1.2736
1.3905818462371826

Evaluating...Epoch: 13
Prec: 0.8687, Recall: 0.8206, F1: 0.8440
model saved to random1_layers2_16res/best_model.pt
New best model saved!

[14] train_loss: 1.5475
[14] train_loss: 1.3787
[14] train_loss: 1.3520
[14] train_loss: 1.2424
[14] train_loss: 1.2417
[14] train_loss: 1.2181
[14] train_loss: 1.1765
[14] train_loss: 1.1715
[14] train_loss: 1.1976
1.446347713470459

Evaluating...Epoch: 14
Prec: 0.8953, Recall: 0.7996, F1: 0.8448
model saved to random1_layers2_16res/best_model.pt
New best model saved!

[15] train_loss: 1.4100
[15] train_loss: 1.3219
[15] train_loss: 1.3391
[15] train_loss: 1.2647
[15] train_loss: 1.2342
[15] train_loss: 1.1999
[15] train_loss: 1.1561
[15] train_loss: 1.1711
[15] train_loss: 1.1812
1.383521556854248

Evaluating...Epoch: 15
Prec: 0.8701, Recall: 0.8435, F1: 0.8566
model saved to random1_layers2_16res/best_model.pt
New best model saved!

[16] train_loss: 1.1380
[16] train_loss: 1.0477
[16] train_loss: 1.1030
[16] train_loss: 1.0418
[16] train_loss: 1.0687
[16] train_loss: 1.0453
[16] train_loss: 1.0256
[16] train_loss: 1.0460
[16] train_loss: 1.0621
1.3769407272338867

Evaluating...Epoch: 16
Prec: 0.8718, Recall: 0.8435, F1: 0.8574
model saved to random1_layers2_16res/best_model.pt
New best model saved!

[17] train_loss: 1.2327
[17] train_loss: 1.1263
[17] train_loss: 1.0596
[17] train_loss: 0.9869
[17] train_loss: 1.0364
[17] train_loss: 1.0198
[17] train_loss: 0.9957
[17] train_loss: 0.9917
[17] train_loss: 0.9958
1.3902060985565186

Evaluating...Epoch: 17
Prec: 0.8750, Recall: 0.8416, F1: 0.8580
model saved to random1_layers2_16res/best_model.pt
New best model saved!

[18] train_loss: 1.0673
[18] train_loss: 0.9712
[18] train_loss: 0.9474
[18] train_loss: 0.8777
[18] train_loss: 0.9011
[18] train_loss: 0.9083
[18] train_loss: 0.9054
[18] train_loss: 0.9187
[18] train_loss: 0.9428
1.3970060348510742

Evaluating...Epoch: 18
Prec: 0.8834, Recall: 0.8531, F1: 0.8680
model saved to random1_layers2_16res/best_model.pt
New best model saved!

[19] train_loss: 0.9366
[19] train_loss: 0.9538
[19] train_loss: 0.9610
[19] train_loss: 0.8792
[19] train_loss: 0.8874
[19] train_loss: 0.8528
[19] train_loss: 0.8252
[19] train_loss: 0.8406
[19] train_loss: 0.8461
1.3865997791290283

Evaluating...Epoch: 19
Prec: 0.8594, Recall: 0.8397, F1: 0.8494

[20] train_loss: 0.9847
[20] train_loss: 0.8306
[20] train_loss: 0.8896
[20] train_loss: 0.8272
[20] train_loss: 0.8361
[20] train_loss: 0.8291
[20] train_loss: 0.8275
[20] train_loss: 0.8313
[20] train_loss: 0.8386
1.3802666664123535

Evaluating...Epoch: 20
Prec: 0.8612, Recall: 0.8645, F1: 0.8629

[21] train_loss: 0.9076
[21] train_loss: 0.7942
[21] train_loss: 0.8361
[21] train_loss: 0.7635
[21] train_loss: 0.7942
[21] train_loss: 0.7617
[21] train_loss: 0.7383
[21] train_loss: 0.7454
[21] train_loss: 0.7608
1.3743407726287842

Evaluating...Epoch: 21
Prec: 0.8552, Recall: 0.8454, F1: 0.8503

[22] train_loss: 0.7522
[22] train_loss: 0.7585
[22] train_loss: 0.7911
[22] train_loss: 0.7429
[22] train_loss: 0.7522
[22] train_loss: 0.7274
[22] train_loss: 0.7070
[22] train_loss: 0.7154
[22] train_loss: 0.7361
1.3774595260620117

Evaluating...Epoch: 22
Prec: 0.8790, Recall: 0.8321, F1: 0.8549

[23] train_loss: 0.7444
[23] train_loss: 0.6973
[23] train_loss: 0.7451
[23] train_loss: 0.7113
[23] train_loss: 0.7632
[23] train_loss: 0.7866
[23] train_loss: 0.7502
[23] train_loss: 0.7329
[23] train_loss: 0.7472
1.3898849487304688

Evaluating...Epoch: 23
Prec: 0.8296, Recall: 0.8550, F1: 0.8421

[24] train_loss: 0.8179
[24] train_loss: 0.7368
[24] train_loss: 0.7744
[24] train_loss: 0.7535
[24] train_loss: 0.7676
[24] train_loss: 0.7416
[24] train_loss: 0.7084
[24] train_loss: 0.7051
[24] train_loss: 0.7136
1.3866748809814453

Evaluating...Epoch: 24
Prec: 0.8721, Recall: 0.8588, F1: 0.8654

[25] train_loss: 0.6737
[25] train_loss: 0.6650
[25] train_loss: 0.7058
[25] train_loss: 0.6537
[25] train_loss: 0.6587
[25] train_loss: 0.6531
[25] train_loss: 0.6465
[25] train_loss: 0.6476
[25] train_loss: 0.6580
1.442720890045166

Evaluating...Epoch: 25
Prec: 0.8571, Recall: 0.8817, F1: 0.8692
model saved to random1_layers2_16res/best_model.pt
New best model saved!

[26] train_loss: 0.7641
[26] train_loss: 0.7054
[26] train_loss: 0.7176
[26] train_loss: 0.6711
[26] train_loss: 0.6998
[26] train_loss: 0.6573
[26] train_loss: 0.6462
[26] train_loss: 0.6438
[26] train_loss: 0.6608
1.3633527755737305

Evaluating...Epoch: 26
Prec: 0.8723, Recall: 0.8607, F1: 0.8665

[27] train_loss: 0.5880
[27] train_loss: 0.5245
[27] train_loss: 0.5541
[27] train_loss: 0.5215
[27] train_loss: 0.5821
[27] train_loss: 0.5634
[27] train_loss: 0.5538
[27] train_loss: 0.5532
[27] train_loss: 0.5676
1.3624212741851807

Evaluating...Epoch: 27
Prec: 0.9179, Recall: 0.8531, F1: 0.8843
model saved to random1_layers2_16res/best_model.pt
New best model saved!

[28] train_loss: 0.6423
[28] train_loss: 0.6321
[28] train_loss: 0.6478
[28] train_loss: 0.5980
[28] train_loss: 0.6112
[28] train_loss: 0.6123
[28] train_loss: 0.6015
[28] train_loss: 0.6040
[28] train_loss: 0.6010
1.3667831420898438

Evaluating...Epoch: 28
Prec: 0.8590, Recall: 0.8607, F1: 0.8599

[29] train_loss: 0.7903
[29] train_loss: 0.6648
[29] train_loss: 0.6405
[29] train_loss: 0.5892
[29] train_loss: 0.6082
[29] train_loss: 0.5869
[29] train_loss: 0.5570
[29] train_loss: 0.5706
[29] train_loss: 0.5745
1.3646950721740723

Evaluating...Epoch: 29
Prec: 0.9045, Recall: 0.8492, F1: 0.8760

[30] train_loss: 0.5323
[30] train_loss: 0.4937
[30] train_loss: 0.4791
[30] train_loss: 0.4766
[30] train_loss: 0.5130
[30] train_loss: 0.5176
[30] train_loss: 0.5020
[30] train_loss: 0.4992
[30] train_loss: 0.4956
1.3949594497680664

Evaluating...Epoch: 30
Prec: 0.8791, Recall: 0.8607, F1: 0.8698

[31] train_loss: 0.5236
[31] train_loss: 0.4500
[31] train_loss: 0.4685
[31] train_loss: 0.4363
[31] train_loss: 0.4701
[31] train_loss: 0.4452
[31] train_loss: 0.4586
[31] train_loss: 0.4754
[31] train_loss: 0.4839
1.4418599605560303

Evaluating...Epoch: 31
Prec: 0.9031, Recall: 0.8359, F1: 0.8682

[32] train_loss: 0.5598
[32] train_loss: 0.4941
[32] train_loss: 0.4706
[32] train_loss: 0.4515
[32] train_loss: 0.4944
[32] train_loss: 0.5015
[32] train_loss: 0.4883
[32] train_loss: 0.4871
[32] train_loss: 0.5027
1.3807578086853027

Evaluating...Epoch: 32
Prec: 0.8820, Recall: 0.8416, F1: 0.8613

[33] train_loss: 0.5047
[33] train_loss: 0.4870
[33] train_loss: 0.5135
[33] train_loss: 0.4755
[33] train_loss: 0.4683
[33] train_loss: 0.4498
[33] train_loss: 0.4388
[33] train_loss: 0.4329
[33] train_loss: 0.4367
1.3814072608947754

Evaluating...Epoch: 33
Prec: 0.8825, Recall: 0.8454, F1: 0.8635

[34] train_loss: 0.5357
[34] train_loss: 0.4752
[34] train_loss: 0.5136
[34] train_loss: 0.4866
[34] train_loss: 0.5066
[34] train_loss: 0.5079
[34] train_loss: 0.4768
[34] train_loss: 0.4647
[34] train_loss: 0.4705
1.3683936595916748

Evaluating...Epoch: 34
Prec: 0.8449, Recall: 0.8626, F1: 0.8536

[35] train_loss: 0.5019
[35] train_loss: 0.4724
[35] train_loss: 0.4942
[35] train_loss: 0.4637
[35] train_loss: 0.4740
[35] train_loss: 0.4619
[35] train_loss: 0.4493
[35] train_loss: 0.4596
[35] train_loss: 0.4774
1.3680241107940674

Evaluating...Epoch: 35
Prec: 0.8702, Recall: 0.8569, F1: 0.8635

[36] train_loss: 0.3799
[36] train_loss: 0.3904
[36] train_loss: 0.4009
[36] train_loss: 0.3804
[36] train_loss: 0.3786
[36] train_loss: 0.3618
[36] train_loss: 0.3481
[36] train_loss: 0.3767
[36] train_loss: 0.3811
1.3799822330474854

Evaluating...Epoch: 36
Prec: 0.8792, Recall: 0.8473, F1: 0.8630

[37] train_loss: 0.5042
[37] train_loss: 0.4151
[37] train_loss: 0.3911
[37] train_loss: 0.3600
[37] train_loss: 0.3664
[37] train_loss: 0.3542
[37] train_loss: 0.3483
[37] train_loss: 0.3471
[37] train_loss: 0.3595
1.4456086158752441

Evaluating...Epoch: 37
Prec: 0.8777, Recall: 0.8492, F1: 0.8632

[38] train_loss: 0.4837
[38] train_loss: 0.3824
[38] train_loss: 0.3652
[38] train_loss: 0.3442
[38] train_loss: 0.3439
[38] train_loss: 0.3364
[38] train_loss: 0.3244
[38] train_loss: 0.3366
[38] train_loss: 0.3474
1.383169174194336

Evaluating...Epoch: 38
Prec: 0.8642, Recall: 0.8626, F1: 0.8634

[39] train_loss: 0.3563
[39] train_loss: 0.3587
[39] train_loss: 0.3554
[39] train_loss: 0.3579
[39] train_loss: 0.3582
[39] train_loss: 0.3544
[39] train_loss: 0.3429
[39] train_loss: 0.3452
[39] train_loss: 0.3457
1.3860645294189453

Evaluating...Epoch: 39
Prec: 0.8795, Recall: 0.8359, F1: 0.8571

[40] train_loss: 0.5121
[40] train_loss: 0.4056
[40] train_loss: 0.3724
[40] train_loss: 0.3500
[40] train_loss: 0.3471
[40] train_loss: 0.3484
[40] train_loss: 0.3464
[40] train_loss: 0.3425
[40] train_loss: 0.3515
1.390369176864624

Evaluating...Epoch: 40
Prec: 0.8876, Recall: 0.8435, F1: 0.8650

[41] train_loss: 0.4454
[41] train_loss: 0.3919
[41] train_loss: 0.3555
[41] train_loss: 0.3320
[41] train_loss: 0.3307
[41] train_loss: 0.3311
[41] train_loss: 0.3188
[41] train_loss: 0.3377
[41] train_loss: 0.3569
1.3798139095306396

Evaluating...Epoch: 41
Prec: 0.8656, Recall: 0.8607, F1: 0.8632

[42] train_loss: 0.3686
[42] train_loss: 0.3637
[42] train_loss: 0.3625
[42] train_loss: 0.3340
[42] train_loss: 0.3272
[42] train_loss: 0.3264
[42] train_loss: 0.3165
[42] train_loss: 0.3109
[42] train_loss: 0.3159
1.3761098384857178

Evaluating...Epoch: 42
Prec: 0.8720, Recall: 0.8454, F1: 0.8585

[43] train_loss: 0.3000
[43] train_loss: 0.2731
[43] train_loss: 0.3265
[43] train_loss: 0.2934
[43] train_loss: 0.3019
[43] train_loss: 0.3015
[43] train_loss: 0.2857
[43] train_loss: 0.2960
[43] train_loss: 0.2976
1.4345753192901611

Evaluating...Epoch: 43
Prec: 0.8770, Recall: 0.8569, F1: 0.8668

[44] train_loss: 0.2794
[44] train_loss: 0.2629
[44] train_loss: 0.2591
[44] train_loss: 0.2472
[44] train_loss: 0.2669
[44] train_loss: 0.2603
[44] train_loss: 0.2526
[44] train_loss: 0.2659
[44] train_loss: 0.2892
1.3793058395385742

Evaluating...Epoch: 44
Prec: 0.8822, Recall: 0.8435, F1: 0.8624

[45] train_loss: 0.3441
[45] train_loss: 0.3299
[45] train_loss: 0.3579
[45] train_loss: 0.3062
[45] train_loss: 0.2918
[45] train_loss: 0.2725
[45] train_loss: 0.2699
[45] train_loss: 0.2831
[45] train_loss: 0.2893
1.3828856945037842

Evaluating...Epoch: 45
Prec: 0.8833, Recall: 0.8378, F1: 0.8599

[46] train_loss: 0.3267
[46] train_loss: 0.2984
[46] train_loss: 0.3166
[46] train_loss: 0.2839
[46] train_loss: 0.2922
[46] train_loss: 0.2892
[46] train_loss: 0.2761
[46] train_loss: 0.2737
[46] train_loss: 0.2755
1.3875231742858887

Evaluating...Epoch: 46
Prec: 0.9055, Recall: 0.8225, F1: 0.8620

[47] train_loss: 0.3851
[47] train_loss: 0.3440
[47] train_loss: 0.3570
[47] train_loss: 0.3360
[47] train_loss: 0.3061
[47] train_loss: 0.2948
[47] train_loss: 0.2795
[47] train_loss: 0.2734
[47] train_loss: 0.2844
1.3784875869750977

Evaluating...Epoch: 47
Prec: 0.8802, Recall: 0.8550, F1: 0.8674

Training ended with 48 epochs.
Final result:
Prec: 0.9179, Recall: 0.8531, F1: 0.8843
loading vocab and embedding matrix from ../data/16res
size of vocab: 3214
shape of loaded embedding matrix: (3214, 300)
Generating mappings
Loading data from ../data/16res with batch size 16...
95 batches created for ../data/16res/train.json
29 batches created for ../data/16res/test.json
Building model...
1462503
[1] train_loss: 11.6564
[1] train_loss: 8.9223
[1] train_loss: 7.8918
[1] train_loss: 7.1157
[1] train_loss: 6.6888
[1] train_loss: 6.2981
[1] train_loss: 5.9312
[1] train_loss: 5.7626
[1] train_loss: 5.5791
1.4445891380310059

Evaluating...Epoch: 1
Prec: 0.7560, Recall: 0.6031, F1: 0.6709
model saved to random1_layers3_16res/best_model.pt
New best model saved!

[2] train_loss: 4.3615
[2] train_loss: 3.8832
[2] train_loss: 3.8943
[2] train_loss: 3.7053
[2] train_loss: 3.6899
[2] train_loss: 3.5822
[2] train_loss: 3.4488
[2] train_loss: 3.4692
[2] train_loss: 3.4398
1.4461534023284912

Evaluating...Epoch: 2
Prec: 0.7219, Recall: 0.7729, F1: 0.7465
model saved to random1_layers3_16res/best_model.pt
New best model saved!

[3] train_loss: 3.5941
[3] train_loss: 3.2509
[3] train_loss: 3.3195
[3] train_loss: 3.1743
[3] train_loss: 3.1464
[3] train_loss: 3.0606
[3] train_loss: 2.9614
[3] train_loss: 2.9758
[3] train_loss: 2.9751
1.4041571617126465

Evaluating...Epoch: 3
Prec: 0.7152, Recall: 0.8244, F1: 0.7660
model saved to random1_layers3_16res/best_model.pt
New best model saved!

[4] train_loss: 3.2956
[4] train_loss: 2.9743
[4] train_loss: 3.0396
[4] train_loss: 2.8563
[4] train_loss: 2.8768
[4] train_loss: 2.7901
[4] train_loss: 2.6941
[4] train_loss: 2.6982
[4] train_loss: 2.7061
1.4095792770385742

Evaluating...Epoch: 4
Prec: 0.7404, Recall: 0.8435, F1: 0.7886
model saved to random1_layers3_16res/best_model.pt
New best model saved!

[5] train_loss: 3.0185
[5] train_loss: 2.7543
[5] train_loss: 2.7416
[5] train_loss: 2.5889
[5] train_loss: 2.5907
[5] train_loss: 2.5183
[5] train_loss: 2.4153
[5] train_loss: 2.4168
[5] train_loss: 2.4167
1.4169301986694336

Evaluating...Epoch: 5
Prec: 0.7551, Recall: 0.8416, F1: 0.7960
model saved to random1_layers3_16res/best_model.pt
New best model saved!

[6] train_loss: 2.6882
[6] train_loss: 2.4833
[6] train_loss: 2.5898
[6] train_loss: 2.4245
[6] train_loss: 2.4218
[6] train_loss: 2.3451
[6] train_loss: 2.2457
[6] train_loss: 2.2481
[6] train_loss: 2.2365
1.4052131175994873

Evaluating...Epoch: 6
Prec: 0.7817, Recall: 0.8473, F1: 0.8132
model saved to random1_layers3_16res/best_model.pt
New best model saved!

[7] train_loss: 2.5187
[7] train_loss: 2.3276
[7] train_loss: 2.3020
[7] train_loss: 2.1694
[7] train_loss: 2.1496
[7] train_loss: 2.0862
[7] train_loss: 2.0044
[7] train_loss: 2.0296
[7] train_loss: 2.0476
1.410539150238037

Evaluating...Epoch: 7
Prec: 0.8301, Recall: 0.8111, F1: 0.8205
model saved to random1_layers3_16res/best_model.pt
New best model saved!

[8] train_loss: 2.4313
[8] train_loss: 2.1322
[8] train_loss: 2.1497
[8] train_loss: 1.9845
[8] train_loss: 1.9490
[8] train_loss: 1.8974
[8] train_loss: 1.8197
[8] train_loss: 1.8469
[8] train_loss: 1.8585
1.4729869365692139

Evaluating...Epoch: 8
Prec: 0.8402, Recall: 0.8225, F1: 0.8312
model saved to random1_layers3_16res/best_model.pt
New best model saved!

[9] train_loss: 2.2302
[9] train_loss: 1.9896
[9] train_loss: 1.9993
[9] train_loss: 1.8486
[9] train_loss: 1.8610
[9] train_loss: 1.8293
[9] train_loss: 1.7459
[9] train_loss: 1.7548
[9] train_loss: 1.7607
1.4018127918243408

Evaluating...Epoch: 9
Prec: 0.8722, Recall: 0.8206, F1: 0.8456
model saved to random1_layers3_16res/best_model.pt
New best model saved!

[10] train_loss: 1.9807
[10] train_loss: 1.7890
[10] train_loss: 1.8170
[10] train_loss: 1.6820
[10] train_loss: 1.6874
[10] train_loss: 1.6412
[10] train_loss: 1.5714
[10] train_loss: 1.6036
[10] train_loss: 1.6154
1.3937501907348633

Evaluating...Epoch: 10
Prec: 0.8254, Recall: 0.8302, F1: 0.8278

[11] train_loss: 1.6999
[11] train_loss: 1.6257
[11] train_loss: 1.6952
[11] train_loss: 1.5798
[11] train_loss: 1.5863
[11] train_loss: 1.5728
[11] train_loss: 1.5166
[11] train_loss: 1.5246
[11] train_loss: 1.5353
1.3914823532104492

Evaluating...Epoch: 11
Prec: 0.8716, Recall: 0.8034, F1: 0.8361

[12] train_loss: 1.7095
[12] train_loss: 1.5477
[12] train_loss: 1.5778
[12] train_loss: 1.4226
[12] train_loss: 1.4360
[12] train_loss: 1.4057
[12] train_loss: 1.4009
[12] train_loss: 1.3927
[12] train_loss: 1.3967
1.3911185264587402

Evaluating...Epoch: 12
Prec: 0.8402, Recall: 0.8225, F1: 0.8312

[13] train_loss: 1.4993
[13] train_loss: 1.4005
[13] train_loss: 1.4158
[13] train_loss: 1.3328
[13] train_loss: 1.3553
[13] train_loss: 1.3071
[13] train_loss: 1.2535
[13] train_loss: 1.2493
[13] train_loss: 1.2649
1.3922135829925537

Evaluating...Epoch: 13
Prec: 0.8700, Recall: 0.8302, F1: 0.8496
model saved to random1_layers3_16res/best_model.pt
New best model saved!

[14] train_loss: 1.4550
[14] train_loss: 1.2134
[14] train_loss: 1.2892
[14] train_loss: 1.1952
[14] train_loss: 1.2577
[14] train_loss: 1.2193
[14] train_loss: 1.1768
[14] train_loss: 1.1885
[14] train_loss: 1.1937
1.4600164890289307

Evaluating...Epoch: 14
Prec: 0.8703, Recall: 0.8454, F1: 0.8577
model saved to random1_layers3_16res/best_model.pt
New best model saved!

[15] train_loss: 1.2415
[15] train_loss: 1.1672
[15] train_loss: 1.1823
[15] train_loss: 1.0724
[15] train_loss: 1.1300
[15] train_loss: 1.1172
[15] train_loss: 1.0921
[15] train_loss: 1.1003
[15] train_loss: 1.1246
1.397064447402954

Evaluating...Epoch: 15
Prec: 0.8740, Recall: 0.8340, F1: 0.8535

[16] train_loss: 1.3011
[16] train_loss: 1.1738
[16] train_loss: 1.1986
[16] train_loss: 1.0974
[16] train_loss: 1.1219
[16] train_loss: 1.1030
[16] train_loss: 1.0631
[16] train_loss: 1.0876
[16] train_loss: 1.1159
1.3898072242736816

Evaluating...Epoch: 16
Prec: 0.8814, Recall: 0.8225, F1: 0.8509

[17] train_loss: 1.1648
[17] train_loss: 1.0840
[17] train_loss: 1.0967
[17] train_loss: 1.0129
[17] train_loss: 1.0575
[17] train_loss: 1.0098
[17] train_loss: 0.9738
[17] train_loss: 0.9792
[17] train_loss: 0.9901
1.388533353805542

Evaluating...Epoch: 17
Prec: 0.8611, Recall: 0.8397, F1: 0.8502

[18] train_loss: 1.1385
[18] train_loss: 1.1054
[18] train_loss: 1.1196
[18] train_loss: 1.0160
[18] train_loss: 1.0442
[18] train_loss: 1.0144
[18] train_loss: 0.9770
[18] train_loss: 0.9729
[18] train_loss: 0.9998
1.388340711593628

Evaluating...Epoch: 18
Prec: 0.8770, Recall: 0.8302, F1: 0.8529

[19] train_loss: 1.0026
[19] train_loss: 0.9445
[19] train_loss: 0.9369
[19] train_loss: 0.8519
[19] train_loss: 0.8602
[19] train_loss: 0.8389
[19] train_loss: 0.8184
[19] train_loss: 0.8137
[19] train_loss: 0.8383
1.3970372676849365

Evaluating...Epoch: 19
Prec: 0.8611, Recall: 0.8282, F1: 0.8444

[20] train_loss: 1.0800
[20] train_loss: 0.9137
[20] train_loss: 0.9105
[20] train_loss: 0.8190
[20] train_loss: 0.8339
[20] train_loss: 0.8007
[20] train_loss: 0.7737
[20] train_loss: 0.8137
[20] train_loss: 0.8282
1.3844537734985352

Evaluating...Epoch: 20
Prec: 0.8762, Recall: 0.8378, F1: 0.8566

[21] train_loss: 0.9695
[21] train_loss: 0.8367
[21] train_loss: 0.8615
[21] train_loss: 0.8037
[21] train_loss: 0.8465
[21] train_loss: 0.8246
[21] train_loss: 0.7904
[21] train_loss: 0.7902
[21] train_loss: 0.8001
1.3764793872833252

Evaluating...Epoch: 21
Prec: 0.8693, Recall: 0.8378, F1: 0.8533

[22] train_loss: 1.0048
[22] train_loss: 0.9133
[22] train_loss: 0.8839
[22] train_loss: 0.8106
[22] train_loss: 0.8095
[22] train_loss: 0.7996
[22] train_loss: 0.7667
[22] train_loss: 0.7792
[22] train_loss: 0.7759
1.3824751377105713

Evaluating...Epoch: 22
Prec: 0.8686, Recall: 0.8454, F1: 0.8569

[23] train_loss: 0.7644
[23] train_loss: 0.7377
[23] train_loss: 0.7754
[23] train_loss: 0.7061
[23] train_loss: 0.7131
[23] train_loss: 0.7239
[23] train_loss: 0.7141
[23] train_loss: 0.6991
[23] train_loss: 0.6999
1.3980159759521484

Evaluating...Epoch: 23
Prec: 0.8636, Recall: 0.8340, F1: 0.8485

[24] train_loss: 0.8171
[24] train_loss: 0.7783
[24] train_loss: 0.7700
[24] train_loss: 0.6800
[24] train_loss: 0.6851
[24] train_loss: 0.6906
[24] train_loss: 0.6669
[24] train_loss: 0.6679
[24] train_loss: 0.6749
1.4008681774139404

Evaluating...Epoch: 24
Prec: 0.8544, Recall: 0.8511, F1: 0.8528

[25] train_loss: 0.7219
[25] train_loss: 0.7182
[25] train_loss: 0.7009
[25] train_loss: 0.6325
[25] train_loss: 0.6499
[25] train_loss: 0.6389
[25] train_loss: 0.6352
[25] train_loss: 0.6431
[25] train_loss: 0.6474
1.4624078273773193

Evaluating...Epoch: 25
Prec: 0.8602, Recall: 0.8569, F1: 0.8585
model saved to random1_layers3_16res/best_model.pt
New best model saved!

[26] train_loss: 0.8401
[26] train_loss: 0.6752
[26] train_loss: 0.6813
[26] train_loss: 0.6144
[26] train_loss: 0.6467
[26] train_loss: 0.6370
[26] train_loss: 0.6208
[26] train_loss: 0.6147
[26] train_loss: 0.6093
1.3837182521820068

Evaluating...Epoch: 26
Prec: 0.8735, Recall: 0.8435, F1: 0.8583

[27] train_loss: 0.6637
[27] train_loss: 0.5999
[27] train_loss: 0.6163
[27] train_loss: 0.5690
[27] train_loss: 0.6034
[27] train_loss: 0.5899
[27] train_loss: 0.5868
[27] train_loss: 0.5757
[27] train_loss: 0.5855
1.3696696758270264

Evaluating...Epoch: 27
Prec: 0.8822, Recall: 0.8721, F1: 0.8772
model saved to random1_layers3_16res/best_model.pt
New best model saved!

[28] train_loss: 0.8809
[28] train_loss: 0.7783
[28] train_loss: 0.7451
[28] train_loss: 0.6614
[28] train_loss: 0.6565
[28] train_loss: 0.6329
[28] train_loss: 0.5877
[28] train_loss: 0.6020
[28] train_loss: 0.5970
1.37575364112854

Evaluating...Epoch: 28
Prec: 0.8938, Recall: 0.8511, F1: 0.8719

[29] train_loss: 0.5987
[29] train_loss: 0.5660
[29] train_loss: 0.5430
[29] train_loss: 0.5139
[29] train_loss: 0.5462
[29] train_loss: 0.5751
[29] train_loss: 0.5672
[29] train_loss: 0.5732
[29] train_loss: 0.5681
1.4100360870361328

Evaluating...Epoch: 29
Prec: 0.8929, Recall: 0.8588, F1: 0.8755

[30] train_loss: 0.6300
[30] train_loss: 0.4948
[30] train_loss: 0.4774
[30] train_loss: 0.4519
[30] train_loss: 0.4823
[30] train_loss: 0.4778
[30] train_loss: 0.4566
[30] train_loss: 0.4749
[30] train_loss: 0.5074
1.4029016494750977

Evaluating...Epoch: 30
Prec: 0.8510, Recall: 0.8721, F1: 0.8615

[31] train_loss: 0.5420
[31] train_loss: 0.5505
[31] train_loss: 0.5740
[31] train_loss: 0.5330
[31] train_loss: 0.5454
[31] train_loss: 0.5426
[31] train_loss: 0.5326
[31] train_loss: 0.5330
[31] train_loss: 0.5441
1.4636154174804688

Evaluating...Epoch: 31
Prec: 0.8604, Recall: 0.8588, F1: 0.8596

[32] train_loss: 0.6455
[32] train_loss: 0.5062
[32] train_loss: 0.5462
[32] train_loss: 0.5005
[32] train_loss: 0.5172
[32] train_loss: 0.5047
[32] train_loss: 0.4835
[32] train_loss: 0.4774
[32] train_loss: 0.4800
1.398381233215332

Evaluating...Epoch: 32
Prec: 0.8476, Recall: 0.8702, F1: 0.8588

[33] train_loss: 0.3878
[33] train_loss: 0.4375
[33] train_loss: 0.4991
[33] train_loss: 0.4480
[33] train_loss: 0.4351
[33] train_loss: 0.4227
[33] train_loss: 0.4189
[33] train_loss: 0.4234
[33] train_loss: 0.4299
1.4026298522949219

Evaluating...Epoch: 33
Prec: 0.8659, Recall: 0.8626, F1: 0.8642

[34] train_loss: 0.4631
[34] train_loss: 0.4132
[34] train_loss: 0.3983
[34] train_loss: 0.4008
[34] train_loss: 0.4541
[34] train_loss: 0.4288
[34] train_loss: 0.4024
[34] train_loss: 0.4090
[34] train_loss: 0.4164
1.405963659286499

Evaluating...Epoch: 34
Prec: 0.9057, Recall: 0.8435, F1: 0.8735

[35] train_loss: 0.4552
[35] train_loss: 0.3808
[35] train_loss: 0.3743
[35] train_loss: 0.3648
[35] train_loss: 0.3787
[35] train_loss: 0.3674
[35] train_loss: 0.3640
[35] train_loss: 0.3703
[35] train_loss: 0.3654
1.4173035621643066

Evaluating...Epoch: 35
Prec: 0.8719, Recall: 0.8702, F1: 0.8711

[36] train_loss: 0.4545
[36] train_loss: 0.3968
[36] train_loss: 0.3812
[36] train_loss: 0.3420
[36] train_loss: 0.3550
[36] train_loss: 0.3439
[36] train_loss: 0.3421
[36] train_loss: 0.3508
[36] train_loss: 0.3605
1.4076435565948486

Evaluating...Epoch: 36
Prec: 0.8966, Recall: 0.8607, F1: 0.8783
model saved to random1_layers3_16res/best_model.pt
New best model saved!

[37] train_loss: 0.4432
[37] train_loss: 0.3531
[37] train_loss: 0.3483
[37] train_loss: 0.3342
[37] train_loss: 0.3718
[37] train_loss: 0.3587
[37] train_loss: 0.3415
[37] train_loss: 0.3402
[37] train_loss: 0.3520
1.462480068206787

Evaluating...Epoch: 37
Prec: 0.9030, Recall: 0.8531, F1: 0.8773

[38] train_loss: 0.3895
[38] train_loss: 0.4021
[38] train_loss: 0.3957
[38] train_loss: 0.3642
[38] train_loss: 0.3684
[38] train_loss: 0.3589
[38] train_loss: 0.3464
[38] train_loss: 0.3550
[38] train_loss: 0.3577
1.3980333805084229

Evaluating...Epoch: 38
Prec: 0.8558, Recall: 0.8607, F1: 0.8582

[39] train_loss: 0.3370
[39] train_loss: 0.3441
[39] train_loss: 0.3638
[39] train_loss: 0.3179
[39] train_loss: 0.3357
[39] train_loss: 0.3285
[39] train_loss: 0.3132
[39] train_loss: 0.3168
[39] train_loss: 0.3233
1.402432918548584

Evaluating...Epoch: 39
Prec: 0.8577, Recall: 0.8740, F1: 0.8658

[40] train_loss: 0.2969
[40] train_loss: 0.3002
[40] train_loss: 0.3065
[40] train_loss: 0.2970
[40] train_loss: 0.3279
[40] train_loss: 0.3198
[40] train_loss: 0.3083
[40] train_loss: 0.3001
[40] train_loss: 0.3124
1.4134185314178467

Evaluating...Epoch: 40
Prec: 0.8992, Recall: 0.8683, F1: 0.8835
model saved to random1_layers3_16res/best_model.pt
New best model saved!

[41] train_loss: 0.3608
[41] train_loss: 0.2845
[41] train_loss: 0.2818
[41] train_loss: 0.2839
[41] train_loss: 0.2980
[41] train_loss: 0.2977
[41] train_loss: 0.2979
[41] train_loss: 0.3000
[41] train_loss: 0.3119
1.4126222133636475

Evaluating...Epoch: 41
Prec: 0.8415, Recall: 0.8511, F1: 0.8463

[42] train_loss: 0.2887
[42] train_loss: 0.3018
[42] train_loss: 0.3072
[42] train_loss: 0.2990
[42] train_loss: 0.3168
[42] train_loss: 0.3157
[42] train_loss: 0.3099
[42] train_loss: 0.3009
[42] train_loss: 0.3046
1.405106782913208

Evaluating...Epoch: 42
Prec: 0.8958, Recall: 0.8531, F1: 0.8739

[43] train_loss: 0.2940
[43] train_loss: 0.2611
[43] train_loss: 0.2880
[43] train_loss: 0.3021
[43] train_loss: 0.3079
[43] train_loss: 0.3032
[43] train_loss: 0.2949
[43] train_loss: 0.3062
[43] train_loss: 0.3078
1.449728012084961

Evaluating...Epoch: 43
Prec: 0.8954, Recall: 0.8492, F1: 0.8717

[44] train_loss: 0.3428
[44] train_loss: 0.3061
[44] train_loss: 0.2973
[44] train_loss: 0.2695
[44] train_loss: 0.2898
[44] train_loss: 0.2854
[44] train_loss: 0.2689
[44] train_loss: 0.2763
[44] train_loss: 0.2833
1.3881380558013916

Evaluating...Epoch: 44
Prec: 0.8818, Recall: 0.8397, F1: 0.8602

[45] train_loss: 0.4926
[45] train_loss: 0.3174
[45] train_loss: 0.2909
[45] train_loss: 0.2925
[45] train_loss: 0.3094
[45] train_loss: 0.2949
[45] train_loss: 0.2731
[45] train_loss: 0.2671
[45] train_loss: 0.2767
1.41141939163208

Evaluating...Epoch: 45
Prec: 0.8790, Recall: 0.8454, F1: 0.8619

[46] train_loss: 0.2648
[46] train_loss: 0.2684
[46] train_loss: 0.2629
[46] train_loss: 0.2423
[46] train_loss: 0.2638
[46] train_loss: 0.2594
[46] train_loss: 0.2583
[46] train_loss: 0.2566
[46] train_loss: 0.2558
1.4046764373779297

Evaluating...Epoch: 46
Prec: 0.8750, Recall: 0.8550, F1: 0.8649

[47] train_loss: 0.2850
[47] train_loss: 0.2579
[47] train_loss: 0.2964
[47] train_loss: 0.2789
[47] train_loss: 0.2740
[47] train_loss: 0.2694
[47] train_loss: 0.2612
[47] train_loss: 0.2528
[47] train_loss: 0.2486
1.407214879989624

Evaluating...Epoch: 47
Prec: 0.8891, Recall: 0.8416, F1: 0.8647

[48] train_loss: 0.3139
[48] train_loss: 0.2741
[48] train_loss: 0.2819
[48] train_loss: 0.2442
[48] train_loss: 0.2349
[48] train_loss: 0.2279
[48] train_loss: 0.2193
[48] train_loss: 0.2272
[48] train_loss: 0.2276
1.4062371253967285

Evaluating...Epoch: 48
Prec: 0.8820, Recall: 0.8416, F1: 0.8613

[49] train_loss: 0.1735
[49] train_loss: 0.2678
[49] train_loss: 0.2626
[49] train_loss: 0.2429
[49] train_loss: 0.2628
[49] train_loss: 0.2593
[49] train_loss: 0.2698
[49] train_loss: 0.2718
[49] train_loss: 0.2775
1.455998182296753

Evaluating...Epoch: 49
Prec: 0.8874, Recall: 0.8569, F1: 0.8718

[50] train_loss: 0.1925
[50] train_loss: 0.2022
[50] train_loss: 0.2175
[50] train_loss: 0.2021
[50] train_loss: 0.2103
[50] train_loss: 0.2078
[50] train_loss: 0.2104
[50] train_loss: 0.2174
[50] train_loss: 0.2251
1.3991007804870605

Evaluating...Epoch: 50
Prec: 0.8889, Recall: 0.8550, F1: 0.8716

[51] train_loss: 0.2371
[51] train_loss: 0.2654
[51] train_loss: 0.2565
[51] train_loss: 0.2468
[51] train_loss: 0.2511
[51] train_loss: 0.2394
[51] train_loss: 0.2280
[51] train_loss: 0.2271
[51] train_loss: 0.2457
1.4052238464355469

Evaluating...Epoch: 51
Prec: 0.8975, Recall: 0.8359, F1: 0.8656

[52] train_loss: 0.1682
[52] train_loss: 0.1553
[52] train_loss: 0.1681
[52] train_loss: 0.1769
[52] train_loss: 0.1994
[52] train_loss: 0.2209
[52] train_loss: 0.2386
[52] train_loss: 0.2307
[52] train_loss: 0.2329
1.3983469009399414

Evaluating...Epoch: 52
Prec: 0.8755, Recall: 0.8454, F1: 0.8602

[53] train_loss: 0.2818
[53] train_loss: 0.1986
[53] train_loss: 0.2176
[53] train_loss: 0.2043
[53] train_loss: 0.2017
[53] train_loss: 0.2018
[53] train_loss: 0.1986
[53] train_loss: 0.2080
[53] train_loss: 0.2077
1.4007596969604492

Evaluating...Epoch: 53
Prec: 0.8876, Recall: 0.8588, F1: 0.8729

[54] train_loss: 0.1816
[54] train_loss: 0.1715
[54] train_loss: 0.1930
[54] train_loss: 0.1768
[54] train_loss: 0.1787
[54] train_loss: 0.1813
[54] train_loss: 0.1766
[54] train_loss: 0.1751
[54] train_loss: 0.1709
1.3978562355041504

Evaluating...Epoch: 54
Prec: 0.8818, Recall: 0.8683, F1: 0.8750

[55] train_loss: 0.2442
[55] train_loss: 0.2141
[55] train_loss: 0.2102
[55] train_loss: 0.1982
[55] train_loss: 0.2131
[55] train_loss: 0.2108
[55] train_loss: 0.2044
[55] train_loss: 0.2301
[55] train_loss: 0.2278
1.4611003398895264

Evaluating...Epoch: 55
Prec: 0.9038, Recall: 0.8607, F1: 0.8817

[56] train_loss: 0.1341
[56] train_loss: 0.1952
[56] train_loss: 0.1804
[56] train_loss: 0.1666
[56] train_loss: 0.1638
[56] train_loss: 0.1547
[56] train_loss: 0.1615
[56] train_loss: 0.1646
[56] train_loss: 0.1615
1.4063172340393066

Evaluating...Epoch: 56
Prec: 0.9052, Recall: 0.8569, F1: 0.8804

[57] train_loss: 0.1707
[57] train_loss: 0.2249
[57] train_loss: 0.1926
[57] train_loss: 0.1856
[57] train_loss: 0.2012
[57] train_loss: 0.2027
[57] train_loss: 0.1980
[57] train_loss: 0.2057
[57] train_loss: 0.2134
1.4025979042053223

Evaluating...Epoch: 57
Prec: 0.9000, Recall: 0.8588, F1: 0.8789

[58] train_loss: 0.1267
[58] train_loss: 0.1447
[58] train_loss: 0.1623
[58] train_loss: 0.1693
[58] train_loss: 0.1635
[58] train_loss: 0.1709
[58] train_loss: 0.1659
[58] train_loss: 0.1660
[58] train_loss: 0.1730
1.4008588790893555

Evaluating...Epoch: 58
Prec: 0.9049, Recall: 0.8531, F1: 0.8782

[59] train_loss: 0.3020
[59] train_loss: 0.2283
[59] train_loss: 0.2261
[59] train_loss: 0.1903
[59] train_loss: 0.1999
[59] train_loss: 0.1931
[59] train_loss: 0.1940
[59] train_loss: 0.2185
[59] train_loss: 0.2236
1.3936383724212646

Evaluating...Epoch: 59
Prec: 0.9097, Recall: 0.8454, F1: 0.8764

[60] train_loss: 0.2187
[60] train_loss: 0.2091
[60] train_loss: 0.2183
[60] train_loss: 0.1906
[60] train_loss: 0.1814
[60] train_loss: 0.1952
[60] train_loss: 0.1912
[60] train_loss: 0.1898
[60] train_loss: 0.1972
1.4081318378448486

Evaluating...Epoch: 60
Prec: 0.8931, Recall: 0.8454, F1: 0.8686

Training ended with 61 epochs.
Final result:
Prec: 0.8992, Recall: 0.8683, F1: 0.8835
loading vocab and embedding matrix from ../data/16res
size of vocab: 3214
shape of loaded embedding matrix: (3214, 300)
Generating mappings
Loading data from ../data/16res with batch size 16...
95 batches created for ../data/16res/train.json
29 batches created for ../data/16res/test.json
Building model...
1502703
[1] train_loss: 10.7652
[1] train_loss: 8.3002
[1] train_loss: 7.5128
[1] train_loss: 6.8380
[1] train_loss: 6.4654
[1] train_loss: 6.1047
[1] train_loss: 5.7672
[1] train_loss: 5.5991
[1] train_loss: 5.4074
1.4572103023529053

Evaluating...Epoch: 1
Prec: 0.6822, Recall: 0.6966, F1: 0.6893
model saved to random1_layers4_16res/best_model.pt
New best model saved!

[2] train_loss: 4.3609
[2] train_loss: 3.9380
[2] train_loss: 3.8865
[2] train_loss: 3.7009
[2] train_loss: 3.6833
[2] train_loss: 3.5742
[2] train_loss: 3.4249
[2] train_loss: 3.4508
[2] train_loss: 3.4386
1.5090034008026123

Evaluating...Epoch: 2
Prec: 0.6594, Recall: 0.8130, F1: 0.7282
model saved to random1_layers4_16res/best_model.pt
New best model saved!

[3] train_loss: 3.5551
[3] train_loss: 3.2465
[3] train_loss: 3.2488
[3] train_loss: 3.1353
[3] train_loss: 3.1765
[3] train_loss: 3.0857
[3] train_loss: 2.9761
[3] train_loss: 2.9830
[3] train_loss: 2.9653
1.460824966430664

Evaluating...Epoch: 3
Prec: 0.7429, Recall: 0.7996, F1: 0.7702
model saved to random1_layers4_16res/best_model.pt
New best model saved!

[4] train_loss: 3.1539
[4] train_loss: 2.8873
[4] train_loss: 2.9362
[4] train_loss: 2.7942
[4] train_loss: 2.7993
[4] train_loss: 2.7229
[4] train_loss: 2.6069
[4] train_loss: 2.6381
[4] train_loss: 2.6518
1.4644551277160645

Evaluating...Epoch: 4
Prec: 0.7040, Recall: 0.8397, F1: 0.7659

[5] train_loss: 3.0535
[5] train_loss: 2.7815
[5] train_loss: 2.8377
[5] train_loss: 2.6830
[5] train_loss: 2.6344
[5] train_loss: 2.5693
[5] train_loss: 2.4771
[5] train_loss: 2.5028
[5] train_loss: 2.5114
1.462843656539917

Evaluating...Epoch: 5
Prec: 0.7698, Recall: 0.8168, F1: 0.7926
model saved to random1_layers4_16res/best_model.pt
New best model saved!

[6] train_loss: 2.8246
[6] train_loss: 2.4990
[6] train_loss: 2.5865
[6] train_loss: 2.3892
[6] train_loss: 2.4356
[6] train_loss: 2.3623
[6] train_loss: 2.2560
[6] train_loss: 2.2669
[6] train_loss: 2.2735
1.454763650894165

Evaluating...Epoch: 6
Prec: 0.7794, Recall: 0.8092, F1: 0.7940
model saved to random1_layers4_16res/best_model.pt
New best model saved!

[7] train_loss: 2.7379
[7] train_loss: 2.4617
[7] train_loss: 2.4196
[7] train_loss: 2.2396
[7] train_loss: 2.2176
[7] train_loss: 2.1640
[7] train_loss: 2.0784
[7] train_loss: 2.0787
[7] train_loss: 2.0831
1.4502389430999756

Evaluating...Epoch: 7
Prec: 0.7882, Recall: 0.8168, F1: 0.8022
model saved to random1_layers4_16res/best_model.pt
New best model saved!

[8] train_loss: 2.5655
[8] train_loss: 2.1819
[8] train_loss: 2.2243
[8] train_loss: 2.0350
[8] train_loss: 2.0374
[8] train_loss: 1.9923
[8] train_loss: 1.9195
[8] train_loss: 1.9200
[8] train_loss: 1.9347
1.5301578044891357

Evaluating...Epoch: 8
Prec: 0.8123, Recall: 0.8092, F1: 0.8107
model saved to random1_layers4_16res/best_model.pt
New best model saved!

[9] train_loss: 2.0375
[9] train_loss: 1.9424
[9] train_loss: 2.0436
[9] train_loss: 1.9141
[9] train_loss: 1.8673
[9] train_loss: 1.7927
[9] train_loss: 1.7349
[9] train_loss: 1.7605
[9] train_loss: 1.7798
1.4599294662475586

Evaluating...Epoch: 9
Prec: 0.8215, Recall: 0.8168, F1: 0.8191
model saved to random1_layers4_16res/best_model.pt
New best model saved!

[10] train_loss: 2.0726
[10] train_loss: 1.8978
[10] train_loss: 1.8886
[10] train_loss: 1.7633
[10] train_loss: 1.7764
[10] train_loss: 1.7525
[10] train_loss: 1.6770
[10] train_loss: 1.6953
[10] train_loss: 1.6958
1.466432809829712

Evaluating...Epoch: 10
Prec: 0.8824, Recall: 0.8015, F1: 0.8400
model saved to random1_layers4_16res/best_model.pt
New best model saved!

[11] train_loss: 1.5563
[11] train_loss: 1.6067
[11] train_loss: 1.6411
[11] train_loss: 1.5175
[11] train_loss: 1.5885
[11] train_loss: 1.5639
[11] train_loss: 1.5054
[11] train_loss: 1.5513
[11] train_loss: 1.5629
1.4596784114837646

Evaluating...Epoch: 11
Prec: 0.8930, Recall: 0.7805, F1: 0.8330

[12] train_loss: 1.7778
[12] train_loss: 1.6612
[12] train_loss: 1.6803
[12] train_loss: 1.5508
[12] train_loss: 1.5414
[12] train_loss: 1.4786
[12] train_loss: 1.4255
[12] train_loss: 1.4132
[12] train_loss: 1.4211
1.4641749858856201

Evaluating...Epoch: 12
Prec: 0.8603, Recall: 0.8111, F1: 0.8350

[13] train_loss: 1.5834
[13] train_loss: 1.5152
[13] train_loss: 1.5297
[13] train_loss: 1.4307
[13] train_loss: 1.4251
[13] train_loss: 1.4102
[13] train_loss: 1.3546
[13] train_loss: 1.3748
[13] train_loss: 1.3955
1.4590954780578613

Evaluating...Epoch: 13
Prec: 0.9063, Recall: 0.7939, F1: 0.8464
model saved to random1_layers4_16res/best_model.pt
New best model saved!

[14] train_loss: 1.5762
[14] train_loss: 1.4111
[14] train_loss: 1.4312
[14] train_loss: 1.2810
[14] train_loss: 1.3114
[14] train_loss: 1.2748
[14] train_loss: 1.2322
[14] train_loss: 1.2477
[14] train_loss: 1.2657
1.510263204574585

Evaluating...Epoch: 14
Prec: 0.9161, Recall: 0.7920, F1: 0.8495
model saved to random1_layers4_16res/best_model.pt
New best model saved!

[15] train_loss: 1.4741
[15] train_loss: 1.3484
[15] train_loss: 1.3044
[15] train_loss: 1.1825
[15] train_loss: 1.1955
[15] train_loss: 1.1585
[15] train_loss: 1.1225
[15] train_loss: 1.1450
[15] train_loss: 1.1367
1.4631943702697754

Evaluating...Epoch: 15
Prec: 0.8912, Recall: 0.8130, F1: 0.8503
model saved to random1_layers4_16res/best_model.pt
New best model saved!

[16] train_loss: 1.3481
[16] train_loss: 1.3025
[16] train_loss: 1.2508
[16] train_loss: 1.1273
[16] train_loss: 1.1024
[16] train_loss: 1.0812
[16] train_loss: 1.0455
[16] train_loss: 1.0618
[16] train_loss: 1.0699
1.4632248878479004

Evaluating...Epoch: 16
Prec: 0.8871, Recall: 0.8244, F1: 0.8546
model saved to random1_layers4_16res/best_model.pt
New best model saved!

[17] train_loss: 1.0387
[17] train_loss: 1.0085
[17] train_loss: 1.0761
[17] train_loss: 1.0145
[17] train_loss: 1.0443
[17] train_loss: 1.0215
[17] train_loss: 1.0169
[17] train_loss: 1.0127
[17] train_loss: 1.0263
1.4620513916015625

Evaluating...Epoch: 17
Prec: 0.8685, Recall: 0.8321, F1: 0.8499

[18] train_loss: 1.1055
[18] train_loss: 1.0025
[18] train_loss: 1.0301
[18] train_loss: 0.9552
[18] train_loss: 0.9442
[18] train_loss: 0.9221
[18] train_loss: 0.8935
[18] train_loss: 0.9017
[18] train_loss: 0.9246
1.4575769901275635

Evaluating...Epoch: 18
Prec: 0.8700, Recall: 0.8302, F1: 0.8496

[19] train_loss: 1.1841
[19] train_loss: 1.0784
[19] train_loss: 1.0854
[19] train_loss: 0.9622
[19] train_loss: 0.9694
[19] train_loss: 0.9868
[19] train_loss: 0.9492
[19] train_loss: 0.9468
[19] train_loss: 0.9611
1.4587836265563965

Evaluating...Epoch: 19
Prec: 0.8806, Recall: 0.8302, F1: 0.8546
model saved to random1_layers4_16res/best_model.pt
New best model saved!

[20] train_loss: 0.8854
[20] train_loss: 0.8642
[20] train_loss: 0.8912
[20] train_loss: 0.8726
[20] train_loss: 0.9082
[20] train_loss: 0.8595
[20] train_loss: 0.8393
[20] train_loss: 0.8330
[20] train_loss: 0.8432
1.450754165649414

Evaluating...Epoch: 20
Prec: 0.9004, Recall: 0.8282, F1: 0.8628
model saved to random1_layers4_16res/best_model.pt
New best model saved!

[21] train_loss: 0.8926
[21] train_loss: 0.7751
[21] train_loss: 0.8331
[21] train_loss: 0.7881
[21] train_loss: 0.7733
[21] train_loss: 0.7818
[21] train_loss: 0.7603
[21] train_loss: 0.7965
[21] train_loss: 0.8056
1.4387104511260986

Evaluating...Epoch: 21
Prec: 0.8880, Recall: 0.8321, F1: 0.8591

[22] train_loss: 1.0612
[22] train_loss: 0.8964
[22] train_loss: 0.9029
[22] train_loss: 0.8311
[22] train_loss: 0.8506
[22] train_loss: 0.8164
[22] train_loss: 0.7924
[22] train_loss: 0.7847
[22] train_loss: 0.7864
1.456932544708252

Evaluating...Epoch: 22
Prec: 0.8788, Recall: 0.8302, F1: 0.8538

[23] train_loss: 0.7766
[23] train_loss: 0.7568
[23] train_loss: 0.7686
[23] train_loss: 0.7168
[23] train_loss: 0.7092
[23] train_loss: 0.6825
[23] train_loss: 0.6557
[23] train_loss: 0.6668
[23] train_loss: 0.7011
1.4568874835968018

Evaluating...Epoch: 23
Prec: 0.8873, Recall: 0.8416, F1: 0.8639
model saved to random1_layers4_16res/best_model.pt
New best model saved!

[24] train_loss: 0.7457
[24] train_loss: 0.6392
[24] train_loss: 0.6889
[24] train_loss: 0.6465
[24] train_loss: 0.6631
[24] train_loss: 0.6670
[24] train_loss: 0.6450
[24] train_loss: 0.6473
[24] train_loss: 0.6628
1.4665305614471436

Evaluating...Epoch: 24
Prec: 0.8689, Recall: 0.8473, F1: 0.8580

[25] train_loss: 0.7501
[25] train_loss: 0.6096
[25] train_loss: 0.6473
[25] train_loss: 0.5877
[25] train_loss: 0.6160
[25] train_loss: 0.6091
[25] train_loss: 0.5901
[25] train_loss: 0.6065
[25] train_loss: 0.6173
1.4615976810455322

Evaluating...Epoch: 25
Prec: 0.8851, Recall: 0.8378, F1: 0.8608

[26] train_loss: 0.8189
[26] train_loss: 0.7886
[26] train_loss: 0.7974
[26] train_loss: 0.7179
[26] train_loss: 0.7293
[26] train_loss: 0.7093
[26] train_loss: 0.6753
[26] train_loss: 0.6814
[26] train_loss: 0.6854
1.4505422115325928

Evaluating...Epoch: 26
Prec: 0.8878, Recall: 0.8302, F1: 0.8580

[27] train_loss: 0.5451
[27] train_loss: 0.6071
[27] train_loss: 0.6390
[27] train_loss: 0.6448
[27] train_loss: 0.6473
[27] train_loss: 0.6187
[27] train_loss: 0.5887
[27] train_loss: 0.6036
[27] train_loss: 0.6304
1.4545609951019287

Evaluating...Epoch: 27
Prec: 0.8708, Recall: 0.8492, F1: 0.8599

[28] train_loss: 0.7246
[28] train_loss: 0.6218
[28] train_loss: 0.6162
[28] train_loss: 0.5887
[28] train_loss: 0.5902
[28] train_loss: 0.5589
[28] train_loss: 0.5459
[28] train_loss: 0.5607
[28] train_loss: 0.5839
1.4579718112945557

Evaluating...Epoch: 28
Prec: 0.8797, Recall: 0.8511, F1: 0.8652
model saved to random1_layers4_16res/best_model.pt
New best model saved!

[29] train_loss: 0.4838
[29] train_loss: 0.5398
[29] train_loss: 0.6056
[29] train_loss: 0.5408
[29] train_loss: 0.5406
[29] train_loss: 0.5329
[29] train_loss: 0.5001
[29] train_loss: 0.4892
[29] train_loss: 0.4928
1.4597325325012207

Evaluating...Epoch: 29
Prec: 0.8794, Recall: 0.8626, F1: 0.8709
model saved to random1_layers4_16res/best_model.pt
New best model saved!

[30] train_loss: 0.4978
[30] train_loss: 0.5138
[30] train_loss: 0.5266
[30] train_loss: 0.5312
[30] train_loss: 0.5162
[30] train_loss: 0.5061
[30] train_loss: 0.4845
[30] train_loss: 0.4967
[30] train_loss: 0.5032
1.4615991115570068

Evaluating...Epoch: 30
Prec: 0.8873, Recall: 0.8416, F1: 0.8639

[31] train_loss: 0.6755
[31] train_loss: 0.5656
[31] train_loss: 0.4965
[31] train_loss: 0.4745
[31] train_loss: 0.4661
[31] train_loss: 0.4477
[31] train_loss: 0.4375
[31] train_loss: 0.4450
[31] train_loss: 0.4570
1.5326838493347168

Evaluating...Epoch: 31
Prec: 0.8802, Recall: 0.8550, F1: 0.8674

[32] train_loss: 0.5520
[32] train_loss: 0.5164
[32] train_loss: 0.5230
[32] train_loss: 0.4771
[32] train_loss: 0.4722
[32] train_loss: 0.4845
[32] train_loss: 0.4700
[32] train_loss: 0.4717
[32] train_loss: 0.4792
1.4562351703643799

Evaluating...Epoch: 32
Prec: 0.8743, Recall: 0.8626, F1: 0.8684

[33] train_loss: 0.4986
[33] train_loss: 0.4675
[33] train_loss: 0.4475
[33] train_loss: 0.4204
[33] train_loss: 0.4441
[33] train_loss: 0.4341
[33] train_loss: 0.4138
[33] train_loss: 0.4267
[33] train_loss: 0.4361
1.452467918395996

Evaluating...Epoch: 33
Prec: 0.8664, Recall: 0.8416, F1: 0.8538

[34] train_loss: 0.5000
[34] train_loss: 0.4786
[34] train_loss: 0.5081
[34] train_loss: 0.4515
[34] train_loss: 0.4587
[34] train_loss: 0.4572
[34] train_loss: 0.4432
[34] train_loss: 0.4334
[34] train_loss: 0.4499
1.4504406452178955

Evaluating...Epoch: 34
Prec: 0.8681, Recall: 0.8664, F1: 0.8672

[35] train_loss: 0.4616
[35] train_loss: 0.4249
[35] train_loss: 0.4308
[35] train_loss: 0.3867
[35] train_loss: 0.4032
[35] train_loss: 0.3966
[35] train_loss: 0.3794
[35] train_loss: 0.3652
[35] train_loss: 0.3950
1.4657633304595947

Evaluating...Epoch: 35
Prec: 0.8683, Recall: 0.8683, F1: 0.8683

[36] train_loss: 0.5501
[36] train_loss: 0.4809
[36] train_loss: 0.4880
[36] train_loss: 0.4370
[36] train_loss: 0.4272
[36] train_loss: 0.4116
[36] train_loss: 0.3885
[36] train_loss: 0.3821
[36] train_loss: 0.3780
1.4614269733428955

Evaluating...Epoch: 36
Prec: 0.8838, Recall: 0.8416, F1: 0.8622

[37] train_loss: 0.2725
[37] train_loss: 0.3067
[37] train_loss: 0.3350
[37] train_loss: 0.3442
[37] train_loss: 0.3782
[37] train_loss: 0.3610
[37] train_loss: 0.3391
[37] train_loss: 0.3897
[37] train_loss: 0.4073
1.4714734554290771

Evaluating...Epoch: 37
Prec: 0.8828, Recall: 0.8340, F1: 0.8577

[38] train_loss: 0.4928
[38] train_loss: 0.4464
[38] train_loss: 0.4376
[38] train_loss: 0.4023
[38] train_loss: 0.4111
[38] train_loss: 0.4225
[38] train_loss: 0.4014
[38] train_loss: 0.4237
[38] train_loss: 0.4133
1.457146406173706

Evaluating...Epoch: 38
Prec: 0.8893, Recall: 0.8588, F1: 0.8738
model saved to random1_layers4_16res/best_model.pt
New best model saved!

[39] train_loss: 0.4433
[39] train_loss: 0.4116
[39] train_loss: 0.4000
[39] train_loss: 0.3591
[39] train_loss: 0.3591
[39] train_loss: 0.3558
[39] train_loss: 0.3384
[39] train_loss: 0.3510
[39] train_loss: 0.3481
1.4532711505889893

Evaluating...Epoch: 39
Prec: 0.8936, Recall: 0.8492, F1: 0.8708

[40] train_loss: 0.3170
[40] train_loss: 0.3091
[40] train_loss: 0.3201
[40] train_loss: 0.2897
[40] train_loss: 0.3044
[40] train_loss: 0.3056
[40] train_loss: 0.2948
[40] train_loss: 0.3055
[40] train_loss: 0.3188
1.4512839317321777

Evaluating...Epoch: 40
Prec: 0.9064, Recall: 0.8321, F1: 0.8677

[41] train_loss: 0.3351
[41] train_loss: 0.3074
[41] train_loss: 0.3088
[41] train_loss: 0.2789
[41] train_loss: 0.2850
[41] train_loss: 0.2743
[41] train_loss: 0.2803
[41] train_loss: 0.2809
[41] train_loss: 0.2828
1.4475395679473877

Evaluating...Epoch: 41
Prec: 0.8936, Recall: 0.8492, F1: 0.8708

[42] train_loss: 0.2195
[42] train_loss: 0.2087
[42] train_loss: 0.3261
[42] train_loss: 0.2984
[42] train_loss: 0.2992
[42] train_loss: 0.3049
[42] train_loss: 0.2888
[42] train_loss: 0.2840
[42] train_loss: 0.3061
1.4422228336334229

Evaluating...Epoch: 42
Prec: 0.8936, Recall: 0.8492, F1: 0.8708

[43] train_loss: 0.3300
[43] train_loss: 0.3249
[43] train_loss: 0.3122
[43] train_loss: 0.3098
[43] train_loss: 0.3055
[43] train_loss: 0.3048
[43] train_loss: 0.2857
[43] train_loss: 0.2842
[43] train_loss: 0.2930
1.4598147869110107

Evaluating...Epoch: 43
Prec: 0.8990, Recall: 0.8492, F1: 0.8734

[44] train_loss: 0.1716
[44] train_loss: 0.2292
[44] train_loss: 0.2741
[44] train_loss: 0.2480
[44] train_loss: 0.2532
[44] train_loss: 0.2414
[44] train_loss: 0.2445
[44] train_loss: 0.2458
[44] train_loss: 0.2575
1.4602930545806885

Evaluating...Epoch: 44
Prec: 0.9062, Recall: 0.8302, F1: 0.8665

[45] train_loss: 0.4277
[45] train_loss: 0.3502
[45] train_loss: 0.3560
[45] train_loss: 0.3355
[45] train_loss: 0.3275
[45] train_loss: 0.3097
[45] train_loss: 0.3076
[45] train_loss: 0.3090
[45] train_loss: 0.3040
1.4638545513153076

Evaluating...Epoch: 45
Prec: 0.9083, Recall: 0.8321, F1: 0.8685

[46] train_loss: 0.2055
[46] train_loss: 0.2636
[46] train_loss: 0.2805
[46] train_loss: 0.2645
[46] train_loss: 0.2716
[46] train_loss: 0.2762
[46] train_loss: 0.2607
[46] train_loss: 0.2664
[46] train_loss: 0.2687
1.4583160877227783

Evaluating...Epoch: 46
Prec: 0.9022, Recall: 0.8454, F1: 0.8729

[47] train_loss: 0.3131
[47] train_loss: 0.2528
[47] train_loss: 0.2553
[47] train_loss: 0.2370
[47] train_loss: 0.2480
[47] train_loss: 0.2421
[47] train_loss: 0.2309
[47] train_loss: 0.2221
[47] train_loss: 0.2240
1.4616978168487549

Evaluating...Epoch: 47
Prec: 0.9047, Recall: 0.8511, F1: 0.8771
model saved to random1_layers4_16res/best_model.pt
New best model saved!

[48] train_loss: 0.3226
[48] train_loss: 0.2630
[48] train_loss: 0.2573
[48] train_loss: 0.2310
[48] train_loss: 0.2187
[48] train_loss: 0.2142
[48] train_loss: 0.2120
[48] train_loss: 0.2133
[48] train_loss: 0.2226
1.4482145309448242

Evaluating...Epoch: 48
Prec: 0.8871, Recall: 0.8397, F1: 0.8627

[49] train_loss: 0.1500
[49] train_loss: 0.2062
[49] train_loss: 0.2054
[49] train_loss: 0.2030
[49] train_loss: 0.2267
[49] train_loss: 0.2311
[49] train_loss: 0.2466
[49] train_loss: 0.2421
[49] train_loss: 0.2515
1.4518864154815674

Evaluating...Epoch: 49
Prec: 0.8972, Recall: 0.8492, F1: 0.8725

[50] train_loss: 0.2351
[50] train_loss: 0.2427
[50] train_loss: 0.2581
[50] train_loss: 0.2712
[50] train_loss: 0.2722
[50] train_loss: 0.2546
[50] train_loss: 0.2466
[50] train_loss: 0.2366
[50] train_loss: 0.2469
1.4525885581970215

Evaluating...Epoch: 50
Prec: 0.8805, Recall: 0.8435, F1: 0.8616

[51] train_loss: 0.2749
[51] train_loss: 0.2997
[51] train_loss: 0.3026
[51] train_loss: 0.2696
[51] train_loss: 0.2750
[51] train_loss: 0.2756
[51] train_loss: 0.2654
[51] train_loss: 0.2594
[51] train_loss: 0.2640
1.4591152667999268

Evaluating...Epoch: 51
Prec: 0.9120, Recall: 0.8111, F1: 0.8586

[52] train_loss: 0.3227
[52] train_loss: 0.2967
[52] train_loss: 0.2891
[52] train_loss: 0.2704
[52] train_loss: 0.2653
[52] train_loss: 0.2490
[52] train_loss: 0.2360
[52] train_loss: 0.2384
[52] train_loss: 0.2440
1.4594225883483887

Evaluating...Epoch: 52
Prec: 0.9029, Recall: 0.8340, F1: 0.8671

[53] train_loss: 0.1617
[53] train_loss: 0.2039
[53] train_loss: 0.2086
[53] train_loss: 0.2045
[53] train_loss: 0.2086
[53] train_loss: 0.2288
[53] train_loss: 0.2205
[53] train_loss: 0.2187
[53] train_loss: 0.2244
1.4522042274475098

Evaluating...Epoch: 53
Prec: 0.8967, Recall: 0.8282, F1: 0.8611

[54] train_loss: 0.2941
[54] train_loss: 0.2579
[54] train_loss: 0.2359
[54] train_loss: 0.2136
[54] train_loss: 0.2107
[54] train_loss: 0.2181
[54] train_loss: 0.2100
[54] train_loss: 0.2170
[54] train_loss: 0.2153
1.4641540050506592

Evaluating...Epoch: 54
Prec: 0.8907, Recall: 0.8397, F1: 0.8644

[55] train_loss: 0.2816
[55] train_loss: 0.3236
[55] train_loss: 0.2911
[55] train_loss: 0.2563
[55] train_loss: 0.2537
[55] train_loss: 0.2447
[55] train_loss: 0.2380
[55] train_loss: 0.2578
[55] train_loss: 0.2484
1.4670758247375488

Evaluating...Epoch: 55
Prec: 0.8627, Recall: 0.8397, F1: 0.8511

[56] train_loss: 0.3905
[56] train_loss: 0.2860
[56] train_loss: 0.2671
[56] train_loss: 0.2318
[56] train_loss: 0.2414
[56] train_loss: 0.2306
[56] train_loss: 0.2175
[56] train_loss: 0.2127
[56] train_loss: 0.2247
1.462118148803711

Evaluating...Epoch: 56
Prec: 0.9010, Recall: 0.8511, F1: 0.8754

[57] train_loss: 0.3361
[57] train_loss: 0.2324
[57] train_loss: 0.2060
[57] train_loss: 0.1877
[57] train_loss: 0.1973
[57] train_loss: 0.1876
[57] train_loss: 0.1875
[57] train_loss: 0.1862
[57] train_loss: 0.1987
1.454662799835205

Evaluating...Epoch: 57
Prec: 0.9130, Recall: 0.8206, F1: 0.8643

[58] train_loss: 0.2139
[58] train_loss: 0.1847
[58] train_loss: 0.1930
[58] train_loss: 0.1774
[58] train_loss: 0.1919
[58] train_loss: 0.1829
[58] train_loss: 0.1731
[58] train_loss: 0.1714
[58] train_loss: 0.1741
1.4567904472351074

Evaluating...Epoch: 58
Prec: 0.9182, Recall: 0.8359, F1: 0.8751

[59] train_loss: 0.2916
[59] train_loss: 0.2902
[59] train_loss: 0.2344
[59] train_loss: 0.2055
[59] train_loss: 0.1890
[59] train_loss: 0.1861
[59] train_loss: 0.1859
[59] train_loss: 0.1976
[59] train_loss: 0.1987
1.4601056575775146

Evaluating...Epoch: 59
Prec: 0.8912, Recall: 0.8282, F1: 0.8586

[60] train_loss: 0.1291
[60] train_loss: 0.1624
[60] train_loss: 0.1830
[60] train_loss: 0.1826
[60] train_loss: 0.2024
[60] train_loss: 0.1996
[60] train_loss: 0.1894
[60] train_loss: 0.2035
[60] train_loss: 0.2005
1.4534518718719482

Evaluating...Epoch: 60
Prec: 0.8960, Recall: 0.8225, F1: 0.8577

[61] train_loss: 0.2307
[61] train_loss: 0.2105
[61] train_loss: 0.2086
[61] train_loss: 0.1953
[61] train_loss: 0.2148
[61] train_loss: 0.2242
[61] train_loss: 0.2188
[61] train_loss: 0.2167
[61] train_loss: 0.2230
1.4476027488708496

Evaluating...Epoch: 61
Prec: 0.9156, Recall: 0.8282, F1: 0.8697

[62] train_loss: 0.2025
[62] train_loss: 0.1514
[62] train_loss: 0.1644
[62] train_loss: 0.1509
[62] train_loss: 0.1613
[62] train_loss: 0.1527
[62] train_loss: 0.1491
[62] train_loss: 0.1564
[62] train_loss: 0.1559
1.4544093608856201

Evaluating...Epoch: 62
Prec: 0.9174, Recall: 0.8263, F1: 0.8695

[63] train_loss: 0.1870
[63] train_loss: 0.1723
[63] train_loss: 0.1788
[63] train_loss: 0.1711
[63] train_loss: 0.1571
[63] train_loss: 0.1513
[63] train_loss: 0.1624
[63] train_loss: 0.1618
[63] train_loss: 0.1664
1.4517946243286133

Evaluating...Epoch: 63
Prec: 0.9012, Recall: 0.8359, F1: 0.8673

[64] train_loss: 0.1434
[64] train_loss: 0.1165
[64] train_loss: 0.1140
[64] train_loss: 0.1366
[64] train_loss: 0.1457
[64] train_loss: 0.1455
[64] train_loss: 0.1398
[64] train_loss: 0.1501
[64] train_loss: 0.1548
1.445533275604248

Evaluating...Epoch: 64
Prec: 0.8986, Recall: 0.8454, F1: 0.8712

[65] train_loss: 0.1568
[65] train_loss: 0.1324
[65] train_loss: 0.1865
[65] train_loss: 0.1831
[65] train_loss: 0.1852
[65] train_loss: 0.1902
[65] train_loss: 0.1948
[65] train_loss: 0.1934
[65] train_loss: 0.1855
1.4554805755615234

Evaluating...Epoch: 65
Prec: 0.8851, Recall: 0.8531, F1: 0.8688

[66] train_loss: 0.2173
[66] train_loss: 0.1585
[66] train_loss: 0.1400
[66] train_loss: 0.1164
[66] train_loss: 0.1244
[66] train_loss: 0.1317
[66] train_loss: 0.1290
[66] train_loss: 0.1353
[66] train_loss: 0.1396
1.449354887008667

Evaluating...Epoch: 66
Prec: 0.9026, Recall: 0.8492, F1: 0.8751

[67] train_loss: 0.1639
[67] train_loss: 0.1402
[67] train_loss: 0.1159
[67] train_loss: 0.1072
[67] train_loss: 0.1149
[67] train_loss: 0.1142
[67] train_loss: 0.1138
[67] train_loss: 0.1145
[67] train_loss: 0.1156
1.5274627208709717

Evaluating...Epoch: 67
Prec: 0.8884, Recall: 0.8511, F1: 0.8694

Training ended with 68 epochs.
Final result:
Prec: 0.9047, Recall: 0.8511, F1: 0.8771
loading vocab and embedding matrix from ../data/16res
size of vocab: 3214
shape of loaded embedding matrix: (3214, 300)
Generating mappings
Loading data from ../data/16res with batch size 16...
95 batches created for ../data/16res/train.json
29 batches created for ../data/16res/test.json
Building model...
1542903
[1] train_loss: 10.0270
[1] train_loss: 7.9033
[1] train_loss: 7.2031
[1] train_loss: 6.6246
[1] train_loss: 6.3126
[1] train_loss: 5.9822
[1] train_loss: 5.6748
[1] train_loss: 5.5217
[1] train_loss: 5.3728
1.5973951816558838

Evaluating...Epoch: 1
Prec: 0.7937, Recall: 0.6240, F1: 0.6987
model saved to random1_layers5_16res/best_model.pt
New best model saved!

[2] train_loss: 4.3893
[2] train_loss: 3.9700
[2] train_loss: 3.9970
[2] train_loss: 3.7721
[2] train_loss: 3.7088
[2] train_loss: 3.5901
[2] train_loss: 3.4577
[2] train_loss: 3.4696
[2] train_loss: 3.4323
1.620173454284668

Evaluating...Epoch: 2
Prec: 0.7158, Recall: 0.7977, F1: 0.7545
model saved to random1_layers5_16res/best_model.pt
New best model saved!

[3] train_loss: 3.7739
[3] train_loss: 3.3527
[3] train_loss: 3.3954
[3] train_loss: 3.2106
[3] train_loss: 3.1946
[3] train_loss: 3.0789
[3] train_loss: 2.9729
[3] train_loss: 2.9813
[3] train_loss: 2.9751
1.5749926567077637

Evaluating...Epoch: 3
Prec: 0.7631, Recall: 0.7805, F1: 0.7717
model saved to random1_layers5_16res/best_model.pt
New best model saved!

[4] train_loss: 3.1904
[4] train_loss: 2.8904
[4] train_loss: 2.9923
[4] train_loss: 2.8733
[4] train_loss: 2.8370
[4] train_loss: 2.7328
[4] train_loss: 2.6447
[4] train_loss: 2.6559
[4] train_loss: 2.6679
1.5745038986206055

Evaluating...Epoch: 4
Prec: 0.7620, Recall: 0.8187, F1: 0.7893
model saved to random1_layers5_16res/best_model.pt
New best model saved!

[5] train_loss: 3.0048
[5] train_loss: 2.7471
[5] train_loss: 2.8462
[5] train_loss: 2.6943
[5] train_loss: 2.6447
[5] train_loss: 2.5553
[5] train_loss: 2.4497
[5] train_loss: 2.4697
[5] train_loss: 2.4884
1.5763177871704102

Evaluating...Epoch: 5
Prec: 0.8080, Recall: 0.8111, F1: 0.8095
model saved to random1_layers5_16res/best_model.pt
New best model saved!

[6] train_loss: 2.5392
[6] train_loss: 2.4201
[6] train_loss: 2.5167
[6] train_loss: 2.3765
[6] train_loss: 2.3852
[6] train_loss: 2.3404
[6] train_loss: 2.2552
[6] train_loss: 2.2698
[6] train_loss: 2.2709
1.571195363998413

Evaluating...Epoch: 6
Prec: 0.8086, Recall: 0.7901, F1: 0.7992

[7] train_loss: 2.6238
[7] train_loss: 2.3763
[7] train_loss: 2.4354
[7] train_loss: 2.2534
[7] train_loss: 2.2042
[7] train_loss: 2.1508
[7] train_loss: 2.0730
[7] train_loss: 2.0802
[7] train_loss: 2.0876
1.5847713947296143

Evaluating...Epoch: 7
Prec: 0.8235, Recall: 0.8015, F1: 0.8124
model saved to random1_layers5_16res/best_model.pt
New best model saved!

[8] train_loss: 2.2592
[8] train_loss: 2.0661
[8] train_loss: 2.1053
[8] train_loss: 1.9842
[8] train_loss: 1.9737
[8] train_loss: 1.9077
[8] train_loss: 1.8391
[8] train_loss: 1.8496
[8] train_loss: 1.8535
1.6431777477264404

Evaluating...Epoch: 8
Prec: 0.8356, Recall: 0.8244, F1: 0.8300
model saved to random1_layers5_16res/best_model.pt
New best model saved!

[9] train_loss: 1.9475
[9] train_loss: 1.8778
[9] train_loss: 1.9399
[9] train_loss: 1.7888
[9] train_loss: 1.7683
[9] train_loss: 1.7639
[9] train_loss: 1.7161
[9] train_loss: 1.7397
[9] train_loss: 1.7507
1.5690369606018066

Evaluating...Epoch: 9
Prec: 0.8199, Recall: 0.8168, F1: 0.8184

[10] train_loss: 1.9277
[10] train_loss: 1.8191
[10] train_loss: 1.8871
[10] train_loss: 1.7385
[10] train_loss: 1.7019
[10] train_loss: 1.6603
[10] train_loss: 1.5921
[10] train_loss: 1.6038
[10] train_loss: 1.6275
1.5815258026123047

Evaluating...Epoch: 10
Prec: 0.8779, Recall: 0.7958, F1: 0.8348
model saved to random1_layers5_16res/best_model.pt
New best model saved!

[11] train_loss: 1.5889
[11] train_loss: 1.4695
[11] train_loss: 1.6583
[11] train_loss: 1.5370
[11] train_loss: 1.5601
[11] train_loss: 1.5372
[11] train_loss: 1.4936
[11] train_loss: 1.4906
[11] train_loss: 1.4956
1.5614025592803955

Evaluating...Epoch: 11
Prec: 0.8682, Recall: 0.7920, F1: 0.8283

[12] train_loss: 1.5357
[12] train_loss: 1.4612
[12] train_loss: 1.5188
[12] train_loss: 1.4060
[12] train_loss: 1.4351
[12] train_loss: 1.4255
[12] train_loss: 1.3632
[12] train_loss: 1.3968
[12] train_loss: 1.4204
1.57778000831604

Evaluating...Epoch: 12
Prec: 0.9083, Recall: 0.7557, F1: 0.8250

[13] train_loss: 1.6013
[13] train_loss: 1.4894
[13] train_loss: 1.5215
[13] train_loss: 1.4124
[13] train_loss: 1.4136
[13] train_loss: 1.3668
[13] train_loss: 1.3385
[13] train_loss: 1.3775
[13] train_loss: 1.3830
1.5727567672729492

Evaluating...Epoch: 13
Prec: 0.9159, Recall: 0.7691, F1: 0.8361
model saved to random1_layers5_16res/best_model.pt
New best model saved!

[14] train_loss: 1.5717
[14] train_loss: 1.3786
[14] train_loss: 1.4081
[14] train_loss: 1.3409
[14] train_loss: 1.3143
[14] train_loss: 1.2726
[14] train_loss: 1.2422
[14] train_loss: 1.2879
[14] train_loss: 1.3135
1.631115198135376

Evaluating...Epoch: 14
Prec: 0.9075, Recall: 0.7863, F1: 0.8425
model saved to random1_layers5_16res/best_model.pt
New best model saved!

[15] train_loss: 1.2227
[15] train_loss: 1.2481
[15] train_loss: 1.2123
[15] train_loss: 1.1066
[15] train_loss: 1.1568
[15] train_loss: 1.1304
[15] train_loss: 1.1004
[15] train_loss: 1.1139
[15] train_loss: 1.1457
1.5693907737731934

Evaluating...Epoch: 15
Prec: 0.8976, Recall: 0.7863, F1: 0.8383

[16] train_loss: 1.2656
[16] train_loss: 1.1433
[16] train_loss: 1.0981
[16] train_loss: 1.0135
[16] train_loss: 1.0524
[16] train_loss: 1.0279
[16] train_loss: 1.0231
[16] train_loss: 1.0378
[16] train_loss: 1.0680
1.5602974891662598

Evaluating...Epoch: 16
Prec: 0.8932, Recall: 0.8302, F1: 0.8605
model saved to random1_layers5_16res/best_model.pt
New best model saved!

[17] train_loss: 1.2745
[17] train_loss: 1.1405
[17] train_loss: 1.0943
[17] train_loss: 0.9686
[17] train_loss: 0.9835
[17] train_loss: 0.9858
[17] train_loss: 0.9592
[17] train_loss: 0.9610
[17] train_loss: 0.9809
1.5658752918243408

Evaluating...Epoch: 17
Prec: 0.8931, Recall: 0.8454, F1: 0.8686
model saved to random1_layers5_16res/best_model.pt
New best model saved!

[18] train_loss: 1.0959
[18] train_loss: 1.0779
[18] train_loss: 1.0967
[18] train_loss: 0.9738
[18] train_loss: 0.9749
[18] train_loss: 0.9614
[18] train_loss: 0.9260
[18] train_loss: 0.9382
[18] train_loss: 0.9787
1.5770294666290283

Evaluating...Epoch: 18
Prec: 0.8852, Recall: 0.8244, F1: 0.8538

[19] train_loss: 0.9690
[19] train_loss: 0.9922
[19] train_loss: 0.9987
[19] train_loss: 0.8870
[19] train_loss: 0.9161
[19] train_loss: 0.8971
[19] train_loss: 0.8683
[19] train_loss: 0.8837
[19] train_loss: 0.8951
1.5656085014343262

Evaluating...Epoch: 19
Prec: 0.8989, Recall: 0.8149, F1: 0.8549

[20] train_loss: 0.9680
[20] train_loss: 0.9043
[20] train_loss: 0.9650
[20] train_loss: 0.8916
[20] train_loss: 0.9010
[20] train_loss: 0.8726
[20] train_loss: 0.8622
[20] train_loss: 0.8786
[20] train_loss: 0.9040
1.5578370094299316

Evaluating...Epoch: 20
Prec: 0.9031, Recall: 0.8359, F1: 0.8682

[21] train_loss: 0.8928
[21] train_loss: 0.8339
[21] train_loss: 0.8360
[21] train_loss: 0.8270
[21] train_loss: 0.8572
[21] train_loss: 0.8068
[21] train_loss: 0.7732
[21] train_loss: 0.7672
[21] train_loss: 0.7677
1.5667588710784912

Evaluating...Epoch: 21
Prec: 0.8848, Recall: 0.8206, F1: 0.8515

[22] train_loss: 0.8167
[22] train_loss: 0.7182
[22] train_loss: 0.7677
[22] train_loss: 0.7398
[22] train_loss: 0.7526
[22] train_loss: 0.7392
[22] train_loss: 0.7353
[22] train_loss: 0.7482
[22] train_loss: 0.7525
1.5648696422576904

Evaluating...Epoch: 22
Prec: 0.8776, Recall: 0.8206, F1: 0.8481

[23] train_loss: 0.8292
[23] train_loss: 0.7649
[23] train_loss: 0.7577
[23] train_loss: 0.6867
[23] train_loss: 0.6978
[23] train_loss: 0.7018
[23] train_loss: 0.6831
[23] train_loss: 0.6993
[23] train_loss: 0.7223
1.5725815296173096

Evaluating...Epoch: 23
Prec: 0.8780, Recall: 0.8378, F1: 0.8574

[24] train_loss: 0.7835
[24] train_loss: 0.7353
[24] train_loss: 0.7677
[24] train_loss: 0.7002
[24] train_loss: 0.7346
[24] train_loss: 0.7168
[24] train_loss: 0.6914
[24] train_loss: 0.6970
[24] train_loss: 0.7025
1.5732052326202393

Evaluating...Epoch: 24
Prec: 0.8497, Recall: 0.8416, F1: 0.8456

[25] train_loss: 0.7992
[25] train_loss: 0.7399
[25] train_loss: 0.6758
[25] train_loss: 0.6188
[25] train_loss: 0.6781
[25] train_loss: 0.6616
[25] train_loss: 0.6291
[25] train_loss: 0.6249
[25] train_loss: 0.6358
1.624636173248291

Evaluating...Epoch: 25
Prec: 0.8798, Recall: 0.8244, F1: 0.8512

[26] train_loss: 0.6800
[26] train_loss: 0.6257
[26] train_loss: 0.6187
[26] train_loss: 0.5833
[26] train_loss: 0.5674
[26] train_loss: 0.5753
[26] train_loss: 0.5612
[26] train_loss: 0.5741
[26] train_loss: 0.5891
1.567474126815796

Evaluating...Epoch: 26
Prec: 0.8953, Recall: 0.8321, F1: 0.8625

[27] train_loss: 0.7696
[27] train_loss: 0.6674
[27] train_loss: 0.6531
[27] train_loss: 0.6310
[27] train_loss: 0.6370
[27] train_loss: 0.6100
[27] train_loss: 0.5979
[27] train_loss: 0.5906
[27] train_loss: 0.6069
1.5691392421722412

Evaluating...Epoch: 27
Prec: 0.8490, Recall: 0.8263, F1: 0.8375

[28] train_loss: 0.6326
[28] train_loss: 0.6714
[28] train_loss: 0.6537
[28] train_loss: 0.5893
[28] train_loss: 0.5912
[28] train_loss: 0.5566
[28] train_loss: 0.5417
[28] train_loss: 0.5399
[28] train_loss: 0.5731
1.5678751468658447

Evaluating...Epoch: 28
Prec: 0.8755, Recall: 0.8321, F1: 0.8532

[29] train_loss: 0.7585
[29] train_loss: 0.6192
[29] train_loss: 0.6266
[29] train_loss: 0.5781
[29] train_loss: 0.6020
[29] train_loss: 0.5718
[29] train_loss: 0.5548
[29] train_loss: 0.5520
[29] train_loss: 0.5610
1.5638158321380615

Evaluating...Epoch: 29
Prec: 0.8964, Recall: 0.8588, F1: 0.8772
model saved to random1_layers5_16res/best_model.pt
New best model saved!

[30] train_loss: 0.5730
[30] train_loss: 0.5221
[30] train_loss: 0.5674
[30] train_loss: 0.5264
[30] train_loss: 0.5437
[30] train_loss: 0.5271
[30] train_loss: 0.5096
[30] train_loss: 0.5063
[30] train_loss: 0.5206
1.56056547164917

Evaluating...Epoch: 30
Prec: 0.8848, Recall: 0.8645, F1: 0.8745

[31] train_loss: 0.4817
[31] train_loss: 0.4844
[31] train_loss: 0.4960
[31] train_loss: 0.4971
[31] train_loss: 0.5320
[31] train_loss: 0.5330
[31] train_loss: 0.4974
[31] train_loss: 0.5120
[31] train_loss: 0.5141
1.6082429885864258

Evaluating...Epoch: 31
Prec: 0.8911, Recall: 0.8435, F1: 0.8667

[32] train_loss: 0.4373
[32] train_loss: 0.4910
[32] train_loss: 0.5026
[32] train_loss: 0.4754
[32] train_loss: 0.4793
[32] train_loss: 0.4726
[32] train_loss: 0.4475
[32] train_loss: 0.4698
[32] train_loss: 0.4724
1.5723378658294678

Evaluating...Epoch: 32
Prec: 0.8809, Recall: 0.8187, F1: 0.8487

[33] train_loss: 0.4756
[33] train_loss: 0.4450
[33] train_loss: 0.4577
[33] train_loss: 0.4179
[33] train_loss: 0.4485
[33] train_loss: 0.4390
[33] train_loss: 0.4294
[33] train_loss: 0.4353
[33] train_loss: 0.4469
1.573819637298584

Evaluating...Epoch: 33
Prec: 0.8835, Recall: 0.8397, F1: 0.8611

[34] train_loss: 0.5314
[34] train_loss: 0.4349
[34] train_loss: 0.4358
[34] train_loss: 0.3972
[34] train_loss: 0.4357
[34] train_loss: 0.4180
[34] train_loss: 0.4116
[34] train_loss: 0.4135
[34] train_loss: 0.4147
1.5691866874694824

Evaluating...Epoch: 34
Prec: 0.8757, Recall: 0.8473, F1: 0.8613

[35] train_loss: 0.4539
[35] train_loss: 0.3461
[35] train_loss: 0.4105
[35] train_loss: 0.3761
[35] train_loss: 0.3795
[35] train_loss: 0.3893
[35] train_loss: 0.3647
[35] train_loss: 0.3653
[35] train_loss: 0.3761
1.5712413787841797

Evaluating...Epoch: 35
Prec: 0.8687, Recall: 0.8588, F1: 0.8637

[36] train_loss: 0.4112
[36] train_loss: 0.4048
[36] train_loss: 0.3959
[36] train_loss: 0.3750
[36] train_loss: 0.3881
[36] train_loss: 0.3798
[36] train_loss: 0.3658
[36] train_loss: 0.3644
[36] train_loss: 0.3617
1.5744102001190186

Evaluating...Epoch: 36
Prec: 0.9045, Recall: 0.8492, F1: 0.8760

[37] train_loss: 0.3270
[37] train_loss: 0.3255
[37] train_loss: 0.3483
[37] train_loss: 0.3280
[37] train_loss: 0.3329
[37] train_loss: 0.3367
[37] train_loss: 0.3281
[37] train_loss: 0.3308
[37] train_loss: 0.3358
1.6359279155731201

Evaluating...Epoch: 37
Prec: 0.8835, Recall: 0.8397, F1: 0.8611

[38] train_loss: 0.3196
[38] train_loss: 0.3063
[38] train_loss: 0.3489
[38] train_loss: 0.3143
[38] train_loss: 0.3453
[38] train_loss: 0.3606
[38] train_loss: 0.3423
[38] train_loss: 0.3509
[38] train_loss: 0.3540
1.5711214542388916

Evaluating...Epoch: 38
Prec: 0.8824, Recall: 0.8302, F1: 0.8555

[39] train_loss: 0.3622
[39] train_loss: 0.3716
[39] train_loss: 0.3889
[39] train_loss: 0.3783
[39] train_loss: 0.3764
[39] train_loss: 0.3634
[39] train_loss: 0.3505
[39] train_loss: 0.3534
[39] train_loss: 0.3554
1.5700709819793701

Evaluating...Epoch: 39
Prec: 0.9021, Recall: 0.8263, F1: 0.8625

[40] train_loss: 0.3480
[40] train_loss: 0.3338
[40] train_loss: 0.3302
[40] train_loss: 0.2899
[40] train_loss: 0.3402
[40] train_loss: 0.3600
[40] train_loss: 0.3677
[40] train_loss: 0.3671
[40] train_loss: 0.3641
1.5653960704803467

Evaluating...Epoch: 40
Prec: 0.8945, Recall: 0.8416, F1: 0.8673

[41] train_loss: 0.3643
[41] train_loss: 0.3002
[41] train_loss: 0.3069
[41] train_loss: 0.2907
[41] train_loss: 0.3057
[41] train_loss: 0.3048
[41] train_loss: 0.3082
[41] train_loss: 0.3207
[41] train_loss: 0.3198
1.5685460567474365

Evaluating...Epoch: 41
Prec: 0.8748, Recall: 0.8531, F1: 0.8638

[42] train_loss: 0.3151
[42] train_loss: 0.3058
[42] train_loss: 0.3333
[42] train_loss: 0.2859
[42] train_loss: 0.2921
[42] train_loss: 0.2929
[42] train_loss: 0.2961
[42] train_loss: 0.2873
[42] train_loss: 0.2965
1.5647478103637695

Evaluating...Epoch: 42
Prec: 0.8695, Recall: 0.8645, F1: 0.8670

[43] train_loss: 0.3024
[43] train_loss: 0.2702
[43] train_loss: 0.3185
[43] train_loss: 0.3334
[43] train_loss: 0.3243
[43] train_loss: 0.3203
[43] train_loss: 0.3084
[43] train_loss: 0.3101
[43] train_loss: 0.3245
1.6319079399108887

Evaluating...Epoch: 43
Prec: 0.9018, Recall: 0.8588, F1: 0.8798
model saved to random1_layers5_16res/best_model.pt
New best model saved!

[44] train_loss: 0.3463
[44] train_loss: 0.2916
[44] train_loss: 0.3848
[44] train_loss: 0.3280
[44] train_loss: 0.3434
[44] train_loss: 0.3302
[44] train_loss: 0.3160
[44] train_loss: 0.3036
[44] train_loss: 0.3025
1.5652880668640137

Evaluating...Epoch: 44
Prec: 0.9089, Recall: 0.8378, F1: 0.8719

[45] train_loss: 0.2233
[45] train_loss: 0.3029
[45] train_loss: 0.2944
[45] train_loss: 0.2654
[45] train_loss: 0.2608
[45] train_loss: 0.2514
[45] train_loss: 0.2357
[45] train_loss: 0.2462
[45] train_loss: 0.2460
1.5713725090026855

Evaluating...Epoch: 45
Prec: 0.8814, Recall: 0.8511, F1: 0.8660

[46] train_loss: 0.2139
[46] train_loss: 0.2327
[46] train_loss: 0.2596
[46] train_loss: 0.2529
[46] train_loss: 0.2502
[46] train_loss: 0.2486
[46] train_loss: 0.2523
[46] train_loss: 0.2569
[46] train_loss: 0.2723
1.570829153060913

Evaluating...Epoch: 46
Prec: 0.9128, Recall: 0.8187, F1: 0.8632

[47] train_loss: 0.3671
[47] train_loss: 0.2931
[47] train_loss: 0.2560
[47] train_loss: 0.2501
[47] train_loss: 0.2843
[47] train_loss: 0.2938
[47] train_loss: 0.2894
[47] train_loss: 0.2893
[47] train_loss: 0.2902
1.5726852416992188

Evaluating...Epoch: 47
Prec: 0.8986, Recall: 0.8454, F1: 0.8712

[48] train_loss: 0.1824
[48] train_loss: 0.2230
[48] train_loss: 0.2184
[48] train_loss: 0.2141
[48] train_loss: 0.2056
[48] train_loss: 0.2076
[48] train_loss: 0.2063
[48] train_loss: 0.2105
[48] train_loss: 0.2283
1.5711913108825684

Evaluating...Epoch: 48
Prec: 0.8835, Recall: 0.8397, F1: 0.8611

[49] train_loss: 0.2703
[49] train_loss: 0.2486
[49] train_loss: 0.2379
[49] train_loss: 0.2438
[49] train_loss: 0.2448
[49] train_loss: 0.2380
[49] train_loss: 0.2247
[49] train_loss: 0.2337
[49] train_loss: 0.2355
1.6102566719055176

Evaluating...Epoch: 49
Prec: 0.9154, Recall: 0.8263, F1: 0.8686

[50] train_loss: 0.2249
[50] train_loss: 0.2335
[50] train_loss: 0.2259
[50] train_loss: 0.2164
[50] train_loss: 0.2296
[50] train_loss: 0.2166
[50] train_loss: 0.2051
[50] train_loss: 0.2162
[50] train_loss: 0.2112
1.5452189445495605

Evaluating...Epoch: 50
Prec: 0.9013, Recall: 0.8187, F1: 0.8580

[51] train_loss: 0.3270
[51] train_loss: 0.2771
[51] train_loss: 0.2544
[51] train_loss: 0.2311
[51] train_loss: 0.2471
[51] train_loss: 0.2602
[51] train_loss: 0.2618
[51] train_loss: 0.2598
[51] train_loss: 0.2703
1.5568788051605225

Evaluating...Epoch: 51
Prec: 0.8787, Recall: 0.8435, F1: 0.8608

[52] train_loss: 0.2394
[52] train_loss: 0.2025
[52] train_loss: 0.2358
[52] train_loss: 0.2226
[52] train_loss: 0.2203
[52] train_loss: 0.2330
[52] train_loss: 0.2388
[52] train_loss: 0.2336
[52] train_loss: 0.2437
1.5653002262115479

Evaluating...Epoch: 52
Prec: 0.9004, Recall: 0.8282, F1: 0.8628

[53] train_loss: 0.2116
[53] train_loss: 0.2331
[53] train_loss: 0.2229
[53] train_loss: 0.1997
[53] train_loss: 0.1926
[53] train_loss: 0.1898
[53] train_loss: 0.2019
[53] train_loss: 0.2096
[53] train_loss: 0.2448
1.5788187980651855

Evaluating...Epoch: 53
Prec: 0.9163, Recall: 0.8359, F1: 0.8743

[54] train_loss: 0.2966
[54] train_loss: 0.2409
[54] train_loss: 0.2630
[54] train_loss: 0.2550
[54] train_loss: 0.2688
[54] train_loss: 0.2645
[54] train_loss: 0.2500
[54] train_loss: 0.2516
[54] train_loss: 0.2653
1.575166940689087

Evaluating...Epoch: 54
Prec: 0.9135, Recall: 0.8263, F1: 0.8677

[55] train_loss: 0.2449
[55] train_loss: 0.2144
[55] train_loss: 0.2253
[55] train_loss: 0.2102
[55] train_loss: 0.1958
[55] train_loss: 0.1933
[55] train_loss: 0.1930
[55] train_loss: 0.1911
[55] train_loss: 0.1949
1.6391546726226807

Evaluating...Epoch: 55
Prec: 0.8977, Recall: 0.8206, F1: 0.8574

[56] train_loss: 0.2685
[56] train_loss: 0.2284
[56] train_loss: 0.2167
[56] train_loss: 0.2123
[56] train_loss: 0.2291
[56] train_loss: 0.2299
[56] train_loss: 0.2239
[56] train_loss: 0.2157
[56] train_loss: 0.2145
1.5528132915496826

Evaluating...Epoch: 56
Prec: 0.9099, Recall: 0.8282, F1: 0.8671

[57] train_loss: 0.1744
[57] train_loss: 0.1492
[57] train_loss: 0.1884
[57] train_loss: 0.1805
[57] train_loss: 0.1921
[57] train_loss: 0.1997
[57] train_loss: 0.1877
[57] train_loss: 0.1873
[57] train_loss: 0.1856
1.565141201019287

Evaluating...Epoch: 57
Prec: 0.9165, Recall: 0.8378, F1: 0.8754

[58] train_loss: 0.4856
[58] train_loss: 0.4425
[58] train_loss: 0.3462
[58] train_loss: 0.2931
[58] train_loss: 0.2808
[58] train_loss: 0.2640
[58] train_loss: 0.2533
[58] train_loss: 0.2633
[58] train_loss: 0.2632
1.5726792812347412

Evaluating...Epoch: 58
Prec: 0.9020, Recall: 0.8435, F1: 0.8718

[59] train_loss: 0.2882
[59] train_loss: 0.2170
[59] train_loss: 0.1906
[59] train_loss: 0.1844
[59] train_loss: 0.1949
[59] train_loss: 0.1817
[59] train_loss: 0.1781
[59] train_loss: 0.1792
[59] train_loss: 0.1747
1.5631537437438965

Evaluating...Epoch: 59
Prec: 0.9287, Recall: 0.8206, F1: 0.8713

[60] train_loss: 0.2011
[60] train_loss: 0.1895
[60] train_loss: 0.1764
[60] train_loss: 0.1624
[60] train_loss: 0.1587
[60] train_loss: 0.1570
[60] train_loss: 0.1500
[60] train_loss: 0.1444
[60] train_loss: 0.1585
1.5670735836029053

Evaluating...Epoch: 60
Prec: 0.9059, Recall: 0.8454, F1: 0.8746

[61] train_loss: 0.1705
[61] train_loss: 0.2023
[61] train_loss: 0.1907
[61] train_loss: 0.1787
[61] train_loss: 0.1858
[61] train_loss: 0.1757
[61] train_loss: 0.1783
[61] train_loss: 0.1819
[61] train_loss: 0.1774
1.6317811012268066

Evaluating...Epoch: 61
Prec: 0.9174, Recall: 0.8263, F1: 0.8695

[62] train_loss: 0.1593
[62] train_loss: 0.1723
[62] train_loss: 0.1656
[62] train_loss: 0.1410
[62] train_loss: 0.1460
[62] train_loss: 0.1507
[62] train_loss: 0.1474
[62] train_loss: 0.1569
[62] train_loss: 0.1496
1.574509859085083

Evaluating...Epoch: 62
Prec: 0.9197, Recall: 0.8302, F1: 0.8726

[63] train_loss: 0.1455
[63] train_loss: 0.1466
[63] train_loss: 0.1598
[63] train_loss: 0.1594
[63] train_loss: 0.1709
[63] train_loss: 0.1931
[63] train_loss: 0.1777
[63] train_loss: 0.1777
[63] train_loss: 0.1840
1.5771899223327637

Evaluating...Epoch: 63
Prec: 0.9151, Recall: 0.8225, F1: 0.8663

Training ended with 64 epochs.
Final result:
Prec: 0.9018, Recall: 0.8588, F1: 0.8798
python train.py --dataset 14lap --gcn_layers 0 --save_dir random1_layers0_14lap
python train.py --dataset 14lap --gcn_layers 1 --save_dir random1_layers1_14lap
python train.py --dataset 14lap --gcn_layers 2 --save_dir random1_layers2_14lap
python train.py --dataset 14lap --gcn_layers 3 --save_dir random1_layers3_14lap
python train.py --dataset 14lap --gcn_layers 4 --save_dir random1_layers4_14lap
python train.py --dataset 14lap --gcn_layers 5 --save_dir random1_layers5_14lap
python train.py --dataset 14res --gcn_layers 0 --save_dir random1_layers0_14res
python train.py --dataset 14res --gcn_layers 1 --save_dir random1_layers1_14res
python train.py --dataset 14res --gcn_layers 2 --save_dir random1_layers2_14res
python train.py --dataset 14res --gcn_layers 3 --save_dir random1_layers3_14res
python train.py --dataset 14res --gcn_layers 4 --save_dir random1_layers4_14res
python train.py --dataset 14res --gcn_layers 5 --save_dir random1_layers5_14res
python train.py --dataset 15res --gcn_layers 0 --save_dir random1_layers0_15res
python train.py --dataset 15res --gcn_layers 1 --save_dir random1_layers1_15res
python train.py --dataset 15res --gcn_layers 2 --save_dir random1_layers2_15res
python train.py --dataset 15res --gcn_layers 3 --save_dir random1_layers3_15res
python train.py --dataset 15res --gcn_layers 4 --save_dir random1_layers4_15res
python train.py --dataset 15res --gcn_layers 5 --save_dir random1_layers5_15res
python train.py --dataset 16res --gcn_layers 0 --save_dir random1_layers0_16res
python train.py --dataset 16res --gcn_layers 1 --save_dir random1_layers1_16res
python train.py --dataset 16res --gcn_layers 2 --save_dir random1_layers2_16res
python train.py --dataset 16res --gcn_layers 3 --save_dir random1_layers3_16res
python train.py --dataset 16res --gcn_layers 4 --save_dir random1_layers4_16res
python train.py --dataset 16res --gcn_layers 5 --save_dir random1_layers5_16res
